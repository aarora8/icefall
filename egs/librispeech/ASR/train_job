Saved current collection of modules to: "default"

SGE_HGR_gpu=0
CUDA_VISIBLE_DEVICES=0
Tue Aug 24 17:28:37 2021       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 465.19.01    Driver Version: 465.19.01    CUDA Version: 11.3     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  NVIDIA Tesla V1...  On   | 00000000:1A:00.0 Off |                    0 |
| N/A   27C    P0    24W / 200W |      0MiB / 32510MiB |      0%   E. Process |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   1  NVIDIA Tesla V1...  On   | 00000000:1B:00.0 Off |                    0 |
| N/A   27C    P0    24W / 200W |      0MiB / 32510MiB |      0%   E. Process |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   2  NVIDIA Tesla V1...  On   | 00000000:1C:00.0 Off |                    0 |
| N/A   27C    P0    25W / 200W |      0MiB / 32510MiB |      0%   E. Process |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   3  NVIDIA Tesla V1...  On   | 00000000:3D:00.0 Off |                    0 |
| N/A   28C    P0    24W / 200W |      0MiB / 32510MiB |      0%   E. Process |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   4  NVIDIA Tesla V1...  On   | 00000000:3E:00.0 Off |                    0 |
| N/A   30C    P0    35W / 200W |   1741MiB / 32510MiB |      0%   E. Process |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   5  NVIDIA Tesla V1...  On   | 00000000:8B:00.0 Off |                    0 |
| N/A   29C    P0    36W / 200W |   1789MiB / 32510MiB |      0%   E. Process |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   6  NVIDIA Tesla V1...  On   | 00000000:8C:00.0 Off |                    0 |
| N/A   28C    P0    35W / 200W |   1837MiB / 32510MiB |      0%   E. Process |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   7  NVIDIA Tesla V1...  On   | 00000000:B4:00.0 Off |                    0 |
| N/A   28C    P0    36W / 200W |   1789MiB / 32510MiB |      0%   E. Process |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   8  NVIDIA Tesla V1...  On   | 00000000:B5:00.0 Off |                    0 |
| N/A   27C    P0    24W / 200W |      0MiB / 32510MiB |      0%   E. Process |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   9  NVIDIA Tesla V1...  On   | 00000000:B6:00.0 Off |                    0 |
| N/A   50C    P0   207W / 200W |  13913MiB / 32510MiB |     79%   E. Process |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|    4   N/A  N/A    429028      C   ...a3/envs/visrep/bin/python     1737MiB |
|    5   N/A  N/A    429029      C   ...a3/envs/visrep/bin/python     1785MiB |
|    6   N/A  N/A    429030      C   ...a3/envs/visrep/bin/python     1833MiB |
|    7   N/A  N/A    429031      C   ...a3/envs/visrep/bin/python     1785MiB |
|    9   N/A  N/A    437053      C   python                          13909MiB |
+-----------------------------------------------------------------------------+
/cm/local/apps/uge/var/spool/r7n04/job_scripts/9492449: Running on r7n04
/cm/local/apps/uge/var/spool/r7n04/job_scripts/9492449: Started at Tue Aug 24 17:28:38 EDT 2021
/cm/local/apps/uge/var/spool/r7n04/job_scripts/9492449: Running the job on GPU(s) 0
2021-08-24 17:28:40,148 INFO [train.py:515] Training started
2021-08-24 17:28:40,148 INFO [train.py:516] {'exp_dir': PosixPath('tdnn_lstm_ctc/exp'), 'lang_dir': PosixPath('data/lang_phone'), 'lr': 0.001, 'feature_dim': 80, 'weight_decay': 0.0005, 'subsampling_factor': 3, 'best_train_loss': inf, 'best_valid_loss': inf, 'best_train_epoch': -1, 'best_valid_epoch': -1, 'batch_idx_train': 0, 'log_interval': 10, 'reset_interval': 200, 'valid_interval': 1000, 'beam_size': 10, 'reduction': 'sum', 'use_double_scores': True, 'world_size': 1, 'master_port': 12354, 'tensorboard': True, 'num_epochs': 20, 'start_epoch': 0, 'full_libri': True, 'feature_dir': PosixPath('data/fbank'), 'max_duration': 500.0, 'bucketing_sampler': False, 'num_buckets': 30, 'concatenate_cuts': False, 'duration_factor': 1.0, 'gap': 1.0, 'on_the_fly_feats': False, 'shuffle': True, 'return_cuts': True, 'num_workers': 2}
2021-08-24 17:28:40,376 INFO [lexicon.py:113] Loading pre-compiled data/lang_phone/Linv.pt
2021-08-24 17:28:43,843 INFO [asr_datamodule.py:158] About to get train cuts
2021-08-24 17:28:43,844 INFO [asr_datamodule.py:319] About to get train cuts
2021-08-24 17:29:37,303 INFO [asr_datamodule.py:161] About to get Musan cuts
2021-08-24 17:29:38,225 INFO [asr_datamodule.py:164] About to create train dataset
2021-08-24 17:29:38,225 INFO [asr_datamodule.py:226] Using SingleCutSampler.
2021-08-24 17:29:38,462 INFO [asr_datamodule.py:232] About to create train dataloader
2021-08-24 17:29:38,462 INFO [asr_datamodule.py:245] About to get dev cuts
2021-08-24 17:29:38,462 INFO [asr_datamodule.py:337] About to get dev cuts
2021-08-24 17:29:45,287 INFO [asr_datamodule.py:256] About to create dev dataset
2021-08-24 17:29:45,289 INFO [asr_datamodule.py:275] About to create dev dataloader
2021-08-24 17:29:54,387 INFO [train.py:450] Epoch 0, batch 0, batch avg loss 3.3120, total avg loss: 3.3120, batch size: 40
2021-08-24 17:30:13,875 INFO [train.py:450] Epoch 0, batch 10, batch avg loss 1.2856, total avg loss: 1.7632, batch size: 42
2021-08-24 17:30:30,753 INFO [train.py:450] Epoch 0, batch 20, batch avg loss 1.0774, total avg loss: 1.4729, batch size: 39
2021-08-24 17:30:47,982 INFO [train.py:450] Epoch 0, batch 30, batch avg loss 1.2948, total avg loss: 1.3630, batch size: 42
2021-08-24 17:31:03,286 INFO [train.py:450] Epoch 0, batch 40, batch avg loss 1.0899, total avg loss: 1.2964, batch size: 41
2021-08-24 17:31:14,339 INFO [train.py:450] Epoch 0, batch 50, batch avg loss 1.0611, total avg loss: 1.2459, batch size: 40
2021-08-24 17:31:24,360 INFO [train.py:450] Epoch 0, batch 60, batch avg loss 1.0433, total avg loss: 1.2117, batch size: 39
2021-08-24 17:31:35,214 INFO [train.py:450] Epoch 0, batch 70, batch avg loss 1.0432, total avg loss: 1.1874, batch size: 46
2021-08-24 17:31:43,874 INFO [train.py:450] Epoch 0, batch 80, batch avg loss 1.0535, total avg loss: 1.1669, batch size: 34
2021-08-24 17:31:49,979 INFO [train.py:450] Epoch 0, batch 90, batch avg loss 0.9668, total avg loss: 1.1449, batch size: 38
2021-08-24 17:31:56,394 INFO [train.py:450] Epoch 0, batch 100, batch avg loss 1.0352, total avg loss: 1.1314, batch size: 42
2021-08-24 17:32:03,111 INFO [train.py:450] Epoch 0, batch 110, batch avg loss 0.9710, total avg loss: 1.1200, batch size: 38
2021-08-24 17:32:09,112 INFO [train.py:450] Epoch 0, batch 120, batch avg loss 0.9032, total avg loss: 1.1051, batch size: 40
2021-08-24 17:32:14,830 INFO [train.py:450] Epoch 0, batch 130, batch avg loss 0.8522, total avg loss: 1.0904, batch size: 41
2021-08-24 17:32:20,633 INFO [train.py:450] Epoch 0, batch 140, batch avg loss 0.8975, total avg loss: 1.0744, batch size: 42
2021-08-24 17:32:26,712 INFO [train.py:450] Epoch 0, batch 150, batch avg loss 0.8478, total avg loss: 1.0596, batch size: 41
2021-08-24 17:32:32,506 INFO [train.py:450] Epoch 0, batch 160, batch avg loss 0.8813, total avg loss: 1.0465, batch size: 41
2021-08-24 17:32:47,484 INFO [train.py:450] Epoch 0, batch 170, batch avg loss 0.8546, total avg loss: 1.0351, batch size: 40
2021-08-24 17:33:01,901 INFO [train.py:450] Epoch 0, batch 180, batch avg loss 0.7667, total avg loss: 1.0224, batch size: 39
2021-08-24 17:33:15,181 INFO [train.py:450] Epoch 0, batch 190, batch avg loss 0.8004, total avg loss: 1.0116, batch size: 39
2021-08-24 17:33:27,912 INFO [train.py:450] Epoch 0, batch 200, batch avg loss 0.8219, total avg loss: 1.0029, batch size: 41
2021-08-24 17:33:40,574 INFO [train.py:450] Epoch 0, batch 210, batch avg loss 0.7767, total avg loss: 0.7904, batch size: 43
2021-08-24 17:33:53,806 INFO [train.py:450] Epoch 0, batch 220, batch avg loss 0.8023, total avg loss: 0.7833, batch size: 43
2021-08-24 17:34:06,418 INFO [train.py:450] Epoch 0, batch 230, batch avg loss 0.8049, total avg loss: 0.7839, batch size: 40
2021-08-24 17:34:18,629 INFO [train.py:450] Epoch 0, batch 240, batch avg loss 0.7663, total avg loss: 0.7781, batch size: 39
2021-08-24 17:34:30,614 INFO [train.py:450] Epoch 0, batch 250, batch avg loss 0.8019, total avg loss: 0.7728, batch size: 43
2021-08-24 17:34:42,221 INFO [train.py:450] Epoch 0, batch 260, batch avg loss 0.7767, total avg loss: 0.7727, batch size: 40
2021-08-24 17:34:53,445 INFO [train.py:450] Epoch 0, batch 270, batch avg loss 0.7437, total avg loss: 0.7710, batch size: 40
2021-08-24 17:35:05,062 INFO [train.py:450] Epoch 0, batch 280, batch avg loss 0.7400, total avg loss: 0.7709, batch size: 39
2021-08-24 17:35:16,587 INFO [train.py:450] Epoch 0, batch 290, batch avg loss 0.7063, total avg loss: 0.7683, batch size: 41
2021-08-24 17:35:27,929 INFO [train.py:450] Epoch 0, batch 300, batch avg loss 0.7613, total avg loss: 0.7644, batch size: 41
2021-08-24 17:35:39,823 INFO [train.py:450] Epoch 0, batch 310, batch avg loss 0.7191, total avg loss: 0.7623, batch size: 44
2021-08-24 17:35:51,588 INFO [train.py:450] Epoch 0, batch 320, batch avg loss 0.8156, total avg loss: 0.7595, batch size: 43
2021-08-24 17:36:03,252 INFO [train.py:450] Epoch 0, batch 330, batch avg loss 0.6701, total avg loss: 0.7563, batch size: 39
2021-08-24 17:36:14,513 INFO [train.py:450] Epoch 0, batch 340, batch avg loss 0.6928, total avg loss: 0.7532, batch size: 39
2021-08-24 17:36:25,212 INFO [train.py:450] Epoch 0, batch 350, batch avg loss 0.6681, total avg loss: 0.7501, batch size: 37
2021-08-24 17:36:36,026 INFO [train.py:450] Epoch 0, batch 360, batch avg loss 0.7385, total avg loss: 0.7474, batch size: 39
2021-08-24 17:36:47,064 INFO [train.py:450] Epoch 0, batch 370, batch avg loss 0.6444, total avg loss: 0.7442, batch size: 40
2021-08-24 17:36:58,233 INFO [train.py:450] Epoch 0, batch 380, batch avg loss 0.6676, total avg loss: 0.7423, batch size: 37
2021-08-24 17:37:09,100 INFO [train.py:450] Epoch 0, batch 390, batch avg loss 0.6849, total avg loss: 0.7401, batch size: 39
2021-08-24 17:37:19,841 INFO [train.py:450] Epoch 0, batch 400, batch avg loss 0.7218, total avg loss: 0.7380, batch size: 43
2021-08-24 17:37:30,702 INFO [train.py:450] Epoch 0, batch 410, batch avg loss 0.6901, total avg loss: 0.6707, batch size: 38
2021-08-24 17:37:41,726 INFO [train.py:450] Epoch 0, batch 420, batch avg loss 0.6577, total avg loss: 0.6747, batch size: 43
2021-08-24 17:37:53,639 INFO [train.py:450] Epoch 0, batch 430, batch avg loss 0.6984, total avg loss: 0.6805, batch size: 36
2021-08-24 17:38:07,162 INFO [train.py:450] Epoch 0, batch 440, batch avg loss 0.6567, total avg loss: 0.6815, batch size: 39
2021-08-24 17:38:18,009 INFO [train.py:450] Epoch 0, batch 450, batch avg loss 0.7588, total avg loss: 0.6839, batch size: 39
2021-08-24 17:38:28,481 INFO [train.py:450] Epoch 0, batch 460, batch avg loss 0.6846, total avg loss: 0.6829, batch size: 38
2021-08-24 17:38:39,459 INFO [train.py:450] Epoch 0, batch 470, batch avg loss 0.6752, total avg loss: 0.6831, batch size: 40
2021-08-24 17:38:50,090 INFO [train.py:450] Epoch 0, batch 480, batch avg loss 0.6835, total avg loss: 0.6837, batch size: 40
2021-08-24 17:39:00,780 INFO [train.py:450] Epoch 0, batch 490, batch avg loss 0.6926, total avg loss: 0.6812, batch size: 45
2021-08-24 17:39:11,138 INFO [train.py:450] Epoch 0, batch 500, batch avg loss 0.7087, total avg loss: 0.6792, batch size: 41
2021-08-24 17:39:21,895 INFO [train.py:450] Epoch 0, batch 510, batch avg loss 0.7145, total avg loss: 0.6772, batch size: 40
2021-08-24 17:39:32,084 INFO [train.py:450] Epoch 0, batch 520, batch avg loss 0.6849, total avg loss: 0.6747, batch size: 41
2021-08-24 17:39:42,623 INFO [train.py:450] Epoch 0, batch 530, batch avg loss 0.6900, total avg loss: 0.6739, batch size: 40
2021-08-24 17:39:52,526 INFO [train.py:450] Epoch 0, batch 540, batch avg loss 0.6629, total avg loss: 0.6720, batch size: 37
2021-08-24 17:40:02,896 INFO [train.py:450] Epoch 0, batch 550, batch avg loss 0.6109, total avg loss: 0.6699, batch size: 39
2021-08-24 17:40:12,992 INFO [train.py:450] Epoch 0, batch 560, batch avg loss 0.6208, total avg loss: 0.6674, batch size: 38
2021-08-24 17:40:23,157 INFO [train.py:450] Epoch 0, batch 570, batch avg loss 0.6387, total avg loss: 0.6656, batch size: 40
2021-08-24 17:40:33,067 INFO [train.py:450] Epoch 0, batch 580, batch avg loss 0.6110, total avg loss: 0.6634, batch size: 39
2021-08-24 17:40:43,022 INFO [train.py:450] Epoch 0, batch 590, batch avg loss 0.5705, total avg loss: 0.6624, batch size: 38
2021-08-24 17:40:53,340 INFO [train.py:450] Epoch 0, batch 600, batch avg loss 0.6720, total avg loss: 0.6613, batch size: 40
2021-08-24 17:41:03,614 INFO [train.py:450] Epoch 0, batch 610, batch avg loss 0.6386, total avg loss: 0.6355, batch size: 41
2021-08-24 17:41:14,447 INFO [train.py:450] Epoch 0, batch 620, batch avg loss 0.6505, total avg loss: 0.6399, batch size: 37
2021-08-24 17:41:24,545 INFO [train.py:450] Epoch 0, batch 630, batch avg loss 0.6394, total avg loss: 0.6371, batch size: 40
2021-08-24 17:41:34,837 INFO [train.py:450] Epoch 0, batch 640, batch avg loss 0.6109, total avg loss: 0.6330, batch size: 37
2021-08-24 17:41:44,769 INFO [train.py:450] Epoch 0, batch 650, batch avg loss 0.7263, total avg loss: 0.6315, batch size: 37
2021-08-24 17:41:54,363 INFO [train.py:450] Epoch 0, batch 660, batch avg loss 0.6826, total avg loss: 0.6313, batch size: 40
2021-08-24 17:42:04,270 INFO [train.py:450] Epoch 0, batch 670, batch avg loss 0.6173, total avg loss: 0.6309, batch size: 40
2021-08-24 17:42:14,464 INFO [train.py:450] Epoch 0, batch 680, batch avg loss 0.5725, total avg loss: 0.6292, batch size: 37
2021-08-24 17:42:24,591 INFO [train.py:450] Epoch 0, batch 690, batch avg loss 0.5735, total avg loss: 0.6280, batch size: 39
2021-08-24 17:42:34,642 INFO [train.py:450] Epoch 0, batch 700, batch avg loss 0.6501, total avg loss: 0.6280, batch size: 39
2021-08-24 17:42:45,003 INFO [train.py:450] Epoch 0, batch 710, batch avg loss 0.6436, total avg loss: 0.6289, batch size: 42
2021-08-24 17:42:55,407 INFO [train.py:450] Epoch 0, batch 720, batch avg loss 0.6183, total avg loss: 0.6280, batch size: 38
2021-08-24 17:43:06,606 INFO [train.py:450] Epoch 0, batch 730, batch avg loss 0.5708, total avg loss: 0.6265, batch size: 42
2021-08-24 17:43:15,684 INFO [train.py:450] Epoch 0, batch 740, batch avg loss 0.5772, total avg loss: 0.6259, batch size: 36
2021-08-24 17:43:28,515 INFO [train.py:450] Epoch 0, batch 750, batch avg loss 0.5282, total avg loss: 0.6237, batch size: 40
2021-08-24 17:43:38,881 INFO [train.py:450] Epoch 0, batch 760, batch avg loss 0.5515, total avg loss: 0.6218, batch size: 41
2021-08-24 17:43:48,709 INFO [train.py:450] Epoch 0, batch 770, batch avg loss 0.5419, total avg loss: 0.6207, batch size: 36
2021-08-24 17:43:58,541 INFO [train.py:450] Epoch 0, batch 780, batch avg loss 0.5616, total avg loss: 0.6204, batch size: 38
2021-08-24 17:44:08,174 INFO [train.py:450] Epoch 0, batch 790, batch avg loss 0.5542, total avg loss: 0.6198, batch size: 37
2021-08-24 17:44:17,801 INFO [train.py:450] Epoch 0, batch 800, batch avg loss 0.5823, total avg loss: 0.6177, batch size: 39
2021-08-24 17:44:27,269 INFO [train.py:450] Epoch 0, batch 810, batch avg loss 0.5711, total avg loss: 0.5943, batch size: 38
2021-08-24 17:44:37,268 INFO [train.py:450] Epoch 0, batch 820, batch avg loss 0.6189, total avg loss: 0.6010, batch size: 39
2021-08-24 17:44:47,275 INFO [train.py:450] Epoch 0, batch 830, batch avg loss 0.6182, total avg loss: 0.6003, batch size: 41
2021-08-24 17:44:57,468 INFO [train.py:450] Epoch 0, batch 840, batch avg loss 0.6143, total avg loss: 0.6015, batch size: 36
2021-08-24 17:45:07,300 INFO [train.py:450] Epoch 0, batch 850, batch avg loss 0.6171, total avg loss: 0.6012, batch size: 39
2021-08-24 17:45:17,462 INFO [train.py:450] Epoch 0, batch 860, batch avg loss 0.6110, total avg loss: 0.6006, batch size: 40
2021-08-24 17:45:28,160 INFO [train.py:450] Epoch 0, batch 870, batch avg loss 0.6327, total avg loss: 0.5997, batch size: 41
2021-08-24 17:45:38,412 INFO [train.py:450] Epoch 0, batch 880, batch avg loss 0.5662, total avg loss: 0.5997, batch size: 39
2021-08-24 17:45:47,700 INFO [train.py:450] Epoch 0, batch 890, batch avg loss 0.5411, total avg loss: 0.5966, batch size: 39
2021-08-24 17:45:57,518 INFO [train.py:450] Epoch 0, batch 900, batch avg loss 0.6330, total avg loss: 0.5946, batch size: 38
2021-08-24 17:46:07,732 INFO [train.py:450] Epoch 0, batch 910, batch avg loss 0.5240, total avg loss: 0.5920, batch size: 39
2021-08-24 17:46:17,579 INFO [train.py:450] Epoch 0, batch 920, batch avg loss 0.5667, total avg loss: 0.5924, batch size: 39
2021-08-24 17:46:27,101 INFO [train.py:450] Epoch 0, batch 930, batch avg loss 0.5657, total avg loss: 0.5918, batch size: 40
2021-08-24 17:46:37,306 INFO [train.py:450] Epoch 0, batch 940, batch avg loss 0.5779, total avg loss: 0.5914, batch size: 39
2021-08-24 17:46:46,900 INFO [train.py:450] Epoch 0, batch 950, batch avg loss 0.6132, total avg loss: 0.5907, batch size: 39
2021-08-24 17:46:56,197 INFO [train.py:450] Epoch 0, batch 960, batch avg loss 0.5979, total avg loss: 0.5903, batch size: 43
2021-08-24 17:47:05,653 INFO [train.py:450] Epoch 0, batch 970, batch avg loss 0.5794, total avg loss: 0.5891, batch size: 38
2021-08-24 17:47:15,623 INFO [train.py:450] Epoch 0, batch 980, batch avg loss 0.5801, total avg loss: 0.5888, batch size: 40
2021-08-24 17:47:25,325 INFO [train.py:450] Epoch 0, batch 990, batch avg loss 0.5529, total avg loss: 0.5878, batch size: 40
2021-08-24 17:47:34,605 INFO [train.py:450] Epoch 0, batch 1000, batch avg loss 0.5913, total avg loss: 0.5872, batch size: 40
2021-08-24 17:48:13,076 INFO [train.py:482] Epoch 0, valid loss 0.4630, best valid loss: 0.4630 best valid epoch: 0
2021-08-24 17:48:21,182 INFO [train.py:450] Epoch 0, batch 1010, batch avg loss 0.5605, total avg loss: 0.5756, batch size: 41
2021-08-24 17:48:32,731 INFO [train.py:450] Epoch 0, batch 1020, batch avg loss 0.5716, total avg loss: 0.5641, batch size: 39
2021-08-24 17:48:43,220 INFO [train.py:450] Epoch 0, batch 1030, batch avg loss 0.6371, total avg loss: 0.5731, batch size: 43
2021-08-24 17:48:52,696 INFO [train.py:450] Epoch 0, batch 1040, batch avg loss 0.5473, total avg loss: 0.5686, batch size: 41
2021-08-24 17:49:01,785 INFO [train.py:450] Epoch 0, batch 1050, batch avg loss 0.5319, total avg loss: 0.5668, batch size: 40
2021-08-24 17:49:11,710 INFO [train.py:450] Epoch 0, batch 1060, batch avg loss 0.5180, total avg loss: 0.5658, batch size: 36
2021-08-24 17:49:21,643 INFO [train.py:450] Epoch 0, batch 1070, batch avg loss 0.5949, total avg loss: 0.5684, batch size: 41
2021-08-24 17:49:30,767 INFO [train.py:450] Epoch 0, batch 1080, batch avg loss 0.5714, total avg loss: 0.5699, batch size: 40
2021-08-24 17:49:39,825 INFO [train.py:450] Epoch 0, batch 1090, batch avg loss 0.5614, total avg loss: 0.5684, batch size: 40
2021-08-24 17:49:49,550 INFO [train.py:450] Epoch 0, batch 1100, batch avg loss 0.6215, total avg loss: 0.5684, batch size: 36
2021-08-24 17:49:58,971 INFO [train.py:450] Epoch 0, batch 1110, batch avg loss 0.6205, total avg loss: 0.5694, batch size: 42
2021-08-24 17:50:08,540 INFO [train.py:450] Epoch 0, batch 1120, batch avg loss 0.5359, total avg loss: 0.5698, batch size: 38
2021-08-24 17:50:17,616 INFO [train.py:450] Epoch 0, batch 1130, batch avg loss 0.5648, total avg loss: 0.5683, batch size: 40
2021-08-24 17:50:27,418 INFO [train.py:450] Epoch 0, batch 1140, batch avg loss 0.5303, total avg loss: 0.5669, batch size: 42
2021-08-24 17:50:36,746 INFO [train.py:450] Epoch 0, batch 1150, batch avg loss 0.5845, total avg loss: 0.5675, batch size: 37
2021-08-24 17:50:45,912 INFO [train.py:450] Epoch 0, batch 1160, batch avg loss 0.5821, total avg loss: 0.5669, batch size: 42
2021-08-24 17:50:55,086 INFO [train.py:450] Epoch 0, batch 1170, batch avg loss 0.5008, total avg loss: 0.5663, batch size: 38
2021-08-24 17:51:04,192 INFO [train.py:450] Epoch 0, batch 1180, batch avg loss 0.6187, total avg loss: 0.5665, batch size: 42
2021-08-24 17:51:13,451 INFO [train.py:450] Epoch 0, batch 1190, batch avg loss 0.5898, total avg loss: 0.5654, batch size: 44
2021-08-24 17:51:22,320 INFO [train.py:450] Epoch 0, batch 1200, batch avg loss 0.5792, total avg loss: 0.5645, batch size: 44
2021-08-24 17:51:31,269 INFO [train.py:450] Epoch 0, batch 1210, batch avg loss 0.5701, total avg loss: 0.5683, batch size: 42
2021-08-24 17:51:40,793 INFO [train.py:450] Epoch 0, batch 1220, batch avg loss 0.5568, total avg loss: 0.5591, batch size: 37
2021-08-24 17:51:49,865 INFO [train.py:450] Epoch 0, batch 1230, batch avg loss 0.5337, total avg loss: 0.5555, batch size: 37
2021-08-24 17:51:59,768 INFO [train.py:450] Epoch 0, batch 1240, batch avg loss 0.6040, total avg loss: 0.5563, batch size: 38
2021-08-24 17:52:08,535 INFO [train.py:450] Epoch 0, batch 1250, batch avg loss 0.5855, total avg loss: 0.5548, batch size: 39
2021-08-24 17:52:18,348 INFO [train.py:450] Epoch 0, batch 1260, batch avg loss 0.5635, total avg loss: 0.5527, batch size: 40
2021-08-24 17:52:26,971 INFO [train.py:450] Epoch 0, batch 1270, batch avg loss 0.4927, total avg loss: 0.5518, batch size: 39
2021-08-24 17:52:36,757 INFO [train.py:450] Epoch 0, batch 1280, batch avg loss 0.5697, total avg loss: 0.5498, batch size: 39
2021-08-24 17:52:46,188 INFO [train.py:450] Epoch 0, batch 1290, batch avg loss 0.5661, total avg loss: 0.5507, batch size: 40
2021-08-24 17:52:55,299 INFO [train.py:450] Epoch 0, batch 1300, batch avg loss 0.5135, total avg loss: 0.5498, batch size: 40
2021-08-24 17:53:04,735 INFO [train.py:450] Epoch 0, batch 1310, batch avg loss 0.5580, total avg loss: 0.5480, batch size: 40
2021-08-24 17:53:13,685 INFO [train.py:450] Epoch 0, batch 1320, batch avg loss 0.4935, total avg loss: 0.5478, batch size: 36
2021-08-24 17:53:22,927 INFO [train.py:450] Epoch 0, batch 1330, batch avg loss 0.5192, total avg loss: 0.5481, batch size: 43
2021-08-24 17:53:32,089 INFO [train.py:450] Epoch 0, batch 1340, batch avg loss 0.5254, total avg loss: 0.5469, batch size: 40
2021-08-24 17:53:43,156 INFO [train.py:450] Epoch 0, batch 1350, batch avg loss 0.5665, total avg loss: 0.5466, batch size: 38
2021-08-24 17:53:56,221 INFO [train.py:450] Epoch 0, batch 1360, batch avg loss 0.5459, total avg loss: 0.5473, batch size: 38
2021-08-24 17:54:05,060 INFO [train.py:450] Epoch 0, batch 1370, batch avg loss 0.5319, total avg loss: 0.5472, batch size: 37
2021-08-24 17:54:14,540 INFO [train.py:450] Epoch 0, batch 1380, batch avg loss 0.5466, total avg loss: 0.5473, batch size: 41
2021-08-24 17:54:23,260 INFO [train.py:450] Epoch 0, batch 1390, batch avg loss 0.5706, total avg loss: 0.5474, batch size: 37
2021-08-24 17:54:32,426 INFO [train.py:450] Epoch 0, batch 1400, batch avg loss 0.4982, total avg loss: 0.5462, batch size: 41
2021-08-24 17:54:41,784 INFO [train.py:450] Epoch 0, batch 1410, batch avg loss 0.5557, total avg loss: 0.5514, batch size: 41
2021-08-24 17:54:51,400 INFO [train.py:450] Epoch 0, batch 1420, batch avg loss 0.5776, total avg loss: 0.5588, batch size: 38
2021-08-24 17:55:01,013 INFO [train.py:450] Epoch 0, batch 1430, batch avg loss 0.5361, total avg loss: 0.5523, batch size: 42
2021-08-24 17:55:10,783 INFO [train.py:450] Epoch 0, batch 1440, batch avg loss 0.5424, total avg loss: 0.5521, batch size: 41
2021-08-24 17:55:19,768 INFO [train.py:450] Epoch 0, batch 1450, batch avg loss 0.5775, total avg loss: 0.5532, batch size: 43
2021-08-24 17:55:29,584 INFO [train.py:450] Epoch 0, batch 1460, batch avg loss 0.5313, total avg loss: 0.5549, batch size: 41
2021-08-24 17:55:39,017 INFO [train.py:450] Epoch 0, batch 1470, batch avg loss 0.6132, total avg loss: 0.5557, batch size: 41
2021-08-24 17:55:48,822 INFO [train.py:450] Epoch 0, batch 1480, batch avg loss 0.5653, total avg loss: 0.5544, batch size: 37
2021-08-24 17:55:58,851 INFO [train.py:450] Epoch 0, batch 1490, batch avg loss 0.5384, total avg loss: 0.5539, batch size: 38
2021-08-24 17:56:07,417 INFO [train.py:450] Epoch 0, batch 1500, batch avg loss 0.4826, total avg loss: 0.5522, batch size: 40
2021-08-24 17:56:16,109 INFO [train.py:450] Epoch 0, batch 1510, batch avg loss 0.5605, total avg loss: 0.5506, batch size: 39
2021-08-24 17:56:25,944 INFO [train.py:450] Epoch 0, batch 1520, batch avg loss 0.5403, total avg loss: 0.5501, batch size: 42
2021-08-24 17:56:36,960 INFO [train.py:450] Epoch 0, batch 1530, batch avg loss 0.5354, total avg loss: 0.5484, batch size: 40
2021-08-24 17:56:46,943 INFO [train.py:450] Epoch 0, batch 1540, batch avg loss 0.4638, total avg loss: 0.5481, batch size: 37
2021-08-24 17:56:56,236 INFO [train.py:450] Epoch 0, batch 1550, batch avg loss 0.5116, total avg loss: 0.5476, batch size: 46
2021-08-24 17:57:05,493 INFO [train.py:450] Epoch 0, batch 1560, batch avg loss 0.6295, total avg loss: 0.5485, batch size: 39
2021-08-24 17:57:15,282 INFO [train.py:450] Epoch 0, batch 1570, batch avg loss 0.5318, total avg loss: 0.5478, batch size: 44
2021-08-24 17:57:24,714 INFO [train.py:450] Epoch 0, batch 1580, batch avg loss 0.5548, total avg loss: 0.5470, batch size: 37
2021-08-24 17:57:34,103 INFO [train.py:450] Epoch 0, batch 1590, batch avg loss 0.5458, total avg loss: 0.5449, batch size: 36
2021-08-24 17:57:43,860 INFO [train.py:450] Epoch 0, batch 1600, batch avg loss 0.5526, total avg loss: 0.5444, batch size: 41
2021-08-24 17:57:52,498 INFO [train.py:450] Epoch 0, batch 1610, batch avg loss 0.5341, total avg loss: 0.5375, batch size: 42
2021-08-24 17:58:00,641 INFO [train.py:450] Epoch 0, batch 1620, batch avg loss 0.5130, total avg loss: 0.5328, batch size: 39
2021-08-24 17:58:09,241 INFO [train.py:450] Epoch 0, batch 1630, batch avg loss 0.5351, total avg loss: 0.5374, batch size: 39
2021-08-24 17:58:18,328 INFO [train.py:450] Epoch 0, batch 1640, batch avg loss 0.5676, total avg loss: 0.5354, batch size: 40
2021-08-24 17:58:27,119 INFO [train.py:450] Epoch 0, batch 1650, batch avg loss 0.5142, total avg loss: 0.5357, batch size: 42
2021-08-24 17:58:36,259 INFO [train.py:450] Epoch 0, batch 1660, batch avg loss 0.5428, total avg loss: 0.5334, batch size: 40
2021-08-24 17:58:45,230 INFO [train.py:450] Epoch 0, batch 1670, batch avg loss 0.5738, total avg loss: 0.5313, batch size: 38
2021-08-24 17:58:54,504 INFO [train.py:450] Epoch 0, batch 1680, batch avg loss 0.4929, total avg loss: 0.5321, batch size: 39
2021-08-24 17:59:03,588 INFO [train.py:450] Epoch 0, batch 1690, batch avg loss 0.5156, total avg loss: 0.5327, batch size: 39
2021-08-24 17:59:13,016 INFO [train.py:450] Epoch 0, batch 1700, batch avg loss 0.5189, total avg loss: 0.5313, batch size: 39
2021-08-24 17:59:24,960 INFO [train.py:450] Epoch 0, batch 1710, batch avg loss 0.5322, total avg loss: 0.5307, batch size: 38
2021-08-24 17:59:34,039 INFO [train.py:450] Epoch 0, batch 1720, batch avg loss 0.5009, total avg loss: 0.5284, batch size: 39
2021-08-24 17:59:42,775 INFO [train.py:450] Epoch 0, batch 1730, batch avg loss 0.5393, total avg loss: 0.5281, batch size: 40
2021-08-24 17:59:51,830 INFO [train.py:450] Epoch 0, batch 1740, batch avg loss 0.5020, total avg loss: 0.5282, batch size: 40
2021-08-24 18:00:01,051 INFO [train.py:450] Epoch 0, batch 1750, batch avg loss 0.5425, total avg loss: 0.5285, batch size: 40
2021-08-24 18:00:09,898 INFO [train.py:450] Epoch 0, batch 1760, batch avg loss 0.6174, total avg loss: 0.5297, batch size: 37
2021-08-24 18:00:19,250 INFO [train.py:450] Epoch 0, batch 1770, batch avg loss 0.4515, total avg loss: 0.5297, batch size: 37
2021-08-24 18:00:28,173 INFO [train.py:450] Epoch 0, batch 1780, batch avg loss 0.5188, total avg loss: 0.5297, batch size: 39
2021-08-24 18:00:37,152 INFO [train.py:450] Epoch 0, batch 1790, batch avg loss 0.5326, total avg loss: 0.5289, batch size: 35
2021-08-24 18:00:45,856 INFO [train.py:450] Epoch 0, batch 1800, batch avg loss 0.5524, total avg loss: 0.5290, batch size: 42
2021-08-24 18:00:54,229 INFO [train.py:450] Epoch 0, batch 1810, batch avg loss 0.5105, total avg loss: 0.5270, batch size: 36
2021-08-24 18:01:02,798 INFO [train.py:450] Epoch 0, batch 1820, batch avg loss 0.4997, total avg loss: 0.5249, batch size: 37
2021-08-24 18:01:11,411 INFO [train.py:450] Epoch 0, batch 1830, batch avg loss 0.4820, total avg loss: 0.5222, batch size: 41
2021-08-24 18:01:20,382 INFO [train.py:450] Epoch 0, batch 1840, batch avg loss 0.5740, total avg loss: 0.5213, batch size: 41
2021-08-24 18:01:29,742 INFO [train.py:450] Epoch 0, batch 1850, batch avg loss 0.5576, total avg loss: 0.5253, batch size: 40
2021-08-24 18:01:38,123 INFO [train.py:450] Epoch 0, batch 1860, batch avg loss 0.5377, total avg loss: 0.5216, batch size: 45
2021-08-24 18:01:46,753 INFO [train.py:450] Epoch 0, batch 1870, batch avg loss 0.5076, total avg loss: 0.5205, batch size: 40
2021-08-24 18:01:55,589 INFO [train.py:450] Epoch 0, batch 1880, batch avg loss 0.5677, total avg loss: 0.5215, batch size: 38
2021-08-24 18:02:04,228 INFO [train.py:450] Epoch 0, batch 1890, batch avg loss 0.5118, total avg loss: 0.5204, batch size: 41
2021-08-24 18:02:13,280 INFO [train.py:450] Epoch 0, batch 1900, batch avg loss 0.5834, total avg loss: 0.5209, batch size: 43
2021-08-24 18:02:22,249 INFO [train.py:450] Epoch 0, batch 1910, batch avg loss 0.5813, total avg loss: 0.5236, batch size: 40
2021-08-24 18:02:31,096 INFO [train.py:450] Epoch 0, batch 1920, batch avg loss 0.4913, total avg loss: 0.5226, batch size: 40
2021-08-24 18:02:39,430 INFO [train.py:450] Epoch 0, batch 1930, batch avg loss 0.4695, total avg loss: 0.5219, batch size: 40
2021-08-24 18:02:48,048 INFO [train.py:450] Epoch 0, batch 1940, batch avg loss 0.5765, total avg loss: 0.5226, batch size: 38
2021-08-24 18:02:56,512 INFO [train.py:450] Epoch 0, batch 1950, batch avg loss 0.5614, total avg loss: 0.5234, batch size: 45
2021-08-24 18:03:05,103 INFO [train.py:450] Epoch 0, batch 1960, batch avg loss 0.5098, total avg loss: 0.5225, batch size: 40
2021-08-24 18:03:13,815 INFO [train.py:450] Epoch 0, batch 1970, batch avg loss 0.5733, total avg loss: 0.5225, batch size: 39
2021-08-24 18:03:22,698 INFO [train.py:450] Epoch 0, batch 1980, batch avg loss 0.4750, total avg loss: 0.5228, batch size: 43
2021-08-24 18:03:31,905 INFO [train.py:450] Epoch 0, batch 1990, batch avg loss 0.5205, total avg loss: 0.5227, batch size: 38
2021-08-24 18:03:41,361 INFO [train.py:450] Epoch 0, batch 2000, batch avg loss 0.5100, total avg loss: 0.5217, batch size: 39
2021-08-24 18:04:20,409 INFO [train.py:482] Epoch 0, valid loss 0.4005, best valid loss: 0.4005 best valid epoch: 0
2021-08-24 18:04:27,040 INFO [train.py:450] Epoch 0, batch 2010, batch avg loss 0.5319, total avg loss: 0.5152, batch size: 38
2021-08-24 18:04:35,750 INFO [train.py:450] Epoch 0, batch 2020, batch avg loss 0.4962, total avg loss: 0.5121, batch size: 38
2021-08-24 18:04:45,948 INFO [train.py:450] Epoch 0, batch 2030, batch avg loss 0.5134, total avg loss: 0.5106, batch size: 38
2021-08-24 18:04:54,841 INFO [train.py:450] Epoch 0, batch 2040, batch avg loss 0.5648, total avg loss: 0.5123, batch size: 40
2021-08-24 18:05:05,574 INFO [train.py:450] Epoch 0, batch 2050, batch avg loss 0.5723, total avg loss: 0.5115, batch size: 43
2021-08-24 18:05:14,491 INFO [train.py:450] Epoch 0, batch 2060, batch avg loss 0.4907, total avg loss: 0.5104, batch size: 40
2021-08-24 18:05:23,220 INFO [train.py:450] Epoch 0, batch 2070, batch avg loss 0.4695, total avg loss: 0.5109, batch size: 38
2021-08-24 18:05:31,929 INFO [train.py:450] Epoch 0, batch 2080, batch avg loss 0.4652, total avg loss: 0.5100, batch size: 40
2021-08-24 18:05:40,305 INFO [train.py:450] Epoch 0, batch 2090, batch avg loss 0.5348, total avg loss: 0.5098, batch size: 38
2021-08-24 18:05:48,359 INFO [train.py:450] Epoch 0, batch 2100, batch avg loss 0.5079, total avg loss: 0.5082, batch size: 41
2021-08-24 18:05:56,809 INFO [train.py:450] Epoch 0, batch 2110, batch avg loss 0.5012, total avg loss: 0.5084, batch size: 39
2021-08-24 18:06:05,149 INFO [train.py:450] Epoch 0, batch 2120, batch avg loss 0.5485, total avg loss: 0.5086, batch size: 40
2021-08-24 18:06:13,321 INFO [train.py:450] Epoch 0, batch 2130, batch avg loss 0.5101, total avg loss: 0.5098, batch size: 38
2021-08-24 18:06:21,556 INFO [train.py:450] Epoch 0, batch 2140, batch avg loss 0.4859, total avg loss: 0.5101, batch size: 40
2021-08-24 18:06:29,811 INFO [train.py:450] Epoch 0, batch 2150, batch avg loss 0.5174, total avg loss: 0.5101, batch size: 39
2021-08-24 18:06:38,366 INFO [train.py:450] Epoch 0, batch 2160, batch avg loss 0.4836, total avg loss: 0.5094, batch size: 37
2021-08-24 18:06:46,167 INFO [train.py:450] Epoch 0, batch 2170, batch avg loss 0.5150, total avg loss: 0.5096, batch size: 39
2021-08-24 18:06:54,600 INFO [train.py:450] Epoch 0, batch 2180, batch avg loss 0.4813, total avg loss: 0.5100, batch size: 39
2021-08-24 18:07:03,369 INFO [train.py:450] Epoch 0, batch 2190, batch avg loss 0.5153, total avg loss: 0.5092, batch size: 41
2021-08-24 18:07:12,297 INFO [train.py:450] Epoch 0, batch 2200, batch avg loss 0.4708, total avg loss: 0.5081, batch size: 41
2021-08-24 18:07:20,132 INFO [train.py:450] Epoch 0, batch 2210, batch avg loss 0.5207, total avg loss: 0.4980, batch size: 38
2021-08-24 18:07:28,143 INFO [train.py:450] Epoch 0, batch 2220, batch avg loss 0.4474, total avg loss: 0.5040, batch size: 39
2021-08-24 18:07:35,851 INFO [train.py:450] Epoch 0, batch 2230, batch avg loss 0.4533, total avg loss: 0.5042, batch size: 37
2021-08-24 18:07:44,238 INFO [train.py:450] Epoch 0, batch 2240, batch avg loss 0.4735, total avg loss: 0.5001, batch size: 44
2021-08-24 18:07:52,946 INFO [train.py:450] Epoch 0, batch 2250, batch avg loss 0.5173, total avg loss: 0.5016, batch size: 42
2021-08-24 18:08:00,546 INFO [train.py:450] Epoch 0, batch 2260, batch avg loss 0.5010, total avg loss: 0.5013, batch size: 41
2021-08-24 18:08:08,325 INFO [train.py:450] Epoch 0, batch 2270, batch avg loss 0.4862, total avg loss: 0.5002, batch size: 40
2021-08-24 18:08:16,287 INFO [train.py:450] Epoch 0, batch 2280, batch avg loss 0.5511, total avg loss: 0.5028, batch size: 39
2021-08-24 18:08:24,555 INFO [train.py:450] Epoch 0, batch 2290, batch avg loss 0.5342, total avg loss: 0.5026, batch size: 41
2021-08-24 18:08:32,909 INFO [train.py:450] Epoch 0, batch 2300, batch avg loss 0.5178, total avg loss: 0.5027, batch size: 41
2021-08-24 18:08:40,736 INFO [train.py:450] Epoch 0, batch 2310, batch avg loss 0.4646, total avg loss: 0.5025, batch size: 38
2021-08-24 18:08:49,048 INFO [train.py:450] Epoch 0, batch 2320, batch avg loss 0.5311, total avg loss: 0.5032, batch size: 38
2021-08-24 18:08:57,072 INFO [train.py:450] Epoch 0, batch 2330, batch avg loss 0.5071, total avg loss: 0.5039, batch size: 36
2021-08-24 18:09:05,431 INFO [train.py:450] Epoch 0, batch 2340, batch avg loss 0.5494, total avg loss: 0.5038, batch size: 38
2021-08-24 18:09:14,057 INFO [train.py:450] Epoch 0, batch 2350, batch avg loss 0.5020, total avg loss: 0.5045, batch size: 43
2021-08-24 18:09:22,544 INFO [train.py:450] Epoch 0, batch 2360, batch avg loss 0.5062, total avg loss: 0.5047, batch size: 42
2021-08-24 18:09:32,161 INFO [train.py:450] Epoch 0, batch 2370, batch avg loss 0.4766, total avg loss: 0.5048, batch size: 45
2021-08-24 18:09:41,156 INFO [train.py:450] Epoch 0, batch 2380, batch avg loss 0.5027, total avg loss: 0.5043, batch size: 38
2021-08-24 18:09:50,651 INFO [train.py:450] Epoch 0, batch 2390, batch avg loss 0.4848, total avg loss: 0.5047, batch size: 39
2021-08-24 18:09:59,274 INFO [train.py:450] Epoch 0, batch 2400, batch avg loss 0.5479, total avg loss: 0.5036, batch size: 42
2021-08-24 18:10:07,430 INFO [train.py:450] Epoch 0, batch 2410, batch avg loss 0.4767, total avg loss: 0.4991, batch size: 44
2021-08-24 18:10:16,745 INFO [train.py:450] Epoch 0, batch 2420, batch avg loss 0.4708, total avg loss: 0.5018, batch size: 42
2021-08-24 18:10:25,069 INFO [train.py:450] Epoch 0, batch 2430, batch avg loss 0.5287, total avg loss: 0.5096, batch size: 39
2021-08-24 18:10:33,190 INFO [train.py:450] Epoch 0, batch 2440, batch avg loss 0.4948, total avg loss: 0.5056, batch size: 46
2021-08-24 18:10:41,723 INFO [train.py:450] Epoch 0, batch 2450, batch avg loss 0.5056, total avg loss: 0.5051, batch size: 37
2021-08-24 18:10:50,192 INFO [train.py:450] Epoch 0, batch 2460, batch avg loss 0.4853, total avg loss: 0.5036, batch size: 43
2021-08-24 18:10:58,237 INFO [train.py:450] Epoch 0, batch 2470, batch avg loss 0.5287, total avg loss: 0.5028, batch size: 39
2021-08-24 18:11:06,234 INFO [train.py:450] Epoch 0, batch 2480, batch avg loss 0.5213, total avg loss: 0.5036, batch size: 43
2021-08-24 18:11:14,245 INFO [train.py:450] Epoch 0, batch 2490, batch avg loss 0.4396, total avg loss: 0.5026, batch size: 40
2021-08-24 18:11:22,290 INFO [train.py:450] Epoch 0, batch 2500, batch avg loss 0.4575, total avg loss: 0.5015, batch size: 40
2021-08-24 18:11:30,450 INFO [train.py:450] Epoch 0, batch 2510, batch avg loss 0.5337, total avg loss: 0.4984, batch size: 40
2021-08-24 18:11:38,437 INFO [train.py:450] Epoch 0, batch 2520, batch avg loss 0.5163, total avg loss: 0.4994, batch size: 41
2021-08-24 18:11:46,674 INFO [train.py:450] Epoch 0, batch 2530, batch avg loss 0.4868, total avg loss: 0.4991, batch size: 43
2021-08-24 18:11:54,475 INFO [train.py:450] Epoch 0, batch 2540, batch avg loss 0.5003, total avg loss: 0.4988, batch size: 36
2021-08-24 18:12:02,433 INFO [train.py:450] Epoch 0, batch 2550, batch avg loss 0.5092, total avg loss: 0.4985, batch size: 42
2021-08-24 18:12:10,849 INFO [train.py:450] Epoch 0, batch 2560, batch avg loss 0.4491, total avg loss: 0.4976, batch size: 38
2021-08-24 18:12:18,715 INFO [train.py:450] Epoch 0, batch 2570, batch avg loss 0.5040, total avg loss: 0.4971, batch size: 39
2021-08-24 18:12:26,600 INFO [train.py:450] Epoch 0, batch 2580, batch avg loss 0.4776, total avg loss: 0.4972, batch size: 36
2021-08-24 18:12:33,853 INFO [train.py:450] Epoch 0, batch 2590, batch avg loss 0.5296, total avg loss: 0.4969, batch size: 34
2021-08-24 18:12:41,786 INFO [train.py:450] Epoch 0, batch 2600, batch avg loss 0.4580, total avg loss: 0.4968, batch size: 43
2021-08-24 18:12:49,940 INFO [train.py:450] Epoch 0, batch 2610, batch avg loss 0.5299, total avg loss: 0.4780, batch size: 42
2021-08-24 18:12:57,734 INFO [train.py:450] Epoch 0, batch 2620, batch avg loss 0.4800, total avg loss: 0.4796, batch size: 36
2021-08-24 18:13:05,529 INFO [train.py:450] Epoch 0, batch 2630, batch avg loss 0.5753, total avg loss: 0.4862, batch size: 41
2021-08-24 18:13:13,650 INFO [train.py:450] Epoch 0, batch 2640, batch avg loss 0.4798, total avg loss: 0.4836, batch size: 38
2021-08-24 18:13:22,050 INFO [train.py:450] Epoch 0, batch 2650, batch avg loss 0.5420, total avg loss: 0.4844, batch size: 40
2021-08-24 18:13:29,921 INFO [train.py:450] Epoch 0, batch 2660, batch avg loss 0.5179, total avg loss: 0.4865, batch size: 42
2021-08-24 18:13:37,842 INFO [train.py:450] Epoch 0, batch 2670, batch avg loss 0.5508, total avg loss: 0.4889, batch size: 40
2021-08-24 18:13:45,599 INFO [train.py:450] Epoch 0, batch 2680, batch avg loss 0.4613, total avg loss: 0.4902, batch size: 39
2021-08-24 18:13:53,392 INFO [train.py:450] Epoch 0, batch 2690, batch avg loss 0.4863, total avg loss: 0.4897, batch size: 43
2021-08-24 18:14:01,873 INFO [train.py:450] Epoch 0, batch 2700, batch avg loss 0.4593, total avg loss: 0.4885, batch size: 38
2021-08-24 18:14:12,323 INFO [train.py:450] Epoch 0, batch 2710, batch avg loss 0.4797, total avg loss: 0.4888, batch size: 38
2021-08-24 18:14:19,692 INFO [train.py:450] Epoch 0, batch 2720, batch avg loss 0.5485, total avg loss: 0.4887, batch size: 42
2021-08-24 18:14:29,872 INFO [train.py:450] Epoch 0, batch 2730, batch avg loss 0.5588, total avg loss: 0.4881, batch size: 40
2021-08-24 18:14:38,018 INFO [train.py:450] Epoch 0, batch 2740, batch avg loss 0.5512, total avg loss: 0.4890, batch size: 42
2021-08-24 18:14:46,364 INFO [train.py:450] Epoch 0, batch 2750, batch avg loss 0.5469, total avg loss: 0.4889, batch size: 42
2021-08-24 18:14:54,068 INFO [train.py:450] Epoch 0, batch 2760, batch avg loss 0.4746, total avg loss: 0.4885, batch size: 41
2021-08-24 18:15:01,711 INFO [train.py:450] Epoch 0, batch 2770, batch avg loss 0.5019, total avg loss: 0.4892, batch size: 40
2021-08-24 18:15:09,446 INFO [train.py:450] Epoch 0, batch 2780, batch avg loss 0.4459, total avg loss: 0.4890, batch size: 40
2021-08-24 18:15:17,330 INFO [train.py:450] Epoch 0, batch 2790, batch avg loss 0.5048, total avg loss: 0.4889, batch size: 39
2021-08-24 18:15:25,521 INFO [train.py:450] Epoch 0, batch 2800, batch avg loss 0.5032, total avg loss: 0.4883, batch size: 41
2021-08-24 18:15:33,427 INFO [train.py:450] Epoch 0, batch 2810, batch avg loss 0.4658, total avg loss: 0.4786, batch size: 38
2021-08-24 18:15:40,758 INFO [train.py:450] Epoch 0, batch 2820, batch avg loss 0.4734, total avg loss: 0.4829, batch size: 39
2021-08-24 18:15:48,511 INFO [train.py:450] Epoch 0, batch 2830, batch avg loss 0.4413, total avg loss: 0.4851, batch size: 39
2021-08-24 18:15:55,963 INFO [train.py:450] Epoch 0, batch 2840, batch avg loss 0.4833, total avg loss: 0.4883, batch size: 41
2021-08-24 18:16:04,040 INFO [train.py:450] Epoch 0, batch 2850, batch avg loss 0.4570, total avg loss: 0.4870, batch size: 37
2021-08-24 18:16:11,561 INFO [train.py:450] Epoch 0, batch 2860, batch avg loss 0.5717, total avg loss: 0.4872, batch size: 40
2021-08-24 18:16:19,511 INFO [train.py:450] Epoch 0, batch 2870, batch avg loss 0.4353, total avg loss: 0.4851, batch size: 39
2021-08-24 18:16:27,517 INFO [train.py:450] Epoch 0, batch 2880, batch avg loss 0.4386, total avg loss: 0.4835, batch size: 41
2021-08-24 18:16:34,995 INFO [train.py:450] Epoch 0, batch 2890, batch avg loss 0.4386, total avg loss: 0.4832, batch size: 39
2021-08-24 18:16:42,470 INFO [train.py:450] Epoch 0, batch 2900, batch avg loss 0.4437, total avg loss: 0.4843, batch size: 39
2021-08-24 18:16:50,283 INFO [train.py:450] Epoch 0, batch 2910, batch avg loss 0.4742, total avg loss: 0.4846, batch size: 43
2021-08-24 18:16:58,077 INFO [train.py:450] Epoch 0, batch 2920, batch avg loss 0.4780, total avg loss: 0.4863, batch size: 37
2021-08-24 18:17:05,788 INFO [train.py:450] Epoch 0, batch 2930, batch avg loss 0.4979, total avg loss: 0.4864, batch size: 40
2021-08-24 18:17:13,502 INFO [train.py:450] Epoch 0, batch 2940, batch avg loss 0.4557, total avg loss: 0.4880, batch size: 41
2021-08-24 18:17:21,021 INFO [train.py:450] Epoch 0, batch 2950, batch avg loss 0.5172, total avg loss: 0.4879, batch size: 38
2021-08-24 18:17:28,929 INFO [train.py:450] Epoch 0, batch 2960, batch avg loss 0.4697, total avg loss: 0.4872, batch size: 40
2021-08-24 18:17:36,790 INFO [train.py:450] Epoch 0, batch 2970, batch avg loss 0.4053, total avg loss: 0.4869, batch size: 39
2021-08-24 18:17:44,285 INFO [train.py:450] Epoch 0, batch 2980, batch avg loss 0.4920, total avg loss: 0.4870, batch size: 41
2021-08-24 18:17:51,931 INFO [train.py:450] Epoch 0, batch 2990, batch avg loss 0.5584, total avg loss: 0.4870, batch size: 39
2021-08-24 18:18:00,051 INFO [train.py:450] Epoch 0, batch 3000, batch avg loss 0.4788, total avg loss: 0.4876, batch size: 37
2021-08-24 18:18:38,694 INFO [train.py:482] Epoch 0, valid loss 0.3651, best valid loss: 0.3651 best valid epoch: 0
2021-08-24 18:18:44,549 INFO [train.py:450] Epoch 0, batch 3010, batch avg loss 0.4795, total avg loss: 0.4790, batch size: 41
2021-08-24 18:18:52,315 INFO [train.py:450] Epoch 0, batch 3020, batch avg loss 0.4646, total avg loss: 0.4745, batch size: 38
2021-08-24 18:18:59,893 INFO [train.py:450] Epoch 0, batch 3030, batch avg loss 0.5177, total avg loss: 0.4772, batch size: 37
2021-08-24 18:19:07,998 INFO [train.py:450] Epoch 0, batch 3040, batch avg loss 0.4551, total avg loss: 0.4770, batch size: 40
2021-08-24 18:19:16,240 INFO [train.py:450] Epoch 0, batch 3050, batch avg loss 0.5326, total avg loss: 0.4772, batch size: 36
2021-08-24 18:19:25,105 INFO [train.py:450] Epoch 0, batch 3060, batch avg loss 0.4484, total avg loss: 0.4774, batch size: 39
2021-08-24 18:19:34,470 INFO [train.py:450] Epoch 0, batch 3070, batch avg loss 0.4799, total avg loss: 0.4756, batch size: 41
2021-08-24 18:19:43,390 INFO [train.py:450] Epoch 0, batch 3080, batch avg loss 0.4962, total avg loss: 0.4763, batch size: 41
2021-08-24 18:19:50,718 INFO [train.py:450] Epoch 0, batch 3090, batch avg loss 0.4622, total avg loss: 0.4780, batch size: 39
2021-08-24 18:19:58,223 INFO [train.py:450] Epoch 0, batch 3100, batch avg loss 0.5158, total avg loss: 0.4782, batch size: 38
2021-08-24 18:20:06,149 INFO [train.py:450] Epoch 0, batch 3110, batch avg loss 0.4258, total avg loss: 0.4789, batch size: 36
2021-08-24 18:20:14,010 INFO [train.py:450] Epoch 0, batch 3120, batch avg loss 0.4837, total avg loss: 0.4783, batch size: 36
2021-08-24 18:20:21,913 INFO [train.py:450] Epoch 0, batch 3130, batch avg loss 0.5497, total avg loss: 0.4777, batch size: 38
2021-08-24 18:20:29,202 INFO [train.py:450] Epoch 0, batch 3140, batch avg loss 0.3965, total avg loss: 0.4761, batch size: 38
2021-08-24 18:20:37,110 INFO [train.py:450] Epoch 0, batch 3150, batch avg loss 0.4975, total avg loss: 0.4748, batch size: 43
2021-08-24 18:20:44,401 INFO [train.py:450] Epoch 0, batch 3160, batch avg loss 0.5116, total avg loss: 0.4745, batch size: 41
2021-08-24 18:20:45,632 WARNING [cut.py:1694] To perform mix, energy must be non-zero and non-negative (got 0.0).  MonoCut with id "a0b3aa5d-2ded-fff9-6ed4-c4db649582c5" will not be mixed in.
2021-08-24 18:20:51,876 INFO [train.py:450] Epoch 0, batch 3170, batch avg loss 0.5057, total avg loss: 0.4757, batch size: 37
2021-08-24 18:20:58,956 INFO [train.py:450] Epoch 0, batch 3180, batch avg loss 0.5211, total avg loss: 0.4754, batch size: 39
2021-08-24 18:21:06,490 INFO [train.py:450] Epoch 0, batch 3190, batch avg loss 0.4023, total avg loss: 0.4749, batch size: 39
2021-08-24 18:21:14,485 INFO [train.py:450] Epoch 0, batch 3200, batch avg loss 0.4616, total avg loss: 0.4756, batch size: 41
2021-08-24 18:21:22,874 INFO [train.py:450] Epoch 0, batch 3210, batch avg loss 0.4345, total avg loss: 0.4727, batch size: 42
2021-08-24 18:21:30,685 INFO [train.py:450] Epoch 0, batch 3220, batch avg loss 0.5402, total avg loss: 0.4812, batch size: 39
2021-08-24 18:21:38,751 INFO [train.py:450] Epoch 0, batch 3230, batch avg loss 0.5009, total avg loss: 0.4832, batch size: 41
2021-08-24 18:21:46,599 INFO [train.py:450] Epoch 0, batch 3240, batch avg loss 0.4925, total avg loss: 0.4835, batch size: 41
2021-08-24 18:21:54,441 INFO [train.py:450] Epoch 0, batch 3250, batch avg loss 0.4672, total avg loss: 0.4829, batch size: 41
2021-08-24 18:22:02,775 INFO [train.py:450] Epoch 0, batch 3260, batch avg loss 0.4858, total avg loss: 0.4828, batch size: 39
2021-08-24 18:22:10,875 INFO [train.py:450] Epoch 0, batch 3270, batch avg loss 0.4807, total avg loss: 0.4844, batch size: 43
2021-08-24 18:22:18,956 INFO [train.py:450] Epoch 0, batch 3280, batch avg loss 0.5171, total avg loss: 0.4831, batch size: 43
2021-08-24 18:22:23,339 WARNING [cut.py:1694] To perform mix, energy must be non-zero and non-negative (got 0.0).  MonoCut with id "fb6fce01-1bd9-5b11-f8b9-4f4dcb341453" will not be mixed in.
2021-08-24 18:22:26,961 INFO [train.py:450] Epoch 0, batch 3290, batch avg loss 0.4398, total avg loss: 0.4828, batch size: 42
2021-08-24 18:22:34,904 INFO [train.py:450] Epoch 0, batch 3300, batch avg loss 0.5329, total avg loss: 0.4841, batch size: 39
2021-08-24 18:22:42,727 INFO [train.py:450] Epoch 0, batch 3310, batch avg loss 0.4443, total avg loss: 0.4828, batch size: 44
2021-08-24 18:22:51,056 INFO [train.py:450] Epoch 0, batch 3320, batch avg loss 0.5120, total avg loss: 0.4826, batch size: 36
2021-08-24 18:22:59,008 INFO [train.py:450] Epoch 0, batch 3330, batch avg loss 0.4206, total avg loss: 0.4822, batch size: 41
2021-08-24 18:23:06,590 INFO [train.py:450] Epoch 0, batch 3340, batch avg loss 0.4768, total avg loss: 0.4820, batch size: 37
2021-08-24 18:23:14,477 INFO [train.py:450] Epoch 0, batch 3350, batch avg loss 0.4797, total avg loss: 0.4819, batch size: 38
2021-08-24 18:23:22,161 INFO [train.py:450] Epoch 0, batch 3360, batch avg loss 0.4635, total avg loss: 0.4803, batch size: 42
2021-08-24 18:23:29,592 INFO [train.py:450] Epoch 0, batch 3370, batch avg loss 0.5024, total avg loss: 0.4805, batch size: 40
2021-08-24 18:23:37,438 INFO [train.py:450] Epoch 0, batch 3380, batch avg loss 0.5628, total avg loss: 0.4816, batch size: 44
2021-08-24 18:23:45,986 INFO [train.py:450] Epoch 0, batch 3390, batch avg loss 0.4642, total avg loss: 0.4815, batch size: 42
2021-08-24 18:23:53,728 INFO [train.py:450] Epoch 0, batch 3400, batch avg loss 0.4848, total avg loss: 0.4808, batch size: 40
2021-08-24 18:24:02,201 INFO [train.py:450] Epoch 0, batch 3410, batch avg loss 0.5091, total avg loss: 0.4852, batch size: 43
2021-08-24 18:24:10,012 INFO [train.py:450] Epoch 0, batch 3420, batch avg loss 0.5198, total avg loss: 0.4882, batch size: 36
2021-08-24 18:24:18,142 INFO [train.py:450] Epoch 0, batch 3430, batch avg loss 0.5087, total avg loss: 0.4828, batch size: 39
2021-08-24 18:24:25,771 INFO [train.py:450] Epoch 0, batch 3440, batch avg loss 0.4665, total avg loss: 0.4768, batch size: 38
2021-08-24 18:24:35,287 INFO [train.py:450] Epoch 0, batch 3450, batch avg loss 0.4646, total avg loss: 0.4769, batch size: 42
2021-08-24 18:24:42,870 INFO [train.py:450] Epoch 0, batch 3460, batch avg loss 0.5455, total avg loss: 0.4761, batch size: 39
2021-08-24 18:24:54,627 INFO [train.py:450] Epoch 0, batch 3470, batch avg loss 0.4607, total avg loss: 0.4771, batch size: 40
2021-08-24 18:25:02,756 INFO [train.py:450] Epoch 0, batch 3480, batch avg loss 0.4675, total avg loss: 0.4756, batch size: 37
2021-08-24 18:25:10,700 INFO [train.py:450] Epoch 0, batch 3490, batch avg loss 0.4035, total avg loss: 0.4743, batch size: 40
2021-08-24 18:25:18,584 INFO [train.py:450] Epoch 0, batch 3500, batch avg loss 0.4287, total avg loss: 0.4740, batch size: 38
2021-08-24 18:25:26,752 INFO [train.py:450] Epoch 0, batch 3510, batch avg loss 0.4881, total avg loss: 0.4738, batch size: 40
2021-08-24 18:25:34,231 INFO [train.py:450] Epoch 0, batch 3520, batch avg loss 0.4745, total avg loss: 0.4724, batch size: 37
2021-08-24 18:25:41,912 INFO [train.py:450] Epoch 0, batch 3530, batch avg loss 0.4489, total avg loss: 0.4718, batch size: 34
2021-08-24 18:25:50,089 INFO [train.py:450] Epoch 0, batch 3540, batch avg loss 0.5156, total avg loss: 0.4725, batch size: 41
2021-08-24 18:25:58,580 INFO [train.py:450] Epoch 0, batch 3550, batch avg loss 0.4797, total avg loss: 0.4734, batch size: 39
2021-08-24 18:26:05,945 INFO [train.py:450] Epoch 0, batch 3560, batch avg loss 0.4650, total avg loss: 0.4739, batch size: 41
2021-08-24 18:26:13,178 INFO [train.py:450] Epoch 0, batch 3570, batch avg loss 0.3928, total avg loss: 0.4736, batch size: 40
2021-08-24 18:26:21,165 INFO [train.py:450] Epoch 0, batch 3580, batch avg loss 0.4996, total avg loss: 0.4747, batch size: 42
2021-08-24 18:26:29,273 INFO [train.py:450] Epoch 0, batch 3590, batch avg loss 0.4259, total avg loss: 0.4746, batch size: 41
2021-08-24 18:26:37,297 INFO [train.py:450] Epoch 0, batch 3600, batch avg loss 0.5012, total avg loss: 0.4746, batch size: 42
2021-08-24 18:26:45,103 INFO [train.py:450] Epoch 0, batch 3610, batch avg loss 0.5052, total avg loss: 0.4757, batch size: 41
2021-08-24 18:26:52,668 INFO [train.py:450] Epoch 0, batch 3620, batch avg loss 0.4570, total avg loss: 0.4650, batch size: 43
2021-08-24 18:27:00,127 INFO [train.py:450] Epoch 0, batch 3630, batch avg loss 0.4276, total avg loss: 0.4683, batch size: 37
2021-08-24 18:27:07,847 INFO [train.py:450] Epoch 0, batch 3640, batch avg loss 0.4824, total avg loss: 0.4653, batch size: 41
2021-08-24 18:27:15,154 INFO [train.py:450] Epoch 0, batch 3650, batch avg loss 0.4298, total avg loss: 0.4630, batch size: 41
2021-08-24 18:27:22,714 INFO [train.py:450] Epoch 0, batch 3660, batch avg loss 0.4822, total avg loss: 0.4615, batch size: 39
2021-08-24 18:27:29,984 INFO [train.py:450] Epoch 0, batch 3670, batch avg loss 0.5146, total avg loss: 0.4626, batch size: 40
2021-08-24 18:27:38,162 INFO [train.py:450] Epoch 0, batch 3680, batch avg loss 0.4389, total avg loss: 0.4655, batch size: 42
2021-08-24 18:27:45,493 INFO [train.py:450] Epoch 0, batch 3690, batch avg loss 0.5356, total avg loss: 0.4669, batch size: 38
2021-08-24 18:27:53,201 INFO [train.py:450] Epoch 0, batch 3700, batch avg loss 0.5103, total avg loss: 0.4667, batch size: 40
2021-08-24 18:28:00,917 INFO [train.py:450] Epoch 0, batch 3710, batch avg loss 0.5002, total avg loss: 0.4660, batch size: 41
2021-08-24 18:28:08,338 INFO [train.py:450] Epoch 0, batch 3720, batch avg loss 0.5263, total avg loss: 0.4652, batch size: 40
2021-08-24 18:28:15,857 INFO [train.py:450] Epoch 0, batch 3730, batch avg loss 0.5052, total avg loss: 0.4644, batch size: 40
2021-08-24 18:28:23,510 INFO [train.py:450] Epoch 0, batch 3740, batch avg loss 0.4694, total avg loss: 0.4647, batch size: 42
2021-08-24 18:28:31,457 INFO [train.py:450] Epoch 0, batch 3750, batch avg loss 0.4396, total avg loss: 0.4655, batch size: 38
2021-08-24 18:28:39,160 INFO [train.py:450] Epoch 0, batch 3760, batch avg loss 0.4583, total avg loss: 0.4654, batch size: 40
2021-08-24 18:28:46,406 INFO [train.py:450] Epoch 0, batch 3770, batch avg loss 0.4666, total avg loss: 0.4652, batch size: 40
2021-08-24 18:28:53,604 INFO [train.py:450] Epoch 0, batch 3780, batch avg loss 0.4428, total avg loss: 0.4649, batch size: 41
2021-08-24 18:29:01,503 INFO [train.py:450] Epoch 0, batch 3790, batch avg loss 0.5331, total avg loss: 0.4659, batch size: 40
2021-08-24 18:29:08,837 INFO [train.py:450] Epoch 0, batch 3800, batch avg loss 0.4788, total avg loss: 0.4659, batch size: 43
2021-08-24 18:29:15,896 INFO [train.py:450] Epoch 0, batch 3810, batch avg loss 0.4476, total avg loss: 0.4563, batch size: 38
2021-08-24 18:29:23,313 INFO [train.py:450] Epoch 0, batch 3820, batch avg loss 0.4472, total avg loss: 0.4659, batch size: 37
2021-08-24 18:29:30,748 INFO [train.py:450] Epoch 0, batch 3830, batch avg loss 0.4945, total avg loss: 0.4631, batch size: 36
2021-08-24 18:29:38,405 INFO [train.py:450] Epoch 0, batch 3840, batch avg loss 0.4594, total avg loss: 0.4657, batch size: 41
2021-08-24 18:29:46,104 INFO [train.py:450] Epoch 0, batch 3850, batch avg loss 0.4509, total avg loss: 0.4663, batch size: 42
2021-08-24 18:29:55,255 INFO [train.py:450] Epoch 0, batch 3860, batch avg loss 0.4765, total avg loss: 0.4638, batch size: 41
2021-08-24 18:30:03,063 INFO [train.py:450] Epoch 0, batch 3870, batch avg loss 0.5040, total avg loss: 0.4680, batch size: 36
2021-08-24 18:30:13,169 INFO [train.py:450] Epoch 0, batch 3880, batch avg loss 0.4462, total avg loss: 0.4671, batch size: 41
2021-08-24 18:30:20,995 INFO [train.py:450] Epoch 0, batch 3890, batch avg loss 0.4547, total avg loss: 0.4675, batch size: 43
2021-08-24 18:30:29,019 INFO [train.py:450] Epoch 0, batch 3900, batch avg loss 0.5020, total avg loss: 0.4665, batch size: 42
2021-08-24 18:30:36,545 INFO [train.py:450] Epoch 0, batch 3910, batch avg loss 0.5285, total avg loss: 0.4662, batch size: 41
2021-08-24 18:30:44,271 INFO [train.py:450] Epoch 0, batch 3920, batch avg loss 0.4269, total avg loss: 0.4670, batch size: 37
2021-08-24 18:30:51,960 INFO [train.py:450] Epoch 0, batch 3930, batch avg loss 0.4035, total avg loss: 0.4662, batch size: 40
2021-08-24 18:30:59,540 INFO [train.py:450] Epoch 0, batch 3940, batch avg loss 0.4845, total avg loss: 0.4669, batch size: 41
2021-08-24 18:31:06,584 INFO [train.py:450] Epoch 0, batch 3950, batch avg loss 0.4621, total avg loss: 0.4672, batch size: 39
2021-08-24 18:31:14,117 INFO [train.py:450] Epoch 0, batch 3960, batch avg loss 0.4197, total avg loss: 0.4675, batch size: 40
2021-08-24 18:31:21,693 INFO [train.py:450] Epoch 0, batch 3970, batch avg loss 0.5409, total avg loss: 0.4692, batch size: 45
2021-08-24 18:31:28,647 INFO [train.py:450] Epoch 0, batch 3980, batch avg loss 0.4566, total avg loss: 0.4693, batch size: 39
2021-08-24 18:31:36,249 INFO [train.py:450] Epoch 0, batch 3990, batch avg loss 0.4610, total avg loss: 0.4696, batch size: 41
2021-08-24 18:31:43,438 INFO [train.py:450] Epoch 0, batch 4000, batch avg loss 0.4709, total avg loss: 0.4689, batch size: 41
2021-08-24 18:32:20,885 INFO [train.py:482] Epoch 0, valid loss 0.3513, best valid loss: 0.3513 best valid epoch: 0
2021-08-24 18:32:27,058 INFO [train.py:450] Epoch 0, batch 4010, batch avg loss 0.4324, total avg loss: 0.4818, batch size: 39
2021-08-24 18:32:34,502 INFO [train.py:450] Epoch 0, batch 4020, batch avg loss 0.4895, total avg loss: 0.4683, batch size: 42
2021-08-24 18:32:42,022 INFO [train.py:450] Epoch 0, batch 4030, batch avg loss 0.3969, total avg loss: 0.4652, batch size: 37
2021-08-24 18:32:49,687 INFO [train.py:450] Epoch 0, batch 4040, batch avg loss 0.4614, total avg loss: 0.4657, batch size: 42
2021-08-24 18:32:56,910 INFO [train.py:450] Epoch 0, batch 4050, batch avg loss 0.5073, total avg loss: 0.4650, batch size: 41
2021-08-24 18:33:04,156 INFO [train.py:450] Epoch 0, batch 4060, batch avg loss 0.4174, total avg loss: 0.4624, batch size: 36
2021-08-24 18:33:12,236 INFO [train.py:450] Epoch 0, batch 4070, batch avg loss 0.4583, total avg loss: 0.4593, batch size: 41
2021-08-24 18:33:19,801 INFO [train.py:450] Epoch 0, batch 4080, batch avg loss 0.4192, total avg loss: 0.4600, batch size: 40
2021-08-24 18:33:27,563 INFO [train.py:450] Epoch 0, batch 4090, batch avg loss 0.4326, total avg loss: 0.4590, batch size: 41
2021-08-24 18:33:35,035 INFO [train.py:450] Epoch 0, batch 4100, batch avg loss 0.5261, total avg loss: 0.4578, batch size: 40
2021-08-24 18:33:42,031 INFO [train.py:450] Epoch 0, batch 4110, batch avg loss 0.4574, total avg loss: 0.4591, batch size: 38
2021-08-24 18:33:49,572 INFO [train.py:450] Epoch 0, batch 4120, batch avg loss 0.5077, total avg loss: 0.4589, batch size: 42
2021-08-24 18:33:57,130 INFO [train.py:450] Epoch 0, batch 4130, batch avg loss 0.4220, total avg loss: 0.4597, batch size: 37
2021-08-24 18:34:04,228 INFO [train.py:450] Epoch 0, batch 4140, batch avg loss 0.4034, total avg loss: 0.4597, batch size: 38
2021-08-24 18:34:11,824 INFO [train.py:450] Epoch 0, batch 4150, batch avg loss 0.4758, total avg loss: 0.4605, batch size: 42
2021-08-24 18:34:19,365 INFO [train.py:450] Epoch 0, batch 4160, batch avg loss 0.4407, total avg loss: 0.4602, batch size: 41
2021-08-24 18:34:26,741 INFO [train.py:450] Epoch 0, batch 4170, batch avg loss 0.4491, total avg loss: 0.4596, batch size: 37
2021-08-24 18:34:33,879 INFO [train.py:450] Epoch 0, batch 4180, batch avg loss 0.3930, total avg loss: 0.4592, batch size: 39
2021-08-24 18:34:41,964 INFO [train.py:450] Epoch 0, batch 4190, batch avg loss 0.4914, total avg loss: 0.4598, batch size: 39
2021-08-24 18:34:50,665 INFO [train.py:450] Epoch 0, batch 4200, batch avg loss 0.4602, total avg loss: 0.4597, batch size: 39
2021-08-24 18:34:59,555 INFO [train.py:450] Epoch 0, batch 4210, batch avg loss 0.4313, total avg loss: 0.4571, batch size: 36
2021-08-24 18:35:08,397 INFO [train.py:450] Epoch 0, batch 4220, batch avg loss 0.4733, total avg loss: 0.4629, batch size: 38
2021-08-24 18:35:15,755 INFO [train.py:450] Epoch 0, batch 4230, batch avg loss 0.4343, total avg loss: 0.4670, batch size: 41
2021-08-24 18:35:23,009 INFO [train.py:450] Epoch 0, batch 4240, batch avg loss 0.4818, total avg loss: 0.4659, batch size: 37
2021-08-24 18:35:30,677 INFO [train.py:450] Epoch 0, batch 4250, batch avg loss 0.4521, total avg loss: 0.4657, batch size: 38
2021-08-24 18:35:38,184 INFO [train.py:450] Epoch 0, batch 4260, batch avg loss 0.4267, total avg loss: 0.4618, batch size: 40
2021-08-24 18:35:45,306 INFO [train.py:450] Epoch 0, batch 4270, batch avg loss 0.4837, total avg loss: 0.4611, batch size: 40
2021-08-24 18:35:52,667 INFO [train.py:450] Epoch 0, batch 4280, batch avg loss 0.5237, total avg loss: 0.4620, batch size: 43
2021-08-24 18:35:59,919 INFO [train.py:450] Epoch 0, batch 4290, batch avg loss 0.4245, total avg loss: 0.4601, batch size: 40
2021-08-24 18:36:07,083 INFO [train.py:450] Epoch 0, batch 4300, batch avg loss 0.4657, total avg loss: 0.4596, batch size: 37
2021-08-24 18:36:14,958 INFO [train.py:450] Epoch 0, batch 4310, batch avg loss 0.4986, total avg loss: 0.4586, batch size: 39
2021-08-24 18:36:22,353 INFO [train.py:450] Epoch 0, batch 4320, batch avg loss 0.4884, total avg loss: 0.4591, batch size: 42
2021-08-24 18:36:29,671 INFO [train.py:450] Epoch 0, batch 4330, batch avg loss 0.4320, total avg loss: 0.4588, batch size: 40
2021-08-24 18:36:36,206 INFO [train.py:450] Epoch 0, batch 4340, batch avg loss 0.5098, total avg loss: 0.4585, batch size: 40
2021-08-24 18:36:43,721 INFO [train.py:450] Epoch 0, batch 4350, batch avg loss 0.4422, total avg loss: 0.4585, batch size: 40
2021-08-24 18:36:51,235 INFO [train.py:450] Epoch 0, batch 4360, batch avg loss 0.4222, total avg loss: 0.4576, batch size: 39
2021-08-24 18:36:58,140 INFO [train.py:450] Epoch 0, batch 4370, batch avg loss 0.4394, total avg loss: 0.4580, batch size: 36
2021-08-24 18:37:05,340 INFO [train.py:450] Epoch 0, batch 4380, batch avg loss 0.4219, total avg loss: 0.4582, batch size: 41
2021-08-24 18:37:07,112 WARNING [cut.py:1694] To perform mix, energy must be non-zero and non-negative (got 0.0).  MonoCut with id "73ab4477-b7cc-8f45-4043-abfcb8f9d25a" will not be mixed in.
2021-08-24 18:37:12,679 INFO [train.py:450] Epoch 0, batch 4390, batch avg loss 0.5217, total avg loss: 0.4577, batch size: 36
2021-08-24 18:37:19,997 INFO [train.py:450] Epoch 0, batch 4400, batch avg loss 0.4502, total avg loss: 0.4586, batch size: 39
2021-08-24 18:37:27,457 INFO [train.py:450] Epoch 0, batch 4410, batch avg loss 0.4248, total avg loss: 0.4560, batch size: 38
2021-08-24 18:37:34,782 INFO [train.py:450] Epoch 0, batch 4420, batch avg loss 0.4133, total avg loss: 0.4463, batch size: 35
2021-08-24 18:37:42,432 INFO [train.py:450] Epoch 0, batch 4430, batch avg loss 0.5269, total avg loss: 0.4540, batch size: 41
2021-08-24 18:37:49,885 INFO [train.py:450] Epoch 0, batch 4440, batch avg loss 0.4599, total avg loss: 0.4561, batch size: 38
2021-08-24 18:37:57,333 INFO [train.py:450] Epoch 0, batch 4450, batch avg loss 0.4711, total avg loss: 0.4579, batch size: 39
2021-08-24 18:38:04,703 INFO [train.py:450] Epoch 0, batch 4460, batch avg loss 0.4557, total avg loss: 0.4589, batch size: 40
2021-08-24 18:38:12,160 INFO [train.py:450] Epoch 0, batch 4470, batch avg loss 0.4567, total avg loss: 0.4585, batch size: 40
2021-08-24 18:38:20,060 INFO [train.py:450] Epoch 0, batch 4480, batch avg loss 0.4339, total avg loss: 0.4590, batch size: 37
2021-08-24 18:38:27,171 INFO [train.py:450] Epoch 0, batch 4490, batch avg loss 0.4194, total avg loss: 0.4579, batch size: 41
2021-08-24 18:38:34,727 INFO [train.py:450] Epoch 0, batch 4500, batch avg loss 0.4901, total avg loss: 0.4570, batch size: 39
2021-08-24 18:38:42,312 INFO [train.py:450] Epoch 0, batch 4510, batch avg loss 0.4456, total avg loss: 0.4568, batch size: 42
2021-08-24 18:38:49,610 INFO [train.py:450] Epoch 0, batch 4520, batch avg loss 0.4298, total avg loss: 0.4565, batch size: 41
2021-08-24 18:38:56,911 INFO [train.py:450] Epoch 0, batch 4530, batch avg loss 0.4522, total avg loss: 0.4563, batch size: 41
2021-08-24 18:39:03,966 INFO [train.py:450] Epoch 0, batch 4540, batch avg loss 0.4861, total avg loss: 0.4567, batch size: 42
2021-08-24 18:39:11,849 INFO [train.py:450] Epoch 0, batch 4550, batch avg loss 0.4044, total avg loss: 0.4567, batch size: 38
2021-08-24 18:39:19,745 INFO [train.py:450] Epoch 0, batch 4560, batch avg loss 0.4286, total avg loss: 0.4565, batch size: 40
2021-08-24 18:39:28,101 INFO [train.py:450] Epoch 0, batch 4570, batch avg loss 0.4611, total avg loss: 0.4567, batch size: 40
2021-08-24 18:39:35,929 INFO [train.py:450] Epoch 0, batch 4580, batch avg loss 0.4359, total avg loss: 0.4557, batch size: 39
2021-08-24 18:39:44,052 INFO [train.py:450] Epoch 0, batch 4590, batch avg loss 0.4156, total avg loss: 0.4553, batch size: 40
2021-08-24 18:39:54,328 INFO [train.py:450] Epoch 0, batch 4600, batch avg loss 0.5279, total avg loss: 0.4556, batch size: 41
2021-08-24 18:40:04,656 INFO [train.py:450] Epoch 0, batch 4610, batch avg loss 0.4123, total avg loss: 0.4349, batch size: 40
2021-08-24 18:40:14,780 INFO [train.py:450] Epoch 0, batch 4620, batch avg loss 0.4694, total avg loss: 0.4444, batch size: 42
2021-08-24 18:40:23,389 INFO [train.py:450] Epoch 0, batch 4630, batch avg loss 0.4576, total avg loss: 0.4429, batch size: 44
2021-08-24 18:40:31,417 INFO [train.py:450] Epoch 0, batch 4640, batch avg loss 0.4906, total avg loss: 0.4444, batch size: 40
2021-08-24 18:40:39,511 INFO [train.py:450] Epoch 0, batch 4650, batch avg loss 0.4625, total avg loss: 0.4437, batch size: 36
2021-08-24 18:40:47,758 INFO [train.py:450] Epoch 0, batch 4660, batch avg loss 0.3848, total avg loss: 0.4455, batch size: 38
2021-08-24 18:40:56,875 INFO [train.py:450] Epoch 0, batch 4670, batch avg loss 0.4550, total avg loss: 0.4480, batch size: 40
2021-08-24 18:41:05,022 INFO [train.py:450] Epoch 0, batch 4680, batch avg loss 0.4576, total avg loss: 0.4483, batch size: 40
2021-08-24 18:41:13,308 INFO [train.py:450] Epoch 0, batch 4690, batch avg loss 0.4949, total avg loss: 0.4469, batch size: 42
2021-08-24 18:41:21,263 INFO [train.py:450] Epoch 0, batch 4700, batch avg loss 0.4788, total avg loss: 0.4480, batch size: 39
2021-08-24 18:41:29,177 INFO [train.py:450] Epoch 0, batch 4710, batch avg loss 0.5135, total avg loss: 0.4493, batch size: 35
2021-08-24 18:41:37,283 INFO [train.py:450] Epoch 0, batch 4720, batch avg loss 0.4204, total avg loss: 0.4495, batch size: 38
2021-08-24 18:41:45,148 INFO [train.py:450] Epoch 0, batch 4730, batch avg loss 0.4637, total avg loss: 0.4497, batch size: 38
2021-08-24 18:41:53,054 INFO [train.py:450] Epoch 0, batch 4740, batch avg loss 0.4774, total avg loss: 0.4491, batch size: 40
2021-08-24 18:42:00,914 INFO [train.py:450] Epoch 0, batch 4750, batch avg loss 0.4135, total avg loss: 0.4477, batch size: 39
2021-08-24 18:42:09,004 INFO [train.py:450] Epoch 0, batch 4760, batch avg loss 0.4037, total avg loss: 0.4476, batch size: 41
2021-08-24 18:42:17,100 INFO [train.py:450] Epoch 0, batch 4770, batch avg loss 0.4354, total avg loss: 0.4463, batch size: 40
2021-08-24 18:42:25,070 INFO [train.py:450] Epoch 0, batch 4780, batch avg loss 0.4969, total avg loss: 0.4459, batch size: 43
2021-08-24 18:42:32,714 INFO [train.py:450] Epoch 0, batch 4790, batch avg loss 0.4294, total avg loss: 0.4457, batch size: 44
2021-08-24 18:42:39,740 INFO [train.py:450] Epoch 0, batch 4800, batch avg loss 0.4162, total avg loss: 0.4446, batch size: 40
2021-08-24 18:42:47,641 INFO [train.py:450] Epoch 0, batch 4810, batch avg loss 0.4778, total avg loss: 0.4385, batch size: 41
2021-08-24 18:42:55,652 INFO [train.py:450] Epoch 0, batch 4820, batch avg loss 0.5025, total avg loss: 0.4366, batch size: 35
2021-08-24 18:43:03,130 INFO [train.py:450] Epoch 0, batch 4830, batch avg loss 0.4712, total avg loss: 0.4356, batch size: 38
2021-08-24 18:43:10,689 INFO [train.py:450] Epoch 0, batch 4840, batch avg loss 0.3942, total avg loss: 0.4314, batch size: 42
2021-08-24 18:43:18,723 INFO [train.py:450] Epoch 0, batch 4850, batch avg loss 0.4575, total avg loss: 0.4359, batch size: 39
2021-08-24 18:43:26,058 INFO [train.py:450] Epoch 0, batch 4860, batch avg loss 0.3793, total avg loss: 0.4344, batch size: 36
2021-08-24 18:43:33,438 INFO [train.py:450] Epoch 0, batch 4870, batch avg loss 0.3942, total avg loss: 0.4370, batch size: 42
2021-08-24 18:43:41,231 INFO [train.py:450] Epoch 0, batch 4880, batch avg loss 0.4241, total avg loss: 0.4369, batch size: 40
2021-08-24 18:43:49,448 INFO [train.py:450] Epoch 0, batch 4890, batch avg loss 0.4786, total avg loss: 0.4383, batch size: 37
2021-08-24 18:43:56,867 INFO [train.py:450] Epoch 0, batch 4900, batch avg loss 0.4088, total avg loss: 0.4378, batch size: 40
2021-08-24 18:44:04,575 INFO [train.py:450] Epoch 0, batch 4910, batch avg loss 0.4221, total avg loss: 0.4386, batch size: 42
2021-08-24 18:44:11,771 INFO [train.py:450] Epoch 0, batch 4920, batch avg loss 0.4661, total avg loss: 0.4390, batch size: 38
2021-08-24 18:44:19,189 INFO [train.py:450] Epoch 0, batch 4930, batch avg loss 0.5092, total avg loss: 0.4401, batch size: 38
2021-08-24 18:44:27,061 INFO [train.py:450] Epoch 0, batch 4940, batch avg loss 0.3948, total avg loss: 0.4410, batch size: 42
2021-08-24 18:44:34,477 INFO [train.py:450] Epoch 0, batch 4950, batch avg loss 0.3779, total avg loss: 0.4406, batch size: 38
2021-08-24 18:44:42,193 INFO [train.py:450] Epoch 0, batch 4960, batch avg loss 0.3894, total avg loss: 0.4402, batch size: 37
2021-08-24 18:44:51,384 INFO [train.py:450] Epoch 0, batch 4970, batch avg loss 0.4773, total avg loss: 0.4408, batch size: 40
2021-08-24 18:44:58,959 INFO [train.py:450] Epoch 0, batch 4980, batch avg loss 0.4652, total avg loss: 0.4412, batch size: 39
2021-08-24 18:45:10,028 INFO [train.py:450] Epoch 0, batch 4990, batch avg loss 0.4103, total avg loss: 0.4410, batch size: 42
2021-08-24 18:45:17,681 INFO [train.py:450] Epoch 0, batch 5000, batch avg loss 0.3881, total avg loss: 0.4413, batch size: 39
2021-08-24 18:45:56,248 INFO [train.py:482] Epoch 0, valid loss 0.3312, best valid loss: 0.3312 best valid epoch: 0
2021-08-24 18:46:02,464 INFO [train.py:450] Epoch 0, batch 5010, batch avg loss 0.4256, total avg loss: 0.4380, batch size: 41
2021-08-24 18:46:10,509 INFO [train.py:450] Epoch 0, batch 5020, batch avg loss 0.4477, total avg loss: 0.4452, batch size: 40
2021-08-24 18:46:18,423 INFO [train.py:450] Epoch 0, batch 5030, batch avg loss 0.3785, total avg loss: 0.4530, batch size: 41
2021-08-24 18:46:26,194 INFO [train.py:450] Epoch 0, batch 5040, batch avg loss 0.4641, total avg loss: 0.4491, batch size: 42
2021-08-24 18:46:34,260 INFO [train.py:450] Epoch 0, batch 5050, batch avg loss 0.4475, total avg loss: 0.4491, batch size: 42
2021-08-24 18:46:41,706 INFO [train.py:450] Epoch 0, batch 5060, batch avg loss 0.4386, total avg loss: 0.4508, batch size: 40
2021-08-24 18:46:49,276 INFO [train.py:450] Epoch 0, batch 5070, batch avg loss 0.4271, total avg loss: 0.4485, batch size: 43
2021-08-24 18:46:56,236 INFO [train.py:450] Epoch 0, batch 5080, batch avg loss 0.4392, total avg loss: 0.4485, batch size: 38
2021-08-24 18:47:03,591 INFO [train.py:450] Epoch 0, batch 5090, batch avg loss 0.4830, total avg loss: 0.4498, batch size: 38
2021-08-24 18:47:11,551 INFO [train.py:450] Epoch 0, batch 5100, batch avg loss 0.4442, total avg loss: 0.4483, batch size: 38
2021-08-24 18:47:19,012 INFO [train.py:450] Epoch 0, batch 5110, batch avg loss 0.4041, total avg loss: 0.4469, batch size: 38
2021-08-24 18:47:26,550 INFO [train.py:450] Epoch 0, batch 5120, batch avg loss 0.4020, total avg loss: 0.4511, batch size: 43
2021-08-24 18:47:34,081 INFO [train.py:450] Epoch 0, batch 5130, batch avg loss 0.3906, total avg loss: 0.4494, batch size: 38
2021-08-24 18:47:41,515 INFO [train.py:450] Epoch 0, batch 5140, batch avg loss 0.4505, total avg loss: 0.4479, batch size: 38
2021-08-24 18:47:49,264 INFO [train.py:450] Epoch 0, batch 5150, batch avg loss 0.5146, total avg loss: 0.4480, batch size: 41
2021-08-24 18:47:56,670 INFO [train.py:450] Epoch 0, batch 5160, batch avg loss 0.4764, total avg loss: 0.4482, batch size: 40
2021-08-24 18:48:03,905 INFO [train.py:450] Epoch 0, batch 5170, batch avg loss 0.4016, total avg loss: 0.4478, batch size: 37
2021-08-24 18:48:11,124 INFO [train.py:450] Epoch 0, batch 5180, batch avg loss 0.3862, total avg loss: 0.4463, batch size: 37
2021-08-24 18:48:18,465 INFO [train.py:450] Epoch 0, batch 5190, batch avg loss 0.3904, total avg loss: 0.4451, batch size: 38
2021-08-24 18:48:25,574 INFO [train.py:450] Epoch 0, batch 5200, batch avg loss 0.4244, total avg loss: 0.4444, batch size: 41
2021-08-24 18:48:32,763 INFO [train.py:450] Epoch 0, batch 5210, batch avg loss 0.4394, total avg loss: 0.4502, batch size: 44
2021-08-24 18:48:39,856 INFO [train.py:450] Epoch 0, batch 5220, batch avg loss 0.4828, total avg loss: 0.4472, batch size: 41
2021-08-24 18:48:47,087 INFO [train.py:450] Epoch 0, batch 5230, batch avg loss 0.4438, total avg loss: 0.4488, batch size: 37
2021-08-24 18:48:54,376 INFO [train.py:450] Epoch 0, batch 5240, batch avg loss 0.4417, total avg loss: 0.4485, batch size: 38
2021-08-24 18:49:01,319 INFO [train.py:450] Epoch 0, batch 5250, batch avg loss 0.4588, total avg loss: 0.4507, batch size: 38
2021-08-24 18:49:08,620 INFO [train.py:450] Epoch 0, batch 5260, batch avg loss 0.4207, total avg loss: 0.4494, batch size: 36
2021-08-24 18:49:16,035 INFO [train.py:450] Epoch 0, batch 5270, batch avg loss 0.4370, total avg loss: 0.4509, batch size: 42
2021-08-24 18:49:23,309 INFO [train.py:450] Epoch 0, batch 5280, batch avg loss 0.4643, total avg loss: 0.4501, batch size: 38
2021-08-24 18:49:30,597 INFO [train.py:450] Epoch 0, batch 5290, batch avg loss 0.4280, total avg loss: 0.4482, batch size: 41
2021-08-24 18:49:37,949 INFO [train.py:450] Epoch 0, batch 5300, batch avg loss 0.4296, total avg loss: 0.4481, batch size: 40
2021-08-24 18:49:38,433 WARNING [cut.py:1694] To perform mix, energy must be non-zero and non-negative (got 0.0).  MonoCut with id "d59c717a-feba-0ed7-c53d-c0072597db23" will not be mixed in.
2021-08-24 18:49:45,476 INFO [train.py:450] Epoch 0, batch 5310, batch avg loss 0.4625, total avg loss: 0.4480, batch size: 41
2021-08-24 18:49:52,320 INFO [train.py:450] Epoch 0, batch 5320, batch avg loss 0.4209, total avg loss: 0.4475, batch size: 39
2021-08-24 18:50:01,032 INFO [train.py:450] Epoch 0, batch 5330, batch avg loss 0.4017, total avg loss: 0.4467, batch size: 39
2021-08-24 18:50:08,053 INFO [train.py:450] Epoch 0, batch 5340, batch avg loss 0.4174, total avg loss: 0.4452, batch size: 42
2021-08-24 18:50:18,573 INFO [train.py:450] Epoch 0, batch 5350, batch avg loss 0.4813, total avg loss: 0.4454, batch size: 42
2021-08-24 18:50:26,195 INFO [train.py:450] Epoch 0, batch 5360, batch avg loss 0.4252, total avg loss: 0.4448, batch size: 38
2021-08-24 18:50:34,178 INFO [train.py:450] Epoch 0, batch 5370, batch avg loss 0.5154, total avg loss: 0.4450, batch size: 38
2021-08-24 18:50:40,911 INFO [train.py:450] Epoch 0, batch 5380, batch avg loss 0.4515, total avg loss: 0.4450, batch size: 37
2021-08-24 18:50:48,065 INFO [train.py:450] Epoch 0, batch 5390, batch avg loss 0.4493, total avg loss: 0.4445, batch size: 38
2021-08-24 18:50:55,162 INFO [train.py:450] Epoch 0, batch 5400, batch avg loss 0.4092, total avg loss: 0.4439, batch size: 45
2021-08-24 18:51:02,071 INFO [train.py:450] Epoch 0, batch 5410, batch avg loss 0.4362, total avg loss: 0.4408, batch size: 41
2021-08-24 18:51:09,523 INFO [train.py:450] Epoch 0, batch 5420, batch avg loss 0.3932, total avg loss: 0.4395, batch size: 41
2021-08-24 18:51:16,660 INFO [train.py:450] Epoch 0, batch 5430, batch avg loss 0.3785, total avg loss: 0.4446, batch size: 40
2021-08-24 18:51:24,818 INFO [train.py:450] Epoch 0, batch 5440, batch avg loss 0.3880, total avg loss: 0.4371, batch size: 36
2021-08-24 18:51:32,046 INFO [train.py:450] Epoch 0, batch 5450, batch avg loss 0.4558, total avg loss: 0.4370, batch size: 41
2021-08-24 18:51:39,041 INFO [train.py:450] Epoch 0, batch 5460, batch avg loss 0.4264, total avg loss: 0.4380, batch size: 41
2021-08-24 18:51:45,982 INFO [train.py:450] Epoch 0, batch 5470, batch avg loss 0.4138, total avg loss: 0.4390, batch size: 41
2021-08-24 18:51:53,182 INFO [train.py:450] Epoch 0, batch 5480, batch avg loss 0.4746, total avg loss: 0.4391, batch size: 38
2021-08-24 18:52:00,828 INFO [train.py:450] Epoch 0, batch 5490, batch avg loss 0.4268, total avg loss: 0.4379, batch size: 41
2021-08-24 18:52:08,261 INFO [train.py:450] Epoch 0, batch 5500, batch avg loss 0.3985, total avg loss: 0.4370, batch size: 40
2021-08-24 18:52:15,085 INFO [train.py:450] Epoch 0, batch 5510, batch avg loss 0.4759, total avg loss: 0.4376, batch size: 40
2021-08-24 18:52:22,193 INFO [train.py:450] Epoch 0, batch 5520, batch avg loss 0.4286, total avg loss: 0.4383, batch size: 40
2021-08-24 18:52:29,383 INFO [train.py:450] Epoch 0, batch 5530, batch avg loss 0.4179, total avg loss: 0.4391, batch size: 36
2021-08-24 18:52:37,215 INFO [train.py:450] Epoch 0, batch 5540, batch avg loss 0.3974, total avg loss: 0.4385, batch size: 41
2021-08-24 18:52:44,721 INFO [train.py:450] Epoch 0, batch 5550, batch avg loss 0.4295, total avg loss: 0.4387, batch size: 43
2021-08-24 18:52:52,269 INFO [train.py:450] Epoch 0, batch 5560, batch avg loss 0.4139, total avg loss: 0.4395, batch size: 42
2021-08-24 18:52:59,810 INFO [train.py:450] Epoch 0, batch 5570, batch avg loss 0.5002, total avg loss: 0.4406, batch size: 41
2021-08-24 18:53:07,538 INFO [train.py:450] Epoch 0, batch 5580, batch avg loss 0.4126, total avg loss: 0.4407, batch size: 42
2021-08-24 18:53:14,871 INFO [train.py:450] Epoch 0, batch 5590, batch avg loss 0.4030, total avg loss: 0.4408, batch size: 41
2021-08-24 18:53:22,140 INFO [train.py:450] Epoch 0, batch 5600, batch avg loss 0.3988, total avg loss: 0.4414, batch size: 40
2021-08-24 18:53:29,727 INFO [train.py:450] Epoch 0, batch 5610, batch avg loss 0.5333, total avg loss: 0.4506, batch size: 43
2021-08-24 18:53:36,837 INFO [train.py:450] Epoch 0, batch 5620, batch avg loss 0.4776, total avg loss: 0.4480, batch size: 41
2021-08-24 18:53:44,040 INFO [train.py:450] Epoch 0, batch 5630, batch avg loss 0.4582, total avg loss: 0.4431, batch size: 40
2021-08-24 18:53:52,180 INFO [train.py:450] Epoch 0, batch 5640, batch avg loss 0.4974, total avg loss: 0.4444, batch size: 39
2021-08-24 18:54:00,406 INFO [train.py:450] Epoch 0, batch 5650, batch avg loss 0.5521, total avg loss: 0.4454, batch size: 41
2021-08-24 18:54:07,870 INFO [train.py:450] Epoch 0, batch 5660, batch avg loss 0.4364, total avg loss: 0.4466, batch size: 40
2021-08-24 18:54:15,645 INFO [train.py:450] Epoch 0, batch 5670, batch avg loss 0.3772, total avg loss: 0.4437, batch size: 36
2021-08-24 18:54:23,233 INFO [train.py:450] Epoch 0, batch 5680, batch avg loss 0.4111, total avg loss: 0.4421, batch size: 36
2021-08-24 18:54:30,784 INFO [train.py:450] Epoch 0, batch 5690, batch avg loss 0.4200, total avg loss: 0.4415, batch size: 41
2021-08-24 18:54:38,522 INFO [train.py:450] Epoch 0, batch 5700, batch avg loss 0.4702, total avg loss: 0.4406, batch size: 40
2021-08-24 18:54:45,818 INFO [train.py:450] Epoch 0, batch 5710, batch avg loss 0.4236, total avg loss: 0.4404, batch size: 37
2021-08-24 18:54:52,959 INFO [train.py:450] Epoch 0, batch 5720, batch avg loss 0.3918, total avg loss: 0.4410, batch size: 38
2021-08-24 18:55:00,796 INFO [train.py:450] Epoch 0, batch 5730, batch avg loss 0.4292, total avg loss: 0.4400, batch size: 39
2021-08-24 18:55:09,420 INFO [train.py:450] Epoch 0, batch 5740, batch avg loss 0.4064, total avg loss: 0.4391, batch size: 37
2021-08-24 18:55:16,931 INFO [train.py:450] Epoch 0, batch 5750, batch avg loss 0.4673, total avg loss: 0.4390, batch size: 39
2021-08-24 18:55:27,748 INFO [train.py:450] Epoch 0, batch 5760, batch avg loss 0.4799, total avg loss: 0.4384, batch size: 40
2021-08-24 18:55:34,637 INFO [train.py:450] Epoch 0, batch 5770, batch avg loss 0.4706, total avg loss: 0.4373, batch size: 38
2021-08-24 18:55:41,728 INFO [train.py:450] Epoch 0, batch 5780, batch avg loss 0.4619, total avg loss: 0.4374, batch size: 39
2021-08-24 18:55:49,124 INFO [train.py:450] Epoch 0, batch 5790, batch avg loss 0.4501, total avg loss: 0.4375, batch size: 40
2021-08-24 18:55:57,424 INFO [train.py:450] Epoch 0, batch 5800, batch avg loss 0.4305, total avg loss: 0.4376, batch size: 39
2021-08-24 18:56:04,803 INFO [train.py:450] Epoch 0, batch 5810, batch avg loss 0.4417, total avg loss: 0.4336, batch size: 40
2021-08-24 18:56:12,358 INFO [train.py:450] Epoch 0, batch 5820, batch avg loss 0.4164, total avg loss: 0.4448, batch size: 43
2021-08-24 18:56:20,093 INFO [train.py:450] Epoch 0, batch 5830, batch avg loss 0.3735, total avg loss: 0.4384, batch size: 42
2021-08-24 18:56:27,075 INFO [train.py:450] Epoch 0, batch 5840, batch avg loss 0.4489, total avg loss: 0.4402, batch size: 40
2021-08-24 18:56:34,609 INFO [train.py:450] Epoch 0, batch 5850, batch avg loss 0.4304, total avg loss: 0.4366, batch size: 38
2021-08-24 18:56:41,526 INFO [train.py:450] Epoch 0, batch 5860, batch avg loss 0.4358, total avg loss: 0.4364, batch size: 44
2021-08-24 18:56:48,472 INFO [train.py:450] Epoch 0, batch 5870, batch avg loss 0.4274, total avg loss: 0.4378, batch size: 38
2021-08-24 18:56:55,420 INFO [train.py:450] Epoch 0, batch 5880, batch avg loss 0.4141, total avg loss: 0.4373, batch size: 43
2021-08-24 18:57:02,632 INFO [train.py:450] Epoch 0, batch 5890, batch avg loss 0.3917, total avg loss: 0.4383, batch size: 40
2021-08-24 18:57:10,170 INFO [train.py:450] Epoch 0, batch 5900, batch avg loss 0.4259, total avg loss: 0.4388, batch size: 43
2021-08-24 18:57:17,539 INFO [train.py:450] Epoch 0, batch 5910, batch avg loss 0.4973, total avg loss: 0.4386, batch size: 44
2021-08-24 18:57:25,145 INFO [train.py:450] Epoch 0, batch 5920, batch avg loss 0.4387, total avg loss: 0.4377, batch size: 39
2021-08-24 18:57:32,549 INFO [train.py:450] Epoch 0, batch 5930, batch avg loss 0.4602, total avg loss: 0.4382, batch size: 40
2021-08-24 18:57:37,923 WARNING [cut.py:1694] To perform mix, energy must be non-zero and non-negative (got 0.0).  MonoCut with id "8196ab58-e5ef-a70b-b574-33dcb48db840" will not be mixed in.
2021-08-24 18:57:40,081 INFO [train.py:450] Epoch 0, batch 5940, batch avg loss 0.3763, total avg loss: 0.4380, batch size: 36
2021-08-24 18:57:47,208 INFO [train.py:450] Epoch 0, batch 5950, batch avg loss 0.5004, total avg loss: 0.4373, batch size: 37
2021-08-24 18:57:54,625 INFO [train.py:450] Epoch 0, batch 5960, batch avg loss 0.4590, total avg loss: 0.4366, batch size: 42
2021-08-24 18:58:01,902 INFO [train.py:450] Epoch 0, batch 5970, batch avg loss 0.4081, total avg loss: 0.4360, batch size: 41
2021-08-24 18:58:09,202 INFO [train.py:450] Epoch 0, batch 5980, batch avg loss 0.3895, total avg loss: 0.4359, batch size: 39
2021-08-24 18:58:17,263 INFO [train.py:450] Epoch 0, batch 5990, batch avg loss 0.3823, total avg loss: 0.4358, batch size: 40
2021-08-24 18:58:24,683 INFO [train.py:450] Epoch 0, batch 6000, batch avg loss 0.3969, total avg loss: 0.4349, batch size: 37
2021-08-24 18:59:02,537 INFO [train.py:482] Epoch 0, valid loss 0.3209, best valid loss: 0.3209 best valid epoch: 0
2021-08-24 18:59:08,432 INFO [train.py:450] Epoch 0, batch 6010, batch avg loss 0.4318, total avg loss: 0.4487, batch size: 41
2021-08-24 18:59:15,678 INFO [train.py:450] Epoch 0, batch 6020, batch avg loss 0.4505, total avg loss: 0.4475, batch size: 41
2021-08-24 18:59:22,643 INFO [train.py:450] Epoch 0, batch 6030, batch avg loss 0.4270, total avg loss: 0.4421, batch size: 40
2021-08-24 18:59:30,613 INFO [train.py:450] Epoch 0, batch 6040, batch avg loss 0.4023, total avg loss: 0.4399, batch size: 37
2021-08-24 18:59:37,926 INFO [train.py:450] Epoch 0, batch 6050, batch avg loss 0.4199, total avg loss: 0.4332, batch size: 42
2021-08-24 18:59:45,382 INFO [train.py:450] Epoch 0, batch 6060, batch avg loss 0.3825, total avg loss: 0.4354, batch size: 41
2021-08-24 18:59:52,898 INFO [train.py:450] Epoch 0, batch 6070, batch avg loss 0.4799, total avg loss: 0.4360, batch size: 39
2021-08-24 19:00:00,459 INFO [train.py:450] Epoch 0, batch 6080, batch avg loss 0.4311, total avg loss: 0.4374, batch size: 39
2021-08-24 19:00:07,830 INFO [train.py:450] Epoch 0, batch 6090, batch avg loss 0.4218, total avg loss: 0.4375, batch size: 40
2021-08-24 19:00:15,426 INFO [train.py:450] Epoch 0, batch 6100, batch avg loss 0.4588, total avg loss: 0.4386, batch size: 37
2021-08-24 19:00:22,592 INFO [train.py:450] Epoch 0, batch 6110, batch avg loss 0.3976, total avg loss: 0.4373, batch size: 40
2021-08-24 19:00:30,768 INFO [train.py:450] Epoch 0, batch 6120, batch avg loss 0.4212, total avg loss: 0.4373, batch size: 39
2021-08-24 19:00:40,008 INFO [train.py:450] Epoch 0, batch 6130, batch avg loss 0.4442, total avg loss: 0.4367, batch size: 39
2021-08-24 19:00:49,324 INFO [train.py:450] Epoch 0, batch 6140, batch avg loss 0.4836, total avg loss: 0.4368, batch size: 40
2021-08-24 19:00:56,770 INFO [train.py:450] Epoch 0, batch 6150, batch avg loss 0.4000, total avg loss: 0.4361, batch size: 40
2021-08-24 19:01:04,711 INFO [train.py:450] Epoch 0, batch 6160, batch avg loss 0.4239, total avg loss: 0.4350, batch size: 42
2021-08-24 19:01:12,152 INFO [train.py:450] Epoch 0, batch 6170, batch avg loss 0.4500, total avg loss: 0.4340, batch size: 39
2021-08-24 19:01:19,794 INFO [train.py:450] Epoch 0, batch 6180, batch avg loss 0.4402, total avg loss: 0.4338, batch size: 41
2021-08-24 19:01:26,696 INFO [train.py:450] Epoch 0, batch 6190, batch avg loss 0.4079, total avg loss: 0.4327, batch size: 38
2021-08-24 19:01:33,879 INFO [train.py:450] Epoch 0, batch 6200, batch avg loss 0.3928, total avg loss: 0.4313, batch size: 39
2021-08-24 19:01:41,150 INFO [train.py:450] Epoch 0, batch 6210, batch avg loss 0.3823, total avg loss: 0.4346, batch size: 40
2021-08-24 19:01:48,043 INFO [train.py:450] Epoch 0, batch 6220, batch avg loss 0.4722, total avg loss: 0.4370, batch size: 45
2021-08-24 19:01:55,863 INFO [train.py:450] Epoch 0, batch 6230, batch avg loss 0.4182, total avg loss: 0.4349, batch size: 41
2021-08-24 19:02:03,088 INFO [train.py:450] Epoch 0, batch 6240, batch avg loss 0.4815, total avg loss: 0.4364, batch size: 40
2021-08-24 19:02:10,495 INFO [train.py:450] Epoch 0, batch 6250, batch avg loss 0.3704, total avg loss: 0.4349, batch size: 40
2021-08-24 19:02:17,991 INFO [train.py:450] Epoch 0, batch 6260, batch avg loss 0.4001, total avg loss: 0.4344, batch size: 39
2021-08-24 19:02:25,863 INFO [train.py:450] Epoch 0, batch 6270, batch avg loss 0.4568, total avg loss: 0.4348, batch size: 39
2021-08-24 19:02:33,677 INFO [train.py:450] Epoch 0, batch 6280, batch avg loss 0.4750, total avg loss: 0.4325, batch size: 38
2021-08-24 19:02:40,856 INFO [train.py:450] Epoch 0, batch 6290, batch avg loss 0.4533, total avg loss: 0.4295, batch size: 37
2021-08-24 19:02:48,744 INFO [train.py:450] Epoch 0, batch 6300, batch avg loss 0.4872, total avg loss: 0.4306, batch size: 41
2021-08-24 19:02:56,319 INFO [train.py:450] Epoch 0, batch 6310, batch avg loss 0.3830, total avg loss: 0.4301, batch size: 39
2021-08-24 19:03:03,567 INFO [train.py:450] Epoch 0, batch 6320, batch avg loss 0.4502, total avg loss: 0.4310, batch size: 39
2021-08-24 19:03:10,765 INFO [train.py:450] Epoch 0, batch 6330, batch avg loss 0.4632, total avg loss: 0.4315, batch size: 39
2021-08-24 19:03:18,055 INFO [train.py:450] Epoch 0, batch 6340, batch avg loss 0.4487, total avg loss: 0.4316, batch size: 40
2021-08-24 19:03:25,021 INFO [train.py:450] Epoch 0, batch 6350, batch avg loss 0.4819, total avg loss: 0.4311, batch size: 39
2021-08-24 19:03:28,941 WARNING [cut.py:1694] To perform mix, energy must be non-zero and non-negative (got 0.0).  MonoCut with id "59146992-bf53-dbdd-a69b-44cb438890cc" will not be mixed in.
2021-08-24 19:03:32,611 INFO [train.py:450] Epoch 0, batch 6360, batch avg loss 0.4428, total avg loss: 0.4310, batch size: 41
2021-08-24 19:03:40,283 INFO [train.py:450] Epoch 0, batch 6370, batch avg loss 0.3904, total avg loss: 0.4309, batch size: 37
2021-08-24 19:03:47,521 INFO [train.py:450] Epoch 0, batch 6380, batch avg loss 0.4397, total avg loss: 0.4311, batch size: 40
2021-08-24 19:03:54,816 INFO [train.py:450] Epoch 0, batch 6390, batch avg loss 0.4613, total avg loss: 0.4316, batch size: 36
2021-08-24 19:04:02,081 INFO [train.py:450] Epoch 0, batch 6400, batch avg loss 0.4729, total avg loss: 0.4311, batch size: 43
2021-08-24 19:04:09,361 INFO [train.py:450] Epoch 0, batch 6410, batch avg loss 0.3992, total avg loss: 0.4358, batch size: 42
2021-08-24 19:04:16,584 INFO [train.py:450] Epoch 0, batch 6420, batch avg loss 0.4074, total avg loss: 0.4317, batch size: 41
2021-08-24 19:04:23,862 INFO [train.py:450] Epoch 0, batch 6430, batch avg loss 0.4003, total avg loss: 0.4273, batch size: 42
2021-08-24 19:04:30,964 INFO [train.py:450] Epoch 0, batch 6440, batch avg loss 0.4229, total avg loss: 0.4242, batch size: 40
2021-08-24 19:04:38,068 INFO [train.py:450] Epoch 0, batch 6450, batch avg loss 0.4430, total avg loss: 0.4235, batch size: 41
2021-08-24 19:04:46,368 INFO [train.py:450] Epoch 0, batch 6460, batch avg loss 0.3423, total avg loss: 0.4230, batch size: 40
2021-08-24 19:04:54,421 INFO [train.py:450] Epoch 0, batch 6470, batch avg loss 0.4639, total avg loss: 0.4236, batch size: 37
2021-08-24 19:05:02,197 INFO [train.py:450] Epoch 0, batch 6480, batch avg loss 0.4118, total avg loss: 0.4245, batch size: 43
2021-08-24 19:05:11,652 INFO [train.py:450] Epoch 0, batch 6490, batch avg loss 0.4625, total avg loss: 0.4271, batch size: 37
2021-08-24 19:05:19,111 INFO [train.py:450] Epoch 0, batch 6500, batch avg loss 0.4506, total avg loss: 0.4282, batch size: 44
2021-08-24 19:05:29,160 INFO [train.py:450] Epoch 0, batch 6510, batch avg loss 0.4232, total avg loss: 0.4290, batch size: 40
2021-08-24 19:05:36,369 INFO [train.py:450] Epoch 0, batch 6520, batch avg loss 0.4445, total avg loss: 0.4306, batch size: 39
2021-08-24 19:05:43,816 INFO [train.py:450] Epoch 0, batch 6530, batch avg loss 0.4583, total avg loss: 0.4316, batch size: 45
2021-08-24 19:05:51,152 INFO [train.py:450] Epoch 0, batch 6540, batch avg loss 0.4172, total avg loss: 0.4307, batch size: 42
2021-08-24 19:05:58,663 INFO [train.py:450] Epoch 0, batch 6550, batch avg loss 0.4446, total avg loss: 0.4301, batch size: 38
2021-08-24 19:06:06,329 INFO [train.py:450] Epoch 0, batch 6560, batch avg loss 0.4407, total avg loss: 0.4298, batch size: 39
2021-08-24 19:06:13,702 INFO [train.py:450] Epoch 0, batch 6570, batch avg loss 0.4070, total avg loss: 0.4286, batch size: 39
2021-08-24 19:06:20,855 INFO [train.py:450] Epoch 0, batch 6580, batch avg loss 0.4394, total avg loss: 0.4286, batch size: 39
2021-08-24 19:06:27,872 INFO [train.py:450] Epoch 0, batch 6590, batch avg loss 0.4310, total avg loss: 0.4282, batch size: 40
2021-08-24 19:06:35,219 INFO [train.py:450] Epoch 0, batch 6600, batch avg loss 0.4032, total avg loss: 0.4278, batch size: 42
2021-08-24 19:06:42,606 INFO [train.py:450] Epoch 0, batch 6610, batch avg loss 0.3930, total avg loss: 0.4280, batch size: 42
2021-08-24 19:06:50,307 INFO [train.py:450] Epoch 0, batch 6620, batch avg loss 0.4781, total avg loss: 0.4328, batch size: 40
2021-08-24 19:06:58,142 INFO [train.py:450] Epoch 0, batch 6630, batch avg loss 0.4782, total avg loss: 0.4332, batch size: 39
2021-08-24 19:07:05,571 INFO [train.py:450] Epoch 0, batch 6640, batch avg loss 0.3625, total avg loss: 0.4283, batch size: 41
2021-08-24 19:07:12,580 INFO [train.py:450] Epoch 0, batch 6650, batch avg loss 0.4736, total avg loss: 0.4299, batch size: 39
2021-08-24 19:07:19,840 INFO [train.py:450] Epoch 0, batch 6660, batch avg loss 0.3752, total avg loss: 0.4290, batch size: 42
2021-08-24 19:07:34,723 INFO [train.py:450] Epoch 0, batch 6670, batch avg loss 0.4398, total avg loss: 0.4314, batch size: 38
2021-08-24 19:07:41,054 INFO [train.py:450] Epoch 0, batch 6680, batch avg loss 0.4335, total avg loss: 0.4322, batch size: 39
2021-08-24 19:07:48,577 INFO [train.py:450] Epoch 0, batch 6690, batch avg loss 0.4254, total avg loss: 0.4311, batch size: 39
2021-08-24 19:07:55,748 INFO [train.py:450] Epoch 0, batch 6700, batch avg loss 0.4089, total avg loss: 0.4295, batch size: 38
2021-08-24 19:08:03,155 INFO [train.py:450] Epoch 0, batch 6710, batch avg loss 0.4182, total avg loss: 0.4285, batch size: 42
2021-08-24 19:08:10,747 INFO [train.py:450] Epoch 0, batch 6720, batch avg loss 0.3811, total avg loss: 0.4274, batch size: 42
2021-08-24 19:08:18,424 INFO [train.py:450] Epoch 0, batch 6730, batch avg loss 0.4334, total avg loss: 0.4269, batch size: 38
2021-08-24 19:08:25,504 INFO [train.py:450] Epoch 0, batch 6740, batch avg loss 0.4949, total avg loss: 0.4265, batch size: 42
2021-08-24 19:08:32,912 INFO [train.py:450] Epoch 0, batch 6750, batch avg loss 0.3840, total avg loss: 0.4269, batch size: 36
2021-08-24 19:08:40,495 INFO [train.py:450] Epoch 0, batch 6760, batch avg loss 0.3967, total avg loss: 0.4261, batch size: 40
2021-08-24 19:08:47,711 INFO [train.py:450] Epoch 0, batch 6770, batch avg loss 0.4630, total avg loss: 0.4260, batch size: 41
2021-08-24 19:08:55,092 INFO [train.py:450] Epoch 0, batch 6780, batch avg loss 0.4985, total avg loss: 0.4270, batch size: 39
2021-08-24 19:09:02,335 INFO [train.py:450] Epoch 0, batch 6790, batch avg loss 0.4659, total avg loss: 0.4270, batch size: 39
2021-08-24 19:09:10,183 INFO [train.py:450] Epoch 0, batch 6800, batch avg loss 0.4025, total avg loss: 0.4263, batch size: 43
2021-08-24 19:09:17,506 INFO [train.py:450] Epoch 0, batch 6810, batch avg loss 0.3703, total avg loss: 0.4300, batch size: 38
2021-08-24 19:09:25,061 INFO [train.py:450] Epoch 0, batch 6820, batch avg loss 0.3871, total avg loss: 0.4211, batch size: 37
2021-08-24 19:09:33,965 INFO [train.py:450] Epoch 0, batch 6830, batch avg loss 0.4256, total avg loss: 0.4230, batch size: 40
2021-08-24 19:09:40,648 INFO [train.py:450] Epoch 0, batch 6840, batch avg loss 0.3945, total avg loss: 0.4178, batch size: 41
2021-08-24 19:09:51,777 INFO [train.py:450] Epoch 0, batch 6850, batch avg loss 0.4342, total avg loss: 0.4216, batch size: 37
2021-08-24 19:09:59,341 INFO [train.py:450] Epoch 0, batch 6860, batch avg loss 0.4148, total avg loss: 0.4222, batch size: 39
2021-08-24 19:10:07,044 INFO [train.py:450] Epoch 0, batch 6870, batch avg loss 0.4112, total avg loss: 0.4209, batch size: 39
2021-08-24 19:10:14,967 INFO [train.py:450] Epoch 0, batch 6880, batch avg loss 0.3953, total avg loss: 0.4222, batch size: 40
2021-08-24 19:10:23,054 INFO [train.py:450] Epoch 0, batch 6890, batch avg loss 0.4557, total avg loss: 0.4213, batch size: 36
2021-08-24 19:10:30,742 INFO [train.py:450] Epoch 0, batch 6900, batch avg loss 0.3879, total avg loss: 0.4235, batch size: 43
2021-08-24 19:10:38,129 INFO [train.py:450] Epoch 0, batch 6910, batch avg loss 0.4687, total avg loss: 0.4252, batch size: 39
2021-08-24 19:10:45,879 INFO [train.py:450] Epoch 0, batch 6920, batch avg loss 0.4205, total avg loss: 0.4250, batch size: 40
2021-08-24 19:10:53,701 INFO [train.py:450] Epoch 0, batch 6930, batch avg loss 0.4418, total avg loss: 0.4251, batch size: 39
2021-08-24 19:11:00,534 INFO [train.py:450] Epoch 0, batch 6940, batch avg loss 0.4243, total avg loss: 0.4249, batch size: 40
2021-08-24 19:11:08,251 INFO [train.py:450] Epoch 0, batch 6950, batch avg loss 0.4660, total avg loss: 0.4250, batch size: 46
2021-08-24 19:11:15,682 INFO [train.py:450] Epoch 0, batch 6960, batch avg loss 0.4185, total avg loss: 0.4263, batch size: 41
2021-08-24 19:11:23,084 INFO [train.py:450] Epoch 0, batch 6970, batch avg loss 0.4366, total avg loss: 0.4260, batch size: 41
2021-08-24 19:11:30,153 INFO [train.py:450] Epoch 0, batch 6980, batch avg loss 0.4000, total avg loss: 0.4260, batch size: 41
2021-08-24 19:11:36,882 INFO [train.py:450] Epoch 0, batch 6990, batch avg loss 0.3749, total avg loss: 0.4249, batch size: 39
2021-08-24 19:11:44,502 INFO [train.py:450] Epoch 0, batch 7000, batch avg loss 0.3749, total avg loss: 0.4244, batch size: 37
2021-08-24 19:12:23,440 INFO [train.py:482] Epoch 0, valid loss 0.3091, best valid loss: 0.3091 best valid epoch: 0
2021-08-24 19:12:29,859 INFO [train.py:450] Epoch 0, batch 7010, batch avg loss 0.4177, total avg loss: 0.4196, batch size: 38
2021-08-24 19:12:37,773 INFO [train.py:450] Epoch 0, batch 7020, batch avg loss 0.4640, total avg loss: 0.4250, batch size: 42
2021-08-24 19:12:45,524 INFO [train.py:450] Epoch 0, batch 7030, batch avg loss 0.4092, total avg loss: 0.4215, batch size: 39
2021-08-24 19:12:55,442 INFO [train.py:450] Epoch 0, batch 7040, batch avg loss 0.3795, total avg loss: 0.4246, batch size: 39
2021-08-24 19:13:04,769 INFO [train.py:450] Epoch 0, batch 7050, batch avg loss 0.4330, total avg loss: 0.4318, batch size: 41
2021-08-24 19:13:12,813 INFO [train.py:450] Epoch 0, batch 7060, batch avg loss 0.3922, total avg loss: 0.4307, batch size: 37
2021-08-24 19:13:19,733 INFO [train.py:450] Epoch 0, batch 7070, batch avg loss 0.4518, total avg loss: 0.4263, batch size: 44
2021-08-24 19:13:26,622 INFO [train.py:450] Epoch 0, batch 7080, batch avg loss 0.4360, total avg loss: 0.4249, batch size: 40
2021-08-24 19:13:34,207 INFO [train.py:450] Epoch 0, batch 7090, batch avg loss 0.4181, total avg loss: 0.4247, batch size: 39
2021-08-24 19:13:41,950 INFO [train.py:450] Epoch 0, batch 7100, batch avg loss 0.3555, total avg loss: 0.4232, batch size: 38
2021-08-24 19:13:49,093 INFO [train.py:450] Epoch 0, batch 7110, batch avg loss 0.3869, total avg loss: 0.4241, batch size: 38
2021-08-24 19:13:56,730 INFO [train.py:450] Epoch 0, batch 7120, batch avg loss 0.4156, total avg loss: 0.4238, batch size: 40
2021-08-24 19:14:03,980 INFO [train.py:450] Epoch 0, batch 7130, batch avg loss 0.4248, total avg loss: 0.4249, batch size: 44
2021-08-24 19:14:11,036 INFO [train.py:450] Epoch 0, batch 7140, batch avg loss 0.4693, total avg loss: 0.4241, batch size: 41
2021-08-24 19:14:18,207 INFO [train.py:450] Epoch 0, batch 7150, batch avg loss 0.3805, total avg loss: 0.4239, batch size: 38
2021-08-24 19:14:25,138 INFO [train.py:450] Epoch 0, batch 7160, batch avg loss 0.3855, total avg loss: 0.4232, batch size: 36
2021-08-24 19:14:32,358 INFO [train.py:450] Epoch 0, batch 7170, batch avg loss 0.4004, total avg loss: 0.4233, batch size: 38
2021-08-24 19:14:39,266 INFO [train.py:450] Epoch 0, batch 7180, batch avg loss 0.4631, total avg loss: 0.4236, batch size: 44
2021-08-24 19:14:46,871 INFO [train.py:450] Epoch 0, batch 7190, batch avg loss 0.4366, total avg loss: 0.4236, batch size: 38
2021-08-24 19:14:54,468 INFO [train.py:450] Epoch 0, batch 7200, batch avg loss 0.4520, total avg loss: 0.4233, batch size: 43
2021-08-24 19:15:01,157 INFO [train.py:450] Epoch 0, batch 7210, batch avg loss 0.4215, total avg loss: 0.3910, batch size: 38
2021-08-24 19:15:08,367 INFO [train.py:450] Epoch 0, batch 7220, batch avg loss 0.4523, total avg loss: 0.4076, batch size: 42
2021-08-24 19:15:15,413 INFO [train.py:450] Epoch 0, batch 7230, batch avg loss 0.4830, total avg loss: 0.4056, batch size: 42
2021-08-24 19:15:22,279 INFO [train.py:450] Epoch 0, batch 7240, batch avg loss 0.4004, total avg loss: 0.4124, batch size: 41
2021-08-24 19:15:29,569 INFO [train.py:450] Epoch 0, batch 7250, batch avg loss 0.4064, total avg loss: 0.4137, batch size: 43
2021-08-24 19:15:36,551 INFO [train.py:450] Epoch 0, batch 7260, batch avg loss 0.4072, total avg loss: 0.4116, batch size: 44
2021-08-24 19:15:43,598 INFO [train.py:450] Epoch 0, batch 7270, batch avg loss 0.4051, total avg loss: 0.4121, batch size: 38
2021-08-24 19:15:50,845 INFO [train.py:450] Epoch 0, batch 7280, batch avg loss 0.3992, total avg loss: 0.4135, batch size: 39
2021-08-24 19:15:58,044 INFO [train.py:450] Epoch 0, batch 7290, batch avg loss 0.4315, total avg loss: 0.4142, batch size: 37
2021-08-24 19:16:05,083 INFO [train.py:450] Epoch 0, batch 7300, batch avg loss 0.4041, total avg loss: 0.4164, batch size: 39
2021-08-24 19:16:12,122 INFO [train.py:450] Epoch 0, batch 7310, batch avg loss 0.3880, total avg loss: 0.4181, batch size: 39
2021-08-24 19:16:19,116 INFO [train.py:450] Epoch 0, batch 7320, batch avg loss 0.3860, total avg loss: 0.4162, batch size: 40
2021-08-24 19:16:26,173 INFO [train.py:450] Epoch 0, batch 7330, batch avg loss 0.4173, total avg loss: 0.4161, batch size: 40
2021-08-24 19:16:33,138 INFO [train.py:450] Epoch 0, batch 7340, batch avg loss 0.3318, total avg loss: 0.4156, batch size: 37
2021-08-24 19:16:39,857 INFO [train.py:450] Epoch 0, batch 7350, batch avg loss 0.4701, total avg loss: 0.4152, batch size: 37
2021-08-24 19:16:46,713 INFO [train.py:450] Epoch 0, batch 7360, batch avg loss 0.3784, total avg loss: 0.4138, batch size: 43
2021-08-24 19:16:53,878 INFO [train.py:450] Epoch 0, batch 7370, batch avg loss 0.4238, total avg loss: 0.4129, batch size: 40
2021-08-24 19:17:00,946 INFO [train.py:450] Epoch 0, batch 7380, batch avg loss 0.3516, total avg loss: 0.4132, batch size: 38
2021-08-24 19:17:08,218 INFO [train.py:450] Epoch 0, batch 7390, batch avg loss 0.4193, total avg loss: 0.4132, batch size: 41
2021-08-24 19:17:15,227 INFO [train.py:450] Epoch 0, batch 7400, batch avg loss 0.4682, total avg loss: 0.4138, batch size: 42
2021-08-24 19:17:22,200 INFO [train.py:450] Epoch 0, batch 7410, batch avg loss 0.4068, total avg loss: 0.4282, batch size: 39
2021-08-24 19:17:29,525 INFO [train.py:450] Epoch 0, batch 7420, batch avg loss 0.3986, total avg loss: 0.4198, batch size: 39
2021-08-24 19:17:35,984 INFO [train.py:450] Epoch 0, batch 7430, batch avg loss 0.4576, total avg loss: 0.4155, batch size: 37
2021-08-24 19:17:42,376 INFO [train.py:450] Epoch 0, batch 7440, batch avg loss 0.4032, total avg loss: 0.4173, batch size: 41
2021-08-24 19:17:49,394 INFO [train.py:450] Epoch 0, batch 7450, batch avg loss 0.4127, total avg loss: 0.4174, batch size: 36
2021-08-24 19:17:56,544 INFO [train.py:450] Epoch 0, batch 7460, batch avg loss 0.3626, total avg loss: 0.4136, batch size: 40
2021-08-24 19:18:04,486 INFO [train.py:450] Epoch 0, batch 7470, batch avg loss 0.4195, total avg loss: 0.4134, batch size: 43
2021-08-24 19:18:10,981 INFO [train.py:450] Epoch 0, batch 7480, batch avg loss 0.4283, total avg loss: 0.4124, batch size: 41
2021-08-24 19:18:20,794 INFO [train.py:450] Epoch 0, batch 7490, batch avg loss 0.3874, total avg loss: 0.4123, batch size: 41
2021-08-24 19:18:27,727 INFO [train.py:450] Epoch 0, batch 7500, batch avg loss 0.4133, total avg loss: 0.4129, batch size: 42
2021-08-24 19:18:34,812 INFO [train.py:450] Epoch 0, batch 7510, batch avg loss 0.3837, total avg loss: 0.4135, batch size: 40
2021-08-24 19:18:42,021 INFO [train.py:450] Epoch 0, batch 7520, batch avg loss 0.3548, total avg loss: 0.4149, batch size: 41
2021-08-24 19:18:48,940 INFO [train.py:450] Epoch 0, batch 7530, batch avg loss 0.3889, total avg loss: 0.4139, batch size: 41
2021-08-24 19:18:56,445 INFO [train.py:450] Epoch 0, batch 7540, batch avg loss 0.4229, total avg loss: 0.4141, batch size: 41
2021-08-24 19:19:03,552 INFO [train.py:450] Epoch 0, batch 7550, batch avg loss 0.3985, total avg loss: 0.4139, batch size: 39
2021-08-24 19:19:10,657 INFO [train.py:450] Epoch 0, batch 7560, batch avg loss 0.3882, total avg loss: 0.4137, batch size: 38
2021-08-24 19:19:17,312 INFO [train.py:450] Epoch 0, batch 7570, batch avg loss 0.3865, total avg loss: 0.4139, batch size: 38
2021-08-24 19:19:23,782 INFO [train.py:450] Epoch 0, batch 7580, batch avg loss 0.4254, total avg loss: 0.4138, batch size: 39
2021-08-24 19:19:30,519 INFO [train.py:450] Epoch 0, batch 7590, batch avg loss 0.3923, total avg loss: 0.4143, batch size: 40
2021-08-24 19:19:37,211 INFO [train.py:450] Epoch 0, batch 7600, batch avg loss 0.4742, total avg loss: 0.4142, batch size: 37
2021-08-24 19:19:44,215 INFO [train.py:450] Epoch 0, batch 7610, batch avg loss 0.3599, total avg loss: 0.4005, batch size: 41
2021-08-24 19:19:51,370 INFO [train.py:450] Epoch 0, batch 7620, batch avg loss 0.4209, total avg loss: 0.4070, batch size: 40
2021-08-24 19:19:57,978 INFO [train.py:450] Epoch 0, batch 7630, batch avg loss 0.4478, total avg loss: 0.4092, batch size: 41
2021-08-24 19:20:04,887 INFO [train.py:450] Epoch 0, batch 7640, batch avg loss 0.4968, total avg loss: 0.4124, batch size: 41
2021-08-24 19:20:11,996 INFO [train.py:450] Epoch 0, batch 7650, batch avg loss 0.4059, total avg loss: 0.4147, batch size: 37
2021-08-24 19:20:19,001 INFO [train.py:450] Epoch 0, batch 7660, batch avg loss 0.4234, total avg loss: 0.4149, batch size: 42
2021-08-24 19:20:25,800 INFO [train.py:450] Epoch 0, batch 7670, batch avg loss 0.3889, total avg loss: 0.4151, batch size: 37
2021-08-24 19:20:33,111 INFO [train.py:450] Epoch 0, batch 7680, batch avg loss 0.4876, total avg loss: 0.4151, batch size: 35
2021-08-24 19:20:40,109 INFO [train.py:450] Epoch 0, batch 7690, batch avg loss 0.4269, total avg loss: 0.4156, batch size: 41
2021-08-24 19:20:47,032 INFO [train.py:450] Epoch 0, batch 7700, batch avg loss 0.3903, total avg loss: 0.4156, batch size: 44
2021-08-24 19:20:53,883 INFO [train.py:450] Epoch 0, batch 7710, batch avg loss 0.4660, total avg loss: 0.4167, batch size: 38
2021-08-24 19:21:00,454 INFO [train.py:450] Epoch 0, batch 7720, batch avg loss 0.4281, total avg loss: 0.4165, batch size: 42
2021-08-24 19:21:07,373 INFO [train.py:450] Epoch 0, batch 7730, batch avg loss 0.3470, total avg loss: 0.4167, batch size: 39
2021-08-24 19:21:14,276 INFO [train.py:450] Epoch 0, batch 7740, batch avg loss 0.4141, total avg loss: 0.4164, batch size: 41
2021-08-24 19:21:21,643 INFO [train.py:450] Epoch 0, batch 7750, batch avg loss 0.4225, total avg loss: 0.4163, batch size: 39
2021-08-24 19:21:28,565 INFO [train.py:450] Epoch 0, batch 7760, batch avg loss 0.4000, total avg loss: 0.4156, batch size: 37
2021-08-24 19:21:35,523 INFO [train.py:450] Epoch 0, batch 7770, batch avg loss 0.3775, total avg loss: 0.4146, batch size: 39
2021-08-24 19:21:42,780 INFO [train.py:450] Epoch 0, batch 7780, batch avg loss 0.3837, total avg loss: 0.4147, batch size: 40
2021-08-24 19:21:50,077 INFO [train.py:450] Epoch 0, batch 7790, batch avg loss 0.3924, total avg loss: 0.4148, batch size: 43
2021-08-24 19:21:56,889 INFO [train.py:450] Epoch 0, batch 7800, batch avg loss 0.3776, total avg loss: 0.4152, batch size: 38
2021-08-24 19:22:03,552 INFO [train.py:450] Epoch 0, batch 7810, batch avg loss 0.4316, total avg loss: 0.4098, batch size: 38
2021-08-24 19:22:10,092 INFO [train.py:450] Epoch 0, batch 7820, batch avg loss 0.4520, total avg loss: 0.4069, batch size: 43
2021-08-24 19:22:17,105 INFO [train.py:450] Epoch 0, batch 7830, batch avg loss 0.4361, total avg loss: 0.4093, batch size: 38
2021-08-24 19:22:24,269 INFO [train.py:450] Epoch 0, batch 7840, batch avg loss 0.3959, total avg loss: 0.4097, batch size: 39
2021-08-24 19:22:31,870 INFO [train.py:450] Epoch 0, batch 7850, batch avg loss 0.4340, total avg loss: 0.4103, batch size: 40
2021-08-24 19:22:38,790 INFO [train.py:450] Epoch 0, batch 7860, batch avg loss 0.4117, total avg loss: 0.4097, batch size: 40
2021-08-24 19:22:47,304 INFO [train.py:450] Epoch 0, batch 7870, batch avg loss 0.3994, total avg loss: 0.4109, batch size: 39
2021-08-24 19:22:54,114 INFO [train.py:450] Epoch 0, batch 7880, batch avg loss 0.4130, total avg loss: 0.4105, batch size: 37
2021-08-24 19:23:04,856 INFO [train.py:450] Epoch 0, batch 7890, batch avg loss 0.4651, total avg loss: 0.4103, batch size: 39
2021-08-24 19:23:11,489 INFO [train.py:450] Epoch 0, batch 7900, batch avg loss 0.4175, total avg loss: 0.4133, batch size: 41
2021-08-24 19:23:19,504 INFO [train.py:450] Epoch 0, batch 7910, batch avg loss 0.4253, total avg loss: 0.4148, batch size: 44
2021-08-24 19:23:26,990 INFO [train.py:450] Epoch 0, batch 7920, batch avg loss 0.3967, total avg loss: 0.4139, batch size: 40
2021-08-24 19:23:33,696 INFO [train.py:450] Epoch 0, batch 7930, batch avg loss 0.3935, total avg loss: 0.4144, batch size: 39
2021-08-24 19:23:40,881 INFO [train.py:450] Epoch 0, batch 7940, batch avg loss 0.5087, total avg loss: 0.4146, batch size: 41
2021-08-24 19:23:47,974 INFO [train.py:450] Epoch 0, batch 7950, batch avg loss 0.3735, total avg loss: 0.4138, batch size: 37
2021-08-24 19:23:55,328 INFO [train.py:450] Epoch 0, batch 7960, batch avg loss 0.4033, total avg loss: 0.4126, batch size: 42
2021-08-24 19:24:01,714 INFO [train.py:450] Epoch 0, batch 7970, batch avg loss 0.4080, total avg loss: 0.4125, batch size: 38
2021-08-24 19:24:08,440 INFO [train.py:450] Epoch 0, batch 7980, batch avg loss 0.4243, total avg loss: 0.4130, batch size: 40
2021-08-24 19:24:15,592 INFO [train.py:450] Epoch 0, batch 7990, batch avg loss 0.3760, total avg loss: 0.4130, batch size: 37
2021-08-24 19:24:17,964 WARNING [cut.py:1694] To perform mix, energy must be non-zero and non-negative (got 0.0).  MonoCut with id "f5abb538-76a5-4b93-5759-fba329f07d05" will not be mixed in.
2021-08-24 19:24:22,242 INFO [train.py:450] Epoch 0, batch 8000, batch avg loss 0.4195, total avg loss: 0.4130, batch size: 41
2021-08-24 19:24:59,702 INFO [train.py:482] Epoch 0, valid loss 0.3046, best valid loss: 0.3046 best valid epoch: 0
2021-08-24 19:25:05,580 INFO [train.py:450] Epoch 0, batch 8010, batch avg loss 0.3911, total avg loss: 0.4035, batch size: 38
2021-08-24 19:25:13,706 INFO [train.py:450] Epoch 0, batch 8020, batch avg loss 0.3913, total avg loss: 0.4105, batch size: 39
2021-08-24 19:25:21,816 INFO [train.py:450] Epoch 0, batch 8030, batch avg loss 0.4206, total avg loss: 0.4134, batch size: 39
2021-08-24 19:25:29,909 INFO [train.py:450] Epoch 0, batch 8040, batch avg loss 0.4340, total avg loss: 0.4124, batch size: 43
2021-08-24 19:25:37,559 INFO [train.py:450] Epoch 0, batch 8050, batch avg loss 0.4480, total avg loss: 0.4112, batch size: 40
2021-08-24 19:25:45,925 INFO [train.py:450] Epoch 0, batch 8060, batch avg loss 0.3924, total avg loss: 0.4130, batch size: 37
2021-08-24 19:25:53,975 INFO [train.py:450] Epoch 0, batch 8070, batch avg loss 0.4509, total avg loss: 0.4124, batch size: 35
2021-08-24 19:26:01,568 INFO [train.py:450] Epoch 0, batch 8080, batch avg loss 0.3916, total avg loss: 0.4117, batch size: 37
2021-08-24 19:26:08,913 INFO [train.py:450] Epoch 0, batch 8090, batch avg loss 0.3529, total avg loss: 0.4099, batch size: 38
2021-08-24 19:26:16,828 INFO [train.py:450] Epoch 0, batch 8100, batch avg loss 0.4461, total avg loss: 0.4098, batch size: 46
2021-08-24 19:26:24,230 INFO [train.py:450] Epoch 0, batch 8110, batch avg loss 0.3933, total avg loss: 0.4099, batch size: 41
2021-08-24 19:26:32,166 INFO [train.py:450] Epoch 0, batch 8120, batch avg loss 0.4076, total avg loss: 0.4084, batch size: 40
2021-08-24 19:26:39,799 INFO [train.py:450] Epoch 0, batch 8130, batch avg loss 0.4317, total avg loss: 0.4088, batch size: 40
2021-08-24 19:26:47,976 INFO [train.py:450] Epoch 0, batch 8140, batch avg loss 0.3912, total avg loss: 0.4102, batch size: 44
2021-08-24 19:26:55,574 INFO [train.py:450] Epoch 0, batch 8150, batch avg loss 0.3973, total avg loss: 0.4102, batch size: 45
2021-08-24 19:27:03,445 INFO [train.py:450] Epoch 0, batch 8160, batch avg loss 0.3787, total avg loss: 0.4112, batch size: 43
2021-08-24 19:27:11,123 INFO [train.py:450] Epoch 0, batch 8170, batch avg loss 0.4237, total avg loss: 0.4124, batch size: 36
2021-08-24 19:27:19,041 INFO [train.py:450] Epoch 0, batch 8180, batch avg loss 0.3803, total avg loss: 0.4118, batch size: 41
2021-08-24 19:27:26,680 INFO [train.py:450] Epoch 0, batch 8190, batch avg loss 0.4061, total avg loss: 0.4120, batch size: 44
2021-08-24 19:27:34,701 INFO [train.py:450] Epoch 0, batch 8200, batch avg loss 0.4020, total avg loss: 0.4134, batch size: 40
2021-08-24 19:27:43,298 INFO [train.py:450] Epoch 0, batch 8210, batch avg loss 0.3702, total avg loss: 0.3979, batch size: 41
2021-08-24 19:27:51,756 INFO [train.py:450] Epoch 0, batch 8220, batch avg loss 0.4242, total avg loss: 0.4014, batch size: 42
2021-08-24 19:28:03,800 INFO [train.py:450] Epoch 0, batch 8230, batch avg loss 0.4018, total avg loss: 0.4065, batch size: 40
2021-08-24 19:28:11,163 INFO [train.py:450] Epoch 0, batch 8240, batch avg loss 0.4345, total avg loss: 0.4069, batch size: 37
2021-08-24 19:28:19,864 INFO [train.py:450] Epoch 0, batch 8250, batch avg loss 0.3974, total avg loss: 0.4064, batch size: 43
2021-08-24 19:28:28,074 INFO [train.py:450] Epoch 0, batch 8260, batch avg loss 0.4060, total avg loss: 0.4051, batch size: 37
2021-08-24 19:28:35,955 INFO [train.py:450] Epoch 0, batch 8270, batch avg loss 0.4012, total avg loss: 0.4071, batch size: 38
2021-08-24 19:28:43,556 INFO [train.py:450] Epoch 0, batch 8280, batch avg loss 0.4852, total avg loss: 0.4071, batch size: 42
2021-08-24 19:28:50,770 INFO [train.py:450] Epoch 0, batch 8290, batch avg loss 0.3951, total avg loss: 0.4091, batch size: 38
2021-08-24 19:28:58,254 INFO [train.py:450] Epoch 0, batch 8300, batch avg loss 0.4176, total avg loss: 0.4111, batch size: 43
2021-08-24 19:29:05,922 INFO [train.py:450] Epoch 0, batch 8310, batch avg loss 0.3729, total avg loss: 0.4116, batch size: 40
2021-08-24 19:29:13,559 INFO [train.py:450] Epoch 0, batch 8320, batch avg loss 0.3968, total avg loss: 0.4110, batch size: 40
2021-08-24 19:29:14,164 WARNING [cut.py:1694] To perform mix, energy must be non-zero and non-negative (got 0.0).  MonoCut with id "91b2b9c9-fe86-1d41-714b-d12844ea0c75" will not be mixed in.
2021-08-24 19:29:20,812 INFO [train.py:450] Epoch 0, batch 8330, batch avg loss 0.3384, total avg loss: 0.4109, batch size: 39
2021-08-24 19:29:28,644 INFO [train.py:450] Epoch 0, batch 8340, batch avg loss 0.3956, total avg loss: 0.4107, batch size: 37
2021-08-24 19:29:36,231 INFO [train.py:450] Epoch 0, batch 8350, batch avg loss 0.4624, total avg loss: 0.4107, batch size: 38
2021-08-24 19:29:44,102 INFO [train.py:450] Epoch 0, batch 8360, batch avg loss 0.4208, total avg loss: 0.4121, batch size: 39
2021-08-24 19:29:51,563 INFO [train.py:450] Epoch 0, batch 8370, batch avg loss 0.4121, total avg loss: 0.4120, batch size: 39
2021-08-24 19:29:59,566 INFO [train.py:450] Epoch 0, batch 8380, batch avg loss 0.3636, total avg loss: 0.4117, batch size: 41
2021-08-24 19:30:07,425 INFO [train.py:450] Epoch 0, batch 8390, batch avg loss 0.4165, total avg loss: 0.4118, batch size: 40
2021-08-24 19:30:14,885 INFO [train.py:450] Epoch 0, batch 8400, batch avg loss 0.3823, total avg loss: 0.4117, batch size: 37
2021-08-24 19:30:23,718 INFO [train.py:450] Epoch 0, batch 8410, batch avg loss 0.4523, total avg loss: 0.4246, batch size: 44
2021-08-24 19:30:31,597 INFO [train.py:450] Epoch 0, batch 8420, batch avg loss 0.3907, total avg loss: 0.4202, batch size: 44
2021-08-24 19:30:39,456 INFO [train.py:450] Epoch 0, batch 8430, batch avg loss 0.3740, total avg loss: 0.4114, batch size: 42
2021-08-24 19:30:46,838 INFO [train.py:450] Epoch 0, batch 8440, batch avg loss 0.3955, total avg loss: 0.4067, batch size: 45
2021-08-24 19:30:54,169 INFO [train.py:450] Epoch 0, batch 8450, batch avg loss 0.4182, total avg loss: 0.4034, batch size: 41
2021-08-24 19:31:01,680 INFO [train.py:450] Epoch 0, batch 8460, batch avg loss 0.4089, total avg loss: 0.4038, batch size: 43
2021-08-24 19:31:09,621 INFO [train.py:450] Epoch 0, batch 8470, batch avg loss 0.3570, total avg loss: 0.4052, batch size: 39
2021-08-24 19:31:17,251 INFO [train.py:450] Epoch 0, batch 8480, batch avg loss 0.4035, total avg loss: 0.4037, batch size: 42
2021-08-24 19:31:24,892 INFO [train.py:450] Epoch 0, batch 8490, batch avg loss 0.3582, total avg loss: 0.4042, batch size: 40
2021-08-24 19:31:32,179 INFO [train.py:450] Epoch 0, batch 8500, batch avg loss 0.3591, total avg loss: 0.4042, batch size: 38
2021-08-24 19:31:39,606 INFO [train.py:450] Epoch 0, batch 8510, batch avg loss 0.4498, total avg loss: 0.4052, batch size: 42
2021-08-24 19:31:47,169 INFO [train.py:450] Epoch 0, batch 8520, batch avg loss 0.4046, total avg loss: 0.4046, batch size: 40
2021-08-24 19:31:55,162 INFO [train.py:450] Epoch 0, batch 8530, batch avg loss 0.3962, total avg loss: 0.4048, batch size: 39
2021-08-24 19:32:02,975 INFO [train.py:450] Epoch 0, batch 8540, batch avg loss 0.4096, total avg loss: 0.4049, batch size: 41
2021-08-24 19:32:10,270 INFO [train.py:450] Epoch 0, batch 8550, batch avg loss 0.3833, total avg loss: 0.4048, batch size: 39
2021-08-24 19:32:17,511 INFO [train.py:450] Epoch 0, batch 8560, batch avg loss 0.4592, total avg loss: 0.4056, batch size: 45
2021-08-24 19:32:18,441 WARNING [cut.py:1694] To perform mix, energy must be non-zero and non-negative (got 0.0).  MonoCut with id "ad75ccf5-35d0-7929-c088-6b1c40de2c81" will not be mixed in.
2021-08-24 19:32:24,695 INFO [train.py:450] Epoch 0, batch 8570, batch avg loss 0.4474, total avg loss: 0.4073, batch size: 37
2021-08-24 19:32:35,550 INFO [train.py:450] Epoch 0, batch 8580, batch avg loss 0.4692, total avg loss: 0.4069, batch size: 40
2021-08-24 19:32:43,895 INFO [train.py:450] Epoch 0, batch 8590, batch avg loss 0.4425, total avg loss: 0.4073, batch size: 43
2021-08-24 19:32:53,503 INFO [train.py:450] Epoch 0, batch 8600, batch avg loss 0.4027, total avg loss: 0.4071, batch size: 38
2021-08-24 19:33:00,477 INFO [train.py:450] Epoch 0, batch 8610, batch avg loss 0.3678, total avg loss: 0.3991, batch size: 38
2021-08-24 19:33:08,160 INFO [train.py:450] Epoch 0, batch 8620, batch avg loss 0.3704, total avg loss: 0.4069, batch size: 40
2021-08-24 19:33:15,913 INFO [train.py:450] Epoch 0, batch 8630, batch avg loss 0.4127, total avg loss: 0.4064, batch size: 40
2021-08-24 19:33:23,626 INFO [train.py:450] Epoch 0, batch 8640, batch avg loss 0.4279, total avg loss: 0.4056, batch size: 36
2021-08-24 19:33:30,847 INFO [train.py:450] Epoch 0, batch 8650, batch avg loss 0.3636, total avg loss: 0.4053, batch size: 38
2021-08-24 19:33:37,990 INFO [train.py:450] Epoch 0, batch 8660, batch avg loss 0.4341, total avg loss: 0.4077, batch size: 42
2021-08-24 19:33:45,317 INFO [train.py:450] Epoch 0, batch 8670, batch avg loss 0.3772, total avg loss: 0.4089, batch size: 42
2021-08-24 19:33:52,722 INFO [train.py:450] Epoch 0, batch 8680, batch avg loss 0.3743, total avg loss: 0.4098, batch size: 38
2021-08-24 19:33:59,942 INFO [train.py:450] Epoch 0, batch 8690, batch avg loss 0.4226, total avg loss: 0.4091, batch size: 40
2021-08-24 19:34:07,651 INFO [train.py:450] Epoch 0, batch 8700, batch avg loss 0.4110, total avg loss: 0.4064, batch size: 42
2021-08-24 19:34:15,074 INFO [train.py:450] Epoch 0, batch 8710, batch avg loss 0.4329, total avg loss: 0.4044, batch size: 40
2021-08-24 19:34:22,164 INFO [train.py:450] Epoch 0, batch 8720, batch avg loss 0.4307, total avg loss: 0.4040, batch size: 41
2021-08-24 19:34:29,701 INFO [train.py:450] Epoch 0, batch 8730, batch avg loss 0.4697, total avg loss: 0.4060, batch size: 40
2021-08-24 19:34:37,100 INFO [train.py:450] Epoch 0, batch 8740, batch avg loss 0.4234, total avg loss: 0.4061, batch size: 39
2021-08-24 19:34:44,102 INFO [train.py:450] Epoch 0, batch 8750, batch avg loss 0.4316, total avg loss: 0.4058, batch size: 39
2021-08-24 19:34:51,554 INFO [train.py:450] Epoch 0, batch 8760, batch avg loss 0.3784, total avg loss: 0.4061, batch size: 39
2021-08-24 19:34:59,076 INFO [train.py:450] Epoch 0, batch 8770, batch avg loss 0.4312, total avg loss: 0.4053, batch size: 40
2021-08-24 19:35:06,469 INFO [train.py:450] Epoch 0, batch 8780, batch avg loss 0.4043, total avg loss: 0.4053, batch size: 39
2021-08-24 19:35:13,996 INFO [train.py:450] Epoch 0, batch 8790, batch avg loss 0.3926, total avg loss: 0.4048, batch size: 38
2021-08-24 19:35:21,147 INFO [train.py:450] Epoch 0, batch 8800, batch avg loss 0.4556, total avg loss: 0.4048, batch size: 41
2021-08-24 19:35:28,535 INFO [train.py:450] Epoch 0, batch 8810, batch avg loss 0.4229, total avg loss: 0.3931, batch size: 43
2021-08-24 19:35:35,859 INFO [train.py:450] Epoch 0, batch 8820, batch avg loss 0.3478, total avg loss: 0.3972, batch size: 40
2021-08-24 19:35:42,859 INFO [train.py:450] Epoch 0, batch 8830, batch avg loss 0.4048, total avg loss: 0.4004, batch size: 38
2021-08-24 19:35:50,200 INFO [train.py:450] Epoch 0, batch 8840, batch avg loss 0.3880, total avg loss: 0.3999, batch size: 39
2021-08-24 19:35:57,443 INFO [train.py:450] Epoch 0, batch 8850, batch avg loss 0.4149, total avg loss: 0.3985, batch size: 40
2021-08-24 19:36:04,788 INFO [train.py:450] Epoch 0, batch 8860, batch avg loss 0.4378, total avg loss: 0.4030, batch size: 46
2021-08-24 19:36:11,674 INFO [train.py:450] Epoch 0, batch 8870, batch avg loss 0.4529, total avg loss: 0.4044, batch size: 37
2021-08-24 19:36:18,708 INFO [train.py:450] Epoch 0, batch 8880, batch avg loss 0.4037, total avg loss: 0.4035, batch size: 42
2021-08-24 19:36:25,218 INFO [train.py:450] Epoch 0, batch 8890, batch avg loss 0.3911, total avg loss: 0.4041, batch size: 38
2021-08-24 19:36:32,177 INFO [train.py:450] Epoch 0, batch 8900, batch avg loss 0.4218, total avg loss: 0.4047, batch size: 39
2021-08-24 19:36:39,527 INFO [train.py:450] Epoch 0, batch 8910, batch avg loss 0.4173, total avg loss: 0.4044, batch size: 41
2021-08-24 19:36:46,560 INFO [train.py:450] Epoch 0, batch 8920, batch avg loss 0.4135, total avg loss: 0.4030, batch size: 38
2021-08-24 19:36:53,876 INFO [train.py:450] Epoch 0, batch 8930, batch avg loss 0.4551, total avg loss: 0.4043, batch size: 39
2021-08-24 19:36:56,619 WARNING [cut.py:1694] To perform mix, energy must be non-zero and non-negative (got 0.0).  MonoCut with id "ca69d00e-03ce-03b6-0623-7241a349cd05" will not be mixed in.
2021-08-24 19:37:00,600 INFO [train.py:450] Epoch 0, batch 8940, batch avg loss 0.3783, total avg loss: 0.4037, batch size: 39
2021-08-24 19:37:07,606 INFO [train.py:450] Epoch 0, batch 8950, batch avg loss 0.4164, total avg loss: 0.4036, batch size: 39
2021-08-24 19:37:14,491 INFO [train.py:450] Epoch 0, batch 8960, batch avg loss 0.4106, total avg loss: 0.4042, batch size: 41
2021-08-24 19:37:21,674 INFO [train.py:450] Epoch 0, batch 8970, batch avg loss 0.4480, total avg loss: 0.4047, batch size: 44
2021-08-24 19:37:29,066 INFO [train.py:450] Epoch 0, batch 8980, batch avg loss 0.4162, total avg loss: 0.4044, batch size: 41
2021-08-24 19:37:36,228 INFO [train.py:450] Epoch 0, batch 8990, batch avg loss 0.3667, total avg loss: 0.4035, batch size: 38
2021-08-24 19:37:44,526 INFO [train.py:450] Epoch 0, batch 9000, batch avg loss 0.4303, total avg loss: 0.4034, batch size: 41
2021-08-24 19:38:23,087 INFO [train.py:482] Epoch 0, valid loss 0.2972, best valid loss: 0.2972 best valid epoch: 0
2021-08-24 19:38:28,991 INFO [train.py:450] Epoch 0, batch 9010, batch avg loss 0.3990, total avg loss: 0.3985, batch size: 38
2021-08-24 19:38:35,385 INFO [train.py:450] Epoch 0, batch 9020, batch avg loss 0.3743, total avg loss: 0.3947, batch size: 38
2021-08-24 19:38:42,264 INFO [train.py:450] Epoch 0, batch 9030, batch avg loss 0.3721, total avg loss: 0.4023, batch size: 40
2021-08-24 19:38:49,695 INFO [train.py:450] Epoch 0, batch 9040, batch avg loss 0.4035, total avg loss: 0.4056, batch size: 40
2021-08-24 19:38:56,338 INFO [train.py:450] Epoch 0, batch 9050, batch avg loss 0.4115, total avg loss: 0.4052, batch size: 40
2021-08-24 19:39:03,362 INFO [train.py:450] Epoch 0, batch 9060, batch avg loss 0.4258, total avg loss: 0.4062, batch size: 41
2021-08-24 19:39:10,664 INFO [train.py:450] Epoch 0, batch 9070, batch avg loss 0.4693, total avg loss: 0.4088, batch size: 42
2021-08-24 19:39:17,390 INFO [train.py:450] Epoch 0, batch 9080, batch avg loss 0.4576, total avg loss: 0.4091, batch size: 40
2021-08-24 19:39:24,277 INFO [train.py:450] Epoch 0, batch 9090, batch avg loss 0.4529, total avg loss: 0.4088, batch size: 41
2021-08-24 19:39:31,019 INFO [train.py:450] Epoch 0, batch 9100, batch avg loss 0.3184, total avg loss: 0.4074, batch size: 38
2021-08-24 19:39:38,136 INFO [train.py:450] Epoch 0, batch 9110, batch avg loss 0.3770, total avg loss: 0.4077, batch size: 41
2021-08-24 19:39:44,881 INFO [train.py:450] Epoch 0, batch 9120, batch avg loss 0.4235, total avg loss: 0.4066, batch size: 39
2021-08-24 19:39:51,960 INFO [train.py:450] Epoch 0, batch 9130, batch avg loss 0.4120, total avg loss: 0.4064, batch size: 38
2021-08-24 19:39:58,996 INFO [train.py:450] Epoch 0, batch 9140, batch avg loss 0.4384, total avg loss: 0.4058, batch size: 41
2021-08-24 19:40:05,498 INFO [train.py:450] Epoch 0, batch 9150, batch avg loss 0.3954, total avg loss: 0.4067, batch size: 41
2021-08-24 19:40:12,639 INFO [train.py:450] Epoch 0, batch 9160, batch avg loss 0.4528, total avg loss: 0.4050, batch size: 38
2021-08-24 19:40:19,568 INFO [train.py:450] Epoch 0, batch 9170, batch avg loss 0.3455, total avg loss: 0.4042, batch size: 36
2021-08-24 19:40:26,826 INFO [train.py:450] Epoch 0, batch 9180, batch avg loss 0.4021, total avg loss: 0.4045, batch size: 45
2021-08-24 19:40:33,973 INFO [train.py:450] Epoch 0, batch 9190, batch avg loss 0.3743, total avg loss: 0.4043, batch size: 36
2021-08-24 19:40:40,935 INFO [train.py:450] Epoch 0, batch 9200, batch avg loss 0.3848, total avg loss: 0.4034, batch size: 39
2021-08-24 19:40:47,565 INFO [train.py:450] Epoch 0, batch 9210, batch avg loss 0.4061, total avg loss: 0.3947, batch size: 42
2021-08-24 19:40:54,418 INFO [train.py:450] Epoch 0, batch 9220, batch avg loss 0.4148, total avg loss: 0.3951, batch size: 40
2021-08-24 19:41:01,443 INFO [train.py:450] Epoch 0, batch 9230, batch avg loss 0.4139, total avg loss: 0.3959, batch size: 40
2021-08-24 19:41:07,997 INFO [train.py:450] Epoch 0, batch 9240, batch avg loss 0.4709, total avg loss: 0.3999, batch size: 37
2021-08-24 19:41:14,520 INFO [train.py:450] Epoch 0, batch 9250, batch avg loss 0.3698, total avg loss: 0.3974, batch size: 38
2021-08-24 19:41:21,790 INFO [train.py:450] Epoch 0, batch 9260, batch avg loss 0.3823, total avg loss: 0.3978, batch size: 42
2021-08-24 19:41:28,556 INFO [train.py:450] Epoch 0, batch 9270, batch avg loss 0.3797, total avg loss: 0.3958, batch size: 43
2021-08-24 19:41:35,112 INFO [train.py:450] Epoch 0, batch 9280, batch avg loss 0.4566, total avg loss: 0.3955, batch size: 41
2021-08-24 19:41:41,726 INFO [train.py:450] Epoch 0, batch 9290, batch avg loss 0.4147, total avg loss: 0.3948, batch size: 38
2021-08-24 19:41:48,341 INFO [train.py:450] Epoch 0, batch 9300, batch avg loss 0.4076, total avg loss: 0.3947, batch size: 43
2021-08-24 19:41:55,041 INFO [train.py:450] Epoch 0, batch 9310, batch avg loss 0.4736, total avg loss: 0.3959, batch size: 40
2021-08-24 19:42:01,932 INFO [train.py:450] Epoch 0, batch 9320, batch avg loss 0.4854, total avg loss: 0.3967, batch size: 40
2021-08-24 19:42:09,267 INFO [train.py:450] Epoch 0, batch 9330, batch avg loss 0.5068, total avg loss: 0.3974, batch size: 41
2021-08-24 19:42:15,772 INFO [train.py:450] Epoch 0, batch 9340, batch avg loss 0.4174, total avg loss: 0.3983, batch size: 37
2021-08-24 19:42:22,466 INFO [train.py:450] Epoch 0, batch 9350, batch avg loss 0.3658, total avg loss: 0.3971, batch size: 39
2021-08-24 19:42:28,564 INFO [train.py:450] Epoch 0, batch 9360, batch avg loss 0.3630, total avg loss: 0.3968, batch size: 43
2021-08-24 19:42:35,379 INFO [train.py:450] Epoch 0, batch 9370, batch avg loss 0.3620, total avg loss: 0.3974, batch size: 38
2021-08-24 19:42:41,987 INFO [train.py:450] Epoch 0, batch 9380, batch avg loss 0.3629, total avg loss: 0.3980, batch size: 39
2021-08-24 19:42:49,642 INFO [train.py:450] Epoch 0, batch 9390, batch avg loss 0.4316, total avg loss: 0.3987, batch size: 40
2021-08-24 19:42:56,888 INFO [train.py:450] Epoch 0, batch 9400, batch avg loss 0.4029, total avg loss: 0.3995, batch size: 36
2021-08-24 19:43:05,081 INFO [train.py:450] Epoch 0, batch 9410, batch avg loss 0.4192, total avg loss: 0.4119, batch size: 40
2021-08-24 19:43:13,651 INFO [train.py:450] Epoch 0, batch 9420, batch avg loss 0.3854, total avg loss: 0.4084, batch size: 40
2021-08-24 19:43:20,400 INFO [train.py:450] Epoch 0, batch 9430, batch avg loss 0.4347, total avg loss: 0.4093, batch size: 40
2021-08-24 19:43:27,595 INFO [train.py:450] Epoch 0, batch 9440, batch avg loss 0.4088, total avg loss: 0.4081, batch size: 39
2021-08-24 19:43:34,348 INFO [train.py:450] Epoch 0, batch 9450, batch avg loss 0.4094, total avg loss: 0.4068, batch size: 39
2021-08-24 19:43:41,406 INFO [train.py:450] Epoch 0, batch 9460, batch avg loss 0.4398, total avg loss: 0.4067, batch size: 40
2021-08-24 19:43:48,043 INFO [train.py:450] Epoch 0, batch 9470, batch avg loss 0.3555, total avg loss: 0.4058, batch size: 38
2021-08-24 19:43:54,365 INFO [train.py:450] Epoch 0, batch 9480, batch avg loss 0.3757, total avg loss: 0.4050, batch size: 35
2021-08-24 19:44:01,613 INFO [train.py:450] Epoch 0, batch 9490, batch avg loss 0.4132, total avg loss: 0.4045, batch size: 39
2021-08-24 19:44:08,442 INFO [train.py:450] Epoch 0, batch 9500, batch avg loss 0.4524, total avg loss: 0.4062, batch size: 41
2021-08-24 19:44:15,011 INFO [train.py:450] Epoch 0, batch 9510, batch avg loss 0.4166, total avg loss: 0.4059, batch size: 39
2021-08-24 19:44:21,641 INFO [train.py:450] Epoch 0, batch 9520, batch avg loss 0.3891, total avg loss: 0.4041, batch size: 38
2021-08-24 19:44:27,886 INFO [train.py:450] Epoch 0, batch 9530, batch avg loss 0.4085, total avg loss: 0.4034, batch size: 37
2021-08-24 19:44:34,341 INFO [train.py:450] Epoch 0, batch 9540, batch avg loss 0.4049, total avg loss: 0.4031, batch size: 38
2021-08-24 19:44:41,173 INFO [train.py:450] Epoch 0, batch 9550, batch avg loss 0.4036, total avg loss: 0.4034, batch size: 42
2021-08-24 19:44:47,966 INFO [train.py:450] Epoch 0, batch 9560, batch avg loss 0.3708, total avg loss: 0.4027, batch size: 41
2021-08-24 19:44:54,598 INFO [train.py:450] Epoch 0, batch 9570, batch avg loss 0.3933, total avg loss: 0.4029, batch size: 39
2021-08-24 19:45:01,075 INFO [train.py:450] Epoch 0, batch 9580, batch avg loss 0.4749, total avg loss: 0.4036, batch size: 43
2021-08-24 19:45:07,862 INFO [train.py:450] Epoch 0, batch 9590, batch avg loss 0.3903, total avg loss: 0.4036, batch size: 40
2021-08-24 19:45:14,730 INFO [train.py:450] Epoch 0, batch 9600, batch avg loss 0.4699, total avg loss: 0.4039, batch size: 40
2021-08-24 19:45:21,538 INFO [train.py:450] Epoch 0, batch 9610, batch avg loss 0.3819, total avg loss: 0.4014, batch size: 36
2021-08-24 19:45:27,977 INFO [train.py:450] Epoch 0, batch 9620, batch avg loss 0.4485, total avg loss: 0.4090, batch size: 39
2021-08-24 19:45:34,808 INFO [train.py:450] Epoch 0, batch 9630, batch avg loss 0.3999, total avg loss: 0.4128, batch size: 39
2021-08-24 19:45:41,496 INFO [train.py:450] Epoch 0, batch 9640, batch avg loss 0.4165, total avg loss: 0.4127, batch size: 41
2021-08-24 19:45:48,461 INFO [train.py:450] Epoch 0, batch 9650, batch avg loss 0.3731, total avg loss: 0.4099, batch size: 38
2021-08-24 19:45:54,640 INFO [train.py:450] Epoch 0, batch 9660, batch avg loss 0.3756, total avg loss: 0.4084, batch size: 39
2021-08-24 19:46:01,871 INFO [train.py:450] Epoch 0, batch 9670, batch avg loss 0.3960, total avg loss: 0.4083, batch size: 40
2021-08-24 19:46:08,316 INFO [train.py:450] Epoch 0, batch 9680, batch avg loss 0.3326, total avg loss: 0.4043, batch size: 40
2021-08-24 19:46:15,904 INFO [train.py:450] Epoch 0, batch 9690, batch avg loss 0.4142, total avg loss: 0.4047, batch size: 41
2021-08-24 19:46:23,133 INFO [train.py:450] Epoch 0, batch 9700, batch avg loss 0.3955, total avg loss: 0.4032, batch size: 37
2021-08-24 19:46:30,026 INFO [train.py:450] Epoch 0, batch 9710, batch avg loss 0.4047, total avg loss: 0.4032, batch size: 39
2021-08-24 19:46:36,941 INFO [train.py:450] Epoch 0, batch 9720, batch avg loss 0.3993, total avg loss: 0.4036, batch size: 42
2021-08-24 19:46:43,445 INFO [train.py:450] Epoch 0, batch 9730, batch avg loss 0.3725, total avg loss: 0.4023, batch size: 40
2021-08-24 19:46:49,811 INFO [train.py:450] Epoch 0, batch 9740, batch avg loss 0.4384, total avg loss: 0.4028, batch size: 42
2021-08-24 19:46:56,511 INFO [train.py:450] Epoch 0, batch 9750, batch avg loss 0.4656, total avg loss: 0.4037, batch size: 39
2021-08-24 19:47:03,293 INFO [train.py:450] Epoch 0, batch 9760, batch avg loss 0.3646, total avg loss: 0.4040, batch size: 40
2021-08-24 19:47:09,744 INFO [train.py:450] Epoch 0, batch 9770, batch avg loss 0.4711, total avg loss: 0.4032, batch size: 41
2021-08-24 19:47:16,397 INFO [train.py:450] Epoch 0, batch 9780, batch avg loss 0.4279, total avg loss: 0.4036, batch size: 37
2021-08-24 19:47:22,905 INFO [train.py:450] Epoch 0, batch 9790, batch avg loss 0.3869, total avg loss: 0.4038, batch size: 42
2021-08-24 19:47:29,307 INFO [train.py:450] Epoch 0, batch 9800, batch avg loss 0.4429, total avg loss: 0.4033, batch size: 40
2021-08-24 19:47:36,170 INFO [train.py:450] Epoch 0, batch 9810, batch avg loss 0.4545, total avg loss: 0.4180, batch size: 38
2021-08-24 19:47:43,055 INFO [train.py:450] Epoch 0, batch 9820, batch avg loss 0.4192, total avg loss: 0.4097, batch size: 41
2021-08-24 19:47:49,977 INFO [train.py:450] Epoch 0, batch 9830, batch avg loss 0.4219, total avg loss: 0.4028, batch size: 43
2021-08-24 19:47:57,196 INFO [train.py:450] Epoch 0, batch 9840, batch avg loss 0.3945, total avg loss: 0.3993, batch size: 38
2021-08-24 19:48:04,440 INFO [train.py:450] Epoch 0, batch 9850, batch avg loss 0.3706, total avg loss: 0.3988, batch size: 39
2021-08-24 19:48:13,020 INFO [train.py:450] Epoch 0, batch 9860, batch avg loss 0.4114, total avg loss: 0.3994, batch size: 40
2021-08-24 19:48:21,100 INFO [train.py:450] Epoch 0, batch 9870, batch avg loss 0.3851, total avg loss: 0.4000, batch size: 40
2021-08-24 19:48:27,555 INFO [train.py:450] Epoch 0, batch 9880, batch avg loss 0.3378, total avg loss: 0.3991, batch size: 42
2021-08-24 19:48:33,883 INFO [train.py:450] Epoch 0, batch 9890, batch avg loss 0.4526, total avg loss: 0.3983, batch size: 39
2021-08-24 19:48:40,602 INFO [train.py:450] Epoch 0, batch 9900, batch avg loss 0.4470, total avg loss: 0.3987, batch size: 41
2021-08-24 19:48:47,285 INFO [train.py:450] Epoch 0, batch 9910, batch avg loss 0.3612, total avg loss: 0.3988, batch size: 41
2021-08-24 19:48:54,131 INFO [train.py:450] Epoch 0, batch 9920, batch avg loss 0.3698, total avg loss: 0.3973, batch size: 39
2021-08-24 19:49:00,837 INFO [train.py:450] Epoch 0, batch 9930, batch avg loss 0.4094, total avg loss: 0.3976, batch size: 39
2021-08-24 19:49:06,885 INFO [train.py:450] Epoch 0, batch 9940, batch avg loss 0.4026, total avg loss: 0.3988, batch size: 36
2021-08-24 19:49:13,219 INFO [train.py:450] Epoch 0, batch 9950, batch avg loss 0.3848, total avg loss: 0.3988, batch size: 39
2021-08-24 19:49:20,088 INFO [train.py:450] Epoch 0, batch 9960, batch avg loss 0.3835, total avg loss: 0.3995, batch size: 40
2021-08-24 19:49:26,589 INFO [train.py:450] Epoch 0, batch 9970, batch avg loss 0.3628, total avg loss: 0.3991, batch size: 39
2021-08-24 19:49:33,509 INFO [train.py:450] Epoch 0, batch 9980, batch avg loss 0.4382, total avg loss: 0.4002, batch size: 39
2021-08-24 19:49:39,832 INFO [train.py:450] Epoch 0, batch 9990, batch avg loss 0.4109, total avg loss: 0.3993, batch size: 36
2021-08-24 19:49:46,504 INFO [train.py:450] Epoch 0, batch 10000, batch avg loss 0.3658, total avg loss: 0.3988, batch size: 41
2021-08-24 19:50:24,961 INFO [train.py:482] Epoch 0, valid loss 0.2911, best valid loss: 0.2911 best valid epoch: 0
2021-08-24 19:50:30,764 INFO [train.py:450] Epoch 0, batch 10010, batch avg loss 0.4133, total avg loss: 0.4014, batch size: 38
2021-08-24 19:50:37,413 INFO [train.py:450] Epoch 0, batch 10020, batch avg loss 0.3691, total avg loss: 0.3974, batch size: 40
2021-08-24 19:50:44,247 INFO [train.py:450] Epoch 0, batch 10030, batch avg loss 0.3941, total avg loss: 0.3978, batch size: 43
2021-08-24 19:50:50,719 INFO [train.py:450] Epoch 0, batch 10040, batch avg loss 0.4518, total avg loss: 0.4001, batch size: 39
2021-08-24 19:50:56,909 INFO [train.py:450] Epoch 0, batch 10050, batch avg loss 0.3652, total avg loss: 0.4013, batch size: 37
2021-08-24 19:51:03,198 INFO [train.py:450] Epoch 0, batch 10060, batch avg loss 0.3543, total avg loss: 0.4019, batch size: 36
2021-08-24 19:51:09,882 INFO [train.py:450] Epoch 0, batch 10070, batch avg loss 0.3901, total avg loss: 0.3990, batch size: 37
2021-08-24 19:51:16,219 INFO [train.py:450] Epoch 0, batch 10080, batch avg loss 0.4374, total avg loss: 0.4002, batch size: 41
2021-08-24 19:51:22,687 INFO [train.py:450] Epoch 0, batch 10090, batch avg loss 0.3699, total avg loss: 0.4000, batch size: 37
2021-08-24 19:51:29,325 INFO [train.py:450] Epoch 0, batch 10100, batch avg loss 0.3687, total avg loss: 0.3992, batch size: 41
2021-08-24 19:51:35,683 INFO [train.py:450] Epoch 0, batch 10110, batch avg loss 0.3933, total avg loss: 0.3979, batch size: 38
2021-08-24 19:51:42,161 INFO [train.py:450] Epoch 0, batch 10120, batch avg loss 0.4171, total avg loss: 0.3984, batch size: 42
2021-08-24 19:51:49,116 INFO [train.py:450] Epoch 0, batch 10130, batch avg loss 0.3941, total avg loss: 0.3986, batch size: 39
2021-08-24 19:51:55,933 INFO [train.py:450] Epoch 0, batch 10140, batch avg loss 0.4107, total avg loss: 0.3981, batch size: 42
2021-08-24 19:52:02,500 INFO [train.py:450] Epoch 0, batch 10150, batch avg loss 0.3944, total avg loss: 0.3982, batch size: 38
2021-08-24 19:52:08,963 INFO [train.py:450] Epoch 0, batch 10160, batch avg loss 0.3608, total avg loss: 0.3980, batch size: 37
2021-08-24 19:52:15,561 INFO [train.py:450] Epoch 0, batch 10170, batch avg loss 0.3975, total avg loss: 0.3979, batch size: 36
2021-08-24 19:52:22,233 INFO [train.py:450] Epoch 0, batch 10180, batch avg loss 0.3790, total avg loss: 0.3988, batch size: 39
2021-08-24 19:52:28,442 INFO [train.py:450] Epoch 0, batch 10190, batch avg loss 0.4458, total avg loss: 0.3981, batch size: 38
2021-08-24 19:52:34,703 INFO [train.py:450] Epoch 0, batch 10200, batch avg loss 0.4481, total avg loss: 0.3992, batch size: 41
2021-08-24 19:52:41,205 INFO [train.py:450] Epoch 0, batch 10210, batch avg loss 0.3748, total avg loss: 0.3957, batch size: 41
2021-08-24 19:52:47,603 INFO [train.py:450] Epoch 0, batch 10220, batch avg loss 0.5087, total avg loss: 0.4008, batch size: 41
2021-08-24 19:52:55,383 INFO [train.py:450] Epoch 0, batch 10230, batch avg loss 0.4138, total avg loss: 0.3990, batch size: 37
2021-08-24 19:53:01,532 INFO [train.py:450] Epoch 0, batch 10240, batch avg loss 0.3566, total avg loss: 0.3975, batch size: 36
2021-08-24 19:53:12,032 INFO [train.py:450] Epoch 0, batch 10250, batch avg loss 0.4386, total avg loss: 0.3988, batch size: 41
2021-08-24 19:53:18,208 INFO [train.py:450] Epoch 0, batch 10260, batch avg loss 0.4283, total avg loss: 0.3976, batch size: 42
2021-08-24 19:53:24,300 INFO [train.py:450] Epoch 0, batch 10270, batch avg loss 0.3462, total avg loss: 0.3968, batch size: 38
2021-08-24 19:53:30,313 INFO [train.py:450] Epoch 0, batch 10280, batch avg loss 0.3708, total avg loss: 0.3938, batch size: 42
2021-08-24 19:53:36,505 INFO [train.py:450] Epoch 0, batch 10290, batch avg loss 0.3775, total avg loss: 0.3936, batch size: 42
2021-08-24 19:53:42,574 INFO [train.py:450] Epoch 0, batch 10300, batch avg loss 0.3975, total avg loss: 0.3939, batch size: 41
2021-08-24 19:53:48,835 INFO [train.py:450] Epoch 0, batch 10310, batch avg loss 0.3621, total avg loss: 0.3937, batch size: 38
2021-08-24 19:53:55,335 INFO [train.py:450] Epoch 0, batch 10320, batch avg loss 0.4841, total avg loss: 0.3941, batch size: 39
2021-08-24 19:54:01,595 INFO [train.py:450] Epoch 0, batch 10330, batch avg loss 0.3868, total avg loss: 0.3951, batch size: 38
2021-08-24 19:54:08,525 INFO [train.py:450] Epoch 0, batch 10340, batch avg loss 0.4290, total avg loss: 0.3949, batch size: 39
2021-08-24 19:54:15,265 INFO [train.py:450] Epoch 0, batch 10350, batch avg loss 0.3807, total avg loss: 0.3941, batch size: 43
2021-08-24 19:54:21,504 INFO [train.py:450] Epoch 0, batch 10360, batch avg loss 0.3602, total avg loss: 0.3943, batch size: 39
2021-08-24 19:54:27,723 INFO [train.py:450] Epoch 0, batch 10370, batch avg loss 0.3844, total avg loss: 0.3947, batch size: 42
2021-08-24 19:54:34,314 INFO [train.py:450] Epoch 0, batch 10380, batch avg loss 0.3870, total avg loss: 0.3954, batch size: 40
2021-08-24 19:54:40,606 INFO [train.py:450] Epoch 0, batch 10390, batch avg loss 0.4082, total avg loss: 0.3950, batch size: 36
2021-08-24 19:54:46,775 INFO [train.py:450] Epoch 0, batch 10400, batch avg loss 0.3992, total avg loss: 0.3947, batch size: 41
2021-08-24 19:54:53,254 INFO [train.py:450] Epoch 0, batch 10410, batch avg loss 0.3431, total avg loss: 0.3885, batch size: 39
2021-08-24 19:55:00,031 INFO [train.py:450] Epoch 0, batch 10420, batch avg loss 0.3615, total avg loss: 0.3922, batch size: 40
2021-08-24 19:55:06,195 INFO [train.py:450] Epoch 0, batch 10430, batch avg loss 0.4259, total avg loss: 0.3962, batch size: 41
2021-08-24 19:55:12,641 INFO [train.py:450] Epoch 0, batch 10440, batch avg loss 0.3684, total avg loss: 0.3909, batch size: 41
2021-08-24 19:55:19,348 INFO [train.py:450] Epoch 0, batch 10450, batch avg loss 0.3664, total avg loss: 0.3910, batch size: 44
2021-08-24 19:55:25,460 INFO [train.py:450] Epoch 0, batch 10460, batch avg loss 0.3629, total avg loss: 0.3908, batch size: 38
2021-08-24 19:55:31,637 INFO [train.py:450] Epoch 0, batch 10470, batch avg loss 0.4280, total avg loss: 0.3940, batch size: 40
2021-08-24 19:55:37,803 INFO [train.py:450] Epoch 0, batch 10480, batch avg loss 0.4099, total avg loss: 0.3931, batch size: 41
2021-08-24 19:55:44,601 INFO [train.py:450] Epoch 0, batch 10490, batch avg loss 0.4367, total avg loss: 0.3925, batch size: 42
2021-08-24 19:55:50,801 INFO [train.py:450] Epoch 0, batch 10500, batch avg loss 0.4108, total avg loss: 0.3910, batch size: 39
2021-08-24 19:55:56,991 INFO [train.py:450] Epoch 0, batch 10510, batch avg loss 0.3998, total avg loss: 0.3903, batch size: 40
2021-08-24 19:56:03,455 INFO [train.py:450] Epoch 0, batch 10520, batch avg loss 0.3883, total avg loss: 0.3905, batch size: 38
2021-08-24 19:56:09,844 INFO [train.py:450] Epoch 0, batch 10530, batch avg loss 0.4388, total avg loss: 0.3906, batch size: 37
2021-08-24 19:56:16,023 INFO [train.py:450] Epoch 0, batch 10540, batch avg loss 0.3231, total avg loss: 0.3901, batch size: 40
2021-08-24 19:56:22,022 INFO [train.py:450] Epoch 0, batch 10550, batch avg loss 0.4002, total avg loss: 0.3901, batch size: 38
2021-08-24 19:56:27,935 INFO [train.py:450] Epoch 0, batch 10560, batch avg loss 0.3865, total avg loss: 0.3900, batch size: 43
2021-08-24 19:56:34,106 INFO [train.py:450] Epoch 0, batch 10570, batch avg loss 0.3320, total avg loss: 0.3893, batch size: 37
2021-08-24 19:56:40,149 INFO [train.py:450] Epoch 0, batch 10580, batch avg loss 0.3314, total avg loss: 0.3884, batch size: 43
2021-08-24 19:56:46,269 INFO [train.py:450] Epoch 0, batch 10590, batch avg loss 0.3973, total avg loss: 0.3887, batch size: 42
2021-08-24 19:56:52,393 INFO [train.py:450] Epoch 0, batch 10600, batch avg loss 0.3763, total avg loss: 0.3881, batch size: 39
2021-08-24 19:56:58,780 INFO [train.py:450] Epoch 0, batch 10610, batch avg loss 0.3945, total avg loss: 0.4027, batch size: 44
2021-08-24 19:57:05,153 INFO [train.py:450] Epoch 0, batch 10620, batch avg loss 0.3340, total avg loss: 0.3914, batch size: 39
2021-08-24 19:57:11,073 INFO [train.py:450] Epoch 0, batch 10630, batch avg loss 0.4270, total avg loss: 0.3925, batch size: 44
2021-08-24 19:57:17,158 INFO [train.py:450] Epoch 0, batch 10640, batch avg loss 0.4110, total avg loss: 0.3894, batch size: 38
2021-08-24 19:57:23,290 INFO [train.py:450] Epoch 0, batch 10650, batch avg loss 0.3557, total avg loss: 0.3900, batch size: 37
2021-08-24 19:57:29,443 INFO [train.py:450] Epoch 0, batch 10660, batch avg loss 0.3707, total avg loss: 0.3929, batch size: 41
2021-08-24 19:57:36,033 INFO [train.py:450] Epoch 0, batch 10670, batch avg loss 0.3963, total avg loss: 0.3931, batch size: 42
2021-08-24 19:57:42,073 INFO [train.py:450] Epoch 0, batch 10680, batch avg loss 0.4103, total avg loss: 0.3935, batch size: 41
2021-08-24 19:57:47,963 INFO [train.py:450] Epoch 0, batch 10690, batch avg loss 0.4098, total avg loss: 0.3914, batch size: 43
2021-08-24 19:57:54,394 INFO [train.py:450] Epoch 0, batch 10700, batch avg loss 0.3931, total avg loss: 0.3900, batch size: 37
2021-08-24 19:58:00,779 INFO [train.py:450] Epoch 0, batch 10710, batch avg loss 0.4320, total avg loss: 0.3900, batch size: 37
2021-08-24 19:58:07,328 INFO [train.py:450] Epoch 0, batch 10720, batch avg loss 0.4244, total avg loss: 0.3900, batch size: 39
2021-08-24 19:58:14,572 INFO [train.py:450] Epoch 0, batch 10730, batch avg loss 0.3927, total avg loss: 0.3905, batch size: 39
2021-08-24 19:58:20,497 INFO [train.py:450] Epoch 0, batch 10740, batch avg loss 0.3678, total avg loss: 0.3902, batch size: 43
2021-08-24 19:58:30,209 INFO [train.py:450] Epoch 0, batch 10750, batch avg loss 0.3990, total avg loss: 0.3910, batch size: 40
2021-08-24 19:58:36,403 INFO [train.py:450] Epoch 0, batch 10760, batch avg loss 0.3946, total avg loss: 0.3902, batch size: 44
2021-08-24 19:58:42,326 INFO [train.py:450] Epoch 0, batch 10770, batch avg loss 0.3942, total avg loss: 0.3897, batch size: 40
2021-08-24 19:58:48,275 INFO [train.py:450] Epoch 0, batch 10780, batch avg loss 0.3834, total avg loss: 0.3899, batch size: 40
2021-08-24 19:58:54,193 INFO [train.py:450] Epoch 0, batch 10790, batch avg loss 0.4614, total avg loss: 0.3895, batch size: 40
2021-08-24 19:59:00,625 INFO [train.py:450] Epoch 0, batch 10800, batch avg loss 0.4400, total avg loss: 0.3908, batch size: 41
2021-08-24 19:59:06,814 INFO [train.py:450] Epoch 0, batch 10810, batch avg loss 0.3621, total avg loss: 0.3788, batch size: 41
2021-08-24 19:59:12,861 INFO [train.py:450] Epoch 0, batch 10820, batch avg loss 0.3715, total avg loss: 0.3880, batch size: 38
2021-08-24 19:59:18,913 INFO [train.py:450] Epoch 0, batch 10830, batch avg loss 0.3845, total avg loss: 0.3906, batch size: 43
2021-08-24 19:59:24,713 INFO [train.py:450] Epoch 0, batch 10840, batch avg loss 0.4202, total avg loss: 0.3915, batch size: 42
2021-08-24 19:59:30,723 INFO [train.py:450] Epoch 0, batch 10850, batch avg loss 0.3736, total avg loss: 0.3909, batch size: 45
2021-08-24 19:59:36,542 INFO [train.py:450] Epoch 0, batch 10860, batch avg loss 0.4089, total avg loss: 0.3910, batch size: 36
2021-08-24 19:59:42,581 INFO [train.py:450] Epoch 0, batch 10870, batch avg loss 0.3701, total avg loss: 0.3919, batch size: 43
2021-08-24 19:59:48,821 INFO [train.py:450] Epoch 0, batch 10880, batch avg loss 0.3643, total avg loss: 0.3911, batch size: 40
2021-08-24 19:59:54,698 INFO [train.py:450] Epoch 0, batch 10890, batch avg loss 0.3904, total avg loss: 0.3923, batch size: 38
2021-08-24 20:00:00,553 INFO [train.py:450] Epoch 0, batch 10900, batch avg loss 0.4287, total avg loss: 0.3927, batch size: 40
2021-08-24 20:00:06,529 INFO [train.py:450] Epoch 0, batch 10910, batch avg loss 0.3975, total avg loss: 0.3922, batch size: 41
2021-08-24 20:00:12,617 INFO [train.py:450] Epoch 0, batch 10920, batch avg loss 0.3767, total avg loss: 0.3920, batch size: 41
2021-08-24 20:00:19,112 INFO [train.py:450] Epoch 0, batch 10930, batch avg loss 0.3747, total avg loss: 0.3916, batch size: 41
2021-08-24 20:00:25,373 INFO [train.py:450] Epoch 0, batch 10940, batch avg loss 0.3906, total avg loss: 0.3912, batch size: 43
2021-08-24 20:00:31,564 INFO [train.py:450] Epoch 0, batch 10950, batch avg loss 0.3686, total avg loss: 0.3905, batch size: 39
2021-08-24 20:00:37,513 INFO [train.py:450] Epoch 0, batch 10960, batch avg loss 0.3977, total avg loss: 0.3902, batch size: 39
2021-08-24 20:00:43,715 INFO [train.py:450] Epoch 0, batch 10970, batch avg loss 0.4176, total avg loss: 0.3903, batch size: 38
2021-08-24 20:00:49,524 INFO [train.py:450] Epoch 0, batch 10980, batch avg loss 0.3993, total avg loss: 0.3912, batch size: 38
2021-08-24 20:00:55,341 INFO [train.py:450] Epoch 0, batch 10990, batch avg loss 0.4141, total avg loss: 0.3909, batch size: 46
2021-08-24 20:01:01,438 INFO [train.py:450] Epoch 0, batch 11000, batch avg loss 0.4243, total avg loss: 0.3918, batch size: 39
2021-08-24 20:01:39,777 INFO [train.py:482] Epoch 0, valid loss 0.2882, best valid loss: 0.2882 best valid epoch: 0
2021-08-24 20:01:45,565 INFO [train.py:450] Epoch 0, batch 11010, batch avg loss 0.4132, total avg loss: 0.4127, batch size: 43
2021-08-24 20:01:51,428 INFO [train.py:450] Epoch 0, batch 11020, batch avg loss 0.3906, total avg loss: 0.4068, batch size: 40
2021-08-24 20:01:57,342 INFO [train.py:450] Epoch 0, batch 11030, batch avg loss 0.3865, total avg loss: 0.4037, batch size: 41
2021-08-24 20:02:03,414 INFO [train.py:450] Epoch 0, batch 11040, batch avg loss 0.3341, total avg loss: 0.3967, batch size: 37
2021-08-24 20:02:09,422 INFO [train.py:450] Epoch 0, batch 11050, batch avg loss 0.3446, total avg loss: 0.3944, batch size: 38
2021-08-24 20:02:15,322 INFO [train.py:450] Epoch 0, batch 11060, batch avg loss 0.4402, total avg loss: 0.3944, batch size: 36
2021-08-24 20:02:21,380 INFO [train.py:450] Epoch 0, batch 11070, batch avg loss 0.4649, total avg loss: 0.3950, batch size: 39
2021-08-24 20:02:27,329 INFO [train.py:450] Epoch 0, batch 11080, batch avg loss 0.4101, total avg loss: 0.3951, batch size: 41
2021-08-24 20:02:33,291 INFO [train.py:450] Epoch 0, batch 11090, batch avg loss 0.4054, total avg loss: 0.3946, batch size: 39
2021-08-24 20:02:39,164 INFO [train.py:450] Epoch 0, batch 11100, batch avg loss 0.4061, total avg loss: 0.3962, batch size: 43
2021-08-24 20:02:45,043 INFO [train.py:450] Epoch 0, batch 11110, batch avg loss 0.3501, total avg loss: 0.3956, batch size: 38
2021-08-24 20:02:51,047 INFO [train.py:450] Epoch 0, batch 11120, batch avg loss 0.4081, total avg loss: 0.3954, batch size: 39
2021-08-24 20:02:58,622 INFO [train.py:450] Epoch 0, batch 11130, batch avg loss 0.3649, total avg loss: 0.3950, batch size: 43
2021-08-24 20:03:04,530 INFO [train.py:450] Epoch 0, batch 11140, batch avg loss 0.3786, total avg loss: 0.3944, batch size: 42
2021-08-24 20:03:10,431 INFO [train.py:450] Epoch 0, batch 11150, batch avg loss 0.3819, total avg loss: 0.3947, batch size: 40
2021-08-24 20:03:16,432 INFO [train.py:450] Epoch 0, batch 11160, batch avg loss 0.3870, total avg loss: 0.3930, batch size: 39
2021-08-24 20:03:23,632 INFO [train.py:450] Epoch 0, batch 11170, batch avg loss 0.4316, total avg loss: 0.3942, batch size: 37
2021-08-24 20:03:29,653 INFO [train.py:450] Epoch 0, batch 11180, batch avg loss 0.4305, total avg loss: 0.3945, batch size: 38
2021-08-24 20:03:37,512 INFO [train.py:450] Epoch 0, batch 11190, batch avg loss 0.3762, total avg loss: 0.3944, batch size: 39
2021-08-24 20:03:44,150 INFO [train.py:450] Epoch 0, batch 11200, batch avg loss 0.3534, total avg loss: 0.3942, batch size: 40
2021-08-24 20:03:50,137 INFO [train.py:450] Epoch 0, batch 11210, batch avg loss 0.3818, total avg loss: 0.3838, batch size: 41
2021-08-24 20:03:55,927 INFO [train.py:450] Epoch 0, batch 11220, batch avg loss 0.3548, total avg loss: 0.3884, batch size: 40
2021-08-24 20:04:01,830 INFO [train.py:450] Epoch 0, batch 11230, batch avg loss 0.3778, total avg loss: 0.3878, batch size: 40
2021-08-24 20:04:07,751 INFO [train.py:450] Epoch 0, batch 11240, batch avg loss 0.4074, total avg loss: 0.3870, batch size: 38
2021-08-24 20:04:13,510 INFO [train.py:450] Epoch 0, batch 11250, batch avg loss 0.3729, total avg loss: 0.3874, batch size: 39
2021-08-24 20:04:19,425 INFO [train.py:450] Epoch 0, batch 11260, batch avg loss 0.3646, total avg loss: 0.3872, batch size: 37
2021-08-24 20:04:25,337 INFO [train.py:450] Epoch 0, batch 11270, batch avg loss 0.4512, total avg loss: 0.3889, batch size: 46
2021-08-24 20:04:31,179 INFO [train.py:450] Epoch 0, batch 11280, batch avg loss 0.4036, total avg loss: 0.3894, batch size: 41
2021-08-24 20:04:37,051 INFO [train.py:450] Epoch 0, batch 11290, batch avg loss 0.3958, total avg loss: 0.3895, batch size: 37
2021-08-24 20:04:43,000 INFO [train.py:450] Epoch 0, batch 11300, batch avg loss 0.3986, total avg loss: 0.3902, batch size: 42
2021-08-24 20:04:49,048 INFO [train.py:450] Epoch 0, batch 11310, batch avg loss 0.4086, total avg loss: 0.3914, batch size: 40
2021-08-24 20:04:54,915 INFO [train.py:450] Epoch 0, batch 11320, batch avg loss 0.3897, total avg loss: 0.3931, batch size: 41
2021-08-24 20:05:00,864 INFO [train.py:450] Epoch 0, batch 11330, batch avg loss 0.4100, total avg loss: 0.3939, batch size: 41
2021-08-24 20:05:06,732 INFO [train.py:450] Epoch 0, batch 11340, batch avg loss 0.3722, total avg loss: 0.3938, batch size: 38
2021-08-24 20:05:12,625 INFO [train.py:450] Epoch 0, batch 11350, batch avg loss 0.4316, total avg loss: 0.3936, batch size: 37
2021-08-24 20:05:18,519 INFO [train.py:450] Epoch 0, batch 11360, batch avg loss 0.3517, total avg loss: 0.3933, batch size: 41
2021-08-24 20:05:24,423 INFO [train.py:450] Epoch 0, batch 11370, batch avg loss 0.3837, total avg loss: 0.3943, batch size: 43
2021-08-24 20:05:30,279 INFO [train.py:450] Epoch 0, batch 11380, batch avg loss 0.3788, total avg loss: 0.3939, batch size: 37
2021-08-24 20:05:36,207 INFO [train.py:450] Epoch 0, batch 11390, batch avg loss 0.3562, total avg loss: 0.3927, batch size: 39
2021-08-24 20:05:42,076 INFO [train.py:450] Epoch 0, batch 11400, batch avg loss 0.4311, total avg loss: 0.3927, batch size: 37
2021-08-24 20:05:48,082 INFO [train.py:450] Epoch 0, batch 11410, batch avg loss 0.3729, total avg loss: 0.4115, batch size: 40
2021-08-24 20:05:54,158 INFO [train.py:450] Epoch 0, batch 11420, batch avg loss 0.3705, total avg loss: 0.4035, batch size: 42
2021-08-24 20:05:59,972 INFO [train.py:450] Epoch 0, batch 11430, batch avg loss 0.3597, total avg loss: 0.3987, batch size: 39
2021-08-24 20:06:05,934 INFO [train.py:450] Epoch 0, batch 11440, batch avg loss 0.4216, total avg loss: 0.3972, batch size: 40
2021-08-24 20:06:11,705 INFO [train.py:450] Epoch 0, batch 11450, batch avg loss 0.4252, total avg loss: 0.3985, batch size: 38
2021-08-24 20:06:17,479 INFO [train.py:450] Epoch 0, batch 11460, batch avg loss 0.3878, total avg loss: 0.4001, batch size: 40
2021-08-24 20:06:23,367 INFO [train.py:450] Epoch 0, batch 11470, batch avg loss 0.3826, total avg loss: 0.3979, batch size: 40
2021-08-24 20:06:29,168 INFO [train.py:450] Epoch 0, batch 11480, batch avg loss 0.3399, total avg loss: 0.3986, batch size: 37
2021-08-24 20:06:35,049 INFO [train.py:450] Epoch 0, batch 11490, batch avg loss 0.3365, total avg loss: 0.3963, batch size: 37
2021-08-24 20:06:41,023 INFO [train.py:450] Epoch 0, batch 11500, batch avg loss 0.3755, total avg loss: 0.3951, batch size: 38
2021-08-24 20:06:46,964 INFO [train.py:450] Epoch 0, batch 11510, batch avg loss 0.3999, total avg loss: 0.3957, batch size: 42
2021-08-24 20:06:52,786 INFO [train.py:450] Epoch 0, batch 11520, batch avg loss 0.3597, total avg loss: 0.3946, batch size: 40
2021-08-24 20:06:58,618 INFO [train.py:450] Epoch 0, batch 11530, batch avg loss 0.3704, total avg loss: 0.3939, batch size: 41
2021-08-24 20:07:04,591 INFO [train.py:450] Epoch 0, batch 11540, batch avg loss 0.3781, total avg loss: 0.3936, batch size: 40
2021-08-24 20:07:10,482 INFO [train.py:450] Epoch 0, batch 11550, batch avg loss 0.3787, total avg loss: 0.3939, batch size: 41
2021-08-24 20:07:16,389 INFO [train.py:450] Epoch 0, batch 11560, batch avg loss 0.3634, total avg loss: 0.3932, batch size: 41
2021-08-24 20:07:22,443 INFO [train.py:450] Epoch 0, batch 11570, batch avg loss 0.3673, total avg loss: 0.3931, batch size: 40
2021-08-24 20:07:28,441 INFO [train.py:450] Epoch 0, batch 11580, batch avg loss 0.3729, total avg loss: 0.3930, batch size: 39
2021-08-24 20:07:34,308 INFO [train.py:450] Epoch 0, batch 11590, batch avg loss 0.3900, total avg loss: 0.3936, batch size: 38
2021-08-24 20:07:40,083 INFO [train.py:450] Epoch 0, batch 11600, batch avg loss 0.4267, total avg loss: 0.3932, batch size: 42
2021-08-24 20:07:45,968 INFO [train.py:450] Epoch 0, batch 11610, batch avg loss 0.3712, total avg loss: 0.3986, batch size: 39
2021-08-24 20:07:51,785 INFO [train.py:450] Epoch 0, batch 11620, batch avg loss 0.3765, total avg loss: 0.3920, batch size: 38
2021-08-24 20:07:57,728 INFO [train.py:450] Epoch 0, batch 11630, batch avg loss 0.3701, total avg loss: 0.3870, batch size: 39
2021-08-24 20:08:03,600 INFO [train.py:450] Epoch 0, batch 11640, batch avg loss 0.4349, total avg loss: 0.3876, batch size: 38
2021-08-24 20:08:10,539 INFO [train.py:450] Epoch 0, batch 11650, batch avg loss 0.4281, total avg loss: 0.3876, batch size: 38
2021-08-24 20:08:16,875 INFO [train.py:450] Epoch 0, batch 11660, batch avg loss 0.4184, total avg loss: 0.3835, batch size: 36
2021-08-24 20:08:22,790 INFO [train.py:450] Epoch 0, batch 11670, batch avg loss 0.4188, total avg loss: 0.3832, batch size: 41
2021-08-24 20:08:31,325 INFO [train.py:450] Epoch 0, batch 11680, batch avg loss 0.4319, total avg loss: 0.3852, batch size: 41
2021-08-24 20:08:37,251 INFO [train.py:450] Epoch 0, batch 11690, batch avg loss 0.3964, total avg loss: 0.3860, batch size: 40
2021-08-24 20:08:43,926 INFO [train.py:450] Epoch 0, batch 11700, batch avg loss 0.3421, total avg loss: 0.3853, batch size: 40
2021-08-24 20:08:50,261 INFO [train.py:450] Epoch 0, batch 11710, batch avg loss 0.3566, total avg loss: 0.3859, batch size: 42
2021-08-24 20:08:56,257 INFO [train.py:450] Epoch 0, batch 11720, batch avg loss 0.3805, total avg loss: 0.3866, batch size: 40
2021-08-24 20:09:02,245 INFO [train.py:450] Epoch 0, batch 11730, batch avg loss 0.3645, total avg loss: 0.3858, batch size: 42
2021-08-24 20:09:08,154 INFO [train.py:450] Epoch 0, batch 11740, batch avg loss 0.4415, total avg loss: 0.3866, batch size: 40
2021-08-24 20:09:14,078 INFO [train.py:450] Epoch 0, batch 11750, batch avg loss 0.4349, total avg loss: 0.3871, batch size: 42
2021-08-24 20:09:19,979 INFO [train.py:450] Epoch 0, batch 11760, batch avg loss 0.3348, total avg loss: 0.3870, batch size: 42
2021-08-24 20:09:25,990 INFO [train.py:450] Epoch 0, batch 11770, batch avg loss 0.3696, total avg loss: 0.3879, batch size: 42
2021-08-24 20:09:31,841 INFO [train.py:450] Epoch 0, batch 11780, batch avg loss 0.3528, total avg loss: 0.3881, batch size: 38
2021-08-24 20:09:37,757 INFO [train.py:450] Epoch 0, batch 11790, batch avg loss 0.4133, total avg loss: 0.3883, batch size: 40
2021-08-24 20:09:43,621 INFO [train.py:450] Epoch 0, batch 11800, batch avg loss 0.4606, total avg loss: 0.3883, batch size: 39
2021-08-24 20:09:50,026 INFO [train.py:450] Epoch 0, batch 11810, batch avg loss 0.4123, total avg loss: 0.3895, batch size: 39
2021-08-24 20:09:56,106 INFO [train.py:450] Epoch 0, batch 11820, batch avg loss 0.3068, total avg loss: 0.3812, batch size: 41
2021-08-24 20:10:02,245 INFO [train.py:450] Epoch 0, batch 11830, batch avg loss 0.3637, total avg loss: 0.3907, batch size: 41
2021-08-24 20:10:08,488 INFO [train.py:450] Epoch 0, batch 11840, batch avg loss 0.3826, total avg loss: 0.3888, batch size: 38
2021-08-24 20:10:14,549 INFO [train.py:450] Epoch 0, batch 11850, batch avg loss 0.3967, total avg loss: 0.3884, batch size: 39
2021-08-24 20:10:20,411 INFO [train.py:450] Epoch 0, batch 11860, batch avg loss 0.3509, total avg loss: 0.3865, batch size: 39
2021-08-24 20:10:26,159 INFO [train.py:450] Epoch 0, batch 11870, batch avg loss 0.4577, total avg loss: 0.3878, batch size: 39
2021-08-24 20:10:32,075 INFO [train.py:450] Epoch 0, batch 11880, batch avg loss 0.4402, total avg loss: 0.3861, batch size: 42
2021-08-24 20:10:38,013 INFO [train.py:450] Epoch 0, batch 11890, batch avg loss 0.4066, total avg loss: 0.3867, batch size: 38
2021-08-24 20:10:43,881 INFO [train.py:450] Epoch 0, batch 11900, batch avg loss 0.4265, total avg loss: 0.3868, batch size: 37
2021-08-24 20:10:49,576 INFO [train.py:450] Epoch 0, batch 11910, batch avg loss 0.3589, total avg loss: 0.3857, batch size: 40
2021-08-24 20:10:55,416 INFO [train.py:450] Epoch 0, batch 11920, batch avg loss 0.4278, total avg loss: 0.3845, batch size: 43
2021-08-24 20:11:01,258 INFO [train.py:450] Epoch 0, batch 11930, batch avg loss 0.3931, total avg loss: 0.3849, batch size: 41
2021-08-24 20:11:07,083 INFO [train.py:450] Epoch 0, batch 11940, batch avg loss 0.3452, total avg loss: 0.3850, batch size: 40
2021-08-24 20:11:12,940 INFO [train.py:450] Epoch 0, batch 11950, batch avg loss 0.3565, total avg loss: 0.3860, batch size: 42
2021-08-24 20:11:18,768 INFO [train.py:450] Epoch 0, batch 11960, batch avg loss 0.3932, total avg loss: 0.3849, batch size: 39
2021-08-24 20:11:24,672 INFO [train.py:450] Epoch 0, batch 11970, batch avg loss 0.3587, total avg loss: 0.3855, batch size: 39
2021-08-24 20:11:30,504 INFO [train.py:450] Epoch 0, batch 11980, batch avg loss 0.4198, total avg loss: 0.3860, batch size: 41
2021-08-24 20:11:36,419 INFO [train.py:450] Epoch 0, batch 11990, batch avg loss 0.3927, total avg loss: 0.3858, batch size: 38
2021-08-24 20:11:42,189 INFO [train.py:450] Epoch 0, batch 12000, batch avg loss 0.3603, total avg loss: 0.3852, batch size: 40
2021-08-24 20:12:21,554 INFO [train.py:482] Epoch 0, valid loss 0.2840, best valid loss: 0.2840 best valid epoch: 0
2021-08-24 20:12:27,507 INFO [train.py:450] Epoch 0, batch 12010, batch avg loss 0.3891, total avg loss: 0.3801, batch size: 41
2021-08-24 20:12:35,187 INFO [train.py:450] Epoch 0, batch 12020, batch avg loss 0.4173, total avg loss: 0.3780, batch size: 39
2021-08-24 20:12:42,832 INFO [train.py:450] Epoch 0, batch 12030, batch avg loss 0.3582, total avg loss: 0.3860, batch size: 41
2021-08-24 20:12:49,789 INFO [train.py:450] Epoch 0, batch 12040, batch avg loss 0.3445, total avg loss: 0.3859, batch size: 41
2021-08-24 20:12:56,496 INFO [train.py:450] Epoch 0, batch 12050, batch avg loss 0.4157, total avg loss: 0.3866, batch size: 39
2021-08-24 20:13:03,654 INFO [train.py:450] Epoch 0, batch 12060, batch avg loss 0.3646, total avg loss: 0.3846, batch size: 39
2021-08-24 20:13:09,925 INFO [train.py:450] Epoch 0, batch 12070, batch avg loss 0.3721, total avg loss: 0.3837, batch size: 40
2021-08-24 20:13:16,585 INFO [train.py:450] Epoch 0, batch 12080, batch avg loss 0.3601, total avg loss: 0.3847, batch size: 37
2021-08-24 20:13:25,872 INFO [train.py:450] Epoch 0, batch 12090, batch avg loss 0.4034, total avg loss: 0.3844, batch size: 41
2021-08-24 20:13:32,323 INFO [train.py:450] Epoch 0, batch 12100, batch avg loss 0.3319, total avg loss: 0.3857, batch size: 38
2021-08-24 20:13:41,195 INFO [train.py:450] Epoch 0, batch 12110, batch avg loss 0.3976, total avg loss: 0.3850, batch size: 41
2021-08-24 20:13:49,662 INFO [train.py:450] Epoch 0, batch 12120, batch avg loss 0.3215, total avg loss: 0.3844, batch size: 35
2021-08-24 20:13:55,737 INFO [train.py:450] Epoch 0, batch 12130, batch avg loss 0.3375, total avg loss: 0.3845, batch size: 40
2021-08-24 20:14:02,353 INFO [train.py:450] Epoch 0, batch 12140, batch avg loss 0.3691, total avg loss: 0.3840, batch size: 42
2021-08-24 20:14:08,723 INFO [train.py:450] Epoch 0, batch 12150, batch avg loss 0.3384, total avg loss: 0.3846, batch size: 39
2021-08-24 20:14:15,426 INFO [train.py:450] Epoch 0, batch 12160, batch avg loss 0.3967, total avg loss: 0.3848, batch size: 41
2021-08-24 20:14:21,839 INFO [train.py:450] Epoch 0, batch 12170, batch avg loss 0.4550, total avg loss: 0.3851, batch size: 40
2021-08-24 20:14:28,021 INFO [train.py:450] Epoch 0, batch 12180, batch avg loss 0.3968, total avg loss: 0.3858, batch size: 40
2021-08-24 20:14:34,244 INFO [train.py:450] Epoch 0, batch 12190, batch avg loss 0.3824, total avg loss: 0.3857, batch size: 38
2021-08-24 20:14:40,214 INFO [train.py:450] Epoch 0, batch 12200, batch avg loss 0.3841, total avg loss: 0.3868, batch size: 41
2021-08-24 20:14:46,260 INFO [train.py:450] Epoch 0, batch 12210, batch avg loss 0.4075, total avg loss: 0.3882, batch size: 39
2021-08-24 20:14:52,850 INFO [train.py:450] Epoch 0, batch 12220, batch avg loss 0.3697, total avg loss: 0.3845, batch size: 39
2021-08-24 20:14:59,031 INFO [train.py:450] Epoch 0, batch 12230, batch avg loss 0.4014, total avg loss: 0.3843, batch size: 38
2021-08-24 20:15:04,883 INFO [train.py:450] Epoch 0, batch 12240, batch avg loss 0.3782, total avg loss: 0.3866, batch size: 40
2021-08-24 20:15:10,725 INFO [train.py:450] Epoch 0, batch 12250, batch avg loss 0.3695, total avg loss: 0.3857, batch size: 40
2021-08-24 20:15:16,609 INFO [train.py:450] Epoch 0, batch 12260, batch avg loss 0.3685, total avg loss: 0.3845, batch size: 37
2021-08-24 20:15:22,506 INFO [train.py:450] Epoch 0, batch 12270, batch avg loss 0.3658, total avg loss: 0.3864, batch size: 37
2021-08-24 20:15:28,440 INFO [train.py:450] Epoch 0, batch 12280, batch avg loss 0.3902, total avg loss: 0.3874, batch size: 43
2021-08-24 20:15:34,253 INFO [train.py:450] Epoch 0, batch 12290, batch avg loss 0.3460, total avg loss: 0.3848, batch size: 39
2021-08-24 20:15:40,103 INFO [train.py:450] Epoch 0, batch 12300, batch avg loss 0.4007, total avg loss: 0.3861, batch size: 38
2021-08-24 20:15:45,993 INFO [train.py:450] Epoch 0, batch 12310, batch avg loss 0.3768, total avg loss: 0.3861, batch size: 40
2021-08-24 20:15:51,989 INFO [train.py:450] Epoch 0, batch 12320, batch avg loss 0.4172, total avg loss: 0.3872, batch size: 42
2021-08-24 20:15:57,836 INFO [train.py:450] Epoch 0, batch 12330, batch avg loss 0.3509, total avg loss: 0.3863, batch size: 42
2021-08-24 20:16:03,656 INFO [train.py:450] Epoch 0, batch 12340, batch avg loss 0.3770, total avg loss: 0.3861, batch size: 40
2021-08-24 20:16:09,607 INFO [train.py:450] Epoch 0, batch 12350, batch avg loss 0.4320, total avg loss: 0.3862, batch size: 39
2021-08-24 20:16:16,009 INFO [train.py:450] Epoch 0, batch 12360, batch avg loss 0.4286, total avg loss: 0.3858, batch size: 43
2021-08-24 20:16:22,376 INFO [train.py:450] Epoch 0, batch 12370, batch avg loss 0.3597, total avg loss: 0.3853, batch size: 39
2021-08-24 20:16:28,246 INFO [train.py:450] Epoch 0, batch 12380, batch avg loss 0.3530, total avg loss: 0.3855, batch size: 44
2021-08-24 20:16:34,276 INFO [train.py:450] Epoch 0, batch 12390, batch avg loss 0.4711, total avg loss: 0.3859, batch size: 39
2021-08-24 20:16:40,167 INFO [train.py:450] Epoch 0, batch 12400, batch avg loss 0.4135, total avg loss: 0.3850, batch size: 41
2021-08-24 20:16:46,132 INFO [train.py:450] Epoch 0, batch 12410, batch avg loss 0.3993, total avg loss: 0.3947, batch size: 39
2021-08-24 20:16:52,205 INFO [train.py:450] Epoch 0, batch 12420, batch avg loss 0.3583, total avg loss: 0.3836, batch size: 38
2021-08-24 20:16:57,974 INFO [train.py:450] Epoch 0, batch 12430, batch avg loss 0.3913, total avg loss: 0.3877, batch size: 38
2021-08-24 20:17:03,844 INFO [train.py:450] Epoch 0, batch 12440, batch avg loss 0.3984, total avg loss: 0.3875, batch size: 40
2021-08-24 20:17:09,819 INFO [train.py:450] Epoch 0, batch 12450, batch avg loss 0.3725, total avg loss: 0.3882, batch size: 38
2021-08-24 20:17:15,855 INFO [train.py:450] Epoch 0, batch 12460, batch avg loss 0.4394, total avg loss: 0.3882, batch size: 39
2021-08-24 20:17:22,319 INFO [train.py:450] Epoch 0, batch 12470, batch avg loss 0.4353, total avg loss: 0.3855, batch size: 39
2021-08-24 20:17:28,199 INFO [train.py:450] Epoch 0, batch 12480, batch avg loss 0.3599, total avg loss: 0.3867, batch size: 38
2021-08-24 20:17:33,887 INFO [train.py:450] Epoch 0, batch 12490, batch avg loss 0.4169, total avg loss: 0.3877, batch size: 39
2021-08-24 20:17:39,725 INFO [train.py:450] Epoch 0, batch 12500, batch avg loss 0.3774, total avg loss: 0.3880, batch size: 39
2021-08-24 20:17:45,601 INFO [train.py:450] Epoch 0, batch 12510, batch avg loss 0.3534, total avg loss: 0.3869, batch size: 38
2021-08-24 20:17:51,408 INFO [train.py:450] Epoch 0, batch 12520, batch avg loss 0.3874, total avg loss: 0.3883, batch size: 39
2021-08-24 20:17:57,345 INFO [train.py:450] Epoch 0, batch 12530, batch avg loss 0.4303, total avg loss: 0.3879, batch size: 42
2021-08-24 20:18:03,231 INFO [train.py:450] Epoch 0, batch 12540, batch avg loss 0.4665, total avg loss: 0.3882, batch size: 41
2021-08-24 20:18:09,026 INFO [train.py:450] Epoch 0, batch 12550, batch avg loss 0.4048, total avg loss: 0.3884, batch size: 40
2021-08-24 20:18:14,824 INFO [train.py:450] Epoch 0, batch 12560, batch avg loss 0.3289, total avg loss: 0.3864, batch size: 39
2021-08-24 20:18:21,461 INFO [train.py:450] Epoch 0, batch 12570, batch avg loss 0.3775, total avg loss: 0.3865, batch size: 40
2021-08-24 20:18:27,264 INFO [train.py:450] Epoch 0, batch 12580, batch avg loss 0.3922, total avg loss: 0.3861, batch size: 41
2021-08-24 20:18:34,383 INFO [train.py:450] Epoch 0, batch 12590, batch avg loss 0.3888, total avg loss: 0.3859, batch size: 41
2021-08-24 20:18:42,005 INFO [train.py:450] Epoch 0, batch 12600, batch avg loss 0.3602, total avg loss: 0.3852, batch size: 39
2021-08-24 20:18:48,055 INFO [train.py:450] Epoch 0, batch 12610, batch avg loss 0.3805, total avg loss: 0.3897, batch size: 39
2021-08-24 20:18:53,962 INFO [train.py:450] Epoch 0, batch 12620, batch avg loss 0.3686, total avg loss: 0.3859, batch size: 41
2021-08-24 20:18:59,775 INFO [train.py:450] Epoch 0, batch 12630, batch avg loss 0.3854, total avg loss: 0.3856, batch size: 42
2021-08-24 20:19:06,028 INFO [train.py:450] Epoch 0, batch 12640, batch avg loss 0.3782, total avg loss: 0.3840, batch size: 42
2021-08-24 20:19:12,063 INFO [train.py:450] Epoch 0, batch 12650, batch avg loss 0.3732, total avg loss: 0.3799, batch size: 37
2021-08-24 20:19:17,814 INFO [train.py:450] Epoch 0, batch 12660, batch avg loss 0.4180, total avg loss: 0.3825, batch size: 41
2021-08-24 20:19:23,614 INFO [train.py:450] Epoch 0, batch 12670, batch avg loss 0.3742, total avg loss: 0.3825, batch size: 41
2021-08-24 20:19:29,533 INFO [train.py:450] Epoch 0, batch 12680, batch avg loss 0.3890, total avg loss: 0.3816, batch size: 41
2021-08-24 20:19:35,405 INFO [train.py:450] Epoch 0, batch 12690, batch avg loss 0.3354, total avg loss: 0.3799, batch size: 37
2021-08-24 20:19:41,363 INFO [train.py:450] Epoch 0, batch 12700, batch avg loss 0.3933, total avg loss: 0.3791, batch size: 41
2021-08-24 20:19:47,179 INFO [train.py:450] Epoch 0, batch 12710, batch avg loss 0.3669, total avg loss: 0.3791, batch size: 38
2021-08-24 20:19:53,004 INFO [train.py:450] Epoch 0, batch 12720, batch avg loss 0.4311, total avg loss: 0.3803, batch size: 42
2021-08-24 20:19:58,886 INFO [train.py:450] Epoch 0, batch 12730, batch avg loss 0.4093, total avg loss: 0.3789, batch size: 41
2021-08-24 20:20:04,696 INFO [train.py:450] Epoch 0, batch 12740, batch avg loss 0.3858, total avg loss: 0.3797, batch size: 39
2021-08-24 20:20:10,550 INFO [train.py:450] Epoch 0, batch 12750, batch avg loss 0.3431, total avg loss: 0.3786, batch size: 41
2021-08-24 20:20:16,394 INFO [train.py:450] Epoch 0, batch 12760, batch avg loss 0.3636, total avg loss: 0.3782, batch size: 36
2021-08-24 20:20:22,220 INFO [train.py:450] Epoch 0, batch 12770, batch avg loss 0.3775, total avg loss: 0.3789, batch size: 39
2021-08-24 20:20:27,867 INFO [train.py:450] Epoch 0, batch 12780, batch avg loss 0.4051, total avg loss: 0.3800, batch size: 39
2021-08-24 20:20:33,780 INFO [train.py:450] Epoch 0, batch 12790, batch avg loss 0.4510, total avg loss: 0.3801, batch size: 40
2021-08-24 20:20:39,782 INFO [train.py:450] Epoch 0, batch 12800, batch avg loss 0.3648, total avg loss: 0.3803, batch size: 42
2021-08-24 20:20:45,634 INFO [train.py:450] Epoch 0, batch 12810, batch avg loss 0.3585, total avg loss: 0.3859, batch size: 41
2021-08-24 20:20:51,615 INFO [train.py:450] Epoch 0, batch 12820, batch avg loss 0.4285, total avg loss: 0.3857, batch size: 37
2021-08-24 20:20:57,408 INFO [train.py:450] Epoch 0, batch 12830, batch avg loss 0.4314, total avg loss: 0.3890, batch size: 42
2021-08-24 20:21:03,284 INFO [train.py:450] Epoch 0, batch 12840, batch avg loss 0.3545, total avg loss: 0.3831, batch size: 41
2021-08-24 20:21:09,165 INFO [train.py:450] Epoch 0, batch 12850, batch avg loss 0.3972, total avg loss: 0.3851, batch size: 37
2021-08-24 20:21:14,922 INFO [train.py:450] Epoch 0, batch 12860, batch avg loss 0.4266, total avg loss: 0.3879, batch size: 40
2021-08-24 20:21:20,708 INFO [train.py:450] Epoch 0, batch 12870, batch avg loss 0.3948, total avg loss: 0.3883, batch size: 43
2021-08-24 20:21:26,433 INFO [train.py:450] Epoch 0, batch 12880, batch avg loss 0.3845, total avg loss: 0.3876, batch size: 37
2021-08-24 20:21:32,296 INFO [train.py:450] Epoch 0, batch 12890, batch avg loss 0.3155, total avg loss: 0.3860, batch size: 40
2021-08-24 20:21:38,017 INFO [train.py:450] Epoch 0, batch 12900, batch avg loss 0.3059, total avg loss: 0.3853, batch size: 38
2021-08-24 20:21:43,844 INFO [train.py:450] Epoch 0, batch 12910, batch avg loss 0.3961, total avg loss: 0.3843, batch size: 39
2021-08-24 20:21:49,686 INFO [train.py:450] Epoch 0, batch 12920, batch avg loss 0.3766, total avg loss: 0.3848, batch size: 38
2021-08-24 20:21:55,490 INFO [train.py:450] Epoch 0, batch 12930, batch avg loss 0.4075, total avg loss: 0.3850, batch size: 40
2021-08-24 20:22:01,437 INFO [train.py:450] Epoch 0, batch 12940, batch avg loss 0.3492, total avg loss: 0.3861, batch size: 42
2021-08-24 20:22:07,245 INFO [train.py:450] Epoch 0, batch 12950, batch avg loss 0.3544, total avg loss: 0.3851, batch size: 37
2021-08-24 20:22:13,071 INFO [train.py:450] Epoch 0, batch 12960, batch avg loss 0.3557, total avg loss: 0.3844, batch size: 41
2021-08-24 20:22:19,010 INFO [train.py:450] Epoch 0, batch 12970, batch avg loss 0.3748, total avg loss: 0.3846, batch size: 39
2021-08-24 20:22:25,321 INFO [train.py:450] Epoch 0, batch 12980, batch avg loss 0.3798, total avg loss: 0.3853, batch size: 41
2021-08-24 20:22:31,256 INFO [train.py:450] Epoch 0, batch 12990, batch avg loss 0.4139, total avg loss: 0.3846, batch size: 40
2021-08-24 20:22:37,090 INFO [train.py:450] Epoch 0, batch 13000, batch avg loss 0.4348, total avg loss: 0.3857, batch size: 40
2021-08-24 20:23:15,082 INFO [train.py:482] Epoch 0, valid loss 0.2795, best valid loss: 0.2795 best valid epoch: 0
2021-08-24 20:23:21,282 INFO [train.py:450] Epoch 0, batch 13010, batch avg loss 0.3771, total avg loss: 0.3883, batch size: 39
2021-08-24 20:23:27,166 INFO [train.py:450] Epoch 0, batch 13020, batch avg loss 0.3348, total avg loss: 0.3892, batch size: 39
2021-08-24 20:23:33,029 INFO [train.py:450] Epoch 0, batch 13030, batch avg loss 0.3334, total avg loss: 0.3850, batch size: 40
2021-08-24 20:23:38,848 INFO [train.py:450] Epoch 0, batch 13040, batch avg loss 0.3658, total avg loss: 0.3846, batch size: 38
2021-08-24 20:23:44,696 INFO [train.py:450] Epoch 0, batch 13050, batch avg loss 0.3323, total avg loss: 0.3843, batch size: 38
2021-08-24 20:23:50,471 INFO [train.py:450] Epoch 0, batch 13060, batch avg loss 0.4053, total avg loss: 0.3831, batch size: 40
2021-08-24 20:23:56,387 INFO [train.py:450] Epoch 0, batch 13070, batch avg loss 0.3736, total avg loss: 0.3812, batch size: 38
2021-08-24 20:24:02,375 INFO [train.py:450] Epoch 0, batch 13080, batch avg loss 0.3290, total avg loss: 0.3797, batch size: 39
2021-08-24 20:24:08,127 INFO [train.py:450] Epoch 0, batch 13090, batch avg loss 0.3513, total avg loss: 0.3797, batch size: 39
2021-08-24 20:24:14,050 INFO [train.py:450] Epoch 0, batch 13100, batch avg loss 0.3560, total avg loss: 0.3813, batch size: 42
2021-08-24 20:24:19,830 INFO [train.py:450] Epoch 0, batch 13110, batch avg loss 0.3385, total avg loss: 0.3807, batch size: 36
2021-08-24 20:24:25,621 INFO [train.py:450] Epoch 0, batch 13120, batch avg loss 0.3701, total avg loss: 0.3797, batch size: 35
2021-08-24 20:24:31,417 INFO [train.py:450] Epoch 0, batch 13130, batch avg loss 0.4174, total avg loss: 0.3790, batch size: 39
2021-08-24 20:24:37,252 INFO [train.py:450] Epoch 0, batch 13140, batch avg loss 0.3499, total avg loss: 0.3793, batch size: 37
2021-08-24 20:24:43,062 INFO [train.py:450] Epoch 0, batch 13150, batch avg loss 0.3746, total avg loss: 0.3805, batch size: 38
2021-08-24 20:24:48,963 INFO [train.py:450] Epoch 0, batch 13160, batch avg loss 0.3697, total avg loss: 0.3809, batch size: 40
2021-08-24 20:24:54,796 INFO [train.py:450] Epoch 0, batch 13170, batch avg loss 0.3505, total avg loss: 0.3815, batch size: 43
2021-08-24 20:25:00,550 INFO [train.py:450] Epoch 0, batch 13180, batch avg loss 0.3139, total avg loss: 0.3822, batch size: 41
2021-08-24 20:25:06,445 INFO [train.py:450] Epoch 0, batch 13190, batch avg loss 0.3345, total avg loss: 0.3817, batch size: 40
2021-08-24 20:25:12,322 INFO [train.py:450] Epoch 0, batch 13200, batch avg loss 0.3794, total avg loss: 0.3821, batch size: 37
2021-08-24 20:25:18,212 INFO [train.py:450] Epoch 0, batch 13210, batch avg loss 0.4032, total avg loss: 0.3781, batch size: 41
2021-08-24 20:25:24,101 INFO [train.py:450] Epoch 0, batch 13220, batch avg loss 0.3253, total avg loss: 0.3788, batch size: 39
2021-08-24 20:25:30,010 INFO [train.py:450] Epoch 0, batch 13230, batch avg loss 0.3683, total avg loss: 0.3729, batch size: 39
2021-08-24 20:25:35,913 INFO [train.py:450] Epoch 0, batch 13240, batch avg loss 0.4325, total avg loss: 0.3742, batch size: 42
2021-08-24 20:25:41,877 INFO [train.py:450] Epoch 0, batch 13250, batch avg loss 0.3215, total avg loss: 0.3754, batch size: 37
2021-08-24 20:25:48,061 INFO [train.py:450] Epoch 0, batch 13260, batch avg loss 0.3466, total avg loss: 0.3760, batch size: 43
2021-08-24 20:25:53,948 INFO [train.py:450] Epoch 0, batch 13270, batch avg loss 0.3459, total avg loss: 0.3769, batch size: 35
2021-08-24 20:25:59,818 INFO [train.py:450] Epoch 0, batch 13280, batch avg loss 0.3930, total avg loss: 0.3796, batch size: 39
2021-08-24 20:26:05,823 INFO [train.py:450] Epoch 0, batch 13290, batch avg loss 0.3458, total avg loss: 0.3804, batch size: 41
2021-08-24 20:26:11,629 INFO [train.py:450] Epoch 0, batch 13300, batch avg loss 0.4179, total avg loss: 0.3810, batch size: 38
2021-08-24 20:26:17,561 INFO [train.py:450] Epoch 0, batch 13310, batch avg loss 0.3723, total avg loss: 0.3806, batch size: 46
2021-08-24 20:26:23,536 INFO [train.py:450] Epoch 0, batch 13320, batch avg loss 0.3332, total avg loss: 0.3815, batch size: 39
2021-08-24 20:26:29,358 INFO [train.py:450] Epoch 0, batch 13330, batch avg loss 0.3706, total avg loss: 0.3815, batch size: 38
2021-08-24 20:26:35,151 INFO [train.py:450] Epoch 0, batch 13340, batch avg loss 0.3768, total avg loss: 0.3822, batch size: 40
2021-08-24 20:26:41,041 INFO [train.py:450] Epoch 0, batch 13350, batch avg loss 0.3992, total avg loss: 0.3831, batch size: 47
2021-08-24 20:26:47,043 INFO [train.py:450] Epoch 0, batch 13360, batch avg loss 0.3993, total avg loss: 0.3822, batch size: 36
2021-08-24 20:26:52,845 INFO [train.py:450] Epoch 0, batch 13370, batch avg loss 0.4424, total avg loss: 0.3826, batch size: 37
2021-08-24 20:26:58,915 INFO [train.py:450] Epoch 0, batch 13380, batch avg loss 0.4019, total avg loss: 0.3829, batch size: 40
2021-08-24 20:27:04,966 INFO [train.py:450] Epoch 0, batch 13390, batch avg loss 0.4384, total avg loss: 0.3824, batch size: 42
2021-08-24 20:27:10,883 INFO [train.py:450] Epoch 0, batch 13400, batch avg loss 0.4167, total avg loss: 0.3823, batch size: 40
2021-08-24 20:27:16,724 INFO [train.py:450] Epoch 0, batch 13410, batch avg loss 0.4064, total avg loss: 0.3984, batch size: 38
2021-08-24 20:27:22,626 INFO [train.py:450] Epoch 0, batch 13420, batch avg loss 0.3973, total avg loss: 0.3911, batch size: 39
2021-08-24 20:27:28,635 INFO [train.py:450] Epoch 0, batch 13430, batch avg loss 0.4037, total avg loss: 0.3887, batch size: 36
2021-08-24 20:27:34,710 INFO [train.py:450] Epoch 0, batch 13440, batch avg loss 0.4014, total avg loss: 0.3861, batch size: 42
2021-08-24 20:27:40,809 INFO [train.py:450] Epoch 0, batch 13450, batch avg loss 0.3225, total avg loss: 0.3864, batch size: 38
2021-08-24 20:27:46,971 INFO [train.py:450] Epoch 0, batch 13460, batch avg loss 0.4210, total avg loss: 0.3877, batch size: 38
2021-08-24 20:27:54,992 INFO [train.py:450] Epoch 0, batch 13470, batch avg loss 0.3418, total avg loss: 0.3869, batch size: 42
2021-08-24 20:28:01,037 INFO [train.py:450] Epoch 0, batch 13480, batch avg loss 0.4287, total avg loss: 0.3855, batch size: 39
2021-08-24 20:28:09,559 INFO [train.py:450] Epoch 0, batch 13490, batch avg loss 0.3586, total avg loss: 0.3843, batch size: 41
2021-08-24 20:28:17,132 INFO [train.py:450] Epoch 0, batch 13500, batch avg loss 0.3477, total avg loss: 0.3831, batch size: 37
2021-08-24 20:28:22,974 INFO [train.py:450] Epoch 0, batch 13510, batch avg loss 0.3317, total avg loss: 0.3835, batch size: 37
2021-08-24 20:28:29,064 INFO [train.py:450] Epoch 0, batch 13520, batch avg loss 0.3684, total avg loss: 0.3831, batch size: 36
2021-08-24 20:28:34,952 INFO [train.py:450] Epoch 0, batch 13530, batch avg loss 0.4236, total avg loss: 0.3839, batch size: 39
2021-08-24 20:28:41,791 INFO [train.py:450] Epoch 0, batch 13540, batch avg loss 0.4271, total avg loss: 0.3833, batch size: 41
2021-08-24 20:28:47,746 INFO [train.py:450] Epoch 0, batch 13550, batch avg loss 0.3534, total avg loss: 0.3836, batch size: 43
2021-08-24 20:28:53,763 INFO [train.py:450] Epoch 0, batch 13560, batch avg loss 0.3569, total avg loss: 0.3839, batch size: 38
2021-08-24 20:28:59,615 INFO [train.py:450] Epoch 0, batch 13570, batch avg loss 0.3700, total avg loss: 0.3834, batch size: 38
2021-08-24 20:29:05,808 INFO [train.py:450] Epoch 0, batch 13580, batch avg loss 0.4297, total avg loss: 0.3839, batch size: 38
2021-08-24 20:29:12,150 INFO [train.py:450] Epoch 0, batch 13590, batch avg loss 0.4009, total avg loss: 0.3848, batch size: 39
2021-08-24 20:29:18,748 INFO [train.py:450] Epoch 0, batch 13600, batch avg loss 0.3751, total avg loss: 0.3855, batch size: 39
2021-08-24 20:29:24,784 INFO [train.py:450] Epoch 0, batch 13610, batch avg loss 0.3533, total avg loss: 0.3713, batch size: 37
2021-08-24 20:29:30,644 INFO [train.py:450] Epoch 0, batch 13620, batch avg loss 0.3713, total avg loss: 0.3708, batch size: 38
2021-08-24 20:29:36,526 INFO [train.py:450] Epoch 0, batch 13630, batch avg loss 0.4063, total avg loss: 0.3734, batch size: 38
2021-08-24 20:29:42,530 INFO [train.py:450] Epoch 0, batch 13640, batch avg loss 0.3690, total avg loss: 0.3755, batch size: 45
2021-08-24 20:29:48,681 INFO [train.py:450] Epoch 0, batch 13650, batch avg loss 0.3754, total avg loss: 0.3779, batch size: 43
2021-08-24 20:29:54,833 INFO [train.py:450] Epoch 0, batch 13660, batch avg loss 0.3755, total avg loss: 0.3766, batch size: 40
2021-08-24 20:30:00,750 INFO [train.py:450] Epoch 0, batch 13670, batch avg loss 0.3925, total avg loss: 0.3766, batch size: 37
2021-08-24 20:30:06,682 INFO [train.py:450] Epoch 0, batch 13680, batch avg loss 0.3898, total avg loss: 0.3745, batch size: 42
2021-08-24 20:30:12,616 INFO [train.py:450] Epoch 0, batch 13690, batch avg loss 0.3832, total avg loss: 0.3750, batch size: 38
2021-08-24 20:30:18,632 INFO [train.py:450] Epoch 0, batch 13700, batch avg loss 0.4539, total avg loss: 0.3759, batch size: 40
2021-08-24 20:30:24,503 INFO [train.py:450] Epoch 0, batch 13710, batch avg loss 0.3296, total avg loss: 0.3753, batch size: 42
2021-08-24 20:30:30,459 INFO [train.py:450] Epoch 0, batch 13720, batch avg loss 0.3345, total avg loss: 0.3762, batch size: 40
2021-08-24 20:30:36,654 INFO [train.py:450] Epoch 0, batch 13730, batch avg loss 0.3646, total avg loss: 0.3765, batch size: 37
2021-08-24 20:30:42,619 INFO [train.py:450] Epoch 0, batch 13740, batch avg loss 0.3957, total avg loss: 0.3780, batch size: 43
2021-08-24 20:30:49,055 INFO [train.py:450] Epoch 0, batch 13750, batch avg loss 0.3661, total avg loss: 0.3793, batch size: 41
2021-08-24 20:30:55,045 INFO [train.py:450] Epoch 0, batch 13760, batch avg loss 0.3961, total avg loss: 0.3787, batch size: 42
2021-08-24 20:31:00,912 INFO [train.py:450] Epoch 0, batch 13770, batch avg loss 0.3797, total avg loss: 0.3791, batch size: 39
2021-08-24 20:31:06,778 INFO [train.py:450] Epoch 0, batch 13780, batch avg loss 0.3899, total avg loss: 0.3792, batch size: 42
2021-08-24 20:31:12,731 INFO [train.py:450] Epoch 0, batch 13790, batch avg loss 0.3339, total avg loss: 0.3780, batch size: 38
2021-08-24 20:31:18,619 INFO [train.py:450] Epoch 0, batch 13800, batch avg loss 0.3794, total avg loss: 0.3780, batch size: 39
2021-08-24 20:31:24,630 INFO [train.py:450] Epoch 0, batch 13810, batch avg loss 0.4161, total avg loss: 0.3995, batch size: 40
2021-08-24 20:31:30,592 INFO [train.py:450] Epoch 0, batch 13820, batch avg loss 0.3973, total avg loss: 0.3944, batch size: 39
2021-08-24 20:31:36,729 INFO [train.py:450] Epoch 0, batch 13830, batch avg loss 0.3588, total avg loss: 0.3862, batch size: 38
2021-08-24 20:31:42,638 INFO [train.py:450] Epoch 0, batch 13840, batch avg loss 0.3466, total avg loss: 0.3852, batch size: 36
2021-08-24 20:31:48,551 INFO [train.py:450] Epoch 0, batch 13850, batch avg loss 0.3888, total avg loss: 0.3837, batch size: 40
2021-08-24 20:31:54,959 INFO [train.py:450] Epoch 0, batch 13860, batch avg loss 0.4402, total avg loss: 0.3822, batch size: 41
2021-08-24 20:32:08,640 INFO [train.py:450] Epoch 0, batch 13870, batch avg loss 0.3496, total avg loss: 0.3800, batch size: 38
2021-08-24 20:32:14,521 INFO [train.py:450] Epoch 0, batch 13880, batch avg loss 0.3805, total avg loss: 0.3818, batch size: 41
2021-08-24 20:32:20,422 INFO [train.py:450] Epoch 0, batch 13890, batch avg loss 0.3714, total avg loss: 0.3818, batch size: 38
2021-08-24 20:32:26,337 INFO [train.py:450] Epoch 0, batch 13900, batch avg loss 0.3546, total avg loss: 0.3817, batch size: 41
2021-08-24 20:32:33,079 INFO [train.py:450] Epoch 0, batch 13910, batch avg loss 0.3395, total avg loss: 0.3821, batch size: 41
2021-08-24 20:32:39,400 INFO [train.py:450] Epoch 0, batch 13920, batch avg loss 0.4215, total avg loss: 0.3800, batch size: 45
2021-08-24 20:32:45,848 INFO [train.py:450] Epoch 0, batch 13930, batch avg loss 0.3353, total avg loss: 0.3799, batch size: 39
2021-08-24 20:32:52,389 INFO [train.py:450] Epoch 0, batch 13940, batch avg loss 0.3927, total avg loss: 0.3797, batch size: 42
2021-08-24 20:32:58,441 INFO [train.py:450] Epoch 0, batch 13950, batch avg loss 0.3970, total avg loss: 0.3802, batch size: 41
2021-08-24 20:33:06,207 INFO [train.py:450] Epoch 0, batch 13960, batch avg loss 0.4443, total avg loss: 0.3805, batch size: 40
2021-08-24 20:33:12,047 INFO [train.py:450] Epoch 0, batch 13970, batch avg loss 0.4465, total avg loss: 0.3816, batch size: 40
2021-08-24 20:33:19,482 INFO [train.py:450] Epoch 0, batch 13980, batch avg loss 0.3959, total avg loss: 0.3815, batch size: 40
2021-08-24 20:33:28,555 INFO [train.py:450] Epoch 0, batch 13990, batch avg loss 0.3972, total avg loss: 0.3816, batch size: 40
2021-08-24 20:33:34,668 INFO [train.py:450] Epoch 0, batch 14000, batch avg loss 0.3497, total avg loss: 0.3814, batch size: 40
2021-08-24 20:34:13,926 INFO [train.py:482] Epoch 0, valid loss 0.2743, best valid loss: 0.2743 best valid epoch: 0
2021-08-24 20:34:19,757 INFO [train.py:450] Epoch 0, batch 14010, batch avg loss 0.3777, total avg loss: 0.3857, batch size: 38
2021-08-24 20:34:25,703 INFO [train.py:450] Epoch 0, batch 14020, batch avg loss 0.3303, total avg loss: 0.3834, batch size: 36
2021-08-24 20:34:31,524 INFO [train.py:450] Epoch 0, batch 14030, batch avg loss 0.3659, total avg loss: 0.3819, batch size: 38
2021-08-24 20:34:37,843 INFO [train.py:450] Epoch 0, batch 14040, batch avg loss 0.3969, total avg loss: 0.3812, batch size: 39
2021-08-24 20:34:44,367 INFO [train.py:450] Epoch 0, batch 14050, batch avg loss 0.3600, total avg loss: 0.3812, batch size: 40
2021-08-24 20:34:50,543 INFO [train.py:450] Epoch 0, batch 14060, batch avg loss 0.4108, total avg loss: 0.3811, batch size: 40
2021-08-24 20:34:56,816 INFO [train.py:450] Epoch 0, batch 14070, batch avg loss 0.3999, total avg loss: 0.3788, batch size: 42
2021-08-24 20:35:03,585 INFO [train.py:450] Epoch 0, batch 14080, batch avg loss 0.3691, total avg loss: 0.3800, batch size: 42
2021-08-24 20:35:09,814 INFO [train.py:450] Epoch 0, batch 14090, batch avg loss 0.3800, total avg loss: 0.3796, batch size: 41
2021-08-24 20:35:16,207 INFO [train.py:450] Epoch 0, batch 14100, batch avg loss 0.3430, total avg loss: 0.3778, batch size: 41
2021-08-24 20:35:22,110 INFO [train.py:450] Epoch 0, batch 14110, batch avg loss 0.3679, total avg loss: 0.3776, batch size: 43
2021-08-24 20:35:28,333 INFO [train.py:450] Epoch 0, batch 14120, batch avg loss 0.3583, total avg loss: 0.3767, batch size: 40
2021-08-24 20:35:34,660 INFO [train.py:450] Epoch 0, batch 14130, batch avg loss 0.4431, total avg loss: 0.3769, batch size: 39
2021-08-24 20:35:40,971 INFO [train.py:450] Epoch 0, batch 14140, batch avg loss 0.3529, total avg loss: 0.3771, batch size: 35
2021-08-24 20:35:47,710 INFO [train.py:450] Epoch 0, batch 14150, batch avg loss 0.3222, total avg loss: 0.3776, batch size: 43
2021-08-24 20:35:53,739 INFO [train.py:450] Epoch 0, batch 14160, batch avg loss 0.4177, total avg loss: 0.3777, batch size: 39
2021-08-24 20:35:59,970 INFO [train.py:450] Epoch 0, batch 14170, batch avg loss 0.3650, total avg loss: 0.3775, batch size: 39
2021-08-24 20:36:05,916 INFO [train.py:450] Epoch 0, batch 14180, batch avg loss 0.3611, total avg loss: 0.3766, batch size: 40
2021-08-24 20:36:12,906 INFO [train.py:450] Epoch 0, batch 14190, batch avg loss 0.4107, total avg loss: 0.3768, batch size: 44
2021-08-24 20:36:19,609 INFO [train.py:450] Epoch 0, batch 14200, batch avg loss 0.3531, total avg loss: 0.3767, batch size: 38
2021-08-24 20:36:26,191 INFO [train.py:450] Epoch 0, batch 14210, batch avg loss 0.3805, total avg loss: 0.3634, batch size: 41
2021-08-24 20:36:32,546 INFO [train.py:450] Epoch 0, batch 14220, batch avg loss 0.3529, total avg loss: 0.3801, batch size: 42
2021-08-24 20:36:38,803 INFO [train.py:450] Epoch 0, batch 14230, batch avg loss 0.3662, total avg loss: 0.3773, batch size: 40
2021-08-24 20:36:45,053 INFO [train.py:450] Epoch 0, batch 14240, batch avg loss 0.3604, total avg loss: 0.3738, batch size: 38
2021-08-24 20:36:51,959 INFO [train.py:450] Epoch 0, batch 14250, batch avg loss 0.3493, total avg loss: 0.3730, batch size: 37
2021-08-24 20:36:58,633 INFO [train.py:450] Epoch 0, batch 14260, batch avg loss 0.3666, total avg loss: 0.3730, batch size: 43
2021-08-24 20:37:04,911 INFO [train.py:450] Epoch 0, batch 14270, batch avg loss 0.3830, total avg loss: 0.3736, batch size: 38
2021-08-24 20:37:12,037 INFO [train.py:450] Epoch 0, batch 14280, batch avg loss 0.3726, total avg loss: 0.3733, batch size: 42
2021-08-24 20:37:19,122 INFO [train.py:450] Epoch 0, batch 14290, batch avg loss 0.4059, total avg loss: 0.3727, batch size: 38
2021-08-24 20:37:25,864 INFO [train.py:450] Epoch 0, batch 14300, batch avg loss 0.3466, total avg loss: 0.3752, batch size: 42
2021-08-24 20:37:32,435 INFO [train.py:450] Epoch 0, batch 14310, batch avg loss 0.3724, total avg loss: 0.3753, batch size: 40
2021-08-24 20:37:39,718 INFO [train.py:450] Epoch 0, batch 14320, batch avg loss 0.3382, total avg loss: 0.3760, batch size: 43
2021-08-24 20:37:46,114 INFO [train.py:450] Epoch 0, batch 14330, batch avg loss 0.3543, total avg loss: 0.3760, batch size: 36
2021-08-24 20:37:52,719 INFO [train.py:450] Epoch 0, batch 14340, batch avg loss 0.4061, total avg loss: 0.3753, batch size: 42
2021-08-24 20:38:05,789 INFO [train.py:450] Epoch 0, batch 14350, batch avg loss 0.3923, total avg loss: 0.3754, batch size: 41
2021-08-24 20:38:12,333 INFO [train.py:450] Epoch 0, batch 14360, batch avg loss 0.3677, total avg loss: 0.3757, batch size: 41
2021-08-24 20:38:18,675 INFO [train.py:450] Epoch 0, batch 14370, batch avg loss 0.3764, total avg loss: 0.3759, batch size: 39
2021-08-24 20:38:25,559 INFO [train.py:450] Epoch 0, batch 14380, batch avg loss 0.3953, total avg loss: 0.3766, batch size: 38
2021-08-24 20:38:31,937 INFO [train.py:450] Epoch 0, batch 14390, batch avg loss 0.4092, total avg loss: 0.3770, batch size: 41
2021-08-24 20:38:38,571 INFO [train.py:450] Epoch 0, batch 14400, batch avg loss 0.3748, total avg loss: 0.3762, batch size: 37
2021-08-24 20:38:45,129 INFO [train.py:450] Epoch 0, batch 14410, batch avg loss 0.4345, total avg loss: 0.3811, batch size: 41
2021-08-24 20:38:51,476 INFO [train.py:450] Epoch 0, batch 14420, batch avg loss 0.3062, total avg loss: 0.3765, batch size: 41
2021-08-24 20:38:58,224 INFO [train.py:450] Epoch 0, batch 14430, batch avg loss 0.3216, total avg loss: 0.3795, batch size: 41
2021-08-24 20:39:05,026 INFO [train.py:450] Epoch 0, batch 14440, batch avg loss 0.3981, total avg loss: 0.3781, batch size: 38
2021-08-24 20:39:12,069 INFO [train.py:450] Epoch 0, batch 14450, batch avg loss 0.3273, total avg loss: 0.3752, batch size: 38
2021-08-24 20:39:19,437 INFO [train.py:450] Epoch 0, batch 14460, batch avg loss 0.2937, total avg loss: 0.3740, batch size: 38
2021-08-24 20:39:26,452 INFO [train.py:450] Epoch 0, batch 14470, batch avg loss 0.4065, total avg loss: 0.3755, batch size: 36
2021-08-24 20:39:33,171 INFO [train.py:450] Epoch 0, batch 14480, batch avg loss 0.4038, total avg loss: 0.3775, batch size: 39
2021-08-24 20:39:40,533 INFO [train.py:450] Epoch 0, batch 14490, batch avg loss 0.3747, total avg loss: 0.3779, batch size: 38
2021-08-24 20:39:47,764 INFO [train.py:450] Epoch 0, batch 14500, batch avg loss 0.3536, total avg loss: 0.3772, batch size: 38
2021-08-24 20:39:54,637 INFO [train.py:450] Epoch 0, batch 14510, batch avg loss 0.3966, total avg loss: 0.3772, batch size: 38
2021-08-24 20:40:01,713 INFO [train.py:450] Epoch 0, batch 14520, batch avg loss 0.4067, total avg loss: 0.3779, batch size: 41
2021-08-24 20:40:09,288 INFO [train.py:450] Epoch 0, batch 14530, batch avg loss 0.3852, total avg loss: 0.3768, batch size: 38
2021-08-24 20:40:16,008 INFO [train.py:450] Epoch 0, batch 14540, batch avg loss 0.4182, total avg loss: 0.3775, batch size: 40
2021-08-24 20:40:22,560 INFO [train.py:450] Epoch 0, batch 14550, batch avg loss 0.3899, total avg loss: 0.3781, batch size: 39
2021-08-24 20:40:29,900 INFO [train.py:450] Epoch 0, batch 14560, batch avg loss 0.3832, total avg loss: 0.3795, batch size: 40
2021-08-24 20:40:36,462 INFO [train.py:450] Epoch 0, batch 14570, batch avg loss 0.4170, total avg loss: 0.3793, batch size: 37
2021-08-24 20:40:43,118 INFO [train.py:450] Epoch 0, batch 14580, batch avg loss 0.4039, total avg loss: 0.3793, batch size: 40
2021-08-24 20:40:50,246 INFO [train.py:450] Epoch 0, batch 14590, batch avg loss 0.3770, total avg loss: 0.3784, batch size: 35
2021-08-24 20:40:57,167 INFO [train.py:450] Epoch 0, batch 14600, batch avg loss 0.3327, total avg loss: 0.3782, batch size: 41
2021-08-24 20:41:03,758 INFO [train.py:450] Epoch 0, batch 14610, batch avg loss 0.3582, total avg loss: 0.3864, batch size: 39
2021-08-24 20:41:10,831 INFO [train.py:450] Epoch 0, batch 14620, batch avg loss 0.3698, total avg loss: 0.3803, batch size: 38
2021-08-24 20:41:18,429 INFO [train.py:450] Epoch 0, batch 14630, batch avg loss 0.3945, total avg loss: 0.3786, batch size: 41
2021-08-24 20:41:25,228 INFO [train.py:450] Epoch 0, batch 14640, batch avg loss 0.4071, total avg loss: 0.3753, batch size: 39
2021-08-24 20:41:32,453 INFO [train.py:450] Epoch 0, batch 14650, batch avg loss 0.3793, total avg loss: 0.3744, batch size: 39
2021-08-24 20:41:39,958 INFO [train.py:450] Epoch 0, batch 14660, batch avg loss 0.4200, total avg loss: 0.3755, batch size: 40
2021-08-24 20:41:46,761 INFO [train.py:450] Epoch 0, batch 14670, batch avg loss 0.3686, total avg loss: 0.3759, batch size: 38
2021-08-24 20:41:53,961 INFO [train.py:450] Epoch 0, batch 14680, batch avg loss 0.3699, total avg loss: 0.3773, batch size: 40
2021-08-24 20:42:01,055 INFO [train.py:450] Epoch 0, batch 14690, batch avg loss 0.4018, total avg loss: 0.3795, batch size: 39
2021-08-24 20:42:08,269 INFO [train.py:450] Epoch 0, batch 14700, batch avg loss 0.3758, total avg loss: 0.3786, batch size: 37
2021-08-24 20:42:14,916 INFO [train.py:450] Epoch 0, batch 14710, batch avg loss 0.3981, total avg loss: 0.3800, batch size: 40
2021-08-24 20:42:22,177 INFO [train.py:450] Epoch 0, batch 14720, batch avg loss 0.4619, total avg loss: 0.3808, batch size: 36
2021-08-24 20:42:28,879 INFO [train.py:450] Epoch 0, batch 14730, batch avg loss 0.3364, total avg loss: 0.3812, batch size: 42
2021-08-24 20:42:35,462 INFO [train.py:450] Epoch 0, batch 14740, batch avg loss 0.3973, total avg loss: 0.3807, batch size: 41
2021-08-24 20:42:43,326 INFO [train.py:450] Epoch 0, batch 14750, batch avg loss 0.4046, total avg loss: 0.3804, batch size: 43
2021-08-24 20:42:51,388 INFO [train.py:450] Epoch 0, batch 14760, batch avg loss 0.3785, total avg loss: 0.3797, batch size: 38
2021-08-24 20:42:59,320 INFO [train.py:450] Epoch 0, batch 14770, batch avg loss 0.3380, total avg loss: 0.3792, batch size: 39
2021-08-24 20:43:07,792 INFO [train.py:450] Epoch 0, batch 14780, batch avg loss 0.3584, total avg loss: 0.3787, batch size: 38
2021-08-24 20:43:14,923 INFO [train.py:450] Epoch 0, batch 14790, batch avg loss 0.3681, total avg loss: 0.3786, batch size: 40
2021-08-24 20:43:21,520 INFO [train.py:450] Epoch 0, batch 14800, batch avg loss 0.3605, total avg loss: 0.3786, batch size: 43
2021-08-24 20:43:27,994 INFO [train.py:450] Epoch 0, batch 14810, batch avg loss 0.3525, total avg loss: 0.3780, batch size: 40
2021-08-24 20:43:34,593 INFO [train.py:450] Epoch 0, batch 14820, batch avg loss 0.3524, total avg loss: 0.3803, batch size: 41
2021-08-24 20:43:41,107 INFO [train.py:450] Epoch 0, batch 14830, batch avg loss 0.3414, total avg loss: 0.3797, batch size: 39
2021-08-24 20:43:47,813 INFO [train.py:450] Epoch 0, batch 14840, batch avg loss 0.3345, total avg loss: 0.3769, batch size: 39
2021-08-24 20:43:54,629 INFO [train.py:450] Epoch 0, batch 14850, batch avg loss 0.3659, total avg loss: 0.3774, batch size: 41
2021-08-24 20:44:01,383 INFO [train.py:450] Epoch 0, batch 14860, batch avg loss 0.4011, total avg loss: 0.3773, batch size: 40
2021-08-24 20:44:08,002 INFO [train.py:450] Epoch 0, batch 14870, batch avg loss 0.3523, total avg loss: 0.3763, batch size: 42
2021-08-24 20:44:14,683 INFO [train.py:450] Epoch 0, batch 14880, batch avg loss 0.4066, total avg loss: 0.3763, batch size: 39
2021-08-24 20:44:21,635 INFO [train.py:450] Epoch 0, batch 14890, batch avg loss 0.3355, total avg loss: 0.3757, batch size: 42
2021-08-24 20:44:28,265 INFO [train.py:450] Epoch 0, batch 14900, batch avg loss 0.3876, total avg loss: 0.3744, batch size: 37
2021-08-24 20:44:34,567 INFO [train.py:450] Epoch 0, batch 14910, batch avg loss 0.3960, total avg loss: 0.3742, batch size: 40
2021-08-24 20:44:41,542 INFO [train.py:450] Epoch 0, batch 14920, batch avg loss 0.3667, total avg loss: 0.3745, batch size: 37
2021-08-24 20:44:48,024 INFO [train.py:450] Epoch 0, batch 14930, batch avg loss 0.4137, total avg loss: 0.3753, batch size: 39
2021-08-24 20:44:54,443 INFO [train.py:450] Epoch 0, batch 14940, batch avg loss 0.3617, total avg loss: 0.3755, batch size: 41
2021-08-24 20:45:00,888 INFO [train.py:450] Epoch 0, batch 14950, batch avg loss 0.3574, total avg loss: 0.3762, batch size: 38
2021-08-24 20:45:07,397 INFO [train.py:450] Epoch 0, batch 14960, batch avg loss 0.3641, total avg loss: 0.3759, batch size: 40
2021-08-24 20:45:14,100 INFO [train.py:450] Epoch 0, batch 14970, batch avg loss 0.4341, total avg loss: 0.3764, batch size: 38
2021-08-24 20:45:20,810 INFO [train.py:450] Epoch 0, batch 14980, batch avg loss 0.3554, total avg loss: 0.3765, batch size: 43
2021-08-24 20:45:27,210 INFO [train.py:450] Epoch 0, batch 14990, batch avg loss 0.3596, total avg loss: 0.3778, batch size: 37
2021-08-24 20:45:33,797 INFO [train.py:450] Epoch 0, batch 15000, batch avg loss 0.3580, total avg loss: 0.3773, batch size: 36
2021-08-24 20:46:13,790 INFO [train.py:482] Epoch 0, valid loss 0.2747, best valid loss: 0.2743 best valid epoch: 0
2021-08-24 20:46:19,734 INFO [train.py:450] Epoch 0, batch 15010, batch avg loss 0.4364, total avg loss: 0.3877, batch size: 39
2021-08-24 20:46:26,095 INFO [train.py:450] Epoch 0, batch 15020, batch avg loss 0.3524, total avg loss: 0.3799, batch size: 38
2021-08-24 20:46:33,004 INFO [train.py:450] Epoch 0, batch 15030, batch avg loss 0.3653, total avg loss: 0.3796, batch size: 40
2021-08-24 20:46:40,156 INFO [train.py:450] Epoch 0, batch 15040, batch avg loss 0.3442, total avg loss: 0.3775, batch size: 39
2021-08-24 20:46:46,480 INFO [train.py:450] Epoch 0, batch 15050, batch avg loss 0.3870, total avg loss: 0.3802, batch size: 38
2021-08-24 20:46:53,085 INFO [train.py:450] Epoch 0, batch 15060, batch avg loss 0.4295, total avg loss: 0.3820, batch size: 41
2021-08-24 20:46:59,679 INFO [train.py:450] Epoch 0, batch 15070, batch avg loss 0.4143, total avg loss: 0.3834, batch size: 39
2021-08-24 20:47:07,106 INFO [train.py:450] Epoch 0, batch 15080, batch avg loss 0.3969, total avg loss: 0.3830, batch size: 41
2021-08-24 20:47:14,406 INFO [train.py:450] Epoch 0, batch 15090, batch avg loss 0.3544, total avg loss: 0.3822, batch size: 43
2021-08-24 20:47:21,342 INFO [train.py:450] Epoch 0, batch 15100, batch avg loss 0.3398, total avg loss: 0.3799, batch size: 38
2021-08-24 20:47:29,707 INFO [train.py:450] Epoch 0, batch 15110, batch avg loss 0.4179, total avg loss: 0.3806, batch size: 42
2021-08-24 20:47:37,158 INFO [train.py:450] Epoch 0, batch 15120, batch avg loss 0.4145, total avg loss: 0.3808, batch size: 42
2021-08-24 20:47:47,737 INFO [train.py:450] Epoch 0, batch 15130, batch avg loss 0.3821, total avg loss: 0.3808, batch size: 40
2021-08-24 20:47:54,854 INFO [train.py:450] Epoch 0, batch 15140, batch avg loss 0.3966, total avg loss: 0.3803, batch size: 42
2021-08-24 20:48:01,792 INFO [train.py:450] Epoch 0, batch 15150, batch avg loss 0.3593, total avg loss: 0.3802, batch size: 37
2021-08-24 20:48:08,307 INFO [train.py:450] Epoch 0, batch 15160, batch avg loss 0.3391, total avg loss: 0.3790, batch size: 37
2021-08-24 20:48:16,023 INFO [train.py:450] Epoch 0, batch 15170, batch avg loss 0.3798, total avg loss: 0.3788, batch size: 42
2021-08-24 20:48:22,594 INFO [train.py:450] Epoch 0, batch 15180, batch avg loss 0.3927, total avg loss: 0.3786, batch size: 39
2021-08-24 20:48:29,283 INFO [train.py:450] Epoch 0, batch 15190, batch avg loss 0.3967, total avg loss: 0.3783, batch size: 39
2021-08-24 20:48:35,515 INFO [train.py:450] Epoch 0, batch 15200, batch avg loss 0.3423, total avg loss: 0.3779, batch size: 39
2021-08-24 20:48:42,171 INFO [train.py:450] Epoch 0, batch 15210, batch avg loss 0.3410, total avg loss: 0.3750, batch size: 40
2021-08-24 20:48:48,809 INFO [train.py:450] Epoch 0, batch 15220, batch avg loss 0.3965, total avg loss: 0.3754, batch size: 39
2021-08-24 20:48:55,574 INFO [train.py:450] Epoch 0, batch 15230, batch avg loss 0.4228, total avg loss: 0.3779, batch size: 40
2021-08-24 20:49:01,982 INFO [train.py:450] Epoch 0, batch 15240, batch avg loss 0.3780, total avg loss: 0.3776, batch size: 43
2021-08-24 20:49:08,502 INFO [train.py:450] Epoch 0, batch 15250, batch avg loss 0.3822, total avg loss: 0.3778, batch size: 39
2021-08-24 20:49:15,673 INFO [train.py:450] Epoch 0, batch 15260, batch avg loss 0.3472, total avg loss: 0.3784, batch size: 38
2021-08-24 20:49:21,788 INFO [train.py:450] Epoch 0, batch 15270, batch avg loss 0.3841, total avg loss: 0.3778, batch size: 41
2021-08-24 20:49:28,598 INFO [train.py:450] Epoch 0, batch 15280, batch avg loss 0.3709, total avg loss: 0.3760, batch size: 38
2021-08-24 20:49:34,960 INFO [train.py:450] Epoch 0, batch 15290, batch avg loss 0.3862, total avg loss: 0.3736, batch size: 37
2021-08-24 20:49:42,133 INFO [train.py:450] Epoch 0, batch 15300, batch avg loss 0.3734, total avg loss: 0.3730, batch size: 47
2021-08-24 20:49:48,679 INFO [train.py:450] Epoch 0, batch 15310, batch avg loss 0.3500, total avg loss: 0.3738, batch size: 41
2021-08-24 20:49:55,077 INFO [train.py:450] Epoch 0, batch 15320, batch avg loss 0.3213, total avg loss: 0.3734, batch size: 40
2021-08-24 20:50:01,593 INFO [train.py:450] Epoch 0, batch 15330, batch avg loss 0.4014, total avg loss: 0.3733, batch size: 42
2021-08-24 20:50:09,039 INFO [train.py:450] Epoch 0, batch 15340, batch avg loss 0.4263, total avg loss: 0.3738, batch size: 38
2021-08-24 20:50:15,691 INFO [train.py:450] Epoch 0, batch 15350, batch avg loss 0.3271, total avg loss: 0.3734, batch size: 40
2021-08-24 20:50:23,241 INFO [train.py:450] Epoch 0, batch 15360, batch avg loss 0.3431, total avg loss: 0.3730, batch size: 40
2021-08-24 20:50:29,940 INFO [train.py:450] Epoch 0, batch 15370, batch avg loss 0.3841, total avg loss: 0.3736, batch size: 37
2021-08-24 20:50:36,396 INFO [train.py:450] Epoch 0, batch 15380, batch avg loss 0.3849, total avg loss: 0.3739, batch size: 37
2021-08-24 20:50:43,038 INFO [train.py:450] Epoch 0, batch 15390, batch avg loss 0.3450, total avg loss: 0.3735, batch size: 41
2021-08-24 20:50:49,608 INFO [train.py:450] Epoch 0, batch 15400, batch avg loss 0.3854, total avg loss: 0.3731, batch size: 43
2021-08-24 20:50:56,158 INFO [train.py:450] Epoch 0, batch 15410, batch avg loss 0.3717, total avg loss: 0.3687, batch size: 39
2021-08-24 20:51:02,524 INFO [train.py:450] Epoch 0, batch 15420, batch avg loss 0.3526, total avg loss: 0.3679, batch size: 40
2021-08-24 20:51:08,797 INFO [train.py:450] Epoch 0, batch 15430, batch avg loss 0.4369, total avg loss: 0.3715, batch size: 41
2021-08-24 20:51:15,462 INFO [train.py:450] Epoch 0, batch 15440, batch avg loss 0.3182, total avg loss: 0.3685, batch size: 39
2021-08-24 20:51:22,204 INFO [train.py:450] Epoch 0, batch 15450, batch avg loss 0.3946, total avg loss: 0.3721, batch size: 41
2021-08-24 20:51:28,390 INFO [train.py:450] Epoch 0, batch 15460, batch avg loss 0.3622, total avg loss: 0.3697, batch size: 38
2021-08-24 20:51:34,606 INFO [train.py:450] Epoch 0, batch 15470, batch avg loss 0.3578, total avg loss: 0.3685, batch size: 40
2021-08-24 20:51:41,216 INFO [train.py:450] Epoch 0, batch 15480, batch avg loss 0.3300, total avg loss: 0.3674, batch size: 39
2021-08-24 20:51:47,808 INFO [train.py:450] Epoch 0, batch 15490, batch avg loss 0.2948, total avg loss: 0.3673, batch size: 38
2021-08-24 20:51:54,877 INFO [train.py:450] Epoch 0, batch 15500, batch avg loss 0.3437, total avg loss: 0.3689, batch size: 42
2021-08-24 20:52:02,054 INFO [train.py:450] Epoch 0, batch 15510, batch avg loss 0.3284, total avg loss: 0.3698, batch size: 40
2021-08-24 20:52:09,852 INFO [train.py:450] Epoch 0, batch 15520, batch avg loss 0.3353, total avg loss: 0.3716, batch size: 40
2021-08-24 20:52:16,382 INFO [train.py:450] Epoch 0, batch 15530, batch avg loss 0.4104, total avg loss: 0.3730, batch size: 37
2021-08-24 20:52:25,009 INFO [train.py:450] Epoch 0, batch 15540, batch avg loss 0.3940, total avg loss: 0.3719, batch size: 39
2021-08-24 20:52:31,594 INFO [train.py:450] Epoch 0, batch 15550, batch avg loss 0.4371, total avg loss: 0.3721, batch size: 42
2021-08-24 20:52:38,265 INFO [train.py:450] Epoch 0, batch 15560, batch avg loss 0.4183, total avg loss: 0.3733, batch size: 40
2021-08-24 20:52:44,485 INFO [train.py:450] Epoch 0, batch 15570, batch avg loss 0.3822, total avg loss: 0.3729, batch size: 40
2021-08-24 20:52:51,590 INFO [train.py:450] Epoch 0, batch 15580, batch avg loss 0.3489, total avg loss: 0.3727, batch size: 36
2021-08-24 20:52:58,338 INFO [train.py:450] Epoch 0, batch 15590, batch avg loss 0.3973, total avg loss: 0.3728, batch size: 41
2021-08-24 20:53:04,516 INFO [train.py:450] Epoch 0, batch 15600, batch avg loss 0.3063, total avg loss: 0.3720, batch size: 38
2021-08-24 20:53:11,223 INFO [train.py:450] Epoch 0, batch 15610, batch avg loss 0.3172, total avg loss: 0.3726, batch size: 41
2021-08-24 20:53:17,269 INFO [train.py:450] Epoch 0, batch 15620, batch avg loss 0.3464, total avg loss: 0.3617, batch size: 42
2021-08-24 20:53:24,040 INFO [train.py:450] Epoch 0, batch 15630, batch avg loss 0.3584, total avg loss: 0.3641, batch size: 42
2021-08-24 20:53:30,725 INFO [train.py:450] Epoch 0, batch 15640, batch avg loss 0.3474, total avg loss: 0.3683, batch size: 39
2021-08-24 20:53:37,380 INFO [train.py:450] Epoch 0, batch 15650, batch avg loss 0.3593, total avg loss: 0.3686, batch size: 40
2021-08-24 20:53:43,954 INFO [train.py:450] Epoch 0, batch 15660, batch avg loss 0.3444, total avg loss: 0.3681, batch size: 38
2021-08-24 20:53:50,135 INFO [train.py:450] Epoch 0, batch 15670, batch avg loss 0.3330, total avg loss: 0.3688, batch size: 36
2021-08-24 20:53:56,033 INFO [train.py:450] Epoch 0, batch 15680, batch avg loss 0.3777, total avg loss: 0.3688, batch size: 41
2021-08-24 20:54:02,925 INFO [train.py:450] Epoch 0, batch 15690, batch avg loss 0.3664, total avg loss: 0.3688, batch size: 38
2021-08-24 20:54:09,324 INFO [train.py:450] Epoch 0, batch 15700, batch avg loss 0.3480, total avg loss: 0.3690, batch size: 42
2021-08-24 20:54:15,919 INFO [train.py:450] Epoch 0, batch 15710, batch avg loss 0.4857, total avg loss: 0.3711, batch size: 39
2021-08-24 20:54:22,642 INFO [train.py:450] Epoch 0, batch 15720, batch avg loss 0.4132, total avg loss: 0.3719, batch size: 39
2021-08-24 20:54:29,348 INFO [train.py:450] Epoch 0, batch 15730, batch avg loss 0.3842, total avg loss: 0.3720, batch size: 41
2021-08-24 20:54:35,720 INFO [train.py:450] Epoch 0, batch 15740, batch avg loss 0.3740, total avg loss: 0.3725, batch size: 43
2021-08-24 20:54:42,046 INFO [train.py:450] Epoch 0, batch 15750, batch avg loss 0.3828, total avg loss: 0.3728, batch size: 40
2021-08-24 20:54:48,720 INFO [train.py:450] Epoch 0, batch 15760, batch avg loss 0.3758, total avg loss: 0.3738, batch size: 39
2021-08-24 20:54:55,218 INFO [train.py:450] Epoch 0, batch 15770, batch avg loss 0.3779, total avg loss: 0.3750, batch size: 36
2021-08-24 20:55:01,785 INFO [train.py:450] Epoch 0, batch 15780, batch avg loss 0.4085, total avg loss: 0.3754, batch size: 36
2021-08-24 20:55:08,629 INFO [train.py:450] Epoch 0, batch 15790, batch avg loss 0.4134, total avg loss: 0.3756, batch size: 41
2021-08-24 20:55:15,310 INFO [train.py:450] Epoch 0, batch 15800, batch avg loss 0.3533, total avg loss: 0.3759, batch size: 37
2021-08-24 20:55:21,788 INFO [train.py:450] Epoch 0, batch 15810, batch avg loss 0.4442, total avg loss: 0.3589, batch size: 45
2021-08-24 20:55:28,154 INFO [train.py:450] Epoch 0, batch 15820, batch avg loss 0.4098, total avg loss: 0.3740, batch size: 36
2021-08-24 20:55:34,390 INFO [train.py:450] Epoch 0, batch 15830, batch avg loss 0.3903, total avg loss: 0.3702, batch size: 38
2021-08-24 20:55:40,892 INFO [train.py:450] Epoch 0, batch 15840, batch avg loss 0.3636, total avg loss: 0.3738, batch size: 42
2021-08-24 20:55:48,070 INFO [train.py:450] Epoch 0, batch 15850, batch avg loss 0.3368, total avg loss: 0.3744, batch size: 40
2021-08-24 20:55:54,676 INFO [train.py:450] Epoch 0, batch 15860, batch avg loss 0.3636, total avg loss: 0.3762, batch size: 39
2021-08-24 20:56:01,135 INFO [train.py:450] Epoch 0, batch 15870, batch avg loss 0.3784, total avg loss: 0.3742, batch size: 44
2021-08-24 20:56:08,020 INFO [train.py:450] Epoch 0, batch 15880, batch avg loss 0.3294, total avg loss: 0.3739, batch size: 39
2021-08-24 20:56:14,552 INFO [train.py:450] Epoch 0, batch 15890, batch avg loss 0.3117, total avg loss: 0.3743, batch size: 40
2021-08-24 20:56:20,604 INFO [train.py:450] Epoch 0, batch 15900, batch avg loss 0.3647, total avg loss: 0.3741, batch size: 37
2021-08-24 20:56:26,807 INFO [train.py:450] Epoch 0, batch 15910, batch avg loss 0.3829, total avg loss: 0.3743, batch size: 40
2021-08-24 20:56:33,560 INFO [train.py:450] Epoch 0, batch 15920, batch avg loss 0.3353, total avg loss: 0.3745, batch size: 39
2021-08-24 20:56:40,036 INFO [train.py:450] Epoch 0, batch 15930, batch avg loss 0.3916, total avg loss: 0.3747, batch size: 41
2021-08-24 20:56:46,460 INFO [train.py:450] Epoch 0, batch 15940, batch avg loss 0.4290, total avg loss: 0.3745, batch size: 44
2021-08-24 20:56:52,785 INFO [train.py:450] Epoch 0, batch 15950, batch avg loss 0.4060, total avg loss: 0.3743, batch size: 40
2021-08-24 20:56:59,221 INFO [train.py:450] Epoch 0, batch 15960, batch avg loss 0.3592, total avg loss: 0.3737, batch size: 39
2021-08-24 20:57:05,609 INFO [train.py:450] Epoch 0, batch 15970, batch avg loss 0.4080, total avg loss: 0.3741, batch size: 42
2021-08-24 20:57:13,178 INFO [train.py:450] Epoch 0, batch 15980, batch avg loss 0.4126, total avg loss: 0.3744, batch size: 43
2021-08-24 20:57:19,354 INFO [train.py:450] Epoch 0, batch 15990, batch avg loss 0.3454, total avg loss: 0.3750, batch size: 40
2021-08-24 20:57:28,784 INFO [train.py:450] Epoch 0, batch 16000, batch avg loss 0.3418, total avg loss: 0.3749, batch size: 37
2021-08-24 20:58:06,996 INFO [train.py:482] Epoch 0, valid loss 0.2729, best valid loss: 0.2729 best valid epoch: 0
2021-08-24 20:58:12,910 INFO [train.py:450] Epoch 0, batch 16010, batch avg loss 0.3253, total avg loss: 0.3564, batch size: 36
2021-08-24 20:58:18,778 INFO [train.py:450] Epoch 0, batch 16020, batch avg loss 0.4050, total avg loss: 0.3680, batch size: 43
2021-08-24 20:58:24,649 INFO [train.py:450] Epoch 0, batch 16030, batch avg loss 0.3866, total avg loss: 0.3678, batch size: 40
2021-08-24 20:58:31,068 INFO [train.py:450] Epoch 0, batch 16040, batch avg loss 0.3457, total avg loss: 0.3658, batch size: 36
2021-08-24 20:58:38,109 INFO [train.py:450] Epoch 0, batch 16050, batch avg loss 0.3410, total avg loss: 0.3674, batch size: 39
2021-08-24 20:58:44,991 INFO [train.py:450] Epoch 0, batch 16060, batch avg loss 0.4461, total avg loss: 0.3687, batch size: 42
2021-08-24 20:58:51,574 INFO [train.py:450] Epoch 0, batch 16070, batch avg loss 0.3592, total avg loss: 0.3685, batch size: 40
2021-08-24 20:58:57,674 INFO [train.py:450] Epoch 0, batch 16080, batch avg loss 0.3706, total avg loss: 0.3690, batch size: 37
2021-08-24 20:59:04,305 INFO [train.py:450] Epoch 0, batch 16090, batch avg loss 0.4081, total avg loss: 0.3690, batch size: 41
2021-08-24 20:59:11,111 INFO [train.py:450] Epoch 0, batch 16100, batch avg loss 0.3750, total avg loss: 0.3695, batch size: 41
2021-08-24 20:59:17,310 INFO [train.py:450] Epoch 0, batch 16110, batch avg loss 0.3492, total avg loss: 0.3700, batch size: 37
2021-08-24 20:59:23,619 INFO [train.py:450] Epoch 0, batch 16120, batch avg loss 0.3249, total avg loss: 0.3701, batch size: 37
2021-08-24 20:59:29,928 INFO [train.py:450] Epoch 0, batch 16130, batch avg loss 0.3714, total avg loss: 0.3709, batch size: 39
2021-08-24 20:59:36,231 INFO [train.py:450] Epoch 0, batch 16140, batch avg loss 0.4405, total avg loss: 0.3702, batch size: 37
2021-08-24 20:59:42,538 INFO [train.py:450] Epoch 0, batch 16150, batch avg loss 0.4519, total avg loss: 0.3705, batch size: 39
2021-08-24 20:59:48,833 INFO [train.py:450] Epoch 0, batch 16160, batch avg loss 0.3407, total avg loss: 0.3707, batch size: 37
2021-08-24 20:59:55,462 INFO [train.py:450] Epoch 0, batch 16170, batch avg loss 0.3115, total avg loss: 0.3717, batch size: 39
2021-08-24 21:00:01,806 INFO [train.py:450] Epoch 0, batch 16180, batch avg loss 0.3447, total avg loss: 0.3727, batch size: 41
2021-08-24 21:00:08,447 INFO [train.py:450] Epoch 0, batch 16190, batch avg loss 0.3456, total avg loss: 0.3734, batch size: 39
2021-08-24 21:00:14,868 INFO [train.py:450] Epoch 0, batch 16200, batch avg loss 0.3243, total avg loss: 0.3722, batch size: 37
2021-08-24 21:00:21,476 INFO [train.py:450] Epoch 0, batch 16210, batch avg loss 0.3861, total avg loss: 0.3734, batch size: 40
2021-08-24 21:00:28,100 INFO [train.py:450] Epoch 0, batch 16220, batch avg loss 0.3972, total avg loss: 0.3779, batch size: 39
2021-08-24 21:00:34,205 INFO [train.py:450] Epoch 0, batch 16230, batch avg loss 0.3925, total avg loss: 0.3804, batch size: 39
2021-08-24 21:00:40,431 INFO [train.py:450] Epoch 0, batch 16240, batch avg loss 0.3640, total avg loss: 0.3817, batch size: 41
2021-08-24 21:00:46,987 INFO [train.py:450] Epoch 0, batch 16250, batch avg loss 0.3246, total avg loss: 0.3808, batch size: 40
2021-08-24 21:00:53,308 INFO [train.py:450] Epoch 0, batch 16260, batch avg loss 0.3725, total avg loss: 0.3771, batch size: 40
2021-08-24 21:00:59,282 INFO [train.py:450] Epoch 0, batch 16270, batch avg loss 0.3671, total avg loss: 0.3741, batch size: 40
2021-08-24 21:01:05,624 INFO [train.py:450] Epoch 0, batch 16280, batch avg loss 0.3486, total avg loss: 0.3751, batch size: 42
2021-08-24 21:01:11,486 INFO [train.py:450] Epoch 0, batch 16290, batch avg loss 0.3737, total avg loss: 0.3748, batch size: 41
2021-08-24 21:01:18,063 INFO [train.py:450] Epoch 0, batch 16300, batch avg loss 0.3376, total avg loss: 0.3758, batch size: 41
2021-08-24 21:01:24,770 INFO [train.py:450] Epoch 0, batch 16310, batch avg loss 0.3288, total avg loss: 0.3756, batch size: 45
2021-08-24 21:01:31,619 INFO [train.py:450] Epoch 0, batch 16320, batch avg loss 0.3481, total avg loss: 0.3746, batch size: 43
2021-08-24 21:01:37,884 INFO [train.py:450] Epoch 0, batch 16330, batch avg loss 0.3411, total avg loss: 0.3743, batch size: 42
2021-08-24 21:01:44,485 INFO [train.py:450] Epoch 0, batch 16340, batch avg loss 0.3682, total avg loss: 0.3746, batch size: 40
2021-08-24 21:01:50,655 INFO [train.py:450] Epoch 0, batch 16350, batch avg loss 0.3966, total avg loss: 0.3741, batch size: 41
2021-08-24 21:01:56,671 INFO [train.py:450] Epoch 0, batch 16360, batch avg loss 0.3770, total avg loss: 0.3741, batch size: 41
2021-08-24 21:02:04,146 INFO [train.py:450] Epoch 0, batch 16370, batch avg loss 0.3632, total avg loss: 0.3747, batch size: 44
2021-08-24 21:02:10,295 INFO [train.py:450] Epoch 0, batch 16380, batch avg loss 0.4012, total avg loss: 0.3739, batch size: 39
2021-08-24 21:02:17,094 INFO [train.py:450] Epoch 0, batch 16390, batch avg loss 0.3151, total avg loss: 0.3739, batch size: 35
2021-08-24 21:02:24,554 INFO [train.py:450] Epoch 0, batch 16400, batch avg loss 0.3679, total avg loss: 0.3739, batch size: 41
2021-08-24 21:02:31,087 INFO [train.py:450] Epoch 0, batch 16410, batch avg loss 0.3679, total avg loss: 0.3732, batch size: 45
2021-08-24 21:02:37,437 INFO [train.py:450] Epoch 0, batch 16420, batch avg loss 0.4503, total avg loss: 0.3727, batch size: 41
2021-08-24 21:02:44,442 INFO [train.py:450] Epoch 0, batch 16430, batch avg loss 0.3942, total avg loss: 0.3667, batch size: 39
2021-08-24 21:02:50,691 INFO [train.py:450] Epoch 0, batch 16440, batch avg loss 0.3471, total avg loss: 0.3690, batch size: 40
2021-08-24 21:02:56,771 INFO [train.py:450] Epoch 0, batch 16450, batch avg loss 0.3303, total avg loss: 0.3751, batch size: 39
2021-08-24 21:03:03,122 INFO [train.py:450] Epoch 0, batch 16460, batch avg loss 0.4503, total avg loss: 0.3773, batch size: 40
2021-08-24 21:03:09,101 INFO [train.py:450] Epoch 0, batch 16470, batch avg loss 0.3835, total avg loss: 0.3758, batch size: 37
2021-08-24 21:03:15,118 INFO [train.py:450] Epoch 0, batch 16480, batch avg loss 0.3924, total avg loss: 0.3751, batch size: 36
2021-08-24 21:03:21,152 INFO [train.py:450] Epoch 0, batch 16490, batch avg loss 0.4059, total avg loss: 0.3744, batch size: 42
2021-08-24 21:03:27,351 INFO [train.py:450] Epoch 0, batch 16500, batch avg loss 0.4414, total avg loss: 0.3749, batch size: 37
2021-08-24 21:03:33,486 INFO [train.py:450] Epoch 0, batch 16510, batch avg loss 0.3714, total avg loss: 0.3745, batch size: 40
2021-08-24 21:03:39,890 INFO [train.py:450] Epoch 0, batch 16520, batch avg loss 0.3619, total avg loss: 0.3742, batch size: 42
2021-08-24 21:03:46,255 INFO [train.py:450] Epoch 0, batch 16530, batch avg loss 0.3428, total avg loss: 0.3726, batch size: 40
2021-08-24 21:03:52,592 INFO [train.py:450] Epoch 0, batch 16540, batch avg loss 0.3649, total avg loss: 0.3717, batch size: 39
2021-08-24 21:03:59,344 INFO [train.py:450] Epoch 0, batch 16550, batch avg loss 0.3568, total avg loss: 0.3712, batch size: 44
2021-08-24 21:04:06,468 INFO [train.py:450] Epoch 0, batch 16560, batch avg loss 0.3914, total avg loss: 0.3716, batch size: 38
2021-08-24 21:04:12,433 INFO [train.py:450] Epoch 0, batch 16570, batch avg loss 0.3697, total avg loss: 0.3719, batch size: 40
2021-08-24 21:04:18,943 INFO [train.py:450] Epoch 0, batch 16580, batch avg loss 0.3538, total avg loss: 0.3712, batch size: 39
2021-08-24 21:04:25,039 INFO [train.py:450] Epoch 0, batch 16590, batch avg loss 0.3385, total avg loss: 0.3708, batch size: 38
2021-08-24 21:04:31,030 INFO [train.py:450] Epoch 0, batch 16600, batch avg loss 0.3550, total avg loss: 0.3708, batch size: 39
2021-08-24 21:04:36,879 INFO [train.py:450] Epoch 0, batch 16610, batch avg loss 0.3946, total avg loss: 0.3688, batch size: 40
2021-08-24 21:04:42,911 INFO [train.py:450] Epoch 0, batch 16620, batch avg loss 0.3554, total avg loss: 0.3740, batch size: 39
2021-08-24 21:04:49,119 INFO [train.py:450] Epoch 0, batch 16630, batch avg loss 0.3593, total avg loss: 0.3784, batch size: 41
2021-08-24 21:04:55,571 INFO [train.py:450] Epoch 0, batch 16640, batch avg loss 0.3135, total avg loss: 0.3781, batch size: 39
2021-08-24 21:05:01,874 INFO [train.py:450] Epoch 0, batch 16650, batch avg loss 0.3430, total avg loss: 0.3782, batch size: 41
2021-08-24 21:05:08,377 INFO [train.py:450] Epoch 0, batch 16660, batch avg loss 0.3293, total avg loss: 0.3763, batch size: 43
2021-08-24 21:05:14,886 INFO [train.py:450] Epoch 0, batch 16670, batch avg loss 0.3985, total avg loss: 0.3754, batch size: 36
2021-08-24 21:05:20,916 INFO [train.py:450] Epoch 0, batch 16680, batch avg loss 0.3982, total avg loss: 0.3754, batch size: 43
2021-08-24 21:05:27,160 INFO [train.py:450] Epoch 0, batch 16690, batch avg loss 0.3777, total avg loss: 0.3740, batch size: 42
2021-08-24 21:05:33,218 INFO [train.py:450] Epoch 0, batch 16700, batch avg loss 0.3487, total avg loss: 0.3751, batch size: 39
2021-08-24 21:05:39,179 INFO [train.py:450] Epoch 0, batch 16710, batch avg loss 0.3509, total avg loss: 0.3747, batch size: 40
2021-08-24 21:05:45,066 INFO [train.py:450] Epoch 0, batch 16720, batch avg loss 0.3612, total avg loss: 0.3738, batch size: 40
2021-08-24 21:05:51,473 INFO [train.py:450] Epoch 0, batch 16730, batch avg loss 0.3297, total avg loss: 0.3739, batch size: 41
2021-08-24 21:05:57,278 INFO [train.py:450] Epoch 0, batch 16740, batch avg loss 0.4134, total avg loss: 0.3742, batch size: 40
2021-08-24 21:06:04,540 INFO [train.py:450] Epoch 0, batch 16750, batch avg loss 0.3621, total avg loss: 0.3744, batch size: 42
2021-08-24 21:06:10,416 INFO [train.py:450] Epoch 0, batch 16760, batch avg loss 0.3302, total avg loss: 0.3739, batch size: 38
2021-08-24 21:06:16,379 INFO [train.py:450] Epoch 0, batch 16770, batch avg loss 0.3483, total avg loss: 0.3732, batch size: 39
2021-08-24 21:06:22,522 INFO [train.py:450] Epoch 0, batch 16780, batch avg loss 0.3668, total avg loss: 0.3726, batch size: 39
2021-08-24 21:06:28,767 INFO [train.py:450] Epoch 0, batch 16790, batch avg loss 0.3348, total avg loss: 0.3720, batch size: 42
2021-08-24 21:06:34,857 INFO [train.py:450] Epoch 0, batch 16800, batch avg loss 0.4377, total avg loss: 0.3733, batch size: 41
2021-08-24 21:06:42,221 INFO [train.py:450] Epoch 0, batch 16810, batch avg loss 0.3603, total avg loss: 0.3701, batch size: 43
2021-08-24 21:06:48,399 INFO [train.py:450] Epoch 0, batch 16820, batch avg loss 0.3912, total avg loss: 0.3668, batch size: 38
2021-08-24 21:06:56,331 INFO [train.py:450] Epoch 0, batch 16830, batch avg loss 0.3333, total avg loss: 0.3683, batch size: 42
2021-08-24 21:07:03,219 INFO [train.py:450] Epoch 0, batch 16840, batch avg loss 0.3806, total avg loss: 0.3667, batch size: 39
2021-08-24 21:07:09,146 INFO [train.py:450] Epoch 0, batch 16850, batch avg loss 0.3367, total avg loss: 0.3702, batch size: 38
2021-08-24 21:07:15,478 INFO [train.py:450] Epoch 0, batch 16860, batch avg loss 0.3485, total avg loss: 0.3699, batch size: 43
2021-08-24 21:07:21,387 INFO [train.py:450] Epoch 0, batch 16870, batch avg loss 0.3784, total avg loss: 0.3692, batch size: 38
2021-08-24 21:07:27,579 INFO [train.py:450] Epoch 0, batch 16880, batch avg loss 0.3302, total avg loss: 0.3686, batch size: 39
2021-08-24 21:07:33,713 INFO [train.py:450] Epoch 0, batch 16890, batch avg loss 0.3954, total avg loss: 0.3695, batch size: 43
2021-08-24 21:07:39,724 INFO [train.py:450] Epoch 0, batch 16900, batch avg loss 0.4039, total avg loss: 0.3700, batch size: 39
2021-08-24 21:07:46,024 INFO [train.py:450] Epoch 0, batch 16910, batch avg loss 0.3806, total avg loss: 0.3689, batch size: 39
2021-08-24 21:07:51,843 INFO [train.py:450] Epoch 0, batch 16920, batch avg loss 0.4432, total avg loss: 0.3704, batch size: 38
2021-08-24 21:07:58,243 INFO [train.py:450] Epoch 0, batch 16930, batch avg loss 0.3833, total avg loss: 0.3701, batch size: 40
2021-08-24 21:08:04,752 INFO [train.py:450] Epoch 0, batch 16940, batch avg loss 0.4185, total avg loss: 0.3708, batch size: 38
2021-08-24 21:08:10,685 INFO [train.py:450] Epoch 0, batch 16950, batch avg loss 0.3538, total avg loss: 0.3706, batch size: 39
2021-08-24 21:08:16,783 INFO [train.py:450] Epoch 0, batch 16960, batch avg loss 0.4060, total avg loss: 0.3714, batch size: 44
2021-08-24 21:08:22,547 INFO [train.py:450] Epoch 0, batch 16970, batch avg loss 0.3624, total avg loss: 0.3714, batch size: 41
2021-08-24 21:08:28,440 INFO [train.py:450] Epoch 0, batch 16980, batch avg loss 0.3854, total avg loss: 0.3705, batch size: 42
2021-08-24 21:08:34,631 INFO [train.py:450] Epoch 0, batch 16990, batch avg loss 0.4028, total avg loss: 0.3702, batch size: 37
2021-08-24 21:08:40,527 INFO [train.py:450] Epoch 0, batch 17000, batch avg loss 0.3719, total avg loss: 0.3704, batch size: 36
2021-08-24 21:09:18,595 INFO [train.py:482] Epoch 0, valid loss 0.2720, best valid loss: 0.2720 best valid epoch: 0
2021-08-24 21:09:24,481 INFO [train.py:450] Epoch 0, batch 17010, batch avg loss 0.3557, total avg loss: 0.3681, batch size: 39
2021-08-24 21:09:30,433 INFO [train.py:450] Epoch 0, batch 17020, batch avg loss 0.3419, total avg loss: 0.3722, batch size: 37
2021-08-24 21:09:36,429 INFO [train.py:450] Epoch 0, batch 17030, batch avg loss 0.3504, total avg loss: 0.3743, batch size: 38
2021-08-24 21:09:42,533 INFO [train.py:450] Epoch 0, batch 17040, batch avg loss 0.3840, total avg loss: 0.3760, batch size: 40
2021-08-24 21:09:48,736 INFO [train.py:450] Epoch 0, batch 17050, batch avg loss 0.3917, total avg loss: 0.3756, batch size: 42
2021-08-24 21:09:54,801 INFO [train.py:450] Epoch 0, batch 17060, batch avg loss 0.3674, total avg loss: 0.3747, batch size: 42
2021-08-24 21:10:00,928 INFO [train.py:450] Epoch 0, batch 17070, batch avg loss 0.3728, total avg loss: 0.3740, batch size: 41
2021-08-24 21:10:06,849 INFO [train.py:450] Epoch 0, batch 17080, batch avg loss 0.3386, total avg loss: 0.3741, batch size: 40
2021-08-24 21:10:13,078 INFO [train.py:450] Epoch 0, batch 17090, batch avg loss 0.3508, total avg loss: 0.3723, batch size: 37
2021-08-24 21:10:19,308 INFO [train.py:450] Epoch 0, batch 17100, batch avg loss 0.3931, total avg loss: 0.3740, batch size: 40
2021-08-24 21:10:25,458 INFO [train.py:450] Epoch 0, batch 17110, batch avg loss 0.3530, total avg loss: 0.3733, batch size: 41
2021-08-24 21:10:31,465 INFO [train.py:450] Epoch 0, batch 17120, batch avg loss 0.3992, total avg loss: 0.3736, batch size: 43
2021-08-24 21:10:37,882 INFO [train.py:450] Epoch 0, batch 17130, batch avg loss 0.3472, total avg loss: 0.3723, batch size: 37
2021-08-24 21:10:44,197 INFO [train.py:450] Epoch 0, batch 17140, batch avg loss 0.3343, total avg loss: 0.3710, batch size: 38
2021-08-24 21:10:51,309 INFO [train.py:450] Epoch 0, batch 17150, batch avg loss 0.4029, total avg loss: 0.3703, batch size: 38
2021-08-24 21:10:57,936 INFO [train.py:450] Epoch 0, batch 17160, batch avg loss 0.3800, total avg loss: 0.3705, batch size: 42
2021-08-24 21:11:06,795 INFO [train.py:450] Epoch 0, batch 17170, batch avg loss 0.4169, total avg loss: 0.3707, batch size: 38
2021-08-24 21:11:14,382 INFO [train.py:450] Epoch 0, batch 17180, batch avg loss 0.3838, total avg loss: 0.3707, batch size: 40
2021-08-24 21:11:20,420 INFO [train.py:450] Epoch 0, batch 17190, batch avg loss 0.3553, total avg loss: 0.3710, batch size: 38
2021-08-24 21:11:26,390 INFO [train.py:450] Epoch 0, batch 17200, batch avg loss 0.3440, total avg loss: 0.3707, batch size: 37
2021-08-24 21:11:32,107 INFO [train.py:450] Epoch 0, batch 17210, batch avg loss 0.3920, total avg loss: 0.3835, batch size: 37
2021-08-24 21:11:38,055 INFO [train.py:450] Epoch 0, batch 17220, batch avg loss 0.3646, total avg loss: 0.3868, batch size: 42
2021-08-24 21:11:43,851 INFO [train.py:450] Epoch 0, batch 17230, batch avg loss 0.3985, total avg loss: 0.3820, batch size: 39
2021-08-24 21:11:50,460 INFO [train.py:450] Epoch 0, batch 17240, batch avg loss 0.3505, total avg loss: 0.3789, batch size: 40
2021-08-24 21:11:56,558 INFO [train.py:450] Epoch 0, batch 17250, batch avg loss 0.3525, total avg loss: 0.3746, batch size: 40
2021-08-24 21:12:02,937 INFO [train.py:450] Epoch 0, batch 17260, batch avg loss 0.3564, total avg loss: 0.3719, batch size: 40
2021-08-24 21:12:09,251 INFO [train.py:450] Epoch 0, batch 17270, batch avg loss 0.4014, total avg loss: 0.3730, batch size: 38
2021-08-24 21:12:15,111 INFO [train.py:450] Epoch 0, batch 17280, batch avg loss 0.3387, total avg loss: 0.3730, batch size: 40
2021-08-24 21:12:21,527 INFO [train.py:450] Epoch 0, batch 17290, batch avg loss 0.3920, total avg loss: 0.3710, batch size: 42
2021-08-24 21:12:27,489 INFO [train.py:450] Epoch 0, batch 17300, batch avg loss 0.3381, total avg loss: 0.3718, batch size: 42
2021-08-24 21:12:33,747 INFO [train.py:450] Epoch 0, batch 17310, batch avg loss 0.4045, total avg loss: 0.3711, batch size: 42
2021-08-24 21:12:40,083 INFO [train.py:450] Epoch 0, batch 17320, batch avg loss 0.3764, total avg loss: 0.3713, batch size: 40
2021-08-24 21:12:46,195 INFO [train.py:450] Epoch 0, batch 17330, batch avg loss 0.3674, total avg loss: 0.3708, batch size: 41
2021-08-24 21:12:52,563 INFO [train.py:450] Epoch 0, batch 17340, batch avg loss 0.3885, total avg loss: 0.3719, batch size: 39
2021-08-24 21:12:58,870 INFO [train.py:450] Epoch 0, batch 17350, batch avg loss 0.3751, total avg loss: 0.3713, batch size: 41
2021-08-24 21:13:05,110 INFO [train.py:450] Epoch 0, batch 17360, batch avg loss 0.3655, total avg loss: 0.3705, batch size: 42
2021-08-24 21:13:11,317 INFO [train.py:450] Epoch 0, batch 17370, batch avg loss 0.4096, total avg loss: 0.3702, batch size: 40
2021-08-24 21:13:17,367 INFO [train.py:450] Epoch 0, batch 17380, batch avg loss 0.3994, total avg loss: 0.3704, batch size: 41
2021-08-24 21:13:23,604 INFO [train.py:450] Epoch 0, batch 17390, batch avg loss 0.3073, total avg loss: 0.3707, batch size: 39
2021-08-24 21:13:30,114 INFO [train.py:450] Epoch 0, batch 17400, batch avg loss 0.3583, total avg loss: 0.3701, batch size: 38
2021-08-24 21:13:36,020 INFO [train.py:450] Epoch 0, batch 17410, batch avg loss 0.3625, total avg loss: 0.3700, batch size: 38
2021-08-24 21:13:41,829 INFO [train.py:450] Epoch 0, batch 17420, batch avg loss 0.3791, total avg loss: 0.3725, batch size: 40
2021-08-24 21:13:48,470 INFO [train.py:450] Epoch 0, batch 17430, batch avg loss 0.3948, total avg loss: 0.3761, batch size: 42
2021-08-24 21:13:55,187 INFO [train.py:450] Epoch 0, batch 17440, batch avg loss 0.3370, total avg loss: 0.3729, batch size: 41
2021-08-24 21:14:01,523 INFO [train.py:450] Epoch 0, batch 17450, batch avg loss 0.3517, total avg loss: 0.3712, batch size: 43
2021-08-24 21:14:07,699 INFO [train.py:450] Epoch 0, batch 17460, batch avg loss 0.3279, total avg loss: 0.3705, batch size: 37
2021-08-24 21:14:14,104 INFO [train.py:450] Epoch 0, batch 17470, batch avg loss 0.3728, total avg loss: 0.3712, batch size: 36
2021-08-24 21:14:20,599 INFO [train.py:450] Epoch 0, batch 17480, batch avg loss 0.3408, total avg loss: 0.3699, batch size: 39
2021-08-24 21:14:26,973 INFO [train.py:450] Epoch 0, batch 17490, batch avg loss 0.4071, total avg loss: 0.3689, batch size: 37
2021-08-24 21:14:32,981 INFO [train.py:450] Epoch 0, batch 17500, batch avg loss 0.3520, total avg loss: 0.3694, batch size: 40
2021-08-24 21:14:39,271 INFO [train.py:450] Epoch 0, batch 17510, batch avg loss 0.3168, total avg loss: 0.3691, batch size: 38
2021-08-24 21:14:45,810 INFO [train.py:450] Epoch 0, batch 17520, batch avg loss 0.4309, total avg loss: 0.3693, batch size: 43
2021-08-24 21:14:52,205 INFO [train.py:450] Epoch 0, batch 17530, batch avg loss 0.3651, total avg loss: 0.3698, batch size: 42
2021-08-24 21:14:58,179 INFO [train.py:450] Epoch 0, batch 17540, batch avg loss 0.4187, total avg loss: 0.3701, batch size: 41
2021-08-24 21:15:00,942 WARNING [cut.py:1694] To perform mix, energy must be non-zero and non-negative (got 0.0).  MonoCut with id "f171767d-2493-1b22-1055-90694fe23839" will not be mixed in.
2021-08-24 21:15:04,103 INFO [train.py:450] Epoch 0, batch 17550, batch avg loss 0.3436, total avg loss: 0.3691, batch size: 39
2021-08-24 21:15:10,723 INFO [train.py:450] Epoch 0, batch 17560, batch avg loss 0.3793, total avg loss: 0.3693, batch size: 40
2021-08-24 21:15:16,806 INFO [train.py:450] Epoch 0, batch 17570, batch avg loss 0.3459, total avg loss: 0.3689, batch size: 38
2021-08-24 21:15:23,298 INFO [train.py:450] Epoch 0, batch 17580, batch avg loss 0.3827, total avg loss: 0.3686, batch size: 43
2021-08-24 21:15:29,530 INFO [train.py:450] Epoch 0, batch 17590, batch avg loss 0.3825, total avg loss: 0.3685, batch size: 41
2021-08-24 21:15:35,689 INFO [train.py:450] Epoch 0, batch 17600, batch avg loss 0.3955, total avg loss: 0.3690, batch size: 36
2021-08-24 21:15:41,847 INFO [train.py:450] Epoch 0, batch 17610, batch avg loss 0.3196, total avg loss: 0.3504, batch size: 41
2021-08-24 21:15:49,646 INFO [train.py:450] Epoch 0, batch 17620, batch avg loss 0.3284, total avg loss: 0.3516, batch size: 39
2021-08-24 21:16:00,015 INFO [train.py:450] Epoch 0, batch 17630, batch avg loss 0.3283, total avg loss: 0.3524, batch size: 39
2021-08-24 21:16:06,057 INFO [train.py:450] Epoch 0, batch 17640, batch avg loss 0.3691, total avg loss: 0.3552, batch size: 41
2021-08-24 21:16:11,840 INFO [train.py:450] Epoch 0, batch 17650, batch avg loss 0.3394, total avg loss: 0.3555, batch size: 37
2021-08-24 21:16:17,851 INFO [train.py:450] Epoch 0, batch 17660, batch avg loss 0.3464, total avg loss: 0.3578, batch size: 39
2021-08-24 21:16:24,402 INFO [train.py:450] Epoch 0, batch 17670, batch avg loss 0.3502, total avg loss: 0.3581, batch size: 40
2021-08-24 21:16:30,593 INFO [train.py:450] Epoch 0, batch 17680, batch avg loss 0.3680, total avg loss: 0.3581, batch size: 38
2021-08-24 21:16:36,806 INFO [train.py:450] Epoch 0, batch 17690, batch avg loss 0.3871, total avg loss: 0.3605, batch size: 42
2021-08-24 21:16:42,933 INFO [train.py:450] Epoch 0, batch 17700, batch avg loss 0.3364, total avg loss: 0.3627, batch size: 40
2021-08-24 21:16:49,102 INFO [train.py:450] Epoch 0, batch 17710, batch avg loss 0.3473, total avg loss: 0.3619, batch size: 38
2021-08-24 21:16:54,966 INFO [train.py:450] Epoch 0, batch 17720, batch avg loss 0.4517, total avg loss: 0.3614, batch size: 41
2021-08-24 21:17:00,962 INFO [train.py:450] Epoch 0, batch 17730, batch avg loss 0.3916, total avg loss: 0.3614, batch size: 38
2021-08-24 21:17:06,849 INFO [train.py:450] Epoch 0, batch 17740, batch avg loss 0.3565, total avg loss: 0.3616, batch size: 39
2021-08-24 21:17:12,773 INFO [train.py:450] Epoch 0, batch 17750, batch avg loss 0.3506, total avg loss: 0.3610, batch size: 38
2021-08-24 21:17:19,404 INFO [train.py:450] Epoch 0, batch 17760, batch avg loss 0.3436, total avg loss: 0.3619, batch size: 38
2021-08-24 21:17:25,619 INFO [train.py:450] Epoch 0, batch 17770, batch avg loss 0.3684, total avg loss: 0.3625, batch size: 43
2021-08-24 21:17:31,924 INFO [train.py:450] Epoch 0, batch 17780, batch avg loss 0.3730, total avg loss: 0.3628, batch size: 41
2021-08-24 21:17:37,799 INFO [train.py:450] Epoch 0, batch 17790, batch avg loss 0.3627, total avg loss: 0.3622, batch size: 41
2021-08-24 21:17:43,808 INFO [train.py:450] Epoch 0, batch 17800, batch avg loss 0.3462, total avg loss: 0.3623, batch size: 41
2021-08-24 21:17:49,662 INFO [train.py:450] Epoch 0, batch 17810, batch avg loss 0.3433, total avg loss: 0.3691, batch size: 39
2021-08-24 21:17:55,888 INFO [train.py:450] Epoch 0, batch 17820, batch avg loss 0.3581, total avg loss: 0.3706, batch size: 42
2021-08-24 21:18:01,937 INFO [train.py:450] Epoch 0, batch 17830, batch avg loss 0.3930, total avg loss: 0.3704, batch size: 38
2021-08-24 21:18:07,954 INFO [train.py:450] Epoch 0, batch 17840, batch avg loss 0.3334, total avg loss: 0.3727, batch size: 39
2021-08-24 21:18:14,293 INFO [train.py:450] Epoch 0, batch 17850, batch avg loss 0.3854, total avg loss: 0.3717, batch size: 42
2021-08-24 21:18:20,123 INFO [train.py:450] Epoch 0, batch 17860, batch avg loss 0.3643, total avg loss: 0.3711, batch size: 37
2021-08-24 21:18:25,940 INFO [train.py:450] Epoch 0, batch 17870, batch avg loss 0.3432, total avg loss: 0.3720, batch size: 38
2021-08-24 21:18:31,775 INFO [train.py:450] Epoch 0, batch 17880, batch avg loss 0.3628, total avg loss: 0.3720, batch size: 37
2021-08-24 21:18:38,099 INFO [train.py:450] Epoch 0, batch 17890, batch avg loss 0.3998, total avg loss: 0.3719, batch size: 39
2021-08-24 21:18:44,300 INFO [train.py:450] Epoch 0, batch 17900, batch avg loss 0.3622, total avg loss: 0.3708, batch size: 41
2021-08-24 21:18:50,349 INFO [train.py:450] Epoch 0, batch 17910, batch avg loss 0.3258, total avg loss: 0.3704, batch size: 43
2021-08-24 21:18:56,461 INFO [train.py:450] Epoch 0, batch 17920, batch avg loss 0.4181, total avg loss: 0.3701, batch size: 42
2021-08-24 21:19:02,570 INFO [train.py:450] Epoch 0, batch 17930, batch avg loss 0.3538, total avg loss: 0.3704, batch size: 40
2021-08-24 21:19:08,605 INFO [train.py:450] Epoch 0, batch 17940, batch avg loss 0.3710, total avg loss: 0.3697, batch size: 44
2021-08-24 21:19:14,907 INFO [train.py:450] Epoch 0, batch 17950, batch avg loss 0.3912, total avg loss: 0.3705, batch size: 40
2021-08-24 21:19:21,398 INFO [train.py:450] Epoch 0, batch 17960, batch avg loss 0.3973, total avg loss: 0.3714, batch size: 42
2021-08-24 21:19:27,649 INFO [train.py:450] Epoch 0, batch 17970, batch avg loss 0.4229, total avg loss: 0.3708, batch size: 40
2021-08-24 21:19:33,749 INFO [train.py:450] Epoch 0, batch 17980, batch avg loss 0.3850, total avg loss: 0.3703, batch size: 38
2021-08-24 21:19:39,961 INFO [train.py:450] Epoch 0, batch 17990, batch avg loss 0.4444, total avg loss: 0.3701, batch size: 41
2021-08-24 21:19:45,929 INFO [train.py:450] Epoch 0, batch 18000, batch avg loss 0.3789, total avg loss: 0.3695, batch size: 39
2021-08-24 21:20:24,067 INFO [train.py:482] Epoch 0, valid loss 0.2665, best valid loss: 0.2665 best valid epoch: 0
2021-08-24 21:20:29,939 INFO [train.py:450] Epoch 0, batch 18010, batch avg loss 0.3369, total avg loss: 0.3690, batch size: 39
2021-08-24 21:20:35,836 INFO [train.py:450] Epoch 0, batch 18020, batch avg loss 0.3419, total avg loss: 0.3736, batch size: 42
2021-08-24 21:20:43,017 INFO [train.py:450] Epoch 0, batch 18030, batch avg loss 0.3021, total avg loss: 0.3711, batch size: 40
2021-08-24 21:20:49,352 INFO [train.py:450] Epoch 0, batch 18040, batch avg loss 0.3449, total avg loss: 0.3708, batch size: 38
2021-08-24 21:20:56,998 INFO [train.py:450] Epoch 0, batch 18050, batch avg loss 0.3366, total avg loss: 0.3716, batch size: 38
2021-08-24 21:21:05,702 INFO [train.py:450] Epoch 0, batch 18060, batch avg loss 0.4637, total avg loss: 0.3706, batch size: 40
2021-08-24 21:21:11,933 INFO [train.py:450] Epoch 0, batch 18070, batch avg loss 0.3464, total avg loss: 0.3693, batch size: 38
2021-08-24 21:21:18,206 INFO [train.py:450] Epoch 0, batch 18080, batch avg loss 0.3448, total avg loss: 0.3692, batch size: 38
2021-08-24 21:21:24,317 INFO [train.py:450] Epoch 0, batch 18090, batch avg loss 0.3539, total avg loss: 0.3675, batch size: 41
2021-08-24 21:21:30,387 INFO [train.py:450] Epoch 0, batch 18100, batch avg loss 0.3108, total avg loss: 0.3658, batch size: 40
2021-08-24 21:21:36,549 INFO [train.py:450] Epoch 0, batch 18110, batch avg loss 0.3657, total avg loss: 0.3653, batch size: 41
2021-08-24 21:21:43,057 INFO [train.py:450] Epoch 0, batch 18120, batch avg loss 0.3164, total avg loss: 0.3673, batch size: 42
2021-08-24 21:21:48,932 INFO [train.py:450] Epoch 0, batch 18130, batch avg loss 0.3260, total avg loss: 0.3662, batch size: 40
2021-08-24 21:21:55,141 INFO [train.py:450] Epoch 0, batch 18140, batch avg loss 0.4446, total avg loss: 0.3675, batch size: 41
2021-08-24 21:22:01,024 INFO [train.py:450] Epoch 0, batch 18150, batch avg loss 0.3597, total avg loss: 0.3670, batch size: 37
2021-08-24 21:22:07,206 INFO [train.py:450] Epoch 0, batch 18160, batch avg loss 0.3153, total avg loss: 0.3651, batch size: 39
2021-08-24 21:22:13,045 INFO [train.py:450] Epoch 0, batch 18170, batch avg loss 0.3534, total avg loss: 0.3660, batch size: 40
2021-08-24 21:22:19,440 INFO [train.py:450] Epoch 0, batch 18180, batch avg loss 0.3512, total avg loss: 0.3667, batch size: 41
2021-08-24 21:22:25,491 INFO [train.py:450] Epoch 0, batch 18190, batch avg loss 0.3233, total avg loss: 0.3665, batch size: 40
2021-08-24 21:22:32,021 INFO [train.py:450] Epoch 0, batch 18200, batch avg loss 0.4182, total avg loss: 0.3664, batch size: 39
2021-08-24 21:22:38,048 INFO [train.py:450] Epoch 0, batch 18210, batch avg loss 0.3378, total avg loss: 0.3738, batch size: 38
2021-08-24 21:22:44,679 INFO [train.py:450] Epoch 0, batch 18220, batch avg loss 0.3928, total avg loss: 0.3710, batch size: 41
2021-08-24 21:22:50,507 INFO [train.py:450] Epoch 0, batch 18230, batch avg loss 0.3506, total avg loss: 0.3610, batch size: 41
2021-08-24 21:22:56,698 INFO [train.py:450] Epoch 0, batch 18240, batch avg loss 0.3599, total avg loss: 0.3630, batch size: 37
2021-08-24 21:23:03,212 INFO [train.py:450] Epoch 0, batch 18250, batch avg loss 0.3369, total avg loss: 0.3619, batch size: 41
2021-08-24 21:23:09,366 INFO [train.py:450] Epoch 0, batch 18260, batch avg loss 0.3256, total avg loss: 0.3611, batch size: 40
2021-08-24 21:23:15,584 INFO [train.py:450] Epoch 0, batch 18270, batch avg loss 0.3873, total avg loss: 0.3613, batch size: 38
2021-08-24 21:23:21,788 INFO [train.py:450] Epoch 0, batch 18280, batch avg loss 0.4347, total avg loss: 0.3643, batch size: 43
2021-08-24 21:23:28,462 INFO [train.py:450] Epoch 0, batch 18290, batch avg loss 0.4073, total avg loss: 0.3651, batch size: 42
2021-08-24 21:23:34,679 INFO [train.py:450] Epoch 0, batch 18300, batch avg loss 0.3354, total avg loss: 0.3664, batch size: 41
2021-08-24 21:23:41,199 INFO [train.py:450] Epoch 0, batch 18310, batch avg loss 0.3978, total avg loss: 0.3680, batch size: 44
2021-08-24 21:23:47,261 INFO [train.py:450] Epoch 0, batch 18320, batch avg loss 0.3684, total avg loss: 0.3679, batch size: 41
2021-08-24 21:23:53,668 INFO [train.py:450] Epoch 0, batch 18330, batch avg loss 0.2900, total avg loss: 0.3673, batch size: 43
2021-08-24 21:24:00,207 INFO [train.py:450] Epoch 0, batch 18340, batch avg loss 0.3546, total avg loss: 0.3669, batch size: 40
2021-08-24 21:24:06,247 INFO [train.py:450] Epoch 0, batch 18350, batch avg loss 0.4198, total avg loss: 0.3679, batch size: 37
2021-08-24 21:24:12,102 INFO [train.py:450] Epoch 0, batch 18360, batch avg loss 0.3167, total avg loss: 0.3676, batch size: 38
2021-08-24 21:24:18,678 INFO [train.py:450] Epoch 0, batch 18370, batch avg loss 0.3714, total avg loss: 0.3677, batch size: 43
2021-08-24 21:24:24,847 INFO [train.py:450] Epoch 0, batch 18380, batch avg loss 0.3456, total avg loss: 0.3666, batch size: 39
2021-08-24 21:24:30,832 INFO [train.py:450] Epoch 0, batch 18390, batch avg loss 0.3480, total avg loss: 0.3665, batch size: 41
2021-08-24 21:24:37,293 INFO [train.py:450] Epoch 0, batch 18400, batch avg loss 0.3378, total avg loss: 0.3660, batch size: 41
2021-08-24 21:24:43,541 INFO [train.py:450] Epoch 0, batch 18410, batch avg loss 0.3505, total avg loss: 0.3573, batch size: 37
2021-08-24 21:24:50,116 INFO [train.py:450] Epoch 0, batch 18420, batch avg loss 0.3540, total avg loss: 0.3669, batch size: 42
2021-08-24 21:24:56,056 INFO [train.py:450] Epoch 0, batch 18430, batch avg loss 0.3212, total avg loss: 0.3643, batch size: 40
2021-08-24 21:25:01,928 INFO [train.py:450] Epoch 0, batch 18440, batch avg loss 0.3582, total avg loss: 0.3622, batch size: 40
2021-08-24 21:25:08,174 INFO [train.py:450] Epoch 0, batch 18450, batch avg loss 0.3744, total avg loss: 0.3643, batch size: 37
2021-08-24 21:25:14,218 INFO [train.py:450] Epoch 0, batch 18460, batch avg loss 0.3314, total avg loss: 0.3640, batch size: 42
2021-08-24 21:25:21,469 INFO [train.py:450] Epoch 0, batch 18470, batch avg loss 0.4143, total avg loss: 0.3642, batch size: 40
2021-08-24 21:25:27,570 INFO [train.py:450] Epoch 0, batch 18480, batch avg loss 0.3817, total avg loss: 0.3664, batch size: 38
2021-08-24 21:25:36,413 INFO [train.py:450] Epoch 0, batch 18490, batch avg loss 0.3833, total avg loss: 0.3667, batch size: 40
2021-08-24 21:25:43,272 INFO [train.py:450] Epoch 0, batch 18500, batch avg loss 0.4581, total avg loss: 0.3676, batch size: 40
2021-08-24 21:25:49,267 INFO [train.py:450] Epoch 0, batch 18510, batch avg loss 0.3385, total avg loss: 0.3686, batch size: 37
2021-08-24 21:25:55,496 INFO [train.py:450] Epoch 0, batch 18520, batch avg loss 0.3706, total avg loss: 0.3689, batch size: 38
2021-08-24 21:26:01,697 INFO [train.py:450] Epoch 0, batch 18530, batch avg loss 0.3533, total avg loss: 0.3676, batch size: 40
2021-08-24 21:26:07,670 INFO [train.py:450] Epoch 0, batch 18540, batch avg loss 0.3420, total avg loss: 0.3675, batch size: 38
2021-08-24 21:26:14,115 INFO [train.py:450] Epoch 0, batch 18550, batch avg loss 0.3552, total avg loss: 0.3672, batch size: 40
2021-08-24 21:26:20,077 INFO [train.py:450] Epoch 0, batch 18560, batch avg loss 0.3671, total avg loss: 0.3666, batch size: 40
2021-08-24 21:26:26,281 INFO [train.py:450] Epoch 0, batch 18570, batch avg loss 0.3687, total avg loss: 0.3675, batch size: 39
2021-08-24 21:26:32,726 INFO [train.py:450] Epoch 0, batch 18580, batch avg loss 0.3545, total avg loss: 0.3672, batch size: 37
2021-08-24 21:26:39,356 INFO [train.py:450] Epoch 0, batch 18590, batch avg loss 0.3272, total avg loss: 0.3677, batch size: 41
2021-08-24 21:26:45,689 INFO [train.py:450] Epoch 0, batch 18600, batch avg loss 0.3629, total avg loss: 0.3684, batch size: 38
2021-08-24 21:26:52,021 INFO [train.py:450] Epoch 0, batch 18610, batch avg loss 0.3571, total avg loss: 0.3616, batch size: 39
2021-08-24 21:26:58,360 INFO [train.py:450] Epoch 0, batch 18620, batch avg loss 0.3552, total avg loss: 0.3640, batch size: 39
2021-08-24 21:27:04,277 INFO [train.py:450] Epoch 0, batch 18630, batch avg loss 0.4189, total avg loss: 0.3694, batch size: 44
2021-08-24 21:27:10,160 INFO [train.py:450] Epoch 0, batch 18640, batch avg loss 0.3516, total avg loss: 0.3700, batch size: 35
2021-08-24 21:27:16,366 INFO [train.py:450] Epoch 0, batch 18650, batch avg loss 0.3843, total avg loss: 0.3716, batch size: 36
2021-08-24 21:27:22,632 INFO [train.py:450] Epoch 0, batch 18660, batch avg loss 0.3473, total avg loss: 0.3684, batch size: 41
2021-08-24 21:27:29,804 INFO [train.py:450] Epoch 0, batch 18670, batch avg loss 0.4609, total avg loss: 0.3672, batch size: 39
2021-08-24 21:27:35,803 INFO [train.py:450] Epoch 0, batch 18680, batch avg loss 0.3638, total avg loss: 0.3662, batch size: 38
2021-08-24 21:27:41,728 INFO [train.py:450] Epoch 0, batch 18690, batch avg loss 0.3608, total avg loss: 0.3658, batch size: 40
2021-08-24 21:27:47,826 INFO [train.py:450] Epoch 0, batch 18700, batch avg loss 0.3443, total avg loss: 0.3669, batch size: 38
2021-08-24 21:27:53,592 INFO [train.py:450] Epoch 0, batch 18710, batch avg loss 0.3610, total avg loss: 0.3670, batch size: 41
2021-08-24 21:27:59,581 INFO [train.py:450] Epoch 0, batch 18720, batch avg loss 0.3805, total avg loss: 0.3668, batch size: 42
2021-08-24 21:28:05,602 INFO [train.py:450] Epoch 0, batch 18730, batch avg loss 0.3315, total avg loss: 0.3666, batch size: 41
2021-08-24 21:28:11,767 INFO [train.py:450] Epoch 0, batch 18740, batch avg loss 0.3980, total avg loss: 0.3673, batch size: 40
2021-08-24 21:28:17,912 INFO [train.py:450] Epoch 0, batch 18750, batch avg loss 0.3830, total avg loss: 0.3663, batch size: 39
2021-08-24 21:28:24,149 INFO [train.py:450] Epoch 0, batch 18760, batch avg loss 0.3833, total avg loss: 0.3673, batch size: 42
2021-08-24 21:28:30,620 INFO [train.py:450] Epoch 0, batch 18770, batch avg loss 0.3428, total avg loss: 0.3677, batch size: 40
2021-08-24 21:28:36,619 INFO [train.py:450] Epoch 0, batch 18780, batch avg loss 0.4027, total avg loss: 0.3680, batch size: 41
2021-08-24 21:28:42,859 INFO [train.py:450] Epoch 0, batch 18790, batch avg loss 0.3158, total avg loss: 0.3678, batch size: 39
2021-08-24 21:28:48,889 INFO [train.py:450] Epoch 0, batch 18800, batch avg loss 0.4139, total avg loss: 0.3681, batch size: 41
2021-08-24 21:28:54,734 INFO [train.py:450] Epoch 0, batch 18810, batch avg loss 0.3413, total avg loss: 0.3532, batch size: 42
2021-08-24 21:29:00,837 INFO [train.py:450] Epoch 0, batch 18820, batch avg loss 0.3384, total avg loss: 0.3611, batch size: 40
2021-08-24 21:29:06,830 INFO [train.py:450] Epoch 0, batch 18830, batch avg loss 0.3708, total avg loss: 0.3579, batch size: 36
2021-08-24 21:29:12,660 INFO [train.py:450] Epoch 0, batch 18840, batch avg loss 0.3401, total avg loss: 0.3611, batch size: 39
2021-08-24 21:29:19,272 INFO [train.py:450] Epoch 0, batch 18850, batch avg loss 0.3342, total avg loss: 0.3627, batch size: 41
2021-08-24 21:29:26,108 INFO [train.py:450] Epoch 0, batch 18860, batch avg loss 0.3197, total avg loss: 0.3638, batch size: 41
2021-08-24 21:29:32,812 INFO [train.py:450] Epoch 0, batch 18870, batch avg loss 0.3812, total avg loss: 0.3637, batch size: 38
2021-08-24 21:29:41,227 INFO [train.py:450] Epoch 0, batch 18880, batch avg loss 0.3879, total avg loss: 0.3629, batch size: 41
2021-08-24 21:29:47,037 INFO [train.py:450] Epoch 0, batch 18890, batch avg loss 0.3820, total avg loss: 0.3653, batch size: 42
2021-08-24 21:29:52,808 INFO [train.py:450] Epoch 0, batch 18900, batch avg loss 0.3496, total avg loss: 0.3647, batch size: 42
2021-08-24 21:29:59,330 INFO [train.py:450] Epoch 0, batch 18910, batch avg loss 0.3988, total avg loss: 0.3648, batch size: 38
2021-08-24 21:30:05,152 INFO [train.py:450] Epoch 0, batch 18920, batch avg loss 0.4328, total avg loss: 0.3647, batch size: 39
2021-08-24 21:30:10,983 INFO [train.py:450] Epoch 0, batch 18930, batch avg loss 0.4083, total avg loss: 0.3649, batch size: 41
2021-08-24 21:30:16,849 INFO [train.py:450] Epoch 0, batch 18940, batch avg loss 0.3218, total avg loss: 0.3642, batch size: 41
2021-08-24 21:30:22,730 INFO [train.py:450] Epoch 0, batch 18950, batch avg loss 0.3140, total avg loss: 0.3633, batch size: 37
2021-08-24 21:30:28,465 INFO [train.py:450] Epoch 0, batch 18960, batch avg loss 0.3319, total avg loss: 0.3639, batch size: 37
2021-08-24 21:30:34,470 INFO [train.py:450] Epoch 0, batch 18970, batch avg loss 0.3994, total avg loss: 0.3639, batch size: 42
2021-08-24 21:30:40,338 INFO [train.py:450] Epoch 0, batch 18980, batch avg loss 0.3524, total avg loss: 0.3637, batch size: 38
2021-08-24 21:30:46,185 INFO [train.py:450] Epoch 0, batch 18990, batch avg loss 0.3545, total avg loss: 0.3634, batch size: 40
2021-08-24 21:30:51,923 INFO [train.py:450] Epoch 0, batch 19000, batch avg loss 0.3286, total avg loss: 0.3643, batch size: 38
2021-08-24 21:31:29,672 INFO [train.py:482] Epoch 0, valid loss 0.2654, best valid loss: 0.2654 best valid epoch: 0
2021-08-24 21:31:35,537 INFO [train.py:450] Epoch 0, batch 19010, batch avg loss 0.3363, total avg loss: 0.3534, batch size: 38
2021-08-24 21:31:41,662 INFO [train.py:450] Epoch 0, batch 19020, batch avg loss 0.4027, total avg loss: 0.3663, batch size: 43
2021-08-24 21:31:47,623 INFO [train.py:450] Epoch 0, batch 19030, batch avg loss 0.3880, total avg loss: 0.3691, batch size: 43
2021-08-24 21:31:53,518 INFO [train.py:450] Epoch 0, batch 19040, batch avg loss 0.3872, total avg loss: 0.3676, batch size: 39
2021-08-24 21:31:59,608 INFO [train.py:450] Epoch 0, batch 19050, batch avg loss 0.4007, total avg loss: 0.3692, batch size: 38
2021-08-24 21:32:05,384 INFO [train.py:450] Epoch 0, batch 19060, batch avg loss 0.3377, total avg loss: 0.3676, batch size: 40
2021-08-24 21:32:11,175 INFO [train.py:450] Epoch 0, batch 19070, batch avg loss 0.4185, total avg loss: 0.3684, batch size: 41
2021-08-24 21:32:17,132 INFO [train.py:450] Epoch 0, batch 19080, batch avg loss 0.3484, total avg loss: 0.3665, batch size: 41
2021-08-24 21:32:23,144 INFO [train.py:450] Epoch 0, batch 19090, batch avg loss 0.3128, total avg loss: 0.3648, batch size: 39
2021-08-24 21:32:28,957 INFO [train.py:450] Epoch 0, batch 19100, batch avg loss 0.3798, total avg loss: 0.3642, batch size: 44
2021-08-24 21:32:34,834 INFO [train.py:450] Epoch 0, batch 19110, batch avg loss 0.3646, total avg loss: 0.3649, batch size: 41
2021-08-24 21:32:40,790 INFO [train.py:450] Epoch 0, batch 19120, batch avg loss 0.3634, total avg loss: 0.3658, batch size: 41
2021-08-24 21:32:46,563 INFO [train.py:450] Epoch 0, batch 19130, batch avg loss 0.2875, total avg loss: 0.3656, batch size: 41
2021-08-24 21:32:52,386 INFO [train.py:450] Epoch 0, batch 19140, batch avg loss 0.3087, total avg loss: 0.3645, batch size: 39
2021-08-24 21:32:58,134 INFO [train.py:450] Epoch 0, batch 19150, batch avg loss 0.4346, total avg loss: 0.3651, batch size: 40
2021-08-24 21:33:03,921 INFO [train.py:450] Epoch 0, batch 19160, batch avg loss 0.3622, total avg loss: 0.3646, batch size: 39
2021-08-24 21:33:09,782 INFO [train.py:450] Epoch 0, batch 19170, batch avg loss 0.3254, total avg loss: 0.3656, batch size: 38
2021-08-24 21:33:15,833 INFO [train.py:450] Epoch 0, batch 19180, batch avg loss 0.4261, total avg loss: 0.3659, batch size: 39
2021-08-24 21:33:21,732 INFO [train.py:450] Epoch 0, batch 19190, batch avg loss 0.3673, total avg loss: 0.3655, batch size: 43
2021-08-24 21:33:27,579 INFO [train.py:450] Epoch 0, batch 19200, batch avg loss 0.3116, total avg loss: 0.3644, batch size: 41
2021-08-24 21:33:34,534 INFO [train.py:450] Epoch 0, batch 19210, batch avg loss 0.3675, total avg loss: 0.3581, batch size: 44
2021-08-24 21:33:40,575 INFO [train.py:450] Epoch 0, batch 19220, batch avg loss 0.3837, total avg loss: 0.3612, batch size: 39
2021-08-24 21:33:46,970 INFO [train.py:450] Epoch 0, batch 19230, batch avg loss 0.3658, total avg loss: 0.3690, batch size: 41
2021-08-24 21:33:54,911 INFO [train.py:450] Epoch 0, batch 19240, batch avg loss 0.3700, total avg loss: 0.3718, batch size: 42
2021-08-24 21:34:00,766 INFO [train.py:450] Epoch 0, batch 19250, batch avg loss 0.3532, total avg loss: 0.3704, batch size: 41
2021-08-24 21:34:06,731 INFO [train.py:450] Epoch 0, batch 19260, batch avg loss 0.3564, total avg loss: 0.3689, batch size: 38
2021-08-24 21:34:12,552 INFO [train.py:450] Epoch 0, batch 19270, batch avg loss 0.3472, total avg loss: 0.3692, batch size: 39
2021-08-24 21:34:18,361 INFO [train.py:450] Epoch 0, batch 19280, batch avg loss 0.3495, total avg loss: 0.3725, batch size: 37
2021-08-24 21:34:24,269 INFO [train.py:450] Epoch 0, batch 19290, batch avg loss 0.3545, total avg loss: 0.3705, batch size: 41
2021-08-24 21:34:30,120 INFO [train.py:450] Epoch 0, batch 19300, batch avg loss 0.3414, total avg loss: 0.3698, batch size: 40
2021-08-24 21:34:36,090 INFO [train.py:450] Epoch 0, batch 19310, batch avg loss 0.3655, total avg loss: 0.3689, batch size: 38
2021-08-24 21:34:41,971 INFO [train.py:450] Epoch 0, batch 19320, batch avg loss 0.3841, total avg loss: 0.3682, batch size: 38
2021-08-24 21:34:47,800 INFO [train.py:450] Epoch 0, batch 19330, batch avg loss 0.3572, total avg loss: 0.3666, batch size: 37
2021-08-24 21:34:53,807 INFO [train.py:450] Epoch 0, batch 19340, batch avg loss 0.3791, total avg loss: 0.3660, batch size: 44
2021-08-24 21:34:59,654 INFO [train.py:450] Epoch 0, batch 19350, batch avg loss 0.3551, total avg loss: 0.3661, batch size: 43
2021-08-24 21:35:05,357 INFO [train.py:450] Epoch 0, batch 19360, batch avg loss 0.3465, total avg loss: 0.3664, batch size: 40
2021-08-24 21:35:11,262 INFO [train.py:450] Epoch 0, batch 19370, batch avg loss 0.3647, total avg loss: 0.3658, batch size: 38
2021-08-24 21:35:17,104 INFO [train.py:450] Epoch 0, batch 19380, batch avg loss 0.3933, total avg loss: 0.3644, batch size: 40
2021-08-24 21:35:22,900 INFO [train.py:450] Epoch 0, batch 19390, batch avg loss 0.3731, total avg loss: 0.3638, batch size: 40
2021-08-24 21:35:28,804 INFO [train.py:450] Epoch 0, batch 19400, batch avg loss 0.3918, total avg loss: 0.3641, batch size: 39
2021-08-24 21:35:34,672 INFO [train.py:450] Epoch 0, batch 19410, batch avg loss 0.3601, total avg loss: 0.3494, batch size: 43
2021-08-24 21:35:40,581 INFO [train.py:450] Epoch 0, batch 19420, batch avg loss 0.4196, total avg loss: 0.3658, batch size: 42
2021-08-24 21:35:46,394 INFO [train.py:450] Epoch 0, batch 19430, batch avg loss 0.3618, total avg loss: 0.3636, batch size: 40
2021-08-24 21:35:52,315 INFO [train.py:450] Epoch 0, batch 19440, batch avg loss 0.3574, total avg loss: 0.3641, batch size: 44
2021-08-24 21:35:58,089 INFO [train.py:450] Epoch 0, batch 19450, batch avg loss 0.3890, total avg loss: 0.3645, batch size: 38
2021-08-24 21:36:03,899 INFO [train.py:450] Epoch 0, batch 19460, batch avg loss 0.3629, total avg loss: 0.3639, batch size: 41
2021-08-24 21:36:09,726 INFO [train.py:450] Epoch 0, batch 19470, batch avg loss 0.3635, total avg loss: 0.3623, batch size: 38
2021-08-24 21:36:15,565 INFO [train.py:450] Epoch 0, batch 19480, batch avg loss 0.3455, total avg loss: 0.3628, batch size: 37
2021-08-24 21:36:21,443 INFO [train.py:450] Epoch 0, batch 19490, batch avg loss 0.3326, total avg loss: 0.3608, batch size: 39
2021-08-24 21:36:27,436 INFO [train.py:450] Epoch 0, batch 19500, batch avg loss 0.4067, total avg loss: 0.3612, batch size: 41
2021-08-24 21:36:33,310 INFO [train.py:450] Epoch 0, batch 19510, batch avg loss 0.3214, total avg loss: 0.3608, batch size: 36
2021-08-24 21:36:39,191 INFO [train.py:450] Epoch 0, batch 19520, batch avg loss 0.3677, total avg loss: 0.3605, batch size: 41
2021-08-24 21:36:45,118 INFO [train.py:450] Epoch 0, batch 19530, batch avg loss 0.3616, total avg loss: 0.3604, batch size: 39
2021-08-24 21:36:51,003 INFO [train.py:450] Epoch 0, batch 19540, batch avg loss 0.3824, total avg loss: 0.3611, batch size: 41
2021-08-24 21:36:57,023 INFO [train.py:450] Epoch 0, batch 19550, batch avg loss 0.3764, total avg loss: 0.3622, batch size: 42
2021-08-24 21:37:02,874 INFO [train.py:450] Epoch 0, batch 19560, batch avg loss 0.3324, total avg loss: 0.3613, batch size: 39
2021-08-24 21:37:08,820 INFO [train.py:450] Epoch 0, batch 19570, batch avg loss 0.3393, total avg loss: 0.3605, batch size: 36
2021-08-24 21:37:14,599 INFO [train.py:450] Epoch 0, batch 19580, batch avg loss 0.3789, total avg loss: 0.3609, batch size: 43
2021-08-24 21:37:20,436 INFO [train.py:450] Epoch 0, batch 19590, batch avg loss 0.3836, total avg loss: 0.3614, batch size: 43
2021-08-24 21:37:26,343 INFO [train.py:450] Epoch 0, batch 19600, batch avg loss 0.3365, total avg loss: 0.3609, batch size: 38
2021-08-24 21:37:32,109 INFO [train.py:450] Epoch 0, batch 19610, batch avg loss 0.3652, total avg loss: 0.3569, batch size: 39
2021-08-24 21:37:37,942 INFO [train.py:450] Epoch 0, batch 19620, batch avg loss 0.4303, total avg loss: 0.3644, batch size: 39
2021-08-24 21:37:43,820 INFO [train.py:450] Epoch 0, batch 19630, batch avg loss 0.3381, total avg loss: 0.3663, batch size: 40
2021-08-24 21:37:49,570 INFO [train.py:450] Epoch 0, batch 19640, batch avg loss 0.3725, total avg loss: 0.3658, batch size: 37
2021-08-24 21:37:55,993 INFO [train.py:450] Epoch 0, batch 19650, batch avg loss 0.3353, total avg loss: 0.3645, batch size: 37
2021-08-24 21:38:01,910 INFO [train.py:450] Epoch 0, batch 19660, batch avg loss 0.3572, total avg loss: 0.3625, batch size: 38
2021-08-24 21:38:09,854 INFO [train.py:450] Epoch 0, batch 19670, batch avg loss 0.3195, total avg loss: 0.3613, batch size: 40
2021-08-24 21:38:15,766 INFO [train.py:450] Epoch 0, batch 19680, batch avg loss 0.3886, total avg loss: 0.3626, batch size: 41
2021-08-24 21:38:21,664 INFO [train.py:450] Epoch 0, batch 19690, batch avg loss 0.3982, total avg loss: 0.3620, batch size: 42
2021-08-24 21:38:27,558 INFO [train.py:450] Epoch 0, batch 19700, batch avg loss 0.4134, total avg loss: 0.3627, batch size: 40
2021-08-24 21:38:33,526 INFO [train.py:450] Epoch 0, batch 19710, batch avg loss 0.3510, total avg loss: 0.3628, batch size: 40
2021-08-24 21:38:39,389 INFO [train.py:450] Epoch 0, batch 19720, batch avg loss 0.3268, total avg loss: 0.3633, batch size: 41
2021-08-24 21:38:42,578 WARNING [cut.py:1694] To perform mix, energy must be non-zero and non-negative (got 0.0).  MonoCut with id "53af6353-ac9e-ea8e-728c-1a91d4298e42" will not be mixed in.
2021-08-24 21:38:45,296 INFO [train.py:450] Epoch 0, batch 19730, batch avg loss 0.4201, total avg loss: 0.3639, batch size: 40
2021-08-24 21:38:51,053 INFO [train.py:450] Epoch 0, batch 19740, batch avg loss 0.3544, total avg loss: 0.3648, batch size: 41
2021-08-24 21:38:56,862 INFO [train.py:450] Epoch 0, batch 19750, batch avg loss 0.3711, total avg loss: 0.3632, batch size: 38
2021-08-24 21:39:02,650 INFO [train.py:450] Epoch 0, batch 19760, batch avg loss 0.4082, total avg loss: 0.3622, batch size: 40
2021-08-24 21:39:08,560 INFO [train.py:450] Epoch 0, batch 19770, batch avg loss 0.3604, total avg loss: 0.3618, batch size: 40
2021-08-24 21:39:14,485 INFO [train.py:450] Epoch 0, batch 19780, batch avg loss 0.3541, total avg loss: 0.3624, batch size: 39
2021-08-24 21:39:20,353 INFO [train.py:450] Epoch 0, batch 19790, batch avg loss 0.3315, total avg loss: 0.3619, batch size: 38
2021-08-24 21:39:26,222 INFO [train.py:450] Epoch 0, batch 19800, batch avg loss 0.3766, total avg loss: 0.3612, batch size: 41
2021-08-24 21:39:32,118 INFO [train.py:450] Epoch 0, batch 19810, batch avg loss 0.3992, total avg loss: 0.3527, batch size: 41
2021-08-24 21:39:38,095 INFO [train.py:450] Epoch 0, batch 19820, batch avg loss 0.3962, total avg loss: 0.3637, batch size: 47
2021-08-24 21:39:43,845 INFO [train.py:450] Epoch 0, batch 19830, batch avg loss 0.3493, total avg loss: 0.3627, batch size: 37
2021-08-24 21:39:49,658 INFO [train.py:450] Epoch 0, batch 19840, batch avg loss 0.3067, total avg loss: 0.3610, batch size: 40
2021-08-24 21:39:55,566 INFO [train.py:450] Epoch 0, batch 19850, batch avg loss 0.3262, total avg loss: 0.3603, batch size: 37
2021-08-24 21:40:01,419 INFO [train.py:450] Epoch 0, batch 19860, batch avg loss 0.3364, total avg loss: 0.3575, batch size: 37
2021-08-24 21:40:07,354 INFO [train.py:450] Epoch 0, batch 19870, batch avg loss 0.3485, total avg loss: 0.3584, batch size: 41
2021-08-24 21:40:13,179 INFO [train.py:450] Epoch 0, batch 19880, batch avg loss 0.3117, total avg loss: 0.3568, batch size: 38
2021-08-24 21:40:19,002 INFO [train.py:450] Epoch 0, batch 19890, batch avg loss 0.3090, total avg loss: 0.3568, batch size: 39
2021-08-24 21:40:24,871 INFO [train.py:450] Epoch 0, batch 19900, batch avg loss 0.3619, total avg loss: 0.3566, batch size: 40
2021-08-24 21:40:30,775 INFO [train.py:450] Epoch 0, batch 19910, batch avg loss 0.3501, total avg loss: 0.3561, batch size: 39
2021-08-24 21:40:36,553 INFO [train.py:450] Epoch 0, batch 19920, batch avg loss 0.4755, total avg loss: 0.3586, batch size: 41
2021-08-24 21:40:42,295 WARNING [cut.py:1694] To perform mix, energy must be non-zero and non-negative (got 0.0).  MonoCut with id "fff90282-d071-f594-77f1-2c626a7e03a0" will not be mixed in.
2021-08-24 21:40:42,401 INFO [train.py:450] Epoch 0, batch 19930, batch avg loss 0.3602, total avg loss: 0.3585, batch size: 38
2021-08-24 21:40:48,236 INFO [train.py:450] Epoch 0, batch 19940, batch avg loss 0.3531, total avg loss: 0.3577, batch size: 39
2021-08-24 21:40:54,184 INFO [train.py:450] Epoch 0, batch 19950, batch avg loss 0.3658, total avg loss: 0.3581, batch size: 45
2021-08-24 21:41:00,002 INFO [train.py:450] Epoch 0, batch 19960, batch avg loss 0.4250, total avg loss: 0.3593, batch size: 40
2021-08-24 21:41:05,808 INFO [train.py:450] Epoch 0, batch 19970, batch avg loss 0.4351, total avg loss: 0.3605, batch size: 39
2021-08-24 21:41:11,641 INFO [train.py:450] Epoch 0, batch 19980, batch avg loss 0.3256, total avg loss: 0.3602, batch size: 42
2021-08-24 21:41:17,427 INFO [train.py:450] Epoch 0, batch 19990, batch avg loss 0.2722, total avg loss: 0.3590, batch size: 39
2021-08-24 21:41:23,238 INFO [train.py:450] Epoch 0, batch 20000, batch avg loss 0.3335, total avg loss: 0.3589, batch size: 42
2021-08-24 21:42:02,861 INFO [train.py:482] Epoch 0, valid loss 0.2614, best valid loss: 0.2614 best valid epoch: 0
2021-08-24 21:42:08,754 INFO [train.py:450] Epoch 0, batch 20010, batch avg loss 0.3560, total avg loss: 0.3568, batch size: 44
2021-08-24 21:42:14,553 INFO [train.py:450] Epoch 0, batch 20020, batch avg loss 0.3668, total avg loss: 0.3593, batch size: 37
2021-08-24 21:42:20,347 INFO [train.py:450] Epoch 0, batch 20030, batch avg loss 0.3721, total avg loss: 0.3646, batch size: 36
2021-08-24 21:42:26,234 INFO [train.py:450] Epoch 0, batch 20040, batch avg loss 0.3256, total avg loss: 0.3663, batch size: 41
2021-08-24 21:42:32,334 INFO [train.py:450] Epoch 0, batch 20050, batch avg loss 0.3449, total avg loss: 0.3637, batch size: 44
2021-08-24 21:42:38,313 INFO [train.py:450] Epoch 0, batch 20060, batch avg loss 0.3886, total avg loss: 0.3634, batch size: 40
2021-08-24 21:42:45,170 INFO [train.py:450] Epoch 0, batch 20070, batch avg loss 0.3876, total avg loss: 0.3644, batch size: 39
2021-08-24 21:42:52,337 INFO [train.py:450] Epoch 0, batch 20080, batch avg loss 0.4020, total avg loss: 0.3637, batch size: 41
2021-08-24 21:42:58,231 INFO [train.py:450] Epoch 0, batch 20090, batch avg loss 0.3191, total avg loss: 0.3630, batch size: 40
2021-08-24 21:43:04,210 INFO [train.py:450] Epoch 0, batch 20100, batch avg loss 0.3572, total avg loss: 0.3621, batch size: 44
2021-08-24 21:43:10,032 INFO [train.py:450] Epoch 0, batch 20110, batch avg loss 0.3254, total avg loss: 0.3633, batch size: 41
2021-08-24 21:43:15,802 INFO [train.py:450] Epoch 0, batch 20120, batch avg loss 0.3297, total avg loss: 0.3620, batch size: 39
2021-08-24 21:43:21,533 INFO [train.py:450] Epoch 0, batch 20130, batch avg loss 0.3819, total avg loss: 0.3635, batch size: 37
2021-08-24 21:43:27,390 INFO [train.py:450] Epoch 0, batch 20140, batch avg loss 0.3384, total avg loss: 0.3630, batch size: 41
2021-08-24 21:43:33,116 INFO [train.py:450] Epoch 0, batch 20150, batch avg loss 0.3798, total avg loss: 0.3624, batch size: 38
2021-08-24 21:43:38,972 INFO [train.py:450] Epoch 0, batch 20160, batch avg loss 0.4045, total avg loss: 0.3635, batch size: 41
2021-08-24 21:43:45,018 INFO [train.py:450] Epoch 0, batch 20170, batch avg loss 0.3097, total avg loss: 0.3637, batch size: 39
2021-08-24 21:43:50,877 INFO [train.py:450] Epoch 0, batch 20180, batch avg loss 0.3377, total avg loss: 0.3620, batch size: 36
2021-08-24 21:43:56,703 INFO [train.py:450] Epoch 0, batch 20190, batch avg loss 0.3601, total avg loss: 0.3616, batch size: 41
2021-08-24 21:44:02,597 INFO [train.py:450] Epoch 0, batch 20200, batch avg loss 0.3331, total avg loss: 0.3611, batch size: 42
2021-08-24 21:44:08,506 INFO [train.py:450] Epoch 0, batch 20210, batch avg loss 0.3025, total avg loss: 0.3366, batch size: 39
2021-08-24 21:44:14,346 INFO [train.py:450] Epoch 0, batch 20220, batch avg loss 0.3546, total avg loss: 0.3526, batch size: 42
2021-08-24 21:44:20,108 INFO [train.py:450] Epoch 0, batch 20230, batch avg loss 0.3276, total avg loss: 0.3582, batch size: 40
2021-08-24 21:44:25,964 INFO [train.py:450] Epoch 0, batch 20240, batch avg loss 0.3353, total avg loss: 0.3592, batch size: 43
2021-08-24 21:44:31,770 INFO [train.py:450] Epoch 0, batch 20250, batch avg loss 0.3694, total avg loss: 0.3605, batch size: 37
2021-08-24 21:44:37,599 INFO [train.py:450] Epoch 0, batch 20260, batch avg loss 0.3396, total avg loss: 0.3640, batch size: 45
2021-08-24 21:44:43,221 INFO [train.py:450] Epoch 0, batch 20270, batch avg loss 0.3329, total avg loss: 0.3622, batch size: 38
2021-08-24 21:44:48,935 INFO [train.py:450] Epoch 0, batch 20280, batch avg loss 0.2997, total avg loss: 0.3583, batch size: 36
2021-08-24 21:44:54,683 INFO [train.py:450] Epoch 0, batch 20290, batch avg loss 0.3446, total avg loss: 0.3588, batch size: 42
2021-08-24 21:45:00,434 INFO [train.py:450] Epoch 0, batch 20300, batch avg loss 0.3279, total avg loss: 0.3590, batch size: 40
2021-08-24 21:45:06,428 INFO [train.py:450] Epoch 0, batch 20310, batch avg loss 0.3842, total avg loss: 0.3606, batch size: 39
2021-08-24 21:45:12,196 INFO [train.py:450] Epoch 0, batch 20320, batch avg loss 0.3321, total avg loss: 0.3597, batch size: 39
2021-08-24 21:45:17,969 INFO [train.py:450] Epoch 0, batch 20330, batch avg loss 0.3334, total avg loss: 0.3599, batch size: 44
2021-08-24 21:45:23,669 INFO [train.py:450] Epoch 0, batch 20340, batch avg loss 0.4001, total avg loss: 0.3611, batch size: 43
2021-08-24 21:45:29,572 INFO [train.py:450] Epoch 0, batch 20350, batch avg loss 0.3545, total avg loss: 0.3620, batch size: 40
2021-08-24 21:45:35,435 INFO [train.py:450] Epoch 0, batch 20360, batch avg loss 0.3490, total avg loss: 0.3618, batch size: 43
2021-08-24 21:45:41,212 INFO [train.py:450] Epoch 0, batch 20370, batch avg loss 0.3794, total avg loss: 0.3613, batch size: 41
2021-08-24 21:45:47,158 INFO [train.py:450] Epoch 0, batch 20380, batch avg loss 0.3960, total avg loss: 0.3618, batch size: 38
2021-08-24 21:45:52,989 INFO [train.py:450] Epoch 0, batch 20390, batch avg loss 0.3980, total avg loss: 0.3615, batch size: 39
2021-08-24 21:45:58,850 INFO [train.py:450] Epoch 0, batch 20400, batch avg loss 0.3501, total avg loss: 0.3619, batch size: 41
2021-08-24 21:46:04,690 INFO [train.py:450] Epoch 0, batch 20410, batch avg loss 0.3642, total avg loss: 0.3432, batch size: 40
2021-08-24 21:46:10,439 INFO [train.py:450] Epoch 0, batch 20420, batch avg loss 0.4061, total avg loss: 0.3506, batch size: 35
2021-08-24 21:46:16,356 INFO [train.py:450] Epoch 0, batch 20430, batch avg loss 0.3904, total avg loss: 0.3493, batch size: 41
2021-08-24 21:46:22,241 INFO [train.py:450] Epoch 0, batch 20440, batch avg loss 0.3793, total avg loss: 0.3577, batch size: 38
2021-08-24 21:46:28,220 INFO [train.py:450] Epoch 0, batch 20450, batch avg loss 0.3507, total avg loss: 0.3575, batch size: 39
2021-08-24 21:46:33,946 INFO [train.py:450] Epoch 0, batch 20460, batch avg loss 0.3300, total avg loss: 0.3584, batch size: 40
2021-08-24 21:46:39,773 INFO [train.py:450] Epoch 0, batch 20470, batch avg loss 0.3628, total avg loss: 0.3601, batch size: 40
2021-08-24 21:46:45,622 INFO [train.py:450] Epoch 0, batch 20480, batch avg loss 0.3884, total avg loss: 0.3592, batch size: 41
2021-08-24 21:46:51,735 INFO [train.py:450] Epoch 0, batch 20490, batch avg loss 0.3814, total avg loss: 0.3612, batch size: 40
2021-08-24 21:46:57,660 INFO [train.py:450] Epoch 0, batch 20500, batch avg loss 0.3559, total avg loss: 0.3615, batch size: 34
2021-08-24 21:47:04,894 INFO [train.py:450] Epoch 0, batch 20510, batch avg loss 0.3387, total avg loss: 0.3617, batch size: 38
2021-08-24 21:47:11,909 INFO [train.py:450] Epoch 0, batch 20520, batch avg loss 0.3584, total avg loss: 0.3601, batch size: 43
2021-08-24 21:47:17,815 INFO [train.py:450] Epoch 0, batch 20530, batch avg loss 0.3110, total avg loss: 0.3600, batch size: 38
2021-08-24 21:47:23,634 INFO [train.py:450] Epoch 0, batch 20540, batch avg loss 0.3182, total avg loss: 0.3597, batch size: 36
2021-08-24 21:47:29,456 INFO [train.py:450] Epoch 0, batch 20550, batch avg loss 0.3431, total avg loss: 0.3603, batch size: 40
2021-08-24 21:47:35,466 INFO [train.py:450] Epoch 0, batch 20560, batch avg loss 0.3492, total avg loss: 0.3609, batch size: 39
2021-08-24 21:47:41,233 INFO [train.py:450] Epoch 0, batch 20570, batch avg loss 0.3282, total avg loss: 0.3606, batch size: 36
2021-08-24 21:47:47,127 INFO [train.py:450] Epoch 0, batch 20580, batch avg loss 0.3657, total avg loss: 0.3599, batch size: 40
2021-08-24 21:47:53,016 INFO [train.py:450] Epoch 0, batch 20590, batch avg loss 0.3684, total avg loss: 0.3601, batch size: 41
2021-08-24 21:47:58,913 INFO [train.py:450] Epoch 0, batch 20600, batch avg loss 0.3714, total avg loss: 0.3595, batch size: 44
2021-08-24 21:48:04,716 INFO [train.py:450] Epoch 0, batch 20610, batch avg loss 0.2977, total avg loss: 0.3577, batch size: 37
2021-08-24 21:48:10,592 INFO [train.py:450] Epoch 0, batch 20620, batch avg loss 0.3638, total avg loss: 0.3634, batch size: 41
2021-08-24 21:48:16,504 INFO [train.py:450] Epoch 0, batch 20630, batch avg loss 0.3753, total avg loss: 0.3585, batch size: 41
2021-08-24 21:48:22,353 INFO [train.py:450] Epoch 0, batch 20640, batch avg loss 0.4301, total avg loss: 0.3617, batch size: 36
2021-08-24 21:48:28,280 INFO [train.py:450] Epoch 0, batch 20650, batch avg loss 0.3753, total avg loss: 0.3651, batch size: 39
2021-08-24 21:48:34,204 INFO [train.py:450] Epoch 0, batch 20660, batch avg loss 0.3596, total avg loss: 0.3665, batch size: 41
2021-08-24 21:48:40,104 INFO [train.py:450] Epoch 0, batch 20670, batch avg loss 0.3491, total avg loss: 0.3665, batch size: 40
2021-08-24 21:48:45,843 INFO [train.py:450] Epoch 0, batch 20680, batch avg loss 0.3669, total avg loss: 0.3653, batch size: 41
2021-08-24 21:48:51,697 INFO [train.py:450] Epoch 0, batch 20690, batch avg loss 0.4136, total avg loss: 0.3649, batch size: 39
2021-08-24 21:48:57,389 INFO [train.py:450] Epoch 0, batch 20700, batch avg loss 0.3306, total avg loss: 0.3649, batch size: 39
2021-08-24 21:49:03,166 INFO [train.py:450] Epoch 0, batch 20710, batch avg loss 0.3577, total avg loss: 0.3653, batch size: 40
2021-08-24 21:49:08,920 INFO [train.py:450] Epoch 0, batch 20720, batch avg loss 0.3783, total avg loss: 0.3649, batch size: 40
2021-08-24 21:49:14,742 INFO [train.py:450] Epoch 0, batch 20730, batch avg loss 0.3195, total avg loss: 0.3645, batch size: 41
2021-08-24 21:49:20,513 INFO [train.py:450] Epoch 0, batch 20740, batch avg loss 0.3759, total avg loss: 0.3630, batch size: 42
2021-08-24 21:49:26,378 INFO [train.py:450] Epoch 0, batch 20750, batch avg loss 0.3421, total avg loss: 0.3633, batch size: 38
2021-08-24 21:49:32,136 INFO [train.py:450] Epoch 0, batch 20760, batch avg loss 0.3655, total avg loss: 0.3645, batch size: 40
2021-08-24 21:49:37,901 INFO [train.py:450] Epoch 0, batch 20770, batch avg loss 0.3629, total avg loss: 0.3643, batch size: 40
2021-08-24 21:49:44,008 INFO [train.py:450] Epoch 0, batch 20780, batch avg loss 0.3823, total avg loss: 0.3637, batch size: 43
2021-08-24 21:49:49,752 INFO [train.py:450] Epoch 0, batch 20790, batch avg loss 0.4042, total avg loss: 0.3640, batch size: 37
2021-08-24 21:49:55,681 INFO [train.py:450] Epoch 0, batch 20800, batch avg loss 0.3683, total avg loss: 0.3629, batch size: 38
2021-08-24 21:50:01,501 INFO [train.py:450] Epoch 0, batch 20810, batch avg loss 0.4091, total avg loss: 0.3576, batch size: 41
2021-08-24 21:50:07,337 INFO [train.py:450] Epoch 0, batch 20820, batch avg loss 0.3527, total avg loss: 0.3524, batch size: 41
2021-08-24 21:50:13,331 INFO [train.py:450] Epoch 0, batch 20830, batch avg loss 0.3356, total avg loss: 0.3561, batch size: 41
2021-08-24 21:50:19,140 INFO [train.py:450] Epoch 0, batch 20840, batch avg loss 0.3813, total avg loss: 0.3530, batch size: 41
2021-08-24 21:50:25,014 INFO [train.py:450] Epoch 0, batch 20850, batch avg loss 0.3656, total avg loss: 0.3567, batch size: 43
2021-08-24 21:50:30,817 INFO [train.py:450] Epoch 0, batch 20860, batch avg loss 0.3438, total avg loss: 0.3572, batch size: 39
2021-08-24 21:50:36,779 INFO [train.py:450] Epoch 0, batch 20870, batch avg loss 0.3638, total avg loss: 0.3581, batch size: 37
2021-08-24 21:50:42,574 INFO [train.py:450] Epoch 0, batch 20880, batch avg loss 0.3689, total avg loss: 0.3599, batch size: 36
2021-08-24 21:50:48,288 INFO [train.py:450] Epoch 0, batch 20890, batch avg loss 0.3679, total avg loss: 0.3602, batch size: 38
2021-08-24 21:50:54,131 INFO [train.py:450] Epoch 0, batch 20900, batch avg loss 0.3882, total avg loss: 0.3603, batch size: 40
2021-08-24 21:50:59,995 INFO [train.py:450] Epoch 0, batch 20910, batch avg loss 0.4188, total avg loss: 0.3598, batch size: 37
2021-08-24 21:51:05,723 INFO [train.py:450] Epoch 0, batch 20920, batch avg loss 0.3900, total avg loss: 0.3599, batch size: 40
2021-08-24 21:51:11,775 INFO [train.py:450] Epoch 0, batch 20930, batch avg loss 0.3914, total avg loss: 0.3599, batch size: 41
2021-08-24 21:51:17,634 INFO [train.py:450] Epoch 0, batch 20940, batch avg loss 0.3273, total avg loss: 0.3604, batch size: 39
2021-08-24 21:51:23,536 INFO [train.py:450] Epoch 0, batch 20950, batch avg loss 0.3843, total avg loss: 0.3604, batch size: 39
2021-08-24 21:51:29,276 INFO [train.py:450] Epoch 0, batch 20960, batch avg loss 0.3383, total avg loss: 0.3615, batch size: 36
2021-08-24 21:51:35,954 INFO [train.py:450] Epoch 0, batch 20970, batch avg loss 0.3640, total avg loss: 0.3608, batch size: 40
2021-08-24 21:51:43,408 INFO [train.py:450] Epoch 0, batch 20980, batch avg loss 0.2941, total avg loss: 0.3600, batch size: 40
2021-08-24 21:51:49,202 INFO [train.py:450] Epoch 0, batch 20990, batch avg loss 0.3681, total avg loss: 0.3601, batch size: 41
2021-08-24 21:51:55,044 INFO [train.py:450] Epoch 0, batch 21000, batch avg loss 0.3687, total avg loss: 0.3601, batch size: 40
2021-08-24 21:52:33,383 INFO [train.py:482] Epoch 0, valid loss 0.2601, best valid loss: 0.2601 best valid epoch: 0
2021-08-24 21:52:39,176 INFO [train.py:450] Epoch 0, batch 21010, batch avg loss 0.3838, total avg loss: 0.3615, batch size: 36
2021-08-24 21:52:44,980 INFO [train.py:450] Epoch 0, batch 21020, batch avg loss 0.3656, total avg loss: 0.3598, batch size: 40
2021-08-24 21:52:50,725 INFO [train.py:450] Epoch 0, batch 21030, batch avg loss 0.3979, total avg loss: 0.3677, batch size: 42
2021-08-24 21:52:56,669 INFO [train.py:450] Epoch 0, batch 21040, batch avg loss 0.4350, total avg loss: 0.3633, batch size: 39
2021-08-24 21:53:02,525 INFO [train.py:450] Epoch 0, batch 21050, batch avg loss 0.3960, total avg loss: 0.3629, batch size: 37
2021-08-24 21:53:08,354 INFO [train.py:450] Epoch 0, batch 21060, batch avg loss 0.3536, total avg loss: 0.3632, batch size: 38
2021-08-24 21:53:14,438 INFO [train.py:450] Epoch 0, batch 21070, batch avg loss 0.4180, total avg loss: 0.3617, batch size: 39
2021-08-24 21:53:20,252 INFO [train.py:450] Epoch 0, batch 21080, batch avg loss 0.3656, total avg loss: 0.3599, batch size: 41
2021-08-24 21:53:26,091 INFO [train.py:450] Epoch 0, batch 21090, batch avg loss 0.3409, total avg loss: 0.3596, batch size: 42
2021-08-24 21:53:31,987 INFO [train.py:450] Epoch 0, batch 21100, batch avg loss 0.3990, total avg loss: 0.3611, batch size: 37
2021-08-24 21:53:37,946 INFO [train.py:450] Epoch 0, batch 21110, batch avg loss 0.4022, total avg loss: 0.3620, batch size: 44
2021-08-24 21:53:53,895 INFO [train.py:450] Epoch 0, batch 21120, batch avg loss 0.3789, total avg loss: 0.3620, batch size: 37
2021-08-24 21:53:59,750 INFO [train.py:450] Epoch 0, batch 21130, batch avg loss 0.3336, total avg loss: 0.3596, batch size: 39
2021-08-24 21:54:05,620 INFO [train.py:450] Epoch 0, batch 21140, batch avg loss 0.3290, total avg loss: 0.3591, batch size: 39
2021-08-24 21:54:11,482 INFO [train.py:450] Epoch 0, batch 21150, batch avg loss 0.3903, total avg loss: 0.3586, batch size: 39
2021-08-24 21:54:17,271 INFO [train.py:450] Epoch 0, batch 21160, batch avg loss 0.3434, total avg loss: 0.3581, batch size: 37
2021-08-24 21:54:23,025 INFO [train.py:450] Epoch 0, batch 21170, batch avg loss 0.3776, total avg loss: 0.3586, batch size: 37
2021-08-24 21:54:28,839 INFO [train.py:450] Epoch 0, batch 21180, batch avg loss 0.3798, total avg loss: 0.3588, batch size: 42
2021-08-24 21:54:33,503 INFO [checkpoint.py:62] Saving checkpoint to tdnn_lstm_ctc/exp/epoch-0.pt
2021-08-24 21:54:35,059 INFO [train.py:563] epoch 1, lr: 0.001
2021-08-24 21:54:49,801 INFO [train.py:450] Epoch 1, batch 0, batch avg loss 0.3349, total avg loss: 0.3349, batch size: 38
2021-08-24 21:55:11,470 INFO [train.py:450] Epoch 1, batch 10, batch avg loss 0.4021, total avg loss: 0.3654, batch size: 42
2021-08-24 21:55:31,499 INFO [train.py:450] Epoch 1, batch 20, batch avg loss 0.3741, total avg loss: 0.3666, batch size: 38
2021-08-24 21:55:48,690 INFO [train.py:450] Epoch 1, batch 30, batch avg loss 0.3545, total avg loss: 0.3634, batch size: 39
2021-08-24 21:56:06,202 INFO [train.py:450] Epoch 1, batch 40, batch avg loss 0.3797, total avg loss: 0.3632, batch size: 38
2021-08-24 21:56:28,609 INFO [train.py:450] Epoch 1, batch 50, batch avg loss 0.3320, total avg loss: 0.3624, batch size: 39
2021-08-24 21:56:45,544 INFO [train.py:450] Epoch 1, batch 60, batch avg loss 0.3471, total avg loss: 0.3611, batch size: 44
2021-08-24 21:57:01,813 INFO [train.py:450] Epoch 1, batch 70, batch avg loss 0.3802, total avg loss: 0.3596, batch size: 39
2021-08-24 21:57:17,056 INFO [train.py:450] Epoch 1, batch 80, batch avg loss 0.3295, total avg loss: 0.3603, batch size: 42
2021-08-24 21:57:31,251 INFO [train.py:450] Epoch 1, batch 90, batch avg loss 0.4011, total avg loss: 0.3592, batch size: 40
2021-08-24 21:57:45,670 INFO [train.py:450] Epoch 1, batch 100, batch avg loss 0.3051, total avg loss: 0.3574, batch size: 36
2021-08-24 21:58:00,453 INFO [train.py:450] Epoch 1, batch 110, batch avg loss 0.4030, total avg loss: 0.3578, batch size: 40
2021-08-24 21:58:14,152 INFO [train.py:450] Epoch 1, batch 120, batch avg loss 0.3439, total avg loss: 0.3586, batch size: 40
2021-08-24 21:58:27,096 INFO [train.py:450] Epoch 1, batch 130, batch avg loss 0.3371, total avg loss: 0.3577, batch size: 37
2021-08-24 21:58:40,464 INFO [train.py:450] Epoch 1, batch 140, batch avg loss 0.3616, total avg loss: 0.3585, batch size: 41
2021-08-24 21:58:53,414 INFO [train.py:450] Epoch 1, batch 150, batch avg loss 0.3420, total avg loss: 0.3575, batch size: 42
2021-08-24 21:59:06,323 INFO [train.py:450] Epoch 1, batch 160, batch avg loss 0.3038, total avg loss: 0.3584, batch size: 41
2021-08-24 21:59:18,820 INFO [train.py:450] Epoch 1, batch 170, batch avg loss 0.3084, total avg loss: 0.3585, batch size: 42
2021-08-24 21:59:31,419 INFO [train.py:450] Epoch 1, batch 180, batch avg loss 0.3303, total avg loss: 0.3586, batch size: 41
2021-08-24 21:59:43,400 INFO [train.py:450] Epoch 1, batch 190, batch avg loss 0.2954, total avg loss: 0.3588, batch size: 36
2021-08-24 21:59:55,819 INFO [train.py:450] Epoch 1, batch 200, batch avg loss 0.3250, total avg loss: 0.3587, batch size: 42
2021-08-24 22:00:07,712 INFO [train.py:450] Epoch 1, batch 210, batch avg loss 0.3270, total avg loss: 0.3517, batch size: 38
2021-08-24 22:00:19,500 INFO [train.py:450] Epoch 1, batch 220, batch avg loss 0.3406, total avg loss: 0.3566, batch size: 44
2021-08-24 22:00:31,599 INFO [train.py:450] Epoch 1, batch 230, batch avg loss 0.3142, total avg loss: 0.3551, batch size: 39
2021-08-24 22:00:49,893 INFO [train.py:450] Epoch 1, batch 240, batch avg loss 0.3919, total avg loss: 0.3576, batch size: 39
2021-08-24 22:01:07,117 INFO [train.py:450] Epoch 1, batch 250, batch avg loss 0.3090, total avg loss: 0.3555, batch size: 37
2021-08-24 22:01:22,388 INFO [train.py:450] Epoch 1, batch 260, batch avg loss 0.3473, total avg loss: 0.3560, batch size: 35
2021-08-24 22:01:35,869 INFO [train.py:450] Epoch 1, batch 270, batch avg loss 0.3880, total avg loss: 0.3581, batch size: 41
2021-08-24 22:01:48,794 INFO [train.py:450] Epoch 1, batch 280, batch avg loss 0.3622, total avg loss: 0.3599, batch size: 41
2021-08-24 22:02:00,798 INFO [train.py:450] Epoch 1, batch 290, batch avg loss 0.3703, total avg loss: 0.3593, batch size: 42
2021-08-24 22:02:08,990 WARNING [cut.py:1694] To perform mix, energy must be non-zero and non-negative (got 0.0).  MonoCut with id "d01fc1db-2213-9dc3-2775-0e9b15c78870" will not be mixed in.
2021-08-24 22:02:11,605 INFO [train.py:450] Epoch 1, batch 300, batch avg loss 0.3874, total avg loss: 0.3595, batch size: 42
2021-08-24 22:02:22,587 INFO [train.py:450] Epoch 1, batch 310, batch avg loss 0.3265, total avg loss: 0.3589, batch size: 40
2021-08-24 22:02:33,094 INFO [train.py:450] Epoch 1, batch 320, batch avg loss 0.3442, total avg loss: 0.3596, batch size: 39
2021-08-24 22:02:43,238 INFO [train.py:450] Epoch 1, batch 330, batch avg loss 0.3423, total avg loss: 0.3599, batch size: 36
2021-08-24 22:02:53,069 INFO [train.py:450] Epoch 1, batch 340, batch avg loss 0.3529, total avg loss: 0.3594, batch size: 39
2021-08-24 22:03:04,256 INFO [train.py:450] Epoch 1, batch 350, batch avg loss 0.4524, total avg loss: 0.3601, batch size: 40
2021-08-24 22:03:14,923 INFO [train.py:450] Epoch 1, batch 360, batch avg loss 0.3479, total avg loss: 0.3599, batch size: 44
2021-08-24 22:03:25,498 INFO [train.py:450] Epoch 1, batch 370, batch avg loss 0.4223, total avg loss: 0.3607, batch size: 43
2021-08-24 22:03:35,489 INFO [train.py:450] Epoch 1, batch 380, batch avg loss 0.3339, total avg loss: 0.3604, batch size: 41
2021-08-24 22:03:45,812 INFO [train.py:450] Epoch 1, batch 390, batch avg loss 0.3759, total avg loss: 0.3605, batch size: 41
2021-08-24 22:03:56,382 INFO [train.py:450] Epoch 1, batch 400, batch avg loss 0.3427, total avg loss: 0.3604, batch size: 38
2021-08-24 22:04:05,754 INFO [train.py:450] Epoch 1, batch 410, batch avg loss 0.3674, total avg loss: 0.3498, batch size: 44
2021-08-24 22:04:15,965 INFO [train.py:450] Epoch 1, batch 420, batch avg loss 0.3388, total avg loss: 0.3654, batch size: 39
2021-08-24 22:04:26,300 INFO [train.py:450] Epoch 1, batch 430, batch avg loss 0.3565, total avg loss: 0.3664, batch size: 41
2021-08-24 22:04:36,385 INFO [train.py:450] Epoch 1, batch 440, batch avg loss 0.3446, total avg loss: 0.3611, batch size: 37
2021-08-24 22:04:46,171 INFO [train.py:450] Epoch 1, batch 450, batch avg loss 0.4361, total avg loss: 0.3640, batch size: 37
2021-08-24 22:04:56,375 INFO [train.py:450] Epoch 1, batch 460, batch avg loss 0.4097, total avg loss: 0.3636, batch size: 40
2021-08-24 22:05:06,299 INFO [train.py:450] Epoch 1, batch 470, batch avg loss 0.3501, total avg loss: 0.3625, batch size: 44
2021-08-24 22:05:17,475 INFO [train.py:450] Epoch 1, batch 480, batch avg loss 0.3615, total avg loss: 0.3600, batch size: 41
2021-08-24 22:05:29,552 INFO [train.py:450] Epoch 1, batch 490, batch avg loss 0.3358, total avg loss: 0.3601, batch size: 37
2021-08-24 22:05:38,963 INFO [train.py:450] Epoch 1, batch 500, batch avg loss 0.3790, total avg loss: 0.3617, batch size: 38
2021-08-24 22:05:48,611 INFO [train.py:450] Epoch 1, batch 510, batch avg loss 0.4015, total avg loss: 0.3616, batch size: 38
2021-08-24 22:05:58,646 INFO [train.py:450] Epoch 1, batch 520, batch avg loss 0.3600, total avg loss: 0.3637, batch size: 42
2021-08-24 22:06:08,069 INFO [train.py:450] Epoch 1, batch 530, batch avg loss 0.3481, total avg loss: 0.3625, batch size: 41
2021-08-24 22:06:17,783 INFO [train.py:450] Epoch 1, batch 540, batch avg loss 0.3312, total avg loss: 0.3622, batch size: 41
2021-08-24 22:06:26,945 INFO [train.py:450] Epoch 1, batch 550, batch avg loss 0.4095, total avg loss: 0.3632, batch size: 40
2021-08-24 22:06:36,822 INFO [train.py:450] Epoch 1, batch 560, batch avg loss 0.4011, total avg loss: 0.3626, batch size: 43
2021-08-24 22:06:46,142 INFO [train.py:450] Epoch 1, batch 570, batch avg loss 0.3610, total avg loss: 0.3618, batch size: 38
2021-08-24 22:06:55,652 INFO [train.py:450] Epoch 1, batch 580, batch avg loss 0.3508, total avg loss: 0.3614, batch size: 41
2021-08-24 22:07:05,171 INFO [train.py:450] Epoch 1, batch 590, batch avg loss 0.3651, total avg loss: 0.3606, batch size: 41
2021-08-24 22:07:14,703 INFO [train.py:450] Epoch 1, batch 600, batch avg loss 0.3908, total avg loss: 0.3598, batch size: 45
2021-08-24 22:07:24,177 INFO [train.py:450] Epoch 1, batch 610, batch avg loss 0.3522, total avg loss: 0.3482, batch size: 42
2021-08-24 22:07:33,631 INFO [train.py:450] Epoch 1, batch 620, batch avg loss 0.3495, total avg loss: 0.3562, batch size: 40
2021-08-24 22:07:42,445 INFO [train.py:450] Epoch 1, batch 630, batch avg loss 0.3969, total avg loss: 0.3548, batch size: 42
2021-08-24 22:07:51,066 INFO [train.py:450] Epoch 1, batch 640, batch avg loss 0.3565, total avg loss: 0.3621, batch size: 42
2021-08-24 22:08:00,421 INFO [train.py:450] Epoch 1, batch 650, batch avg loss 0.3551, total avg loss: 0.3612, batch size: 41
2021-08-24 22:08:09,468 INFO [train.py:450] Epoch 1, batch 660, batch avg loss 0.3885, total avg loss: 0.3601, batch size: 40
2021-08-24 22:08:18,412 INFO [train.py:450] Epoch 1, batch 670, batch avg loss 0.3061, total avg loss: 0.3570, batch size: 41
2021-08-24 22:08:27,962 INFO [train.py:450] Epoch 1, batch 680, batch avg loss 0.3614, total avg loss: 0.3568, batch size: 39
2021-08-24 22:08:37,915 INFO [train.py:450] Epoch 1, batch 690, batch avg loss 0.3717, total avg loss: 0.3561, batch size: 35
2021-08-24 22:08:47,946 INFO [train.py:450] Epoch 1, batch 700, batch avg loss 0.3390, total avg loss: 0.3549, batch size: 42
2021-08-24 22:08:58,079 INFO [train.py:450] Epoch 1, batch 710, batch avg loss 0.3480, total avg loss: 0.3545, batch size: 44
2021-08-24 22:09:08,007 INFO [train.py:450] Epoch 1, batch 720, batch avg loss 0.3952, total avg loss: 0.3546, batch size: 41
2021-08-24 22:09:18,015 INFO [train.py:450] Epoch 1, batch 730, batch avg loss 0.3492, total avg loss: 0.3550, batch size: 38
2021-08-24 22:09:27,544 INFO [train.py:450] Epoch 1, batch 740, batch avg loss 0.3347, total avg loss: 0.3549, batch size: 41
2021-08-24 22:09:37,498 INFO [train.py:450] Epoch 1, batch 750, batch avg loss 0.3858, total avg loss: 0.3549, batch size: 41
2021-08-24 22:09:46,771 INFO [train.py:450] Epoch 1, batch 760, batch avg loss 0.3280, total avg loss: 0.3555, batch size: 37
2021-08-24 22:09:57,319 INFO [train.py:450] Epoch 1, batch 770, batch avg loss 0.3319, total avg loss: 0.3555, batch size: 44
2021-08-24 22:10:09,702 INFO [train.py:450] Epoch 1, batch 780, batch avg loss 0.4039, total avg loss: 0.3557, batch size: 40
2021-08-24 22:10:19,247 INFO [train.py:450] Epoch 1, batch 790, batch avg loss 0.3520, total avg loss: 0.3550, batch size: 38
2021-08-24 22:10:28,627 INFO [train.py:450] Epoch 1, batch 800, batch avg loss 0.3579, total avg loss: 0.3552, batch size: 44
2021-08-24 22:10:37,971 INFO [train.py:450] Epoch 1, batch 810, batch avg loss 0.3381, total avg loss: 0.3438, batch size: 39
2021-08-24 22:10:47,708 INFO [train.py:450] Epoch 1, batch 820, batch avg loss 0.3270, total avg loss: 0.3518, batch size: 43
2021-08-24 22:10:57,144 INFO [train.py:450] Epoch 1, batch 830, batch avg loss 0.3703, total avg loss: 0.3528, batch size: 36
2021-08-24 22:11:06,678 INFO [train.py:450] Epoch 1, batch 840, batch avg loss 0.3378, total avg loss: 0.3509, batch size: 41
2021-08-24 22:11:16,345 INFO [train.py:450] Epoch 1, batch 850, batch avg loss 0.3333, total avg loss: 0.3518, batch size: 38
2021-08-24 22:11:25,346 INFO [train.py:450] Epoch 1, batch 860, batch avg loss 0.3023, total avg loss: 0.3510, batch size: 37
2021-08-24 22:11:34,524 INFO [train.py:450] Epoch 1, batch 870, batch avg loss 0.2970, total avg loss: 0.3492, batch size: 37
2021-08-24 22:11:44,270 INFO [train.py:450] Epoch 1, batch 880, batch avg loss 0.4115, total avg loss: 0.3492, batch size: 37
2021-08-24 22:11:53,385 INFO [train.py:450] Epoch 1, batch 890, batch avg loss 0.3599, total avg loss: 0.3506, batch size: 40
2021-08-24 22:12:02,625 INFO [train.py:450] Epoch 1, batch 900, batch avg loss 0.3558, total avg loss: 0.3514, batch size: 36
2021-08-24 22:12:11,908 INFO [train.py:450] Epoch 1, batch 910, batch avg loss 0.3132, total avg loss: 0.3527, batch size: 37
2021-08-24 22:12:20,552 INFO [train.py:450] Epoch 1, batch 920, batch avg loss 0.3727, total avg loss: 0.3520, batch size: 41
2021-08-24 22:12:29,756 INFO [train.py:450] Epoch 1, batch 930, batch avg loss 0.3675, total avg loss: 0.3523, batch size: 42
2021-08-24 22:12:39,071 INFO [train.py:450] Epoch 1, batch 940, batch avg loss 0.3443, total avg loss: 0.3520, batch size: 41
2021-08-24 22:12:48,538 INFO [train.py:450] Epoch 1, batch 950, batch avg loss 0.3503, total avg loss: 0.3525, batch size: 38
2021-08-24 22:12:58,018 INFO [train.py:450] Epoch 1, batch 960, batch avg loss 0.3186, total avg loss: 0.3528, batch size: 38
2021-08-24 22:13:07,592 INFO [train.py:450] Epoch 1, batch 970, batch avg loss 0.4074, total avg loss: 0.3534, batch size: 40
2021-08-24 22:13:16,586 INFO [train.py:450] Epoch 1, batch 980, batch avg loss 0.3396, total avg loss: 0.3563, batch size: 37
2021-08-24 22:13:25,587 INFO [train.py:450] Epoch 1, batch 990, batch avg loss 0.3555, total avg loss: 0.3564, batch size: 38
2021-08-24 22:13:34,354 INFO [train.py:450] Epoch 1, batch 1000, batch avg loss 0.3647, total avg loss: 0.3573, batch size: 37
2021-08-24 22:14:15,336 INFO [train.py:482] Epoch 1, valid loss 0.2602, best valid loss: 0.2601 best valid epoch: 0
2021-08-24 22:14:21,862 INFO [train.py:450] Epoch 1, batch 1010, batch avg loss 0.3497, total avg loss: 0.3724, batch size: 40
2021-08-24 22:14:34,345 INFO [train.py:450] Epoch 1, batch 1020, batch avg loss 0.3161, total avg loss: 0.3595, batch size: 41
2021-08-24 22:14:43,089 INFO [train.py:450] Epoch 1, batch 1030, batch avg loss 0.3644, total avg loss: 0.3605, batch size: 39
2021-08-24 22:14:52,511 INFO [train.py:450] Epoch 1, batch 1040, batch avg loss 0.3476, total avg loss: 0.3591, batch size: 37
2021-08-24 22:15:01,944 INFO [train.py:450] Epoch 1, batch 1050, batch avg loss 0.3577, total avg loss: 0.3558, batch size: 39
2021-08-24 22:15:10,822 INFO [train.py:450] Epoch 1, batch 1060, batch avg loss 0.3688, total avg loss: 0.3552, batch size: 40
2021-08-24 22:15:20,182 INFO [train.py:450] Epoch 1, batch 1070, batch avg loss 0.3693, total avg loss: 0.3559, batch size: 42
2021-08-24 22:15:29,493 INFO [train.py:450] Epoch 1, batch 1080, batch avg loss 0.3658, total avg loss: 0.3582, batch size: 40
2021-08-24 22:15:38,464 INFO [train.py:450] Epoch 1, batch 1090, batch avg loss 0.3051, total avg loss: 0.3571, batch size: 37
2021-08-24 22:15:47,574 INFO [train.py:450] Epoch 1, batch 1100, batch avg loss 0.3654, total avg loss: 0.3566, batch size: 39
2021-08-24 22:15:56,816 INFO [train.py:450] Epoch 1, batch 1110, batch avg loss 0.3507, total avg loss: 0.3563, batch size: 39
2021-08-24 22:16:05,480 INFO [train.py:450] Epoch 1, batch 1120, batch avg loss 0.3883, total avg loss: 0.3569, batch size: 38
2021-08-24 22:16:15,157 INFO [train.py:450] Epoch 1, batch 1130, batch avg loss 0.4004, total avg loss: 0.3571, batch size: 43
2021-08-24 22:16:23,711 INFO [train.py:450] Epoch 1, batch 1140, batch avg loss 0.3636, total avg loss: 0.3566, batch size: 39
2021-08-24 22:16:32,442 INFO [train.py:450] Epoch 1, batch 1150, batch avg loss 0.2917, total avg loss: 0.3562, batch size: 38
2021-08-24 22:16:41,183 INFO [train.py:450] Epoch 1, batch 1160, batch avg loss 0.4269, total avg loss: 0.3568, batch size: 40
2021-08-24 22:16:50,243 INFO [train.py:450] Epoch 1, batch 1170, batch avg loss 0.3351, total avg loss: 0.3567, batch size: 41
2021-08-24 22:16:59,390 INFO [train.py:450] Epoch 1, batch 1180, batch avg loss 0.3814, total avg loss: 0.3568, batch size: 41
2021-08-24 22:17:09,098 INFO [train.py:450] Epoch 1, batch 1190, batch avg loss 0.3062, total avg loss: 0.3572, batch size: 39
2021-08-24 22:17:18,467 INFO [train.py:450] Epoch 1, batch 1200, batch avg loss 0.3418, total avg loss: 0.3572, batch size: 40
2021-08-24 22:17:27,744 INFO [train.py:450] Epoch 1, batch 1210, batch avg loss 0.3777, total avg loss: 0.3710, batch size: 41
2021-08-24 22:17:36,626 INFO [train.py:450] Epoch 1, batch 1220, batch avg loss 0.4036, total avg loss: 0.3627, batch size: 43
2021-08-24 22:17:45,308 INFO [train.py:450] Epoch 1, batch 1230, batch avg loss 0.3304, total avg loss: 0.3586, batch size: 40
2021-08-24 22:17:54,035 INFO [train.py:450] Epoch 1, batch 1240, batch avg loss 0.3715, total avg loss: 0.3607, batch size: 41
2021-08-24 22:18:03,039 INFO [train.py:450] Epoch 1, batch 1250, batch avg loss 0.3765, total avg loss: 0.3571, batch size: 43
2021-08-24 22:18:11,492 INFO [train.py:450] Epoch 1, batch 1260, batch avg loss 0.3395, total avg loss: 0.3588, batch size: 40
2021-08-24 22:18:20,356 INFO [train.py:450] Epoch 1, batch 1270, batch avg loss 0.3757, total avg loss: 0.3580, batch size: 41
2021-08-24 22:18:29,263 INFO [train.py:450] Epoch 1, batch 1280, batch avg loss 0.3515, total avg loss: 0.3565, batch size: 41
2021-08-24 22:18:38,250 INFO [train.py:450] Epoch 1, batch 1290, batch avg loss 0.3029, total avg loss: 0.3584, batch size: 40
2021-08-24 22:18:47,045 INFO [train.py:450] Epoch 1, batch 1300, batch avg loss 0.3109, total avg loss: 0.3575, batch size: 39
2021-08-24 22:18:57,001 INFO [train.py:450] Epoch 1, batch 1310, batch avg loss 0.3657, total avg loss: 0.3584, batch size: 39
2021-08-24 22:19:08,955 INFO [train.py:450] Epoch 1, batch 1320, batch avg loss 0.3871, total avg loss: 0.3581, batch size: 39
2021-08-24 22:19:17,979 INFO [train.py:450] Epoch 1, batch 1330, batch avg loss 0.3769, total avg loss: 0.3590, batch size: 39
2021-08-24 22:19:26,629 INFO [train.py:450] Epoch 1, batch 1340, batch avg loss 0.4022, total avg loss: 0.3598, batch size: 38
2021-08-24 22:19:35,346 INFO [train.py:450] Epoch 1, batch 1350, batch avg loss 0.3409, total avg loss: 0.3585, batch size: 42
2021-08-24 22:19:44,557 INFO [train.py:450] Epoch 1, batch 1360, batch avg loss 0.3374, total avg loss: 0.3596, batch size: 38
2021-08-24 22:19:53,020 INFO [train.py:450] Epoch 1, batch 1370, batch avg loss 0.3329, total avg loss: 0.3584, batch size: 42
2021-08-24 22:20:01,850 INFO [train.py:450] Epoch 1, batch 1380, batch avg loss 0.3214, total avg loss: 0.3588, batch size: 38
2021-08-24 22:20:11,055 INFO [train.py:450] Epoch 1, batch 1390, batch avg loss 0.3488, total avg loss: 0.3590, batch size: 40
2021-08-24 22:20:20,145 INFO [train.py:450] Epoch 1, batch 1400, batch avg loss 0.3612, total avg loss: 0.3579, batch size: 40
2021-08-24 22:20:28,586 INFO [train.py:450] Epoch 1, batch 1410, batch avg loss 0.3196, total avg loss: 0.3435, batch size: 42
2021-08-24 22:20:36,950 INFO [train.py:450] Epoch 1, batch 1420, batch avg loss 0.2854, total avg loss: 0.3423, batch size: 39
2021-08-24 22:20:45,814 INFO [train.py:450] Epoch 1, batch 1430, batch avg loss 0.2983, total avg loss: 0.3452, batch size: 38
2021-08-24 22:20:54,545 INFO [train.py:450] Epoch 1, batch 1440, batch avg loss 0.3297, total avg loss: 0.3472, batch size: 39
2021-08-24 22:21:02,857 INFO [train.py:450] Epoch 1, batch 1450, batch avg loss 0.3492, total avg loss: 0.3469, batch size: 37
2021-08-24 22:21:11,986 INFO [train.py:450] Epoch 1, batch 1460, batch avg loss 0.3248, total avg loss: 0.3479, batch size: 46
2021-08-24 22:21:21,204 INFO [train.py:450] Epoch 1, batch 1470, batch avg loss 0.3305, total avg loss: 0.3493, batch size: 38
2021-08-24 22:21:29,489 INFO [train.py:450] Epoch 1, batch 1480, batch avg loss 0.3664, total avg loss: 0.3490, batch size: 39
2021-08-24 22:21:38,142 INFO [train.py:450] Epoch 1, batch 1490, batch avg loss 0.3932, total avg loss: 0.3495, batch size: 42
2021-08-24 22:21:46,367 INFO [train.py:450] Epoch 1, batch 1500, batch avg loss 0.3022, total avg loss: 0.3491, batch size: 38
2021-08-24 22:21:54,392 INFO [train.py:450] Epoch 1, batch 1510, batch avg loss 0.3886, total avg loss: 0.3515, batch size: 42
2021-08-24 22:22:02,878 INFO [train.py:450] Epoch 1, batch 1520, batch avg loss 0.3650, total avg loss: 0.3522, batch size: 39
2021-08-24 22:22:12,095 INFO [train.py:450] Epoch 1, batch 1530, batch avg loss 0.4117, total avg loss: 0.3531, batch size: 42
2021-08-24 22:22:20,593 INFO [train.py:450] Epoch 1, batch 1540, batch avg loss 0.3837, total avg loss: 0.3527, batch size: 43
2021-08-24 22:22:28,969 INFO [train.py:450] Epoch 1, batch 1550, batch avg loss 0.2817, total avg loss: 0.3525, batch size: 38
2021-08-24 22:22:37,812 INFO [train.py:450] Epoch 1, batch 1560, batch avg loss 0.4141, total avg loss: 0.3537, batch size: 45
2021-08-24 22:22:45,936 INFO [train.py:450] Epoch 1, batch 1570, batch avg loss 0.3674, total avg loss: 0.3539, batch size: 41
2021-08-24 22:22:54,357 INFO [train.py:450] Epoch 1, batch 1580, batch avg loss 0.3396, total avg loss: 0.3538, batch size: 40
2021-08-24 22:23:04,344 INFO [train.py:450] Epoch 1, batch 1590, batch avg loss 0.3893, total avg loss: 0.3539, batch size: 38
2021-08-24 22:23:13,813 INFO [train.py:450] Epoch 1, batch 1600, batch avg loss 0.3598, total avg loss: 0.3544, batch size: 39
2021-08-24 22:23:24,177 INFO [train.py:450] Epoch 1, batch 1610, batch avg loss 0.3266, total avg loss: 0.3486, batch size: 38
2021-08-24 22:23:32,657 INFO [train.py:450] Epoch 1, batch 1620, batch avg loss 0.3162, total avg loss: 0.3526, batch size: 43
2021-08-24 22:23:40,934 INFO [train.py:450] Epoch 1, batch 1630, batch avg loss 0.3323, total avg loss: 0.3523, batch size: 40
2021-08-24 22:23:48,996 INFO [train.py:450] Epoch 1, batch 1640, batch avg loss 0.2979, total avg loss: 0.3495, batch size: 37
2021-08-24 22:23:57,416 INFO [train.py:450] Epoch 1, batch 1650, batch avg loss 0.3609, total avg loss: 0.3480, batch size: 41
2021-08-24 22:24:05,944 INFO [train.py:450] Epoch 1, batch 1660, batch avg loss 0.3802, total avg loss: 0.3490, batch size: 40
2021-08-24 22:24:14,512 INFO [train.py:450] Epoch 1, batch 1670, batch avg loss 0.3095, total avg loss: 0.3507, batch size: 39
2021-08-24 22:24:22,675 INFO [train.py:450] Epoch 1, batch 1680, batch avg loss 0.3323, total avg loss: 0.3482, batch size: 39
2021-08-24 22:24:31,955 INFO [train.py:450] Epoch 1, batch 1690, batch avg loss 0.3894, total avg loss: 0.3505, batch size: 39
2021-08-24 22:24:40,321 INFO [train.py:450] Epoch 1, batch 1700, batch avg loss 0.3436, total avg loss: 0.3525, batch size: 42
2021-08-24 22:24:49,678 INFO [train.py:450] Epoch 1, batch 1710, batch avg loss 0.4088, total avg loss: 0.3524, batch size: 40
2021-08-24 22:24:58,006 INFO [train.py:450] Epoch 1, batch 1720, batch avg loss 0.3819, total avg loss: 0.3528, batch size: 41
2021-08-24 22:25:06,105 INFO [train.py:450] Epoch 1, batch 1730, batch avg loss 0.3789, total avg loss: 0.3526, batch size: 38
2021-08-24 22:25:14,400 INFO [train.py:450] Epoch 1, batch 1740, batch avg loss 0.3653, total avg loss: 0.3543, batch size: 37
2021-08-24 22:25:22,719 INFO [train.py:450] Epoch 1, batch 1750, batch avg loss 0.3914, total avg loss: 0.3548, batch size: 40
2021-08-24 22:25:31,172 INFO [train.py:450] Epoch 1, batch 1760, batch avg loss 0.3483, total avg loss: 0.3535, batch size: 40
2021-08-24 22:25:39,283 INFO [train.py:450] Epoch 1, batch 1770, batch avg loss 0.3656, total avg loss: 0.3536, batch size: 39
2021-08-24 22:25:47,472 INFO [train.py:450] Epoch 1, batch 1780, batch avg loss 0.3941, total avg loss: 0.3536, batch size: 38
2021-08-24 22:25:55,712 INFO [train.py:450] Epoch 1, batch 1790, batch avg loss 0.3898, total avg loss: 0.3536, batch size: 40
2021-08-24 22:26:03,637 INFO [train.py:450] Epoch 1, batch 1800, batch avg loss 0.3242, total avg loss: 0.3535, batch size: 40
2021-08-24 22:26:12,071 INFO [train.py:450] Epoch 1, batch 1810, batch avg loss 0.3732, total avg loss: 0.3445, batch size: 37
2021-08-24 22:26:20,544 INFO [train.py:450] Epoch 1, batch 1820, batch avg loss 0.3525, total avg loss: 0.3472, batch size: 41
2021-08-24 22:26:28,630 INFO [train.py:450] Epoch 1, batch 1830, batch avg loss 0.3186, total avg loss: 0.3446, batch size: 40
2021-08-24 22:26:36,679 INFO [train.py:450] Epoch 1, batch 1840, batch avg loss 0.3069, total avg loss: 0.3443, batch size: 38
2021-08-24 22:26:45,083 INFO [train.py:450] Epoch 1, batch 1850, batch avg loss 0.3710, total avg loss: 0.3456, batch size: 37
2021-08-24 22:26:53,309 INFO [train.py:450] Epoch 1, batch 1860, batch avg loss 0.3264, total avg loss: 0.3454, batch size: 40
2021-08-24 22:27:01,590 INFO [train.py:450] Epoch 1, batch 1870, batch avg loss 0.3383, total avg loss: 0.3461, batch size: 41
2021-08-24 22:27:09,925 INFO [train.py:450] Epoch 1, batch 1880, batch avg loss 0.3384, total avg loss: 0.3468, batch size: 38
2021-08-24 22:27:18,315 INFO [train.py:450] Epoch 1, batch 1890, batch avg loss 0.3695, total avg loss: 0.3476, batch size: 38
2021-08-24 22:27:26,600 INFO [train.py:450] Epoch 1, batch 1900, batch avg loss 0.4288, total avg loss: 0.3504, batch size: 42
2021-08-24 22:27:34,488 INFO [train.py:450] Epoch 1, batch 1910, batch avg loss 0.3423, total avg loss: 0.3507, batch size: 41
2021-08-24 22:27:42,513 INFO [train.py:450] Epoch 1, batch 1920, batch avg loss 0.3424, total avg loss: 0.3510, batch size: 43
2021-08-24 22:27:51,780 INFO [train.py:450] Epoch 1, batch 1930, batch avg loss 0.3083, total avg loss: 0.3519, batch size: 42
2021-08-24 22:27:59,266 INFO [train.py:450] Epoch 1, batch 1940, batch avg loss 0.2980, total avg loss: 0.3516, batch size: 37
2021-08-24 22:28:11,330 INFO [train.py:450] Epoch 1, batch 1950, batch avg loss 0.3827, total avg loss: 0.3511, batch size: 41
2021-08-24 22:28:19,583 INFO [train.py:450] Epoch 1, batch 1960, batch avg loss 0.3694, total avg loss: 0.3510, batch size: 39
2021-08-24 22:28:27,550 INFO [train.py:450] Epoch 1, batch 1970, batch avg loss 0.3643, total avg loss: 0.3515, batch size: 38
2021-08-24 22:28:35,263 INFO [train.py:450] Epoch 1, batch 1980, batch avg loss 0.3309, total avg loss: 0.3514, batch size: 42
2021-08-24 22:28:43,855 INFO [train.py:450] Epoch 1, batch 1990, batch avg loss 0.4057, total avg loss: 0.3519, batch size: 42
2021-08-24 22:28:51,777 INFO [train.py:450] Epoch 1, batch 2000, batch avg loss 0.3551, total avg loss: 0.3520, batch size: 38
2021-08-24 22:29:30,145 INFO [train.py:482] Epoch 1, valid loss 0.2586, best valid loss: 0.2586 best valid epoch: 1
2021-08-24 22:29:36,556 INFO [train.py:450] Epoch 1, batch 2010, batch avg loss 0.3738, total avg loss: 0.3553, batch size: 42
2021-08-24 22:29:44,569 INFO [train.py:450] Epoch 1, batch 2020, batch avg loss 0.3740, total avg loss: 0.3583, batch size: 38
2021-08-24 22:29:52,882 INFO [train.py:450] Epoch 1, batch 2030, batch avg loss 0.3750, total avg loss: 0.3582, batch size: 37
2021-08-24 22:30:01,057 INFO [train.py:450] Epoch 1, batch 2040, batch avg loss 0.3548, total avg loss: 0.3592, batch size: 43
2021-08-24 22:30:08,960 INFO [train.py:450] Epoch 1, batch 2050, batch avg loss 0.3097, total avg loss: 0.3557, batch size: 40
2021-08-24 22:30:16,905 INFO [train.py:450] Epoch 1, batch 2060, batch avg loss 0.3824, total avg loss: 0.3549, batch size: 41
2021-08-24 22:30:24,856 INFO [train.py:450] Epoch 1, batch 2070, batch avg loss 0.3954, total avg loss: 0.3561, batch size: 38
2021-08-24 22:30:32,715 INFO [train.py:450] Epoch 1, batch 2080, batch avg loss 0.4109, total avg loss: 0.3552, batch size: 40
2021-08-24 22:30:40,428 INFO [train.py:450] Epoch 1, batch 2090, batch avg loss 0.3521, total avg loss: 0.3552, batch size: 38
2021-08-24 22:30:48,580 INFO [train.py:450] Epoch 1, batch 2100, batch avg loss 0.3737, total avg loss: 0.3556, batch size: 39
2021-08-24 22:30:56,591 INFO [train.py:450] Epoch 1, batch 2110, batch avg loss 0.3307, total avg loss: 0.3564, batch size: 37
2021-08-24 22:31:04,618 INFO [train.py:450] Epoch 1, batch 2120, batch avg loss 0.3819, total avg loss: 0.3572, batch size: 36
2021-08-24 22:31:12,719 INFO [train.py:450] Epoch 1, batch 2130, batch avg loss 0.3958, total avg loss: 0.3584, batch size: 37
2021-08-24 22:31:20,740 INFO [train.py:450] Epoch 1, batch 2140, batch avg loss 0.3849, total avg loss: 0.3583, batch size: 39
2021-08-24 22:31:28,853 INFO [train.py:450] Epoch 1, batch 2150, batch avg loss 0.3967, total avg loss: 0.3581, batch size: 37
2021-08-24 22:31:36,952 INFO [train.py:450] Epoch 1, batch 2160, batch avg loss 0.3296, total avg loss: 0.3585, batch size: 39
2021-08-24 22:31:44,674 INFO [train.py:450] Epoch 1, batch 2170, batch avg loss 0.2845, total avg loss: 0.3576, batch size: 38
2021-08-24 22:31:52,118 INFO [train.py:450] Epoch 1, batch 2180, batch avg loss 0.3645, total avg loss: 0.3575, batch size: 38
2021-08-24 22:31:59,803 INFO [train.py:450] Epoch 1, batch 2190, batch avg loss 0.3420, total avg loss: 0.3573, batch size: 39
2021-08-24 22:32:07,541 INFO [train.py:450] Epoch 1, batch 2200, batch avg loss 0.3330, total avg loss: 0.3566, batch size: 41
2021-08-24 22:32:15,596 INFO [train.py:450] Epoch 1, batch 2210, batch avg loss 0.3097, total avg loss: 0.3494, batch size: 39
2021-08-24 22:32:28,181 INFO [train.py:450] Epoch 1, batch 2220, batch avg loss 0.3866, total avg loss: 0.3603, batch size: 37
2021-08-24 22:32:35,712 INFO [train.py:450] Epoch 1, batch 2230, batch avg loss 0.3519, total avg loss: 0.3584, batch size: 42
2021-08-24 22:32:43,147 INFO [train.py:450] Epoch 1, batch 2240, batch avg loss 0.3469, total avg loss: 0.3600, batch size: 40
2021-08-24 22:32:50,518 INFO [train.py:450] Epoch 1, batch 2250, batch avg loss 0.3479, total avg loss: 0.3587, batch size: 41
2021-08-24 22:32:58,548 INFO [train.py:450] Epoch 1, batch 2260, batch avg loss 0.3917, total avg loss: 0.3590, batch size: 38
2021-08-24 22:33:06,651 INFO [train.py:450] Epoch 1, batch 2270, batch avg loss 0.3746, total avg loss: 0.3594, batch size: 39
2021-08-24 22:33:14,598 INFO [train.py:450] Epoch 1, batch 2280, batch avg loss 0.3663, total avg loss: 0.3597, batch size: 41
2021-08-24 22:33:22,405 INFO [train.py:450] Epoch 1, batch 2290, batch avg loss 0.3197, total avg loss: 0.3568, batch size: 39
2021-08-24 22:33:30,058 INFO [train.py:450] Epoch 1, batch 2300, batch avg loss 0.3413, total avg loss: 0.3555, batch size: 37
2021-08-24 22:33:38,198 INFO [train.py:450] Epoch 1, batch 2310, batch avg loss 0.3449, total avg loss: 0.3567, batch size: 39
2021-08-24 22:33:46,463 INFO [train.py:450] Epoch 1, batch 2320, batch avg loss 0.3211, total avg loss: 0.3555, batch size: 39
2021-08-24 22:33:54,392 INFO [train.py:450] Epoch 1, batch 2330, batch avg loss 0.3770, total avg loss: 0.3552, batch size: 42
2021-08-24 22:34:02,898 INFO [train.py:450] Epoch 1, batch 2340, batch avg loss 0.4099, total avg loss: 0.3564, batch size: 43
2021-08-24 22:34:10,955 INFO [train.py:450] Epoch 1, batch 2350, batch avg loss 0.3765, total avg loss: 0.3569, batch size: 35
2021-08-24 22:34:18,974 INFO [train.py:450] Epoch 1, batch 2360, batch avg loss 0.3725, total avg loss: 0.3567, batch size: 42
2021-08-24 22:34:26,835 INFO [train.py:450] Epoch 1, batch 2370, batch avg loss 0.3637, total avg loss: 0.3579, batch size: 40
2021-08-24 22:34:34,617 INFO [train.py:450] Epoch 1, batch 2380, batch avg loss 0.3823, total avg loss: 0.3581, batch size: 37
2021-08-24 22:34:41,997 INFO [train.py:450] Epoch 1, batch 2390, batch avg loss 0.3459, total avg loss: 0.3574, batch size: 37
2021-08-24 22:34:49,522 INFO [train.py:450] Epoch 1, batch 2400, batch avg loss 0.3998, total avg loss: 0.3585, batch size: 42
2021-08-24 22:34:57,234 INFO [train.py:450] Epoch 1, batch 2410, batch avg loss 0.3593, total avg loss: 0.3436, batch size: 37
2021-08-24 22:35:04,703 INFO [train.py:450] Epoch 1, batch 2420, batch avg loss 0.4135, total avg loss: 0.3558, batch size: 44
2021-08-24 22:35:12,412 INFO [train.py:450] Epoch 1, batch 2430, batch avg loss 0.3072, total avg loss: 0.3550, batch size: 37
2021-08-24 22:35:20,076 INFO [train.py:450] Epoch 1, batch 2440, batch avg loss 0.3404, total avg loss: 0.3558, batch size: 40
2021-08-24 22:35:27,846 INFO [train.py:450] Epoch 1, batch 2450, batch avg loss 0.3523, total avg loss: 0.3554, batch size: 39
2021-08-24 22:35:35,376 INFO [train.py:450] Epoch 1, batch 2460, batch avg loss 0.3632, total avg loss: 0.3549, batch size: 40
2021-08-24 22:35:43,494 INFO [train.py:450] Epoch 1, batch 2470, batch avg loss 0.3589, total avg loss: 0.3576, batch size: 42
2021-08-24 22:35:51,743 INFO [train.py:450] Epoch 1, batch 2480, batch avg loss 0.3682, total avg loss: 0.3589, batch size: 40
2021-08-24 22:35:59,835 INFO [train.py:450] Epoch 1, batch 2490, batch avg loss 0.3592, total avg loss: 0.3585, batch size: 40
2021-08-24 22:36:07,626 INFO [train.py:450] Epoch 1, batch 2500, batch avg loss 0.3372, total avg loss: 0.3589, batch size: 38
2021-08-24 22:36:16,730 INFO [train.py:450] Epoch 1, batch 2510, batch avg loss 0.3328, total avg loss: 0.3590, batch size: 40
2021-08-24 22:36:24,712 INFO [train.py:450] Epoch 1, batch 2520, batch avg loss 0.3416, total avg loss: 0.3590, batch size: 39
2021-08-24 22:36:35,027 INFO [train.py:450] Epoch 1, batch 2530, batch avg loss 0.3741, total avg loss: 0.3592, batch size: 39
2021-08-24 22:36:42,750 INFO [train.py:450] Epoch 1, batch 2540, batch avg loss 0.3384, total avg loss: 0.3575, batch size: 42
2021-08-24 22:36:50,705 INFO [train.py:450] Epoch 1, batch 2550, batch avg loss 0.3784, total avg loss: 0.3584, batch size: 40
2021-08-24 22:36:58,795 INFO [train.py:450] Epoch 1, batch 2560, batch avg loss 0.3694, total avg loss: 0.3586, batch size: 37
2021-08-24 22:37:06,468 INFO [train.py:450] Epoch 1, batch 2570, batch avg loss 0.3537, total avg loss: 0.3581, batch size: 39
2021-08-24 22:37:13,883 INFO [train.py:450] Epoch 1, batch 2580, batch avg loss 0.3738, total avg loss: 0.3581, batch size: 40
2021-08-24 22:37:21,458 INFO [train.py:450] Epoch 1, batch 2590, batch avg loss 0.3742, total avg loss: 0.3580, batch size: 37
2021-08-24 22:37:29,439 INFO [train.py:450] Epoch 1, batch 2600, batch avg loss 0.3820, total avg loss: 0.3572, batch size: 41
2021-08-24 22:37:37,098 INFO [train.py:450] Epoch 1, batch 2610, batch avg loss 0.3408, total avg loss: 0.3755, batch size: 42
2021-08-24 22:37:44,766 INFO [train.py:450] Epoch 1, batch 2620, batch avg loss 0.3515, total avg loss: 0.3626, batch size: 41
2021-08-24 22:37:52,576 INFO [train.py:450] Epoch 1, batch 2630, batch avg loss 0.4280, total avg loss: 0.3617, batch size: 42
2021-08-24 22:38:00,868 INFO [train.py:450] Epoch 1, batch 2640, batch avg loss 0.4055, total avg loss: 0.3642, batch size: 40
2021-08-24 22:38:08,838 INFO [train.py:450] Epoch 1, batch 2650, batch avg loss 0.3773, total avg loss: 0.3646, batch size: 37
2021-08-24 22:38:16,728 INFO [train.py:450] Epoch 1, batch 2660, batch avg loss 0.3215, total avg loss: 0.3608, batch size: 39
2021-08-24 22:38:24,834 INFO [train.py:450] Epoch 1, batch 2670, batch avg loss 0.3127, total avg loss: 0.3606, batch size: 40
2021-08-24 22:38:33,386 INFO [train.py:450] Epoch 1, batch 2680, batch avg loss 0.3850, total avg loss: 0.3593, batch size: 44
2021-08-24 22:38:40,856 INFO [train.py:450] Epoch 1, batch 2690, batch avg loss 0.3634, total avg loss: 0.3580, batch size: 37
2021-08-24 22:38:48,893 INFO [train.py:450] Epoch 1, batch 2700, batch avg loss 0.3382, total avg loss: 0.3590, batch size: 40
2021-08-24 22:38:56,516 INFO [train.py:450] Epoch 1, batch 2710, batch avg loss 0.3671, total avg loss: 0.3587, batch size: 41
2021-08-24 22:39:04,510 INFO [train.py:450] Epoch 1, batch 2720, batch avg loss 0.3286, total avg loss: 0.3605, batch size: 41
2021-08-24 22:39:12,582 INFO [train.py:450] Epoch 1, batch 2730, batch avg loss 0.3514, total avg loss: 0.3613, batch size: 42
2021-08-24 22:39:20,242 INFO [train.py:450] Epoch 1, batch 2740, batch avg loss 0.3585, total avg loss: 0.3609, batch size: 39
2021-08-24 22:39:28,342 INFO [train.py:450] Epoch 1, batch 2750, batch avg loss 0.4031, total avg loss: 0.3616, batch size: 40
2021-08-24 22:39:36,112 INFO [train.py:450] Epoch 1, batch 2760, batch avg loss 0.3867, total avg loss: 0.3615, batch size: 39
2021-08-24 22:39:44,154 INFO [train.py:450] Epoch 1, batch 2770, batch avg loss 0.3304, total avg loss: 0.3615, batch size: 41
2021-08-24 22:39:52,234 INFO [train.py:450] Epoch 1, batch 2780, batch avg loss 0.3000, total avg loss: 0.3616, batch size: 41
2021-08-24 22:39:59,981 INFO [train.py:450] Epoch 1, batch 2790, batch avg loss 0.3625, total avg loss: 0.3608, batch size: 42
2021-08-24 22:40:08,547 INFO [train.py:450] Epoch 1, batch 2800, batch avg loss 0.3167, total avg loss: 0.3602, batch size: 37
2021-08-24 22:40:16,237 INFO [train.py:450] Epoch 1, batch 2810, batch avg loss 0.3558, total avg loss: 0.3447, batch size: 41
2021-08-24 22:40:26,533 INFO [train.py:450] Epoch 1, batch 2820, batch avg loss 0.3333, total avg loss: 0.3445, batch size: 37
2021-08-24 22:40:34,108 INFO [train.py:450] Epoch 1, batch 2830, batch avg loss 0.3334, total avg loss: 0.3472, batch size: 39
2021-08-24 22:40:41,847 INFO [train.py:450] Epoch 1, batch 2840, batch avg loss 0.3190, total avg loss: 0.3500, batch size: 42
2021-08-24 22:40:49,194 INFO [train.py:450] Epoch 1, batch 2850, batch avg loss 0.3266, total avg loss: 0.3519, batch size: 40
2021-08-24 22:40:56,994 INFO [train.py:450] Epoch 1, batch 2860, batch avg loss 0.3748, total avg loss: 0.3538, batch size: 41
2021-08-24 22:41:04,422 INFO [train.py:450] Epoch 1, batch 2870, batch avg loss 0.3071, total avg loss: 0.3560, batch size: 40
2021-08-24 22:41:11,738 INFO [train.py:450] Epoch 1, batch 2880, batch avg loss 0.3257, total avg loss: 0.3536, batch size: 45
2021-08-24 22:41:19,429 INFO [train.py:450] Epoch 1, batch 2890, batch avg loss 0.3619, total avg loss: 0.3538, batch size: 38
2021-08-24 22:41:27,307 INFO [train.py:450] Epoch 1, batch 2900, batch avg loss 0.3213, total avg loss: 0.3541, batch size: 40
2021-08-24 22:41:35,354 INFO [train.py:450] Epoch 1, batch 2910, batch avg loss 0.2928, total avg loss: 0.3537, batch size: 42
2021-08-24 22:41:43,244 INFO [train.py:450] Epoch 1, batch 2920, batch avg loss 0.3371, total avg loss: 0.3549, batch size: 43
2021-08-24 22:41:50,685 INFO [train.py:450] Epoch 1, batch 2930, batch avg loss 0.3069, total avg loss: 0.3540, batch size: 40
2021-08-24 22:41:58,677 INFO [train.py:450] Epoch 1, batch 2940, batch avg loss 0.3878, total avg loss: 0.3538, batch size: 39
2021-08-24 22:42:06,539 INFO [train.py:450] Epoch 1, batch 2950, batch avg loss 0.4043, total avg loss: 0.3551, batch size: 41
2021-08-24 22:42:14,019 INFO [train.py:450] Epoch 1, batch 2960, batch avg loss 0.3566, total avg loss: 0.3559, batch size: 38
2021-08-24 22:42:21,476 INFO [train.py:450] Epoch 1, batch 2970, batch avg loss 0.3689, total avg loss: 0.3572, batch size: 40
2021-08-24 22:42:28,384 INFO [train.py:450] Epoch 1, batch 2980, batch avg loss 0.3805, total avg loss: 0.3567, batch size: 41
2021-08-24 22:42:35,619 INFO [train.py:450] Epoch 1, batch 2990, batch avg loss 0.4048, total avg loss: 0.3560, batch size: 38
2021-08-24 22:42:43,111 INFO [train.py:450] Epoch 1, batch 3000, batch avg loss 0.3167, total avg loss: 0.3557, batch size: 36
2021-08-24 22:43:20,560 INFO [train.py:482] Epoch 1, valid loss 0.2575, best valid loss: 0.2575 best valid epoch: 1
2021-08-24 22:43:26,407 INFO [train.py:450] Epoch 1, batch 3010, batch avg loss 0.4178, total avg loss: 0.3568, batch size: 39
2021-08-24 22:43:33,768 INFO [train.py:450] Epoch 1, batch 3020, batch avg loss 0.3529, total avg loss: 0.3523, batch size: 37
2021-08-24 22:43:40,528 INFO [train.py:450] Epoch 1, batch 3030, batch avg loss 0.3386, total avg loss: 0.3553, batch size: 38
2021-08-24 22:43:47,745 INFO [train.py:450] Epoch 1, batch 3040, batch avg loss 0.3455, total avg loss: 0.3527, batch size: 38
2021-08-24 22:43:54,929 INFO [train.py:450] Epoch 1, batch 3050, batch avg loss 0.3379, total avg loss: 0.3535, batch size: 39
2021-08-24 22:44:03,820 INFO [train.py:450] Epoch 1, batch 3060, batch avg loss 0.4008, total avg loss: 0.3541, batch size: 39
2021-08-24 22:44:10,700 INFO [train.py:450] Epoch 1, batch 3070, batch avg loss 0.3592, total avg loss: 0.3562, batch size: 42
2021-08-24 22:44:20,398 INFO [train.py:450] Epoch 1, batch 3080, batch avg loss 0.3659, total avg loss: 0.3540, batch size: 38
2021-08-24 22:44:27,669 INFO [train.py:450] Epoch 1, batch 3090, batch avg loss 0.3830, total avg loss: 0.3536, batch size: 40
2021-08-24 22:44:35,114 INFO [train.py:450] Epoch 1, batch 3100, batch avg loss 0.3525, total avg loss: 0.3535, batch size: 41
2021-08-24 22:44:43,063 INFO [train.py:450] Epoch 1, batch 3110, batch avg loss 0.3609, total avg loss: 0.3536, batch size: 41
2021-08-24 22:44:50,890 INFO [train.py:450] Epoch 1, batch 3120, batch avg loss 0.3554, total avg loss: 0.3554, batch size: 41
2021-08-24 22:44:58,575 INFO [train.py:450] Epoch 1, batch 3130, batch avg loss 0.3877, total avg loss: 0.3548, batch size: 40
2021-08-24 22:45:06,254 INFO [train.py:450] Epoch 1, batch 3140, batch avg loss 0.3423, total avg loss: 0.3556, batch size: 37
2021-08-24 22:45:13,534 INFO [train.py:450] Epoch 1, batch 3150, batch avg loss 0.3984, total avg loss: 0.3563, batch size: 41
2021-08-24 22:45:20,615 INFO [train.py:450] Epoch 1, batch 3160, batch avg loss 0.3109, total avg loss: 0.3554, batch size: 36
2021-08-24 22:45:28,114 INFO [train.py:450] Epoch 1, batch 3170, batch avg loss 0.3263, total avg loss: 0.3555, batch size: 42
2021-08-24 22:45:35,640 INFO [train.py:450] Epoch 1, batch 3180, batch avg loss 0.3766, total avg loss: 0.3554, batch size: 40
2021-08-24 22:45:42,402 INFO [train.py:450] Epoch 1, batch 3190, batch avg loss 0.3371, total avg loss: 0.3544, batch size: 39
2021-08-24 22:45:49,705 INFO [train.py:450] Epoch 1, batch 3200, batch avg loss 0.3458, total avg loss: 0.3542, batch size: 40
2021-08-24 22:45:56,429 INFO [train.py:450] Epoch 1, batch 3210, batch avg loss 0.2991, total avg loss: 0.3444, batch size: 35
2021-08-24 22:46:03,593 INFO [train.py:450] Epoch 1, batch 3220, batch avg loss 0.4360, total avg loss: 0.3583, batch size: 40
2021-08-24 22:46:11,215 INFO [train.py:450] Epoch 1, batch 3230, batch avg loss 0.3866, total avg loss: 0.3654, batch size: 36
2021-08-24 22:46:17,918 INFO [train.py:450] Epoch 1, batch 3240, batch avg loss 0.3425, total avg loss: 0.3580, batch size: 40
2021-08-24 22:46:25,542 INFO [train.py:450] Epoch 1, batch 3250, batch avg loss 0.3661, total avg loss: 0.3558, batch size: 40
2021-08-24 22:46:32,425 INFO [train.py:450] Epoch 1, batch 3260, batch avg loss 0.3887, total avg loss: 0.3556, batch size: 39
2021-08-24 22:46:39,856 INFO [train.py:450] Epoch 1, batch 3270, batch avg loss 0.3301, total avg loss: 0.3580, batch size: 41
2021-08-24 22:46:46,989 INFO [train.py:450] Epoch 1, batch 3280, batch avg loss 0.3388, total avg loss: 0.3578, batch size: 38
2021-08-24 22:46:54,416 INFO [train.py:450] Epoch 1, batch 3290, batch avg loss 0.4143, total avg loss: 0.3578, batch size: 40
2021-08-24 22:47:01,437 INFO [train.py:450] Epoch 1, batch 3300, batch avg loss 0.3243, total avg loss: 0.3575, batch size: 40
2021-08-24 22:47:08,814 INFO [train.py:450] Epoch 1, batch 3310, batch avg loss 0.3373, total avg loss: 0.3577, batch size: 37
2021-08-24 22:47:15,699 INFO [train.py:450] Epoch 1, batch 3320, batch avg loss 0.3658, total avg loss: 0.3568, batch size: 39
2021-08-24 22:47:22,683 INFO [train.py:450] Epoch 1, batch 3330, batch avg loss 0.3744, total avg loss: 0.3579, batch size: 40
2021-08-24 22:47:29,714 INFO [train.py:450] Epoch 1, batch 3340, batch avg loss 0.3036, total avg loss: 0.3583, batch size: 39
2021-08-24 22:47:36,551 INFO [train.py:450] Epoch 1, batch 3350, batch avg loss 0.3678, total avg loss: 0.3576, batch size: 40
2021-08-24 22:47:43,917 INFO [train.py:450] Epoch 1, batch 3360, batch avg loss 0.3687, total avg loss: 0.3579, batch size: 43
2021-08-24 22:47:51,530 INFO [train.py:450] Epoch 1, batch 3370, batch avg loss 0.3415, total avg loss: 0.3571, batch size: 42
2021-08-24 22:47:58,538 INFO [train.py:450] Epoch 1, batch 3380, batch avg loss 0.3378, total avg loss: 0.3571, batch size: 42
2021-08-24 22:48:05,663 INFO [train.py:450] Epoch 1, batch 3390, batch avg loss 0.3966, total avg loss: 0.3578, batch size: 35
2021-08-24 22:48:12,865 INFO [train.py:450] Epoch 1, batch 3400, batch avg loss 0.3535, total avg loss: 0.3576, batch size: 43
2021-08-24 22:48:21,291 INFO [train.py:450] Epoch 1, batch 3410, batch avg loss 0.3703, total avg loss: 0.3548, batch size: 40
2021-08-24 22:48:27,719 INFO [train.py:450] Epoch 1, batch 3420, batch avg loss 0.3920, total avg loss: 0.3616, batch size: 42
2021-08-24 22:48:36,140 INFO [train.py:450] Epoch 1, batch 3430, batch avg loss 0.3632, total avg loss: 0.3608, batch size: 38
2021-08-24 22:48:43,456 INFO [train.py:450] Epoch 1, batch 3440, batch avg loss 0.3391, total avg loss: 0.3584, batch size: 39
2021-08-24 22:48:50,616 INFO [train.py:450] Epoch 1, batch 3450, batch avg loss 0.3429, total avg loss: 0.3535, batch size: 43
2021-08-24 22:48:58,065 INFO [train.py:450] Epoch 1, batch 3460, batch avg loss 0.3985, total avg loss: 0.3572, batch size: 36
2021-08-24 22:49:04,933 INFO [train.py:450] Epoch 1, batch 3470, batch avg loss 0.3828, total avg loss: 0.3557, batch size: 39
2021-08-24 22:49:12,127 INFO [train.py:450] Epoch 1, batch 3480, batch avg loss 0.3766, total avg loss: 0.3557, batch size: 40
2021-08-24 22:49:18,719 INFO [train.py:450] Epoch 1, batch 3490, batch avg loss 0.3767, total avg loss: 0.3559, batch size: 39
2021-08-24 22:49:25,844 INFO [train.py:450] Epoch 1, batch 3500, batch avg loss 0.3758, total avg loss: 0.3554, batch size: 38
2021-08-24 22:49:32,562 INFO [train.py:450] Epoch 1, batch 3510, batch avg loss 0.3332, total avg loss: 0.3549, batch size: 42
2021-08-24 22:49:39,503 INFO [train.py:450] Epoch 1, batch 3520, batch avg loss 0.4419, total avg loss: 0.3557, batch size: 40
2021-08-24 22:49:46,185 INFO [train.py:450] Epoch 1, batch 3530, batch avg loss 0.3882, total avg loss: 0.3551, batch size: 44
2021-08-24 22:49:53,167 INFO [train.py:450] Epoch 1, batch 3540, batch avg loss 0.3361, total avg loss: 0.3549, batch size: 39
2021-08-24 22:50:00,011 INFO [train.py:450] Epoch 1, batch 3550, batch avg loss 0.4120, total avg loss: 0.3552, batch size: 42
2021-08-24 22:50:07,182 INFO [train.py:450] Epoch 1, batch 3560, batch avg loss 0.2798, total avg loss: 0.3543, batch size: 40
2021-08-24 22:50:13,910 INFO [train.py:450] Epoch 1, batch 3570, batch avg loss 0.3349, total avg loss: 0.3542, batch size: 43
2021-08-24 22:50:20,782 INFO [train.py:450] Epoch 1, batch 3580, batch avg loss 0.2737, total avg loss: 0.3536, batch size: 39
2021-08-24 22:50:27,605 INFO [train.py:450] Epoch 1, batch 3590, batch avg loss 0.3347, total avg loss: 0.3528, batch size: 38
2021-08-24 22:50:34,000 INFO [train.py:450] Epoch 1, batch 3600, batch avg loss 0.3609, total avg loss: 0.3532, batch size: 42
2021-08-24 22:50:40,936 INFO [train.py:450] Epoch 1, batch 3610, batch avg loss 0.2972, total avg loss: 0.3548, batch size: 43
2021-08-24 22:50:47,668 INFO [train.py:450] Epoch 1, batch 3620, batch avg loss 0.3469, total avg loss: 0.3677, batch size: 39
2021-08-24 22:50:54,664 INFO [train.py:450] Epoch 1, batch 3630, batch avg loss 0.3839, total avg loss: 0.3644, batch size: 43
2021-08-24 22:51:01,510 INFO [train.py:450] Epoch 1, batch 3640, batch avg loss 0.3921, total avg loss: 0.3625, batch size: 40
2021-08-24 22:51:08,044 INFO [train.py:450] Epoch 1, batch 3650, batch avg loss 0.3541, total avg loss: 0.3637, batch size: 39
2021-08-24 22:51:14,630 INFO [train.py:450] Epoch 1, batch 3660, batch avg loss 0.3499, total avg loss: 0.3595, batch size: 46
2021-08-24 22:51:21,551 INFO [train.py:450] Epoch 1, batch 3670, batch avg loss 0.3194, total avg loss: 0.3574, batch size: 39
2021-08-24 22:51:27,893 INFO [train.py:450] Epoch 1, batch 3680, batch avg loss 0.3338, total avg loss: 0.3559, batch size: 40
2021-08-24 22:51:34,252 INFO [train.py:450] Epoch 1, batch 3690, batch avg loss 0.3083, total avg loss: 0.3544, batch size: 37
2021-08-24 22:51:41,072 INFO [train.py:450] Epoch 1, batch 3700, batch avg loss 0.3841, total avg loss: 0.3537, batch size: 42
2021-08-24 22:51:47,728 INFO [train.py:450] Epoch 1, batch 3710, batch avg loss 0.3316, total avg loss: 0.3542, batch size: 40
2021-08-24 22:51:55,838 INFO [train.py:450] Epoch 1, batch 3720, batch avg loss 0.3420, total avg loss: 0.3543, batch size: 41
2021-08-24 22:52:03,128 INFO [train.py:450] Epoch 1, batch 3730, batch avg loss 0.3603, total avg loss: 0.3544, batch size: 43
2021-08-24 22:52:13,219 INFO [train.py:450] Epoch 1, batch 3740, batch avg loss 0.3242, total avg loss: 0.3541, batch size: 43
2021-08-24 22:52:19,911 INFO [train.py:450] Epoch 1, batch 3750, batch avg loss 0.3722, total avg loss: 0.3544, batch size: 40
2021-08-24 22:52:26,983 INFO [train.py:450] Epoch 1, batch 3760, batch avg loss 0.4207, total avg loss: 0.3554, batch size: 39
2021-08-24 22:52:33,620 INFO [train.py:450] Epoch 1, batch 3770, batch avg loss 0.3876, total avg loss: 0.3561, batch size: 38
2021-08-24 22:52:40,731 INFO [train.py:450] Epoch 1, batch 3780, batch avg loss 0.3330, total avg loss: 0.3565, batch size: 40
2021-08-24 22:52:47,372 INFO [train.py:450] Epoch 1, batch 3790, batch avg loss 0.3359, total avg loss: 0.3566, batch size: 39
2021-08-24 22:52:53,894 INFO [train.py:450] Epoch 1, batch 3800, batch avg loss 0.3856, total avg loss: 0.3568, batch size: 45
2021-08-24 22:53:00,446 INFO [train.py:450] Epoch 1, batch 3810, batch avg loss 0.3890, total avg loss: 0.3596, batch size: 39
2021-08-24 22:53:06,966 INFO [train.py:450] Epoch 1, batch 3820, batch avg loss 0.3800, total avg loss: 0.3524, batch size: 38
2021-08-24 22:53:13,201 INFO [train.py:450] Epoch 1, batch 3830, batch avg loss 0.3200, total avg loss: 0.3523, batch size: 36
2021-08-24 22:53:19,303 INFO [train.py:450] Epoch 1, batch 3840, batch avg loss 0.3228, total avg loss: 0.3520, batch size: 41
2021-08-24 22:53:25,883 INFO [train.py:450] Epoch 1, batch 3850, batch avg loss 0.3738, total avg loss: 0.3523, batch size: 41
2021-08-24 22:53:32,048 INFO [train.py:450] Epoch 1, batch 3860, batch avg loss 0.3155, total avg loss: 0.3500, batch size: 39
2021-08-24 22:53:38,383 INFO [train.py:450] Epoch 1, batch 3870, batch avg loss 0.3209, total avg loss: 0.3505, batch size: 40
2021-08-24 22:53:44,999 INFO [train.py:450] Epoch 1, batch 3880, batch avg loss 0.3394, total avg loss: 0.3521, batch size: 36
2021-08-24 22:53:51,634 INFO [train.py:450] Epoch 1, batch 3890, batch avg loss 0.3828, total avg loss: 0.3509, batch size: 37
2021-08-24 22:53:57,966 INFO [train.py:450] Epoch 1, batch 3900, batch avg loss 0.3581, total avg loss: 0.3502, batch size: 37
2021-08-24 22:54:04,607 INFO [train.py:450] Epoch 1, batch 3910, batch avg loss 0.3312, total avg loss: 0.3504, batch size: 40
2021-08-24 22:54:10,810 INFO [train.py:450] Epoch 1, batch 3920, batch avg loss 0.3091, total avg loss: 0.3485, batch size: 36
2021-08-24 22:54:16,971 INFO [train.py:450] Epoch 1, batch 3930, batch avg loss 0.3933, total avg loss: 0.3469, batch size: 41
2021-08-24 22:54:23,854 INFO [train.py:450] Epoch 1, batch 3940, batch avg loss 0.3467, total avg loss: 0.3477, batch size: 41
2021-08-24 22:54:30,341 INFO [train.py:450] Epoch 1, batch 3950, batch avg loss 0.3953, total avg loss: 0.3491, batch size: 42
2021-08-24 22:54:36,856 INFO [train.py:450] Epoch 1, batch 3960, batch avg loss 0.3918, total avg loss: 0.3497, batch size: 38
2021-08-24 22:54:43,542 INFO [train.py:450] Epoch 1, batch 3970, batch avg loss 0.4239, total avg loss: 0.3499, batch size: 36
2021-08-24 22:54:50,074 INFO [train.py:450] Epoch 1, batch 3980, batch avg loss 0.2959, total avg loss: 0.3499, batch size: 44
2021-08-24 22:54:56,619 INFO [train.py:450] Epoch 1, batch 3990, batch avg loss 0.3602, total avg loss: 0.3500, batch size: 39
2021-08-24 22:55:03,270 INFO [train.py:450] Epoch 1, batch 4000, batch avg loss 0.3812, total avg loss: 0.3509, batch size: 37
2021-08-24 22:55:41,659 INFO [train.py:482] Epoch 1, valid loss 0.2555, best valid loss: 0.2555 best valid epoch: 1
2021-08-24 22:55:47,466 INFO [train.py:450] Epoch 1, batch 4010, batch avg loss 0.3890, total avg loss: 0.3489, batch size: 42
2021-08-24 22:55:53,311 INFO [train.py:450] Epoch 1, batch 4020, batch avg loss 0.3480, total avg loss: 0.3512, batch size: 39
2021-08-24 22:55:59,474 INFO [train.py:450] Epoch 1, batch 4030, batch avg loss 0.3183, total avg loss: 0.3492, batch size: 41
2021-08-24 22:56:07,748 INFO [train.py:450] Epoch 1, batch 4040, batch avg loss 0.3976, total avg loss: 0.3514, batch size: 42
2021-08-24 22:56:13,655 INFO [train.py:450] Epoch 1, batch 4050, batch avg loss 0.3430, total avg loss: 0.3524, batch size: 40
2021-08-24 22:56:20,158 INFO [train.py:450] Epoch 1, batch 4060, batch avg loss 0.3353, total avg loss: 0.3471, batch size: 40
2021-08-24 22:56:28,030 INFO [train.py:450] Epoch 1, batch 4070, batch avg loss 0.3172, total avg loss: 0.3469, batch size: 39
2021-08-24 22:56:34,236 INFO [train.py:450] Epoch 1, batch 4080, batch avg loss 0.4099, total avg loss: 0.3467, batch size: 41
2021-08-24 22:56:41,036 INFO [train.py:450] Epoch 1, batch 4090, batch avg loss 0.3386, total avg loss: 0.3476, batch size: 45
2021-08-24 22:56:47,224 INFO [train.py:450] Epoch 1, batch 4100, batch avg loss 0.3320, total avg loss: 0.3490, batch size: 39
2021-08-24 22:56:53,225 INFO [train.py:450] Epoch 1, batch 4110, batch avg loss 0.3694, total avg loss: 0.3482, batch size: 39
2021-08-24 22:56:59,696 INFO [train.py:450] Epoch 1, batch 4120, batch avg loss 0.3750, total avg loss: 0.3489, batch size: 37
2021-08-24 22:57:06,441 INFO [train.py:450] Epoch 1, batch 4130, batch avg loss 0.3161, total avg loss: 0.3487, batch size: 39
2021-08-24 22:57:13,171 INFO [train.py:450] Epoch 1, batch 4140, batch avg loss 0.3827, total avg loss: 0.3496, batch size: 38
2021-08-24 22:57:19,325 INFO [train.py:450] Epoch 1, batch 4150, batch avg loss 0.2947, total avg loss: 0.3480, batch size: 41
2021-08-24 22:57:26,310 INFO [train.py:450] Epoch 1, batch 4160, batch avg loss 0.3496, total avg loss: 0.3484, batch size: 41
2021-08-24 22:57:32,850 INFO [train.py:450] Epoch 1, batch 4170, batch avg loss 0.3405, total avg loss: 0.3489, batch size: 39
2021-08-24 22:57:39,435 INFO [train.py:450] Epoch 1, batch 4180, batch avg loss 0.4228, total avg loss: 0.3484, batch size: 42
2021-08-24 22:57:45,955 INFO [train.py:450] Epoch 1, batch 4190, batch avg loss 0.3307, total avg loss: 0.3482, batch size: 36
2021-08-24 22:57:52,476 INFO [train.py:450] Epoch 1, batch 4200, batch avg loss 0.3157, total avg loss: 0.3485, batch size: 41
2021-08-24 22:57:59,215 INFO [train.py:450] Epoch 1, batch 4210, batch avg loss 0.3585, total avg loss: 0.3539, batch size: 38
2021-08-24 22:58:05,622 INFO [train.py:450] Epoch 1, batch 4220, batch avg loss 0.3390, total avg loss: 0.3603, batch size: 40
2021-08-24 22:58:11,904 INFO [train.py:450] Epoch 1, batch 4230, batch avg loss 0.3301, total avg loss: 0.3569, batch size: 39
2021-08-24 22:58:18,104 INFO [train.py:450] Epoch 1, batch 4240, batch avg loss 0.3025, total avg loss: 0.3553, batch size: 41
2021-08-24 22:58:24,848 INFO [train.py:450] Epoch 1, batch 4250, batch avg loss 0.3460, total avg loss: 0.3551, batch size: 43
2021-08-24 22:58:31,493 INFO [train.py:450] Epoch 1, batch 4260, batch avg loss 0.3413, total avg loss: 0.3542, batch size: 42
2021-08-24 22:58:38,231 INFO [train.py:450] Epoch 1, batch 4270, batch avg loss 0.3534, total avg loss: 0.3520, batch size: 40
2021-08-24 22:58:45,086 INFO [train.py:450] Epoch 1, batch 4280, batch avg loss 0.3674, total avg loss: 0.3500, batch size: 39
2021-08-24 22:58:51,968 INFO [train.py:450] Epoch 1, batch 4290, batch avg loss 0.3835, total avg loss: 0.3506, batch size: 40
2021-08-24 22:58:58,532 INFO [train.py:450] Epoch 1, batch 4300, batch avg loss 0.3210, total avg loss: 0.3511, batch size: 36
2021-08-24 22:59:04,730 INFO [train.py:450] Epoch 1, batch 4310, batch avg loss 0.3567, total avg loss: 0.3502, batch size: 38
2021-08-24 22:59:11,196 INFO [train.py:450] Epoch 1, batch 4320, batch avg loss 0.3879, total avg loss: 0.3499, batch size: 45
2021-08-24 22:59:17,887 INFO [train.py:450] Epoch 1, batch 4330, batch avg loss 0.3387, total avg loss: 0.3496, batch size: 42
2021-08-24 22:59:24,168 INFO [train.py:450] Epoch 1, batch 4340, batch avg loss 0.3695, total avg loss: 0.3494, batch size: 41
2021-08-24 22:59:30,865 INFO [train.py:450] Epoch 1, batch 4350, batch avg loss 0.3024, total avg loss: 0.3501, batch size: 40
2021-08-24 22:59:37,630 INFO [train.py:450] Epoch 1, batch 4360, batch avg loss 0.2912, total avg loss: 0.3493, batch size: 41
2021-08-24 22:59:44,816 INFO [train.py:450] Epoch 1, batch 4370, batch avg loss 0.3293, total avg loss: 0.3489, batch size: 43
2021-08-24 22:59:51,049 INFO [train.py:450] Epoch 1, batch 4380, batch avg loss 0.3368, total avg loss: 0.3486, batch size: 38
2021-08-24 22:59:57,680 INFO [train.py:450] Epoch 1, batch 4390, batch avg loss 0.3155, total avg loss: 0.3479, batch size: 38
2021-08-24 23:00:04,078 INFO [train.py:450] Epoch 1, batch 4400, batch avg loss 0.3107, total avg loss: 0.3485, batch size: 38
2021-08-24 23:00:10,573 INFO [train.py:450] Epoch 1, batch 4410, batch avg loss 0.3727, total avg loss: 0.3341, batch size: 45
2021-08-24 23:00:15,696 WARNING [cut.py:1694] To perform mix, energy must be non-zero and non-negative (got 0.0).  MonoCut with id "f4718e4a-bd3e-eb24-014b-7af2ae22b0c3" will not be mixed in.
2021-08-24 23:00:17,397 INFO [train.py:450] Epoch 1, batch 4420, batch avg loss 0.3040, total avg loss: 0.3403, batch size: 38
2021-08-24 23:00:24,167 INFO [train.py:450] Epoch 1, batch 4430, batch avg loss 0.3936, total avg loss: 0.3483, batch size: 41
2021-08-24 23:00:31,818 INFO [train.py:450] Epoch 1, batch 4440, batch avg loss 0.3175, total avg loss: 0.3496, batch size: 43
2021-08-24 23:00:37,836 INFO [train.py:450] Epoch 1, batch 4450, batch avg loss 0.3275, total avg loss: 0.3491, batch size: 39
2021-08-24 23:00:48,294 INFO [train.py:450] Epoch 1, batch 4460, batch avg loss 0.3546, total avg loss: 0.3486, batch size: 38
2021-08-24 23:00:54,644 INFO [train.py:450] Epoch 1, batch 4470, batch avg loss 0.3892, total avg loss: 0.3501, batch size: 38
2021-08-24 23:01:01,278 INFO [train.py:450] Epoch 1, batch 4480, batch avg loss 0.3928, total avg loss: 0.3507, batch size: 39
2021-08-24 23:01:08,513 INFO [train.py:450] Epoch 1, batch 4490, batch avg loss 0.3763, total avg loss: 0.3533, batch size: 40
2021-08-24 23:01:15,258 INFO [train.py:450] Epoch 1, batch 4500, batch avg loss 0.3724, total avg loss: 0.3531, batch size: 38
2021-08-24 23:01:21,810 INFO [train.py:450] Epoch 1, batch 4510, batch avg loss 0.3330, total avg loss: 0.3536, batch size: 39
2021-08-24 23:01:28,867 INFO [train.py:450] Epoch 1, batch 4520, batch avg loss 0.3313, total avg loss: 0.3545, batch size: 45
2021-08-24 23:01:35,274 INFO [train.py:450] Epoch 1, batch 4530, batch avg loss 0.3187, total avg loss: 0.3543, batch size: 43
2021-08-24 23:01:41,492 INFO [train.py:450] Epoch 1, batch 4540, batch avg loss 0.3287, total avg loss: 0.3543, batch size: 37
2021-08-24 23:01:48,194 INFO [train.py:450] Epoch 1, batch 4550, batch avg loss 0.3727, total avg loss: 0.3539, batch size: 42
2021-08-24 23:01:54,590 INFO [train.py:450] Epoch 1, batch 4560, batch avg loss 0.3502, total avg loss: 0.3538, batch size: 45
2021-08-24 23:02:01,596 INFO [train.py:450] Epoch 1, batch 4570, batch avg loss 0.3497, total avg loss: 0.3543, batch size: 43
2021-08-24 23:02:07,710 INFO [train.py:450] Epoch 1, batch 4580, batch avg loss 0.3311, total avg loss: 0.3535, batch size: 41
2021-08-24 23:02:14,063 INFO [train.py:450] Epoch 1, batch 4590, batch avg loss 0.3409, total avg loss: 0.3528, batch size: 38
2021-08-24 23:02:20,666 INFO [train.py:450] Epoch 1, batch 4600, batch avg loss 0.3755, total avg loss: 0.3530, batch size: 43
2021-08-24 23:02:26,978 INFO [train.py:450] Epoch 1, batch 4610, batch avg loss 0.3380, total avg loss: 0.3471, batch size: 43
2021-08-24 23:02:33,520 INFO [train.py:450] Epoch 1, batch 4620, batch avg loss 0.3369, total avg loss: 0.3497, batch size: 39
2021-08-24 23:02:40,695 INFO [train.py:450] Epoch 1, batch 4630, batch avg loss 0.3061, total avg loss: 0.3524, batch size: 40
2021-08-24 23:02:47,040 INFO [train.py:450] Epoch 1, batch 4640, batch avg loss 0.3077, total avg loss: 0.3508, batch size: 39
2021-08-24 23:02:53,725 INFO [train.py:450] Epoch 1, batch 4650, batch avg loss 0.3491, total avg loss: 0.3509, batch size: 38
2021-08-24 23:03:00,243 INFO [train.py:450] Epoch 1, batch 4660, batch avg loss 0.3410, total avg loss: 0.3538, batch size: 35
2021-08-24 23:03:07,097 INFO [train.py:450] Epoch 1, batch 4670, batch avg loss 0.4011, total avg loss: 0.3536, batch size: 42
2021-08-24 23:03:13,570 INFO [train.py:450] Epoch 1, batch 4680, batch avg loss 0.3267, total avg loss: 0.3530, batch size: 40
2021-08-24 23:03:20,359 INFO [train.py:450] Epoch 1, batch 4690, batch avg loss 0.3734, total avg loss: 0.3549, batch size: 39
2021-08-24 23:03:27,321 INFO [train.py:450] Epoch 1, batch 4700, batch avg loss 0.3680, total avg loss: 0.3542, batch size: 42
2021-08-24 23:03:34,305 INFO [train.py:450] Epoch 1, batch 4710, batch avg loss 0.3770, total avg loss: 0.3530, batch size: 41
2021-08-24 23:03:40,857 INFO [train.py:450] Epoch 1, batch 4720, batch avg loss 0.3606, total avg loss: 0.3518, batch size: 40
2021-08-24 23:03:47,714 INFO [train.py:450] Epoch 1, batch 4730, batch avg loss 0.3846, total avg loss: 0.3516, batch size: 41
2021-08-24 23:03:54,221 INFO [train.py:450] Epoch 1, batch 4740, batch avg loss 0.3427, total avg loss: 0.3517, batch size: 37
2021-08-24 23:04:01,412 INFO [train.py:450] Epoch 1, batch 4750, batch avg loss 0.3391, total avg loss: 0.3514, batch size: 45
2021-08-24 23:04:07,894 INFO [train.py:450] Epoch 1, batch 4760, batch avg loss 0.3389, total avg loss: 0.3517, batch size: 42
2021-08-24 23:04:14,645 INFO [train.py:450] Epoch 1, batch 4770, batch avg loss 0.3685, total avg loss: 0.3525, batch size: 38
2021-08-24 23:04:21,575 INFO [train.py:450] Epoch 1, batch 4780, batch avg loss 0.3811, total avg loss: 0.3524, batch size: 42
2021-08-24 23:04:28,495 INFO [train.py:450] Epoch 1, batch 4790, batch avg loss 0.3587, total avg loss: 0.3521, batch size: 36
2021-08-24 23:04:35,454 INFO [train.py:450] Epoch 1, batch 4800, batch avg loss 0.3101, total avg loss: 0.3520, batch size: 40
2021-08-24 23:04:42,908 INFO [train.py:450] Epoch 1, batch 4810, batch avg loss 0.3125, total avg loss: 0.3528, batch size: 38
2021-08-24 23:04:51,411 INFO [train.py:450] Epoch 1, batch 4820, batch avg loss 0.3633, total avg loss: 0.3468, batch size: 41
2021-08-24 23:05:00,908 INFO [train.py:450] Epoch 1, batch 4830, batch avg loss 0.3392, total avg loss: 0.3476, batch size: 43
2021-08-24 23:05:07,636 INFO [train.py:450] Epoch 1, batch 4840, batch avg loss 0.3794, total avg loss: 0.3507, batch size: 41
2021-08-24 23:05:13,747 INFO [train.py:450] Epoch 1, batch 4850, batch avg loss 0.2862, total avg loss: 0.3485, batch size: 37
2021-08-24 23:05:20,455 INFO [train.py:450] Epoch 1, batch 4860, batch avg loss 0.3504, total avg loss: 0.3492, batch size: 40
2021-08-24 23:05:27,500 INFO [train.py:450] Epoch 1, batch 4870, batch avg loss 0.3389, total avg loss: 0.3486, batch size: 42
2021-08-24 23:05:33,962 INFO [train.py:450] Epoch 1, batch 4880, batch avg loss 0.3430, total avg loss: 0.3484, batch size: 39
2021-08-24 23:05:40,590 INFO [train.py:450] Epoch 1, batch 4890, batch avg loss 0.3268, total avg loss: 0.3474, batch size: 39
2021-08-24 23:05:46,844 INFO [train.py:450] Epoch 1, batch 4900, batch avg loss 0.3643, total avg loss: 0.3467, batch size: 37
2021-08-24 23:05:52,994 INFO [train.py:450] Epoch 1, batch 4910, batch avg loss 0.3831, total avg loss: 0.3476, batch size: 39
2021-08-24 23:05:59,456 INFO [train.py:450] Epoch 1, batch 4920, batch avg loss 0.3787, total avg loss: 0.3477, batch size: 39
2021-08-24 23:06:06,132 INFO [train.py:450] Epoch 1, batch 4930, batch avg loss 0.3600, total avg loss: 0.3475, batch size: 35
2021-08-24 23:06:12,464 INFO [train.py:450] Epoch 1, batch 4940, batch avg loss 0.3424, total avg loss: 0.3466, batch size: 42
2021-08-24 23:06:19,313 INFO [train.py:450] Epoch 1, batch 4950, batch avg loss 0.3767, total avg loss: 0.3469, batch size: 36
2021-08-24 23:06:25,520 INFO [train.py:450] Epoch 1, batch 4960, batch avg loss 0.3755, total avg loss: 0.3477, batch size: 39
2021-08-24 23:06:32,275 INFO [train.py:450] Epoch 1, batch 4970, batch avg loss 0.3533, total avg loss: 0.3477, batch size: 40
2021-08-24 23:06:38,660 INFO [train.py:450] Epoch 1, batch 4980, batch avg loss 0.3011, total avg loss: 0.3486, batch size: 38
2021-08-24 23:06:45,585 INFO [train.py:450] Epoch 1, batch 4990, batch avg loss 0.3094, total avg loss: 0.3492, batch size: 39
2021-08-24 23:06:52,346 INFO [train.py:450] Epoch 1, batch 5000, batch avg loss 0.3370, total avg loss: 0.3500, batch size: 38
2021-08-24 23:07:30,439 INFO [train.py:482] Epoch 1, valid loss 0.2564, best valid loss: 0.2555 best valid epoch: 1
2021-08-24 23:07:36,285 INFO [train.py:450] Epoch 1, batch 5010, batch avg loss 0.3501, total avg loss: 0.3647, batch size: 39
2021-08-24 23:07:42,520 INFO [train.py:450] Epoch 1, batch 5020, batch avg loss 0.3432, total avg loss: 0.3516, batch size: 43
2021-08-24 23:07:49,628 INFO [train.py:450] Epoch 1, batch 5030, batch avg loss 0.4055, total avg loss: 0.3464, batch size: 40
2021-08-24 23:07:56,235 INFO [train.py:450] Epoch 1, batch 5040, batch avg loss 0.3443, total avg loss: 0.3474, batch size: 44
2021-08-24 23:08:03,191 INFO [train.py:450] Epoch 1, batch 5050, batch avg loss 0.4249, total avg loss: 0.3457, batch size: 42
2021-08-24 23:08:09,397 INFO [train.py:450] Epoch 1, batch 5060, batch avg loss 0.3480, total avg loss: 0.3478, batch size: 39
2021-08-24 23:08:15,866 INFO [train.py:450] Epoch 1, batch 5070, batch avg loss 0.3465, total avg loss: 0.3474, batch size: 40
2021-08-24 23:08:22,759 INFO [train.py:450] Epoch 1, batch 5080, batch avg loss 0.3997, total avg loss: 0.3480, batch size: 39
2021-08-24 23:08:29,281 INFO [train.py:450] Epoch 1, batch 5090, batch avg loss 0.3425, total avg loss: 0.3489, batch size: 40
2021-08-24 23:08:35,839 INFO [train.py:450] Epoch 1, batch 5100, batch avg loss 0.3714, total avg loss: 0.3486, batch size: 37
2021-08-24 23:08:42,260 INFO [train.py:450] Epoch 1, batch 5110, batch avg loss 0.3311, total avg loss: 0.3489, batch size: 40
2021-08-24 23:08:49,353 INFO [train.py:450] Epoch 1, batch 5120, batch avg loss 0.3358, total avg loss: 0.3494, batch size: 41
2021-08-24 23:08:56,876 INFO [train.py:450] Epoch 1, batch 5130, batch avg loss 0.3481, total avg loss: 0.3490, batch size: 38
2021-08-24 23:09:03,093 INFO [train.py:450] Epoch 1, batch 5140, batch avg loss 0.3750, total avg loss: 0.3498, batch size: 40
2021-08-24 23:09:13,757 INFO [train.py:450] Epoch 1, batch 5150, batch avg loss 0.3531, total avg loss: 0.3508, batch size: 38
2021-08-24 23:09:19,793 INFO [train.py:450] Epoch 1, batch 5160, batch avg loss 0.3284, total avg loss: 0.3503, batch size: 41
2021-08-24 23:09:27,204 INFO [train.py:450] Epoch 1, batch 5170, batch avg loss 0.3611, total avg loss: 0.3510, batch size: 38
2021-08-24 23:09:34,015 INFO [train.py:450] Epoch 1, batch 5180, batch avg loss 0.3355, total avg loss: 0.3509, batch size: 38
2021-08-24 23:09:40,951 INFO [train.py:450] Epoch 1, batch 5190, batch avg loss 0.3639, total avg loss: 0.3506, batch size: 40
2021-08-24 23:09:46,734 INFO [train.py:450] Epoch 1, batch 5200, batch avg loss 0.3354, total avg loss: 0.3494, batch size: 39
2021-08-24 23:09:53,569 INFO [train.py:450] Epoch 1, batch 5210, batch avg loss 0.3388, total avg loss: 0.3393, batch size: 39
2021-08-24 23:09:59,955 INFO [train.py:450] Epoch 1, batch 5220, batch avg loss 0.3238, total avg loss: 0.3406, batch size: 39
2021-08-24 23:10:07,020 INFO [train.py:450] Epoch 1, batch 5230, batch avg loss 0.3020, total avg loss: 0.3458, batch size: 42
2021-08-24 23:10:13,494 INFO [train.py:450] Epoch 1, batch 5240, batch avg loss 0.3239, total avg loss: 0.3452, batch size: 42
2021-08-24 23:10:19,802 INFO [train.py:450] Epoch 1, batch 5250, batch avg loss 0.3832, total avg loss: 0.3456, batch size: 44
2021-08-24 23:10:26,521 INFO [train.py:450] Epoch 1, batch 5260, batch avg loss 0.3828, total avg loss: 0.3467, batch size: 41
2021-08-24 23:10:34,114 INFO [train.py:450] Epoch 1, batch 5270, batch avg loss 0.3977, total avg loss: 0.3484, batch size: 42
2021-08-24 23:10:40,538 INFO [train.py:450] Epoch 1, batch 5280, batch avg loss 0.3531, total avg loss: 0.3500, batch size: 40
2021-08-24 23:10:46,847 INFO [train.py:450] Epoch 1, batch 5290, batch avg loss 0.3616, total avg loss: 0.3523, batch size: 41
2021-08-24 23:10:53,995 INFO [train.py:450] Epoch 1, batch 5300, batch avg loss 0.3553, total avg loss: 0.3517, batch size: 38
2021-08-24 23:11:00,693 INFO [train.py:450] Epoch 1, batch 5310, batch avg loss 0.3112, total avg loss: 0.3515, batch size: 43
2021-08-24 23:11:07,326 INFO [train.py:450] Epoch 1, batch 5320, batch avg loss 0.3365, total avg loss: 0.3514, batch size: 37
2021-08-24 23:11:14,239 INFO [train.py:450] Epoch 1, batch 5330, batch avg loss 0.3441, total avg loss: 0.3509, batch size: 40
2021-08-24 23:11:21,370 INFO [train.py:450] Epoch 1, batch 5340, batch avg loss 0.3550, total avg loss: 0.3503, batch size: 39
2021-08-24 23:11:28,196 INFO [train.py:450] Epoch 1, batch 5350, batch avg loss 0.2870, total avg loss: 0.3492, batch size: 41
2021-08-24 23:11:34,889 INFO [train.py:450] Epoch 1, batch 5360, batch avg loss 0.3424, total avg loss: 0.3485, batch size: 37
2021-08-24 23:11:41,495 INFO [train.py:450] Epoch 1, batch 5370, batch avg loss 0.3027, total avg loss: 0.3488, batch size: 38
2021-08-24 23:11:48,247 INFO [train.py:450] Epoch 1, batch 5380, batch avg loss 0.3833, total avg loss: 0.3493, batch size: 42
2021-08-24 23:11:55,018 INFO [train.py:450] Epoch 1, batch 5390, batch avg loss 0.3175, total avg loss: 0.3491, batch size: 40
2021-08-24 23:12:01,371 INFO [train.py:450] Epoch 1, batch 5400, batch avg loss 0.3477, total avg loss: 0.3490, batch size: 41
2021-08-24 23:12:07,458 INFO [train.py:450] Epoch 1, batch 5410, batch avg loss 0.3868, total avg loss: 0.3510, batch size: 45
2021-08-24 23:12:13,775 INFO [train.py:450] Epoch 1, batch 5420, batch avg loss 0.3488, total avg loss: 0.3436, batch size: 41
2021-08-24 23:12:20,224 INFO [train.py:450] Epoch 1, batch 5430, batch avg loss 0.3277, total avg loss: 0.3471, batch size: 39
2021-08-24 23:12:26,577 INFO [train.py:450] Epoch 1, batch 5440, batch avg loss 0.3184, total avg loss: 0.3450, batch size: 38
2021-08-24 23:12:33,420 INFO [train.py:450] Epoch 1, batch 5450, batch avg loss 0.3461, total avg loss: 0.3483, batch size: 39
2021-08-24 23:12:39,962 INFO [train.py:450] Epoch 1, batch 5460, batch avg loss 0.3736, total avg loss: 0.3490, batch size: 39
2021-08-24 23:12:46,646 INFO [train.py:450] Epoch 1, batch 5470, batch avg loss 0.3425, total avg loss: 0.3482, batch size: 40
2021-08-24 23:12:53,124 INFO [train.py:450] Epoch 1, batch 5480, batch avg loss 0.3373, total avg loss: 0.3476, batch size: 39
2021-08-24 23:12:59,491 INFO [train.py:450] Epoch 1, batch 5490, batch avg loss 0.3601, total avg loss: 0.3476, batch size: 45
2021-08-24 23:13:06,442 INFO [train.py:450] Epoch 1, batch 5500, batch avg loss 0.3824, total avg loss: 0.3468, batch size: 41
2021-08-24 23:13:13,226 INFO [train.py:450] Epoch 1, batch 5510, batch avg loss 0.3169, total avg loss: 0.3464, batch size: 41
2021-08-24 23:13:21,003 INFO [train.py:450] Epoch 1, batch 5520, batch avg loss 0.3323, total avg loss: 0.3476, batch size: 42
2021-08-24 23:13:27,404 INFO [train.py:450] Epoch 1, batch 5530, batch avg loss 0.3500, total avg loss: 0.3481, batch size: 42
2021-08-24 23:13:36,775 INFO [train.py:450] Epoch 1, batch 5540, batch avg loss 0.3931, total avg loss: 0.3485, batch size: 41
2021-08-24 23:13:43,042 INFO [train.py:450] Epoch 1, batch 5550, batch avg loss 0.3771, total avg loss: 0.3486, batch size: 40
2021-08-24 23:13:45,004 WARNING [cut.py:1694] To perform mix, energy must be non-zero and non-negative (got 0.0).  MonoCut with id "5c6bdf5a-cb77-4142-65bf-f1e33b83fda3" will not be mixed in.
2021-08-24 23:13:49,320 INFO [train.py:450] Epoch 1, batch 5560, batch avg loss 0.3078, total avg loss: 0.3500, batch size: 39
2021-08-24 23:13:55,742 INFO [train.py:450] Epoch 1, batch 5570, batch avg loss 0.3630, total avg loss: 0.3501, batch size: 37
2021-08-24 23:14:02,196 INFO [train.py:450] Epoch 1, batch 5580, batch avg loss 0.3398, total avg loss: 0.3498, batch size: 39
2021-08-24 23:14:08,264 INFO [train.py:450] Epoch 1, batch 5590, batch avg loss 0.3644, total avg loss: 0.3507, batch size: 38
2021-08-24 23:14:15,162 INFO [train.py:450] Epoch 1, batch 5600, batch avg loss 0.3156, total avg loss: 0.3508, batch size: 42
2021-08-24 23:14:21,624 INFO [train.py:450] Epoch 1, batch 5610, batch avg loss 0.3310, total avg loss: 0.3652, batch size: 41
2021-08-24 23:14:28,034 INFO [train.py:450] Epoch 1, batch 5620, batch avg loss 0.3641, total avg loss: 0.3565, batch size: 40
2021-08-24 23:14:35,042 INFO [train.py:450] Epoch 1, batch 5630, batch avg loss 0.3354, total avg loss: 0.3564, batch size: 41
2021-08-24 23:14:41,911 INFO [train.py:450] Epoch 1, batch 5640, batch avg loss 0.3394, total avg loss: 0.3594, batch size: 40
2021-08-24 23:14:48,057 INFO [train.py:450] Epoch 1, batch 5650, batch avg loss 0.3307, total avg loss: 0.3599, batch size: 38
2021-08-24 23:14:54,392 INFO [train.py:450] Epoch 1, batch 5660, batch avg loss 0.3344, total avg loss: 0.3584, batch size: 41
2021-08-24 23:15:01,034 INFO [train.py:450] Epoch 1, batch 5670, batch avg loss 0.4461, total avg loss: 0.3566, batch size: 37
2021-08-24 23:15:07,636 INFO [train.py:450] Epoch 1, batch 5680, batch avg loss 0.3734, total avg loss: 0.3559, batch size: 36
2021-08-24 23:15:14,562 INFO [train.py:450] Epoch 1, batch 5690, batch avg loss 0.3122, total avg loss: 0.3576, batch size: 37
2021-08-24 23:15:20,532 INFO [train.py:450] Epoch 1, batch 5700, batch avg loss 0.3652, total avg loss: 0.3578, batch size: 43
2021-08-24 23:15:26,863 INFO [train.py:450] Epoch 1, batch 5710, batch avg loss 0.3543, total avg loss: 0.3577, batch size: 45
2021-08-24 23:15:33,029 INFO [train.py:450] Epoch 1, batch 5720, batch avg loss 0.3648, total avg loss: 0.3579, batch size: 39
2021-08-24 23:15:39,744 INFO [train.py:450] Epoch 1, batch 5730, batch avg loss 0.3198, total avg loss: 0.3572, batch size: 39
2021-08-24 23:15:46,116 INFO [train.py:450] Epoch 1, batch 5740, batch avg loss 0.3749, total avg loss: 0.3562, batch size: 40
2021-08-24 23:15:52,731 INFO [train.py:450] Epoch 1, batch 5750, batch avg loss 0.3575, total avg loss: 0.3561, batch size: 36
2021-08-24 23:15:58,967 INFO [train.py:450] Epoch 1, batch 5760, batch avg loss 0.3937, total avg loss: 0.3564, batch size: 39
2021-08-24 23:16:05,803 INFO [train.py:450] Epoch 1, batch 5770, batch avg loss 0.3841, total avg loss: 0.3567, batch size: 45
2021-08-24 23:16:11,836 INFO [train.py:450] Epoch 1, batch 5780, batch avg loss 0.3617, total avg loss: 0.3566, batch size: 42
2021-08-24 23:16:18,737 INFO [train.py:450] Epoch 1, batch 5790, batch avg loss 0.3265, total avg loss: 0.3560, batch size: 37
2021-08-24 23:16:25,732 INFO [train.py:450] Epoch 1, batch 5800, batch avg loss 0.3881, total avg loss: 0.3559, batch size: 41
2021-08-24 23:16:32,516 INFO [train.py:450] Epoch 1, batch 5810, batch avg loss 0.4017, total avg loss: 0.3574, batch size: 40
2021-08-24 23:16:39,787 INFO [train.py:450] Epoch 1, batch 5820, batch avg loss 0.3521, total avg loss: 0.3693, batch size: 39
2021-08-24 23:16:46,129 INFO [train.py:450] Epoch 1, batch 5830, batch avg loss 0.4346, total avg loss: 0.3675, batch size: 41
2021-08-24 23:16:52,133 INFO [train.py:450] Epoch 1, batch 5840, batch avg loss 0.3166, total avg loss: 0.3640, batch size: 42
2021-08-24 23:16:58,506 INFO [train.py:450] Epoch 1, batch 5850, batch avg loss 0.3115, total avg loss: 0.3602, batch size: 36
2021-08-24 23:17:04,950 INFO [train.py:450] Epoch 1, batch 5860, batch avg loss 0.3289, total avg loss: 0.3552, batch size: 38
2021-08-24 23:17:11,855 INFO [train.py:450] Epoch 1, batch 5870, batch avg loss 0.3824, total avg loss: 0.3553, batch size: 42
2021-08-24 23:17:18,236 INFO [train.py:450] Epoch 1, batch 5880, batch avg loss 0.3709, total avg loss: 0.3553, batch size: 39
2021-08-24 23:17:24,828 INFO [train.py:450] Epoch 1, batch 5890, batch avg loss 0.3053, total avg loss: 0.3547, batch size: 39
2021-08-24 23:17:31,336 INFO [train.py:450] Epoch 1, batch 5900, batch avg loss 0.3211, total avg loss: 0.3520, batch size: 38
2021-08-24 23:17:38,127 INFO [train.py:450] Epoch 1, batch 5910, batch avg loss 0.3542, total avg loss: 0.3522, batch size: 42
2021-08-24 23:17:44,709 INFO [train.py:450] Epoch 1, batch 5920, batch avg loss 0.3723, total avg loss: 0.3522, batch size: 38
2021-08-24 23:17:52,267 INFO [train.py:450] Epoch 1, batch 5930, batch avg loss 0.2989, total avg loss: 0.3518, batch size: 36
2021-08-24 23:17:58,702 INFO [train.py:450] Epoch 1, batch 5940, batch avg loss 0.3497, total avg loss: 0.3510, batch size: 45
2021-08-24 23:18:07,371 INFO [train.py:450] Epoch 1, batch 5950, batch avg loss 0.3373, total avg loss: 0.3482, batch size: 39
2021-08-24 23:18:13,731 INFO [train.py:450] Epoch 1, batch 5960, batch avg loss 0.3088, total avg loss: 0.3472, batch size: 36
2021-08-24 23:18:20,637 INFO [train.py:450] Epoch 1, batch 5970, batch avg loss 0.3665, total avg loss: 0.3476, batch size: 38
2021-08-24 23:18:27,515 INFO [train.py:450] Epoch 1, batch 5980, batch avg loss 0.3603, total avg loss: 0.3480, batch size: 40
2021-08-24 23:18:33,961 INFO [train.py:450] Epoch 1, batch 5990, batch avg loss 0.3337, total avg loss: 0.3471, batch size: 44
2021-08-24 23:18:41,108 INFO [train.py:450] Epoch 1, batch 6000, batch avg loss 0.3852, total avg loss: 0.3479, batch size: 38
2021-08-24 23:19:21,970 INFO [train.py:482] Epoch 1, valid loss 0.2530, best valid loss: 0.2530 best valid epoch: 1
2021-08-24 23:19:27,966 INFO [train.py:450] Epoch 1, batch 6010, batch avg loss 0.3662, total avg loss: 0.3422, batch size: 38
2021-08-24 23:19:34,350 INFO [train.py:450] Epoch 1, batch 6020, batch avg loss 0.3707, total avg loss: 0.3427, batch size: 42
2021-08-24 23:19:41,671 INFO [train.py:450] Epoch 1, batch 6030, batch avg loss 0.3788, total avg loss: 0.3448, batch size: 38
2021-08-24 23:19:48,889 INFO [train.py:450] Epoch 1, batch 6040, batch avg loss 0.3260, total avg loss: 0.3477, batch size: 39
2021-08-24 23:19:56,130 INFO [train.py:450] Epoch 1, batch 6050, batch avg loss 0.3979, total avg loss: 0.3501, batch size: 37
2021-08-24 23:20:02,856 INFO [train.py:450] Epoch 1, batch 6060, batch avg loss 0.3376, total avg loss: 0.3475, batch size: 40
2021-08-24 23:20:09,637 INFO [train.py:450] Epoch 1, batch 6070, batch avg loss 0.3514, total avg loss: 0.3483, batch size: 39
2021-08-24 23:20:16,478 INFO [train.py:450] Epoch 1, batch 6080, batch avg loss 0.3646, total avg loss: 0.3479, batch size: 39
2021-08-24 23:20:23,954 INFO [train.py:450] Epoch 1, batch 6090, batch avg loss 0.2615, total avg loss: 0.3460, batch size: 40
2021-08-24 23:20:30,522 INFO [train.py:450] Epoch 1, batch 6100, batch avg loss 0.3559, total avg loss: 0.3473, batch size: 41
2021-08-24 23:20:37,733 INFO [train.py:450] Epoch 1, batch 6110, batch avg loss 0.4794, total avg loss: 0.3495, batch size: 35
2021-08-24 23:20:45,056 INFO [train.py:450] Epoch 1, batch 6120, batch avg loss 0.3782, total avg loss: 0.3498, batch size: 38
2021-08-24 23:20:52,041 INFO [train.py:450] Epoch 1, batch 6130, batch avg loss 0.4100, total avg loss: 0.3500, batch size: 42
2021-08-24 23:20:59,280 INFO [train.py:450] Epoch 1, batch 6140, batch avg loss 0.4019, total avg loss: 0.3493, batch size: 40
2021-08-24 23:21:06,494 INFO [train.py:450] Epoch 1, batch 6150, batch avg loss 0.3151, total avg loss: 0.3489, batch size: 43
2021-08-24 23:21:13,670 INFO [train.py:450] Epoch 1, batch 6160, batch avg loss 0.3760, total avg loss: 0.3488, batch size: 36
2021-08-24 23:21:20,675 INFO [train.py:450] Epoch 1, batch 6170, batch avg loss 0.3285, total avg loss: 0.3491, batch size: 42
2021-08-24 23:21:27,579 INFO [train.py:450] Epoch 1, batch 6180, batch avg loss 0.3197, total avg loss: 0.3491, batch size: 41
2021-08-24 23:21:35,028 INFO [train.py:450] Epoch 1, batch 6190, batch avg loss 0.2774, total avg loss: 0.3490, batch size: 37
2021-08-24 23:21:42,210 INFO [train.py:450] Epoch 1, batch 6200, batch avg loss 0.3810, total avg loss: 0.3500, batch size: 40
2021-08-24 23:21:49,584 INFO [train.py:450] Epoch 1, batch 6210, batch avg loss 0.3540, total avg loss: 0.3642, batch size: 39
2021-08-24 23:21:56,774 INFO [train.py:450] Epoch 1, batch 6220, batch avg loss 0.4293, total avg loss: 0.3692, batch size: 42
2021-08-24 23:22:03,820 INFO [train.py:450] Epoch 1, batch 6230, batch avg loss 0.3191, total avg loss: 0.3686, batch size: 37
2021-08-24 23:22:10,931 INFO [train.py:450] Epoch 1, batch 6240, batch avg loss 0.3144, total avg loss: 0.3595, batch size: 41
2021-08-24 23:22:18,778 INFO [train.py:450] Epoch 1, batch 6250, batch avg loss 0.3778, total avg loss: 0.3608, batch size: 39
2021-08-24 23:22:27,649 INFO [train.py:450] Epoch 1, batch 6260, batch avg loss 0.3547, total avg loss: 0.3572, batch size: 44
2021-08-24 23:22:35,349 INFO [train.py:450] Epoch 1, batch 6270, batch avg loss 0.2992, total avg loss: 0.3572, batch size: 38
2021-08-24 23:22:45,953 INFO [train.py:450] Epoch 1, batch 6280, batch avg loss 0.3476, total avg loss: 0.3554, batch size: 43
2021-08-24 23:22:52,995 INFO [train.py:450] Epoch 1, batch 6290, batch avg loss 0.3533, total avg loss: 0.3549, batch size: 40
2021-08-24 23:23:01,320 INFO [train.py:450] Epoch 1, batch 6300, batch avg loss 0.3547, total avg loss: 0.3545, batch size: 41
2021-08-24 23:23:09,196 INFO [train.py:450] Epoch 1, batch 6310, batch avg loss 0.3633, total avg loss: 0.3548, batch size: 42
2021-08-24 23:23:16,507 INFO [train.py:450] Epoch 1, batch 6320, batch avg loss 0.3144, total avg loss: 0.3537, batch size: 38
2021-08-24 23:23:24,044 INFO [train.py:450] Epoch 1, batch 6330, batch avg loss 0.3771, total avg loss: 0.3530, batch size: 40
2021-08-24 23:23:31,755 INFO [train.py:450] Epoch 1, batch 6340, batch avg loss 0.3239, total avg loss: 0.3534, batch size: 36
2021-08-24 23:23:39,656 INFO [train.py:450] Epoch 1, batch 6350, batch avg loss 0.3742, total avg loss: 0.3523, batch size: 42
2021-08-24 23:23:47,886 INFO [train.py:450] Epoch 1, batch 6360, batch avg loss 0.3909, total avg loss: 0.3523, batch size: 40
2021-08-24 23:23:55,938 INFO [train.py:450] Epoch 1, batch 6370, batch avg loss 0.3290, total avg loss: 0.3527, batch size: 39
2021-08-24 23:24:04,255 INFO [train.py:450] Epoch 1, batch 6380, batch avg loss 0.2860, total avg loss: 0.3526, batch size: 37
2021-08-24 23:24:12,158 INFO [train.py:450] Epoch 1, batch 6390, batch avg loss 0.3571, total avg loss: 0.3524, batch size: 41
2021-08-24 23:24:20,366 INFO [train.py:450] Epoch 1, batch 6400, batch avg loss 0.3634, total avg loss: 0.3523, batch size: 38
2021-08-24 23:24:27,957 INFO [train.py:450] Epoch 1, batch 6410, batch avg loss 0.3530, total avg loss: 0.3638, batch size: 39
2021-08-24 23:24:36,587 INFO [train.py:450] Epoch 1, batch 6420, batch avg loss 0.3227, total avg loss: 0.3617, batch size: 39
2021-08-24 23:24:44,686 INFO [train.py:450] Epoch 1, batch 6430, batch avg loss 0.2966, total avg loss: 0.3587, batch size: 39
2021-08-24 23:24:53,005 INFO [train.py:450] Epoch 1, batch 6440, batch avg loss 0.3183, total avg loss: 0.3583, batch size: 40
2021-08-24 23:25:01,240 INFO [train.py:450] Epoch 1, batch 6450, batch avg loss 0.3124, total avg loss: 0.3564, batch size: 38
2021-08-24 23:25:08,976 INFO [train.py:450] Epoch 1, batch 6460, batch avg loss 0.4173, total avg loss: 0.3546, batch size: 38
2021-08-24 23:25:17,261 INFO [train.py:450] Epoch 1, batch 6470, batch avg loss 0.3119, total avg loss: 0.3525, batch size: 42
2021-08-24 23:25:25,718 INFO [train.py:450] Epoch 1, batch 6480, batch avg loss 0.3770, total avg loss: 0.3527, batch size: 36
2021-08-24 23:25:34,222 INFO [train.py:450] Epoch 1, batch 6490, batch avg loss 0.3746, total avg loss: 0.3543, batch size: 39
2021-08-24 23:25:42,151 INFO [train.py:450] Epoch 1, batch 6500, batch avg loss 0.3002, total avg loss: 0.3535, batch size: 38
2021-08-24 23:25:50,354 INFO [train.py:450] Epoch 1, batch 6510, batch avg loss 0.3093, total avg loss: 0.3519, batch size: 39
2021-08-24 23:25:57,766 INFO [train.py:450] Epoch 1, batch 6520, batch avg loss 0.3089, total avg loss: 0.3509, batch size: 46
2021-08-24 23:26:06,020 INFO [train.py:450] Epoch 1, batch 6530, batch avg loss 0.3010, total avg loss: 0.3485, batch size: 41
2021-08-24 23:26:14,257 INFO [train.py:450] Epoch 1, batch 6540, batch avg loss 0.3481, total avg loss: 0.3473, batch size: 40
2021-08-24 23:26:22,333 INFO [train.py:450] Epoch 1, batch 6550, batch avg loss 0.3474, total avg loss: 0.3474, batch size: 39
2021-08-24 23:26:30,588 INFO [train.py:450] Epoch 1, batch 6560, batch avg loss 0.2838, total avg loss: 0.3462, batch size: 39
2021-08-24 23:26:39,133 INFO [train.py:450] Epoch 1, batch 6570, batch avg loss 0.3602, total avg loss: 0.3459, batch size: 39
2021-08-24 23:26:48,008 INFO [train.py:450] Epoch 1, batch 6580, batch avg loss 0.3403, total avg loss: 0.3455, batch size: 39
2021-08-24 23:26:55,842 INFO [train.py:450] Epoch 1, batch 6590, batch avg loss 0.3130, total avg loss: 0.3452, batch size: 37
2021-08-24 23:27:03,733 INFO [train.py:450] Epoch 1, batch 6600, batch avg loss 0.3862, total avg loss: 0.3453, batch size: 42
2021-08-24 23:27:11,524 INFO [train.py:450] Epoch 1, batch 6610, batch avg loss 0.3811, total avg loss: 0.3393, batch size: 39
2021-08-24 23:27:19,725 INFO [train.py:450] Epoch 1, batch 6620, batch avg loss 0.3092, total avg loss: 0.3282, batch size: 38
2021-08-24 23:27:28,939 INFO [train.py:450] Epoch 1, batch 6630, batch avg loss 0.3677, total avg loss: 0.3377, batch size: 39
2021-08-24 23:27:39,281 INFO [train.py:450] Epoch 1, batch 6640, batch avg loss 0.3605, total avg loss: 0.3417, batch size: 40
2021-08-24 23:27:47,720 INFO [train.py:450] Epoch 1, batch 6650, batch avg loss 0.3412, total avg loss: 0.3404, batch size: 43
2021-08-24 23:27:55,748 INFO [train.py:450] Epoch 1, batch 6660, batch avg loss 0.3062, total avg loss: 0.3430, batch size: 43
2021-08-24 23:28:04,120 INFO [train.py:450] Epoch 1, batch 6670, batch avg loss 0.4030, total avg loss: 0.3461, batch size: 44
2021-08-24 23:28:12,865 INFO [train.py:450] Epoch 1, batch 6680, batch avg loss 0.3280, total avg loss: 0.3463, batch size: 42
2021-08-24 23:28:20,913 INFO [train.py:450] Epoch 1, batch 6690, batch avg loss 0.3156, total avg loss: 0.3463, batch size: 40
2021-08-24 23:28:28,846 INFO [train.py:450] Epoch 1, batch 6700, batch avg loss 0.3516, total avg loss: 0.3451, batch size: 40
2021-08-24 23:28:37,085 INFO [train.py:450] Epoch 1, batch 6710, batch avg loss 0.3167, total avg loss: 0.3443, batch size: 38
2021-08-24 23:28:45,058 INFO [train.py:450] Epoch 1, batch 6720, batch avg loss 0.3375, total avg loss: 0.3454, batch size: 42
2021-08-24 23:28:53,187 INFO [train.py:450] Epoch 1, batch 6730, batch avg loss 0.4147, total avg loss: 0.3455, batch size: 41
2021-08-24 23:29:01,791 INFO [train.py:450] Epoch 1, batch 6740, batch avg loss 0.3222, total avg loss: 0.3451, batch size: 41
2021-08-24 23:29:09,720 INFO [train.py:450] Epoch 1, batch 6750, batch avg loss 0.3370, total avg loss: 0.3455, batch size: 43
2021-08-24 23:29:17,659 INFO [train.py:450] Epoch 1, batch 6760, batch avg loss 0.3492, total avg loss: 0.3451, batch size: 38
2021-08-24 23:29:25,558 INFO [train.py:450] Epoch 1, batch 6770, batch avg loss 0.3093, total avg loss: 0.3443, batch size: 40
2021-08-24 23:29:33,274 INFO [train.py:450] Epoch 1, batch 6780, batch avg loss 0.3370, total avg loss: 0.3453, batch size: 39
2021-08-24 23:29:40,731 INFO [train.py:450] Epoch 1, batch 6790, batch avg loss 0.3849, total avg loss: 0.3467, batch size: 40
2021-08-24 23:29:48,643 INFO [train.py:450] Epoch 1, batch 6800, batch avg loss 0.3476, total avg loss: 0.3471, batch size: 42
2021-08-24 23:29:56,581 INFO [train.py:450] Epoch 1, batch 6810, batch avg loss 0.3277, total avg loss: 0.3318, batch size: 41
2021-08-24 23:30:04,291 INFO [train.py:450] Epoch 1, batch 6820, batch avg loss 0.3239, total avg loss: 0.3397, batch size: 41
2021-08-24 23:30:11,742 INFO [train.py:450] Epoch 1, batch 6830, batch avg loss 0.2888, total avg loss: 0.3450, batch size: 42
2021-08-24 23:30:19,205 INFO [train.py:450] Epoch 1, batch 6840, batch avg loss 0.3289, total avg loss: 0.3426, batch size: 42
2021-08-24 23:30:26,680 INFO [train.py:450] Epoch 1, batch 6850, batch avg loss 0.3223, total avg loss: 0.3461, batch size: 37
2021-08-24 23:30:35,032 INFO [train.py:450] Epoch 1, batch 6860, batch avg loss 0.3598, total avg loss: 0.3464, batch size: 41
2021-08-24 23:30:42,339 INFO [train.py:450] Epoch 1, batch 6870, batch avg loss 0.3382, total avg loss: 0.3470, batch size: 38
2021-08-24 23:30:50,012 INFO [train.py:450] Epoch 1, batch 6880, batch avg loss 0.3097, total avg loss: 0.3454, batch size: 38
2021-08-24 23:30:58,213 INFO [train.py:450] Epoch 1, batch 6890, batch avg loss 0.3200, total avg loss: 0.3465, batch size: 41
2021-08-24 23:31:06,082 INFO [train.py:450] Epoch 1, batch 6900, batch avg loss 0.3454, total avg loss: 0.3449, batch size: 44
2021-08-24 23:31:13,609 INFO [train.py:450] Epoch 1, batch 6910, batch avg loss 0.3307, total avg loss: 0.3442, batch size: 40
2021-08-24 23:31:22,378 INFO [train.py:450] Epoch 1, batch 6920, batch avg loss 0.3112, total avg loss: 0.3439, batch size: 38
2021-08-24 23:31:30,074 INFO [train.py:450] Epoch 1, batch 6930, batch avg loss 0.3332, total avg loss: 0.3430, batch size: 38
2021-08-24 23:31:37,544 INFO [train.py:450] Epoch 1, batch 6940, batch avg loss 0.3505, total avg loss: 0.3434, batch size: 39
2021-08-24 23:31:45,068 INFO [train.py:450] Epoch 1, batch 6950, batch avg loss 0.3580, total avg loss: 0.3447, batch size: 38
2021-08-24 23:31:52,716 INFO [train.py:450] Epoch 1, batch 6960, batch avg loss 0.3239, total avg loss: 0.3455, batch size: 38
2021-08-24 23:32:00,223 INFO [train.py:450] Epoch 1, batch 6970, batch avg loss 0.3403, total avg loss: 0.3455, batch size: 38
2021-08-24 23:32:09,676 INFO [train.py:450] Epoch 1, batch 6980, batch avg loss 0.3640, total avg loss: 0.3456, batch size: 44
2021-08-24 23:32:18,671 INFO [train.py:450] Epoch 1, batch 6990, batch avg loss 0.4242, total avg loss: 0.3463, batch size: 37
2021-08-24 23:32:27,218 INFO [train.py:450] Epoch 1, batch 7000, batch avg loss 0.3722, total avg loss: 0.3457, batch size: 37
2021-08-24 23:33:23,527 INFO [train.py:482] Epoch 1, valid loss 0.2507, best valid loss: 0.2507 best valid epoch: 1
2021-08-24 23:33:29,439 INFO [train.py:450] Epoch 1, batch 7010, batch avg loss 0.4110, total avg loss: 0.3364, batch size: 42
2021-08-24 23:33:36,612 INFO [train.py:450] Epoch 1, batch 7020, batch avg loss 0.3866, total avg loss: 0.3330, batch size: 44
2021-08-24 23:33:44,632 INFO [train.py:450] Epoch 1, batch 7030, batch avg loss 0.3523, total avg loss: 0.3343, batch size: 38
2021-08-24 23:33:52,463 INFO [train.py:450] Epoch 1, batch 7040, batch avg loss 0.3594, total avg loss: 0.3389, batch size: 41
2021-08-24 23:33:59,502 INFO [train.py:450] Epoch 1, batch 7050, batch avg loss 0.3866, total avg loss: 0.3425, batch size: 44
2021-08-24 23:34:07,113 INFO [train.py:450] Epoch 1, batch 7060, batch avg loss 0.3408, total avg loss: 0.3478, batch size: 38
2021-08-24 23:34:14,540 INFO [train.py:450] Epoch 1, batch 7070, batch avg loss 0.3977, total avg loss: 0.3489, batch size: 39
2021-08-24 23:34:22,469 INFO [train.py:450] Epoch 1, batch 7080, batch avg loss 0.3563, total avg loss: 0.3500, batch size: 39
2021-08-24 23:34:29,558 INFO [train.py:450] Epoch 1, batch 7090, batch avg loss 0.3324, total avg loss: 0.3495, batch size: 41
2021-08-24 23:34:36,411 INFO [train.py:450] Epoch 1, batch 7100, batch avg loss 0.3358, total avg loss: 0.3498, batch size: 39
2021-08-24 23:34:44,009 INFO [train.py:450] Epoch 1, batch 7110, batch avg loss 0.3323, total avg loss: 0.3490, batch size: 37
2021-08-24 23:34:51,092 INFO [train.py:450] Epoch 1, batch 7120, batch avg loss 0.3115, total avg loss: 0.3485, batch size: 38
2021-08-24 23:34:58,312 INFO [train.py:450] Epoch 1, batch 7130, batch avg loss 0.3543, total avg loss: 0.3473, batch size: 39
2021-08-24 23:35:05,904 INFO [train.py:450] Epoch 1, batch 7140, batch avg loss 0.3337, total avg loss: 0.3481, batch size: 40
2021-08-24 23:35:12,870 INFO [train.py:450] Epoch 1, batch 7150, batch avg loss 0.3172, total avg loss: 0.3469, batch size: 38
2021-08-24 23:35:20,091 INFO [train.py:450] Epoch 1, batch 7160, batch avg loss 0.3652, total avg loss: 0.3471, batch size: 41
2021-08-24 23:35:28,183 INFO [train.py:450] Epoch 1, batch 7170, batch avg loss 0.4078, total avg loss: 0.3479, batch size: 40
2021-08-24 23:35:35,272 INFO [train.py:450] Epoch 1, batch 7180, batch avg loss 0.3103, total avg loss: 0.3488, batch size: 37
2021-08-24 23:35:42,035 INFO [train.py:450] Epoch 1, batch 7190, batch avg loss 0.3204, total avg loss: 0.3483, batch size: 39
2021-08-24 23:35:49,578 INFO [train.py:450] Epoch 1, batch 7200, batch avg loss 0.3342, total avg loss: 0.3487, batch size: 43
2021-08-24 23:35:56,970 INFO [train.py:450] Epoch 1, batch 7210, batch avg loss 0.3525, total avg loss: 0.3604, batch size: 41
2021-08-24 23:36:04,709 INFO [train.py:450] Epoch 1, batch 7220, batch avg loss 0.2855, total avg loss: 0.3537, batch size: 41
2021-08-24 23:36:11,390 INFO [train.py:450] Epoch 1, batch 7230, batch avg loss 0.3636, total avg loss: 0.3590, batch size: 38
2021-08-24 23:36:18,407 INFO [train.py:450] Epoch 1, batch 7240, batch avg loss 0.2761, total avg loss: 0.3571, batch size: 42
2021-08-24 23:36:25,798 INFO [train.py:450] Epoch 1, batch 7250, batch avg loss 0.3727, total avg loss: 0.3564, batch size: 37
2021-08-24 23:36:33,020 INFO [train.py:450] Epoch 1, batch 7260, batch avg loss 0.3655, total avg loss: 0.3527, batch size: 38
2021-08-24 23:36:41,207 INFO [train.py:450] Epoch 1, batch 7270, batch avg loss 0.3388, total avg loss: 0.3498, batch size: 42
2021-08-24 23:36:50,499 INFO [train.py:450] Epoch 1, batch 7280, batch avg loss 0.3419, total avg loss: 0.3499, batch size: 39
2021-08-24 23:36:59,232 INFO [train.py:450] Epoch 1, batch 7290, batch avg loss 0.3256, total avg loss: 0.3503, batch size: 39
2021-08-24 23:37:05,853 INFO [train.py:450] Epoch 1, batch 7300, batch avg loss 0.3503, total avg loss: 0.3506, batch size: 37
2021-08-24 23:37:12,735 INFO [train.py:450] Epoch 1, batch 7310, batch avg loss 0.3872, total avg loss: 0.3500, batch size: 41
2021-08-24 23:37:19,818 INFO [train.py:450] Epoch 1, batch 7320, batch avg loss 0.3970, total avg loss: 0.3502, batch size: 37
2021-08-24 23:37:27,042 INFO [train.py:450] Epoch 1, batch 7330, batch avg loss 0.3340, total avg loss: 0.3505, batch size: 39
2021-08-24 23:37:34,027 INFO [train.py:450] Epoch 1, batch 7340, batch avg loss 0.3284, total avg loss: 0.3495, batch size: 40
2021-08-24 23:37:41,382 INFO [train.py:450] Epoch 1, batch 7350, batch avg loss 0.3192, total avg loss: 0.3506, batch size: 40
2021-08-24 23:37:48,449 INFO [train.py:450] Epoch 1, batch 7360, batch avg loss 0.3558, total avg loss: 0.3506, batch size: 41
2021-08-24 23:37:55,293 INFO [train.py:450] Epoch 1, batch 7370, batch avg loss 0.3187, total avg loss: 0.3501, batch size: 39
2021-08-24 23:38:02,563 INFO [train.py:450] Epoch 1, batch 7380, batch avg loss 0.3417, total avg loss: 0.3501, batch size: 39
2021-08-24 23:38:09,561 INFO [train.py:450] Epoch 1, batch 7390, batch avg loss 0.3626, total avg loss: 0.3506, batch size: 39
2021-08-24 23:38:16,619 INFO [train.py:450] Epoch 1, batch 7400, batch avg loss 0.3354, total avg loss: 0.3497, batch size: 42
2021-08-24 23:38:23,691 INFO [train.py:450] Epoch 1, batch 7410, batch avg loss 0.3386, total avg loss: 0.3496, batch size: 37
2021-08-24 23:38:31,016 INFO [train.py:450] Epoch 1, batch 7420, batch avg loss 0.3862, total avg loss: 0.3540, batch size: 40
2021-08-24 23:38:38,833 INFO [train.py:450] Epoch 1, batch 7430, batch avg loss 0.3494, total avg loss: 0.3487, batch size: 40
2021-08-24 23:38:45,731 INFO [train.py:450] Epoch 1, batch 7440, batch avg loss 0.3674, total avg loss: 0.3452, batch size: 39
2021-08-24 23:38:53,054 INFO [train.py:450] Epoch 1, batch 7450, batch avg loss 0.3816, total avg loss: 0.3442, batch size: 38
2021-08-24 23:39:00,018 INFO [train.py:450] Epoch 1, batch 7460, batch avg loss 0.3254, total avg loss: 0.3437, batch size: 38
2021-08-24 23:39:07,023 INFO [train.py:450] Epoch 1, batch 7470, batch avg loss 0.3142, total avg loss: 0.3440, batch size: 41
2021-08-24 23:39:14,194 INFO [train.py:450] Epoch 1, batch 7480, batch avg loss 0.3080, total avg loss: 0.3443, batch size: 40
2021-08-24 23:39:20,796 INFO [train.py:450] Epoch 1, batch 7490, batch avg loss 0.3298, total avg loss: 0.3452, batch size: 41
2021-08-24 23:39:27,697 INFO [train.py:450] Epoch 1, batch 7500, batch avg loss 0.4964, total avg loss: 0.3468, batch size: 42
2021-08-24 23:39:34,440 INFO [train.py:450] Epoch 1, batch 7510, batch avg loss 0.3242, total avg loss: 0.3472, batch size: 39
2021-08-24 23:39:41,532 INFO [train.py:450] Epoch 1, batch 7520, batch avg loss 0.3231, total avg loss: 0.3464, batch size: 42
2021-08-24 23:39:48,684 INFO [train.py:450] Epoch 1, batch 7530, batch avg loss 0.3568, total avg loss: 0.3463, batch size: 37
2021-08-24 23:39:55,790 INFO [train.py:450] Epoch 1, batch 7540, batch avg loss 0.4061, total avg loss: 0.3457, batch size: 42
2021-08-24 23:40:02,622 INFO [train.py:450] Epoch 1, batch 7550, batch avg loss 0.3771, total avg loss: 0.3461, batch size: 39
2021-08-24 23:40:09,971 INFO [train.py:450] Epoch 1, batch 7560, batch avg loss 0.3835, total avg loss: 0.3463, batch size: 38
2021-08-24 23:40:16,717 INFO [train.py:450] Epoch 1, batch 7570, batch avg loss 0.3586, total avg loss: 0.3457, batch size: 40
2021-08-24 23:40:24,313 INFO [train.py:450] Epoch 1, batch 7580, batch avg loss 0.3236, total avg loss: 0.3454, batch size: 41
2021-08-24 23:40:31,504 INFO [train.py:450] Epoch 1, batch 7590, batch avg loss 0.2910, total avg loss: 0.3446, batch size: 41
2021-08-24 23:40:38,159 INFO [train.py:450] Epoch 1, batch 7600, batch avg loss 0.3156, total avg loss: 0.3450, batch size: 36
2021-08-24 23:40:45,126 INFO [train.py:450] Epoch 1, batch 7610, batch avg loss 0.3723, total avg loss: 0.3450, batch size: 38
2021-08-24 23:40:52,326 INFO [train.py:450] Epoch 1, batch 7620, batch avg loss 0.3784, total avg loss: 0.3576, batch size: 36
2021-08-24 23:40:59,832 INFO [train.py:450] Epoch 1, batch 7630, batch avg loss 0.3168, total avg loss: 0.3549, batch size: 42
2021-08-24 23:41:09,148 INFO [train.py:450] Epoch 1, batch 7640, batch avg loss 0.3505, total avg loss: 0.3514, batch size: 43
2021-08-24 23:41:16,343 INFO [train.py:450] Epoch 1, batch 7650, batch avg loss 0.3366, total avg loss: 0.3523, batch size: 37
2021-08-24 23:41:27,119 INFO [train.py:450] Epoch 1, batch 7660, batch avg loss 0.3264, total avg loss: 0.3507, batch size: 41
2021-08-24 23:41:34,510 INFO [train.py:450] Epoch 1, batch 7670, batch avg loss 0.3353, total avg loss: 0.3489, batch size: 40
2021-08-24 23:41:41,890 INFO [train.py:450] Epoch 1, batch 7680, batch avg loss 0.3186, total avg loss: 0.3475, batch size: 42
2021-08-24 23:41:49,106 INFO [train.py:450] Epoch 1, batch 7690, batch avg loss 0.3919, total avg loss: 0.3473, batch size: 41
2021-08-24 23:41:56,278 INFO [train.py:450] Epoch 1, batch 7700, batch avg loss 0.3999, total avg loss: 0.3482, batch size: 39
2021-08-24 23:42:03,131 INFO [train.py:450] Epoch 1, batch 7710, batch avg loss 0.3334, total avg loss: 0.3482, batch size: 42
2021-08-24 23:42:09,924 INFO [train.py:450] Epoch 1, batch 7720, batch avg loss 0.3417, total avg loss: 0.3478, batch size: 42
2021-08-24 23:42:16,955 INFO [train.py:450] Epoch 1, batch 7730, batch avg loss 0.3312, total avg loss: 0.3483, batch size: 39
2021-08-24 23:42:24,301 INFO [train.py:450] Epoch 1, batch 7740, batch avg loss 0.3228, total avg loss: 0.3485, batch size: 39
2021-08-24 23:42:31,678 INFO [train.py:450] Epoch 1, batch 7750, batch avg loss 0.3311, total avg loss: 0.3488, batch size: 38
2021-08-24 23:42:38,792 INFO [train.py:450] Epoch 1, batch 7760, batch avg loss 0.3338, total avg loss: 0.3497, batch size: 36
2021-08-24 23:42:45,798 INFO [train.py:450] Epoch 1, batch 7770, batch avg loss 0.3229, total avg loss: 0.3499, batch size: 37
2021-08-24 23:42:52,989 INFO [train.py:450] Epoch 1, batch 7780, batch avg loss 0.3284, total avg loss: 0.3495, batch size: 43
2021-08-24 23:43:00,278 INFO [train.py:450] Epoch 1, batch 7790, batch avg loss 0.3356, total avg loss: 0.3489, batch size: 41
2021-08-24 23:43:07,629 INFO [train.py:450] Epoch 1, batch 7800, batch avg loss 0.3245, total avg loss: 0.3484, batch size: 37
2021-08-24 23:43:14,735 INFO [train.py:450] Epoch 1, batch 7810, batch avg loss 0.2972, total avg loss: 0.3359, batch size: 37
2021-08-24 23:43:22,113 INFO [train.py:450] Epoch 1, batch 7820, batch avg loss 0.2913, total avg loss: 0.3429, batch size: 37
2021-08-24 23:43:28,979 INFO [train.py:450] Epoch 1, batch 7830, batch avg loss 0.2977, total avg loss: 0.3416, batch size: 37
2021-08-24 23:43:35,985 INFO [train.py:450] Epoch 1, batch 7840, batch avg loss 0.3518, total avg loss: 0.3433, batch size: 42
2021-08-24 23:43:43,767 INFO [train.py:450] Epoch 1, batch 7850, batch avg loss 0.3563, total avg loss: 0.3474, batch size: 41
2021-08-24 23:43:50,880 INFO [train.py:450] Epoch 1, batch 7860, batch avg loss 0.3340, total avg loss: 0.3432, batch size: 39
2021-08-24 23:43:58,132 INFO [train.py:450] Epoch 1, batch 7870, batch avg loss 0.3343, total avg loss: 0.3449, batch size: 42
2021-08-24 23:44:05,246 INFO [train.py:450] Epoch 1, batch 7880, batch avg loss 0.3303, total avg loss: 0.3473, batch size: 41
2021-08-24 23:44:12,640 INFO [train.py:450] Epoch 1, batch 7890, batch avg loss 0.4047, total avg loss: 0.3465, batch size: 40
2021-08-24 23:44:19,861 INFO [train.py:450] Epoch 1, batch 7900, batch avg loss 0.3583, total avg loss: 0.3467, batch size: 41
2021-08-24 23:44:27,002 INFO [train.py:450] Epoch 1, batch 7910, batch avg loss 0.4154, total avg loss: 0.3480, batch size: 41
2021-08-24 23:44:34,245 INFO [train.py:450] Epoch 1, batch 7920, batch avg loss 0.3257, total avg loss: 0.3477, batch size: 36
2021-08-24 23:44:41,457 INFO [train.py:450] Epoch 1, batch 7930, batch avg loss 0.3550, total avg loss: 0.3478, batch size: 40
2021-08-24 23:44:48,271 INFO [train.py:450] Epoch 1, batch 7940, batch avg loss 0.3108, total avg loss: 0.3464, batch size: 42
2021-08-24 23:44:55,410 INFO [train.py:450] Epoch 1, batch 7950, batch avg loss 0.3591, total avg loss: 0.3466, batch size: 40
2021-08-24 23:45:02,628 INFO [train.py:450] Epoch 1, batch 7960, batch avg loss 0.4046, total avg loss: 0.3469, batch size: 37
2021-08-24 23:45:09,924 INFO [train.py:450] Epoch 1, batch 7970, batch avg loss 0.3656, total avg loss: 0.3488, batch size: 41
2021-08-24 23:45:16,761 INFO [train.py:450] Epoch 1, batch 7980, batch avg loss 0.3472, total avg loss: 0.3482, batch size: 36
2021-08-24 23:45:23,889 INFO [train.py:450] Epoch 1, batch 7990, batch avg loss 0.3330, total avg loss: 0.3478, batch size: 39
2021-08-24 23:45:32,090 INFO [train.py:450] Epoch 1, batch 8000, batch avg loss 0.3880, total avg loss: 0.3481, batch size: 39
2021-08-24 23:46:10,021 INFO [train.py:482] Epoch 1, valid loss 0.2546, best valid loss: 0.2507 best valid epoch: 1
2021-08-24 23:46:15,932 INFO [train.py:450] Epoch 1, batch 8010, batch avg loss 0.4420, total avg loss: 0.3537, batch size: 37
2021-08-24 23:46:23,438 INFO [train.py:450] Epoch 1, batch 8020, batch avg loss 0.3166, total avg loss: 0.3462, batch size: 36
2021-08-24 23:46:30,884 INFO [train.py:450] Epoch 1, batch 8030, batch avg loss 0.3477, total avg loss: 0.3456, batch size: 39
2021-08-24 23:46:38,202 INFO [train.py:450] Epoch 1, batch 8040, batch avg loss 0.3370, total avg loss: 0.3439, batch size: 39
2021-08-24 23:46:45,501 INFO [train.py:450] Epoch 1, batch 8050, batch avg loss 0.3366, total avg loss: 0.3453, batch size: 40
2021-08-24 23:46:53,201 INFO [train.py:450] Epoch 1, batch 8060, batch avg loss 0.3793, total avg loss: 0.3454, batch size: 42
2021-08-24 23:47:00,771 INFO [train.py:450] Epoch 1, batch 8070, batch avg loss 0.3398, total avg loss: 0.3458, batch size: 40
2021-08-24 23:47:07,834 INFO [train.py:450] Epoch 1, batch 8080, batch avg loss 0.4528, total avg loss: 0.3476, batch size: 37
2021-08-24 23:47:14,901 INFO [train.py:450] Epoch 1, batch 8090, batch avg loss 0.3369, total avg loss: 0.3467, batch size: 43
2021-08-24 23:47:22,109 INFO [train.py:450] Epoch 1, batch 8100, batch avg loss 0.3935, total avg loss: 0.3463, batch size: 39
2021-08-24 23:47:29,614 INFO [train.py:450] Epoch 1, batch 8110, batch avg loss 0.3741, total avg loss: 0.3464, batch size: 40
2021-08-24 23:47:36,838 INFO [train.py:450] Epoch 1, batch 8120, batch avg loss 0.3446, total avg loss: 0.3478, batch size: 40
2021-08-24 23:47:43,517 INFO [train.py:450] Epoch 1, batch 8130, batch avg loss 0.3641, total avg loss: 0.3480, batch size: 39
2021-08-24 23:47:51,454 INFO [train.py:450] Epoch 1, batch 8140, batch avg loss 0.3556, total avg loss: 0.3481, batch size: 40
2021-08-24 23:47:58,666 INFO [train.py:450] Epoch 1, batch 8150, batch avg loss 0.3473, total avg loss: 0.3485, batch size: 39
2021-08-24 23:48:06,592 INFO [train.py:450] Epoch 1, batch 8160, batch avg loss 0.4241, total avg loss: 0.3494, batch size: 37
2021-08-24 23:48:14,021 INFO [train.py:450] Epoch 1, batch 8170, batch avg loss 0.3802, total avg loss: 0.3495, batch size: 38
2021-08-24 23:48:20,825 INFO [train.py:450] Epoch 1, batch 8180, batch avg loss 0.3543, total avg loss: 0.3495, batch size: 36
2021-08-24 23:48:28,100 INFO [train.py:450] Epoch 1, batch 8190, batch avg loss 0.3173, total avg loss: 0.3492, batch size: 37
2021-08-24 23:48:35,137 INFO [train.py:450] Epoch 1, batch 8200, batch avg loss 0.3407, total avg loss: 0.3487, batch size: 42
2021-08-24 23:48:42,758 INFO [train.py:450] Epoch 1, batch 8210, batch avg loss 0.3882, total avg loss: 0.3434, batch size: 38
2021-08-24 23:48:50,902 INFO [train.py:450] Epoch 1, batch 8220, batch avg loss 0.4393, total avg loss: 0.3430, batch size: 42
2021-08-24 23:48:57,520 INFO [train.py:450] Epoch 1, batch 8230, batch avg loss 0.3273, total avg loss: 0.3444, batch size: 39
2021-08-24 23:49:05,294 INFO [train.py:450] Epoch 1, batch 8240, batch avg loss 0.3762, total avg loss: 0.3484, batch size: 42
2021-08-24 23:49:12,192 INFO [train.py:450] Epoch 1, batch 8250, batch avg loss 0.3341, total avg loss: 0.3494, batch size: 41
2021-08-24 23:49:19,347 INFO [train.py:450] Epoch 1, batch 8260, batch avg loss 0.3214, total avg loss: 0.3467, batch size: 39
2021-08-24 23:49:26,660 INFO [train.py:450] Epoch 1, batch 8270, batch avg loss 0.3887, total avg loss: 0.3439, batch size: 38
2021-08-24 23:49:35,533 INFO [train.py:450] Epoch 1, batch 8280, batch avg loss 0.3209, total avg loss: 0.3443, batch size: 41
2021-08-24 23:49:42,080 INFO [train.py:450] Epoch 1, batch 8290, batch avg loss 0.3320, total avg loss: 0.3468, batch size: 37
2021-08-24 23:49:52,502 INFO [train.py:450] Epoch 1, batch 8300, batch avg loss 0.3725, total avg loss: 0.3471, batch size: 43
2021-08-24 23:49:59,292 INFO [train.py:450] Epoch 1, batch 8310, batch avg loss 0.3424, total avg loss: 0.3446, batch size: 40
2021-08-24 23:50:06,548 INFO [train.py:450] Epoch 1, batch 8320, batch avg loss 0.3971, total avg loss: 0.3461, batch size: 41
2021-08-24 23:50:13,885 INFO [train.py:450] Epoch 1, batch 8330, batch avg loss 0.4070, total avg loss: 0.3469, batch size: 39
2021-08-24 23:50:21,607 INFO [train.py:450] Epoch 1, batch 8340, batch avg loss 0.3314, total avg loss: 0.3467, batch size: 43
2021-08-24 23:50:29,398 INFO [train.py:450] Epoch 1, batch 8350, batch avg loss 0.3544, total avg loss: 0.3474, batch size: 36
2021-08-24 23:50:36,444 INFO [train.py:450] Epoch 1, batch 8360, batch avg loss 0.4105, total avg loss: 0.3476, batch size: 38
2021-08-24 23:50:43,423 INFO [train.py:450] Epoch 1, batch 8370, batch avg loss 0.4217, total avg loss: 0.3484, batch size: 39
2021-08-24 23:50:50,989 INFO [train.py:450] Epoch 1, batch 8380, batch avg loss 0.3530, total avg loss: 0.3480, batch size: 41
2021-08-24 23:50:57,986 INFO [train.py:450] Epoch 1, batch 8390, batch avg loss 0.3601, total avg loss: 0.3477, batch size: 40
2021-08-24 23:51:05,101 INFO [train.py:450] Epoch 1, batch 8400, batch avg loss 0.3912, total avg loss: 0.3476, batch size: 43
2021-08-24 23:51:12,962 INFO [train.py:450] Epoch 1, batch 8410, batch avg loss 0.3076, total avg loss: 0.3542, batch size: 44
2021-08-24 23:51:20,191 INFO [train.py:450] Epoch 1, batch 8420, batch avg loss 0.2621, total avg loss: 0.3463, batch size: 41
2021-08-24 23:51:27,566 INFO [train.py:450] Epoch 1, batch 8430, batch avg loss 0.3354, total avg loss: 0.3468, batch size: 40
2021-08-24 23:51:34,778 INFO [train.py:450] Epoch 1, batch 8440, batch avg loss 0.3288, total avg loss: 0.3478, batch size: 43
2021-08-24 23:51:41,853 INFO [train.py:450] Epoch 1, batch 8450, batch avg loss 0.3374, total avg loss: 0.3473, batch size: 40
2021-08-24 23:51:49,111 INFO [train.py:450] Epoch 1, batch 8460, batch avg loss 0.3581, total avg loss: 0.3470, batch size: 38
2021-08-24 23:51:57,057 INFO [train.py:450] Epoch 1, batch 8470, batch avg loss 0.3019, total avg loss: 0.3447, batch size: 42
2021-08-24 23:52:04,408 INFO [train.py:450] Epoch 1, batch 8480, batch avg loss 0.4086, total avg loss: 0.3427, batch size: 42
2021-08-24 23:52:12,343 INFO [train.py:450] Epoch 1, batch 8490, batch avg loss 0.3313, total avg loss: 0.3423, batch size: 44
2021-08-24 23:52:19,553 INFO [train.py:450] Epoch 1, batch 8500, batch avg loss 0.3960, total avg loss: 0.3446, batch size: 39
2021-08-24 23:52:26,877 INFO [train.py:450] Epoch 1, batch 8510, batch avg loss 0.3635, total avg loss: 0.3451, batch size: 37
2021-08-24 23:52:33,982 INFO [train.py:450] Epoch 1, batch 8520, batch avg loss 0.3357, total avg loss: 0.3454, batch size: 38
2021-08-24 23:52:41,444 INFO [train.py:450] Epoch 1, batch 8530, batch avg loss 0.3487, total avg loss: 0.3448, batch size: 41
2021-08-24 23:52:48,710 INFO [train.py:450] Epoch 1, batch 8540, batch avg loss 0.3184, total avg loss: 0.3446, batch size: 39
2021-08-24 23:52:56,038 INFO [train.py:450] Epoch 1, batch 8550, batch avg loss 0.3537, total avg loss: 0.3450, batch size: 39
2021-08-24 23:53:03,416 INFO [train.py:450] Epoch 1, batch 8560, batch avg loss 0.3413, total avg loss: 0.3448, batch size: 41
2021-08-24 23:53:11,448 INFO [train.py:450] Epoch 1, batch 8570, batch avg loss 0.3306, total avg loss: 0.3449, batch size: 36
2021-08-24 23:53:18,082 INFO [train.py:450] Epoch 1, batch 8580, batch avg loss 0.3793, total avg loss: 0.3447, batch size: 43
2021-08-24 23:53:27,276 INFO [train.py:450] Epoch 1, batch 8590, batch avg loss 0.3469, total avg loss: 0.3450, batch size: 41
2021-08-24 23:53:34,659 INFO [train.py:450] Epoch 1, batch 8600, batch avg loss 0.3354, total avg loss: 0.3450, batch size: 41
2021-08-24 23:53:45,385 INFO [train.py:450] Epoch 1, batch 8610, batch avg loss 0.3207, total avg loss: 0.3405, batch size: 40
2021-08-24 23:53:53,767 INFO [train.py:450] Epoch 1, batch 8620, batch avg loss 0.3863, total avg loss: 0.3432, batch size: 40
2021-08-24 23:54:01,235 INFO [train.py:450] Epoch 1, batch 8630, batch avg loss 0.3199, total avg loss: 0.3420, batch size: 39
2021-08-24 23:54:08,623 INFO [train.py:450] Epoch 1, batch 8640, batch avg loss 0.3353, total avg loss: 0.3400, batch size: 41
2021-08-24 23:54:16,514 INFO [train.py:450] Epoch 1, batch 8650, batch avg loss 0.3315, total avg loss: 0.3413, batch size: 37
2021-08-24 23:54:23,643 INFO [train.py:450] Epoch 1, batch 8660, batch avg loss 0.3346, total avg loss: 0.3408, batch size: 37
2021-08-24 23:54:31,777 INFO [train.py:450] Epoch 1, batch 8670, batch avg loss 0.3700, total avg loss: 0.3409, batch size: 39
2021-08-24 23:54:39,226 INFO [train.py:450] Epoch 1, batch 8680, batch avg loss 0.3049, total avg loss: 0.3411, batch size: 39
2021-08-24 23:54:45,998 INFO [train.py:450] Epoch 1, batch 8690, batch avg loss 0.3313, total avg loss: 0.3404, batch size: 40
2021-08-24 23:54:53,375 INFO [train.py:450] Epoch 1, batch 8700, batch avg loss 0.3137, total avg loss: 0.3399, batch size: 38
2021-08-24 23:55:00,575 INFO [train.py:450] Epoch 1, batch 8710, batch avg loss 0.3494, total avg loss: 0.3428, batch size: 44
2021-08-24 23:55:08,100 INFO [train.py:450] Epoch 1, batch 8720, batch avg loss 0.3661, total avg loss: 0.3441, batch size: 41
2021-08-24 23:55:15,715 INFO [train.py:450] Epoch 1, batch 8730, batch avg loss 0.3390, total avg loss: 0.3439, batch size: 43
2021-08-24 23:55:23,111 INFO [train.py:450] Epoch 1, batch 8740, batch avg loss 0.3889, total avg loss: 0.3439, batch size: 42
2021-08-24 23:55:30,671 INFO [train.py:450] Epoch 1, batch 8750, batch avg loss 0.3275, total avg loss: 0.3432, batch size: 39
2021-08-24 23:55:38,134 INFO [train.py:450] Epoch 1, batch 8760, batch avg loss 0.3366, total avg loss: 0.3437, batch size: 40
2021-08-24 23:55:45,684 INFO [train.py:450] Epoch 1, batch 8770, batch avg loss 0.3966, total avg loss: 0.3450, batch size: 39
2021-08-24 23:55:53,408 INFO [train.py:450] Epoch 1, batch 8780, batch avg loss 0.4171, total avg loss: 0.3454, batch size: 45
2021-08-24 23:56:01,587 INFO [train.py:450] Epoch 1, batch 8790, batch avg loss 0.3115, total avg loss: 0.3463, batch size: 39
2021-08-24 23:56:09,214 INFO [train.py:450] Epoch 1, batch 8800, batch avg loss 0.3283, total avg loss: 0.3460, batch size: 40
2021-08-24 23:56:17,620 INFO [train.py:450] Epoch 1, batch 8810, batch avg loss 0.3204, total avg loss: 0.3328, batch size: 41
2021-08-24 23:56:25,224 INFO [train.py:450] Epoch 1, batch 8820, batch avg loss 0.3140, total avg loss: 0.3368, batch size: 41
2021-08-24 23:56:32,980 INFO [train.py:450] Epoch 1, batch 8830, batch avg loss 0.4564, total avg loss: 0.3459, batch size: 38
2021-08-24 23:56:40,370 INFO [train.py:450] Epoch 1, batch 8840, batch avg loss 0.4069, total avg loss: 0.3477, batch size: 37
2021-08-24 23:56:48,242 INFO [train.py:450] Epoch 1, batch 8850, batch avg loss 0.3696, total avg loss: 0.3485, batch size: 39
2021-08-24 23:56:55,933 INFO [train.py:450] Epoch 1, batch 8860, batch avg loss 0.2971, total avg loss: 0.3485, batch size: 40
2021-08-24 23:57:03,248 INFO [train.py:450] Epoch 1, batch 8870, batch avg loss 0.3374, total avg loss: 0.3468, batch size: 40
2021-08-24 23:57:11,332 INFO [train.py:450] Epoch 1, batch 8880, batch avg loss 0.3353, total avg loss: 0.3474, batch size: 43
2021-08-24 23:57:18,899 INFO [train.py:450] Epoch 1, batch 8890, batch avg loss 0.3156, total avg loss: 0.3464, batch size: 40
2021-08-24 23:57:26,663 INFO [train.py:450] Epoch 1, batch 8900, batch avg loss 0.3459, total avg loss: 0.3474, batch size: 38
2021-08-24 23:57:33,967 INFO [train.py:450] Epoch 1, batch 8910, batch avg loss 0.2988, total avg loss: 0.3459, batch size: 39
2021-08-24 23:57:43,164 INFO [train.py:450] Epoch 1, batch 8920, batch avg loss 0.4033, total avg loss: 0.3468, batch size: 35
2021-08-24 23:57:50,788 INFO [train.py:450] Epoch 1, batch 8930, batch avg loss 0.3326, total avg loss: 0.3458, batch size: 40
2021-08-24 23:58:01,915 INFO [train.py:450] Epoch 1, batch 8940, batch avg loss 0.3772, total avg loss: 0.3460, batch size: 41
2021-08-24 23:58:09,523 INFO [train.py:450] Epoch 1, batch 8950, batch avg loss 0.3363, total avg loss: 0.3453, batch size: 41
2021-08-24 23:58:17,210 INFO [train.py:450] Epoch 1, batch 8960, batch avg loss 0.3361, total avg loss: 0.3443, batch size: 42
2021-08-24 23:58:24,976 INFO [train.py:450] Epoch 1, batch 8970, batch avg loss 0.3501, total avg loss: 0.3436, batch size: 39
2021-08-24 23:58:32,478 INFO [train.py:450] Epoch 1, batch 8980, batch avg loss 0.3397, total avg loss: 0.3439, batch size: 40
2021-08-24 23:58:40,035 INFO [train.py:450] Epoch 1, batch 8990, batch avg loss 0.3515, total avg loss: 0.3448, batch size: 39
2021-08-24 23:58:47,800 INFO [train.py:450] Epoch 1, batch 9000, batch avg loss 0.3328, total avg loss: 0.3456, batch size: 39
2021-08-24 23:59:27,276 INFO [train.py:482] Epoch 1, valid loss 0.2509, best valid loss: 0.2507 best valid epoch: 1
2021-08-24 23:59:33,933 INFO [train.py:450] Epoch 1, batch 9010, batch avg loss 0.3703, total avg loss: 0.3494, batch size: 38
2021-08-24 23:59:41,636 INFO [train.py:450] Epoch 1, batch 9020, batch avg loss 0.3665, total avg loss: 0.3442, batch size: 39
2021-08-24 23:59:49,284 INFO [train.py:450] Epoch 1, batch 9030, batch avg loss 0.3221, total avg loss: 0.3425, batch size: 39
2021-08-24 23:59:57,493 INFO [train.py:450] Epoch 1, batch 9040, batch avg loss 0.3781, total avg loss: 0.3459, batch size: 39
2021-08-25 00:00:05,342 INFO [train.py:450] Epoch 1, batch 9050, batch avg loss 0.3068, total avg loss: 0.3454, batch size: 44
2021-08-25 00:00:13,449 INFO [train.py:450] Epoch 1, batch 9060, batch avg loss 0.3267, total avg loss: 0.3445, batch size: 40
2021-08-25 00:00:21,508 INFO [train.py:450] Epoch 1, batch 9070, batch avg loss 0.3446, total avg loss: 0.3445, batch size: 42
2021-08-25 00:00:29,303 INFO [train.py:450] Epoch 1, batch 9080, batch avg loss 0.3459, total avg loss: 0.3436, batch size: 40
2021-08-25 00:00:37,823 INFO [train.py:450] Epoch 1, batch 9090, batch avg loss 0.3702, total avg loss: 0.3453, batch size: 41
2021-08-25 00:00:45,319 INFO [train.py:450] Epoch 1, batch 9100, batch avg loss 0.3390, total avg loss: 0.3448, batch size: 37
2021-08-25 00:00:52,983 INFO [train.py:450] Epoch 1, batch 9110, batch avg loss 0.3040, total avg loss: 0.3451, batch size: 40
2021-08-25 00:01:00,777 INFO [train.py:450] Epoch 1, batch 9120, batch avg loss 0.3614, total avg loss: 0.3458, batch size: 37
2021-08-25 00:01:08,009 INFO [train.py:450] Epoch 1, batch 9130, batch avg loss 0.3532, total avg loss: 0.3466, batch size: 37
2021-08-25 00:01:16,065 INFO [train.py:450] Epoch 1, batch 9140, batch avg loss 0.3986, total avg loss: 0.3477, batch size: 40
2021-08-25 00:01:23,888 INFO [train.py:450] Epoch 1, batch 9150, batch avg loss 0.3533, total avg loss: 0.3480, batch size: 41
2021-08-25 00:01:31,469 INFO [train.py:450] Epoch 1, batch 9160, batch avg loss 0.3345, total avg loss: 0.3484, batch size: 40
2021-08-25 00:01:38,917 INFO [train.py:450] Epoch 1, batch 9170, batch avg loss 0.3273, total avg loss: 0.3485, batch size: 43
2021-08-25 00:01:46,064 INFO [train.py:450] Epoch 1, batch 9180, batch avg loss 0.3849, total avg loss: 0.3484, batch size: 39
2021-08-25 00:01:53,723 INFO [train.py:450] Epoch 1, batch 9190, batch avg loss 0.3676, total avg loss: 0.3488, batch size: 37
2021-08-25 00:02:02,683 INFO [train.py:450] Epoch 1, batch 9200, batch avg loss 0.3713, total avg loss: 0.3484, batch size: 37
2021-08-25 00:02:12,288 INFO [train.py:450] Epoch 1, batch 9210, batch avg loss 0.3025, total avg loss: 0.3593, batch size: 39
2021-08-25 00:02:21,307 INFO [train.py:450] Epoch 1, batch 9220, batch avg loss 0.3432, total avg loss: 0.3561, batch size: 39
2021-08-25 00:02:28,836 INFO [train.py:450] Epoch 1, batch 9230, batch avg loss 0.3957, total avg loss: 0.3553, batch size: 37
2021-08-25 00:02:36,764 INFO [train.py:450] Epoch 1, batch 9240, batch avg loss 0.3333, total avg loss: 0.3508, batch size: 42
2021-08-25 00:02:44,326 INFO [train.py:450] Epoch 1, batch 9250, batch avg loss 0.3757, total avg loss: 0.3502, batch size: 38
2021-08-25 00:02:52,133 INFO [train.py:450] Epoch 1, batch 9260, batch avg loss 0.4221, total avg loss: 0.3520, batch size: 43
2021-08-25 00:02:59,264 INFO [train.py:450] Epoch 1, batch 9270, batch avg loss 0.3386, total avg loss: 0.3509, batch size: 39
2021-08-25 00:03:06,486 INFO [train.py:450] Epoch 1, batch 9280, batch avg loss 0.3687, total avg loss: 0.3524, batch size: 39
2021-08-25 00:03:13,932 INFO [train.py:450] Epoch 1, batch 9290, batch avg loss 0.3353, total avg loss: 0.3501, batch size: 41
2021-08-25 00:03:20,847 INFO [train.py:450] Epoch 1, batch 9300, batch avg loss 0.3442, total avg loss: 0.3474, batch size: 40
2021-08-25 00:03:28,479 INFO [train.py:450] Epoch 1, batch 9310, batch avg loss 0.3321, total avg loss: 0.3471, batch size: 37
2021-08-25 00:03:36,844 INFO [train.py:450] Epoch 1, batch 9320, batch avg loss 0.3277, total avg loss: 0.3459, batch size: 40
2021-08-25 00:03:45,489 INFO [train.py:450] Epoch 1, batch 9330, batch avg loss 0.4203, total avg loss: 0.3462, batch size: 36
2021-08-25 00:03:53,887 INFO [train.py:450] Epoch 1, batch 9340, batch avg loss 0.3709, total avg loss: 0.3446, batch size: 40
2021-08-25 00:04:02,742 INFO [train.py:450] Epoch 1, batch 9350, batch avg loss 0.3814, total avg loss: 0.3456, batch size: 39
2021-08-25 00:04:11,345 INFO [train.py:450] Epoch 1, batch 9360, batch avg loss 0.3900, total avg loss: 0.3450, batch size: 38
2021-08-25 00:04:19,272 INFO [train.py:450] Epoch 1, batch 9370, batch avg loss 0.3379, total avg loss: 0.3445, batch size: 35
2021-08-25 00:04:28,991 INFO [train.py:450] Epoch 1, batch 9380, batch avg loss 0.4384, total avg loss: 0.3448, batch size: 42
2021-08-25 00:04:37,507 INFO [train.py:450] Epoch 1, batch 9390, batch avg loss 0.3804, total avg loss: 0.3449, batch size: 43
2021-08-25 00:04:46,284 INFO [train.py:450] Epoch 1, batch 9400, batch avg loss 0.4161, total avg loss: 0.3446, batch size: 42
2021-08-25 00:04:54,836 INFO [train.py:450] Epoch 1, batch 9410, batch avg loss 0.3414, total avg loss: 0.3375, batch size: 38
2021-08-25 00:05:03,271 INFO [train.py:450] Epoch 1, batch 9420, batch avg loss 0.3358, total avg loss: 0.3434, batch size: 38
2021-08-25 00:05:12,125 INFO [train.py:450] Epoch 1, batch 9430, batch avg loss 0.3405, total avg loss: 0.3433, batch size: 40
2021-08-25 00:05:20,321 INFO [train.py:450] Epoch 1, batch 9440, batch avg loss 0.3030, total avg loss: 0.3421, batch size: 40
2021-08-25 00:05:29,571 INFO [train.py:450] Epoch 1, batch 9450, batch avg loss 0.3252, total avg loss: 0.3473, batch size: 39
2021-08-25 00:05:38,156 INFO [train.py:450] Epoch 1, batch 9460, batch avg loss 0.3183, total avg loss: 0.3479, batch size: 36
2021-08-25 00:05:47,214 INFO [train.py:450] Epoch 1, batch 9470, batch avg loss 0.3904, total avg loss: 0.3476, batch size: 43
2021-08-25 00:05:55,531 INFO [train.py:450] Epoch 1, batch 9480, batch avg loss 0.3865, total avg loss: 0.3491, batch size: 41
2021-08-25 00:06:04,232 INFO [train.py:450] Epoch 1, batch 9490, batch avg loss 0.3113, total avg loss: 0.3491, batch size: 41
2021-08-25 00:06:12,464 INFO [train.py:450] Epoch 1, batch 9500, batch avg loss 0.3260, total avg loss: 0.3470, batch size: 39
2021-08-25 00:06:21,227 INFO [train.py:450] Epoch 1, batch 9510, batch avg loss 0.3243, total avg loss: 0.3467, batch size: 39
2021-08-25 00:06:29,448 INFO [train.py:450] Epoch 1, batch 9520, batch avg loss 0.3335, total avg loss: 0.3477, batch size: 39
2021-08-25 00:06:39,097 INFO [train.py:450] Epoch 1, batch 9530, batch avg loss 0.3220, total avg loss: 0.3465, batch size: 37
2021-08-25 00:06:47,796 INFO [train.py:450] Epoch 1, batch 9540, batch avg loss 0.3284, total avg loss: 0.3462, batch size: 42
2021-08-25 00:06:59,270 INFO [train.py:450] Epoch 1, batch 9550, batch avg loss 0.3825, total avg loss: 0.3463, batch size: 42
2021-08-25 00:07:07,370 INFO [train.py:450] Epoch 1, batch 9560, batch avg loss 0.3512, total avg loss: 0.3466, batch size: 39
2021-08-25 00:07:15,537 INFO [train.py:450] Epoch 1, batch 9570, batch avg loss 0.3460, total avg loss: 0.3464, batch size: 41
2021-08-25 00:07:23,615 INFO [train.py:450] Epoch 1, batch 9580, batch avg loss 0.2939, total avg loss: 0.3470, batch size: 39
2021-08-25 00:07:31,878 INFO [train.py:450] Epoch 1, batch 9590, batch avg loss 0.4263, total avg loss: 0.3477, batch size: 38
2021-08-25 00:07:40,704 INFO [train.py:450] Epoch 1, batch 9600, batch avg loss 0.3908, total avg loss: 0.3479, batch size: 39
2021-08-25 00:07:48,473 INFO [train.py:450] Epoch 1, batch 9610, batch avg loss 0.2975, total avg loss: 0.3320, batch size: 36
2021-08-25 00:07:56,984 INFO [train.py:450] Epoch 1, batch 9620, batch avg loss 0.3125, total avg loss: 0.3276, batch size: 42
2021-08-25 00:08:04,847 INFO [train.py:450] Epoch 1, batch 9630, batch avg loss 0.3761, total avg loss: 0.3392, batch size: 42
2021-08-25 00:08:13,259 INFO [train.py:450] Epoch 1, batch 9640, batch avg loss 0.3252, total avg loss: 0.3418, batch size: 41
2021-08-25 00:08:21,808 INFO [train.py:450] Epoch 1, batch 9650, batch avg loss 0.3156, total avg loss: 0.3448, batch size: 40
2021-08-25 00:08:29,564 INFO [train.py:450] Epoch 1, batch 9660, batch avg loss 0.3039, total avg loss: 0.3458, batch size: 39
2021-08-25 00:08:37,539 INFO [train.py:450] Epoch 1, batch 9670, batch avg loss 0.2995, total avg loss: 0.3464, batch size: 39
2021-08-25 00:08:46,109 INFO [train.py:450] Epoch 1, batch 9680, batch avg loss 0.3261, total avg loss: 0.3439, batch size: 41
2021-08-25 00:08:53,971 INFO [train.py:450] Epoch 1, batch 9690, batch avg loss 0.3836, total avg loss: 0.3451, batch size: 39
2021-08-25 00:09:02,016 INFO [train.py:450] Epoch 1, batch 9700, batch avg loss 0.3057, total avg loss: 0.3444, batch size: 38
2021-08-25 00:09:10,162 INFO [train.py:450] Epoch 1, batch 9710, batch avg loss 0.3251, total avg loss: 0.3441, batch size: 39
2021-08-25 00:09:18,239 INFO [train.py:450] Epoch 1, batch 9720, batch avg loss 0.4463, total avg loss: 0.3447, batch size: 44
2021-08-25 00:09:26,225 INFO [train.py:450] Epoch 1, batch 9730, batch avg loss 0.2866, total avg loss: 0.3447, batch size: 37
2021-08-25 00:09:34,173 INFO [train.py:450] Epoch 1, batch 9740, batch avg loss 0.3015, total avg loss: 0.3446, batch size: 36
2021-08-25 00:09:42,049 INFO [train.py:450] Epoch 1, batch 9750, batch avg loss 0.4020, total avg loss: 0.3447, batch size: 39
2021-08-25 00:09:48,478 WARNING [cut.py:1694] To perform mix, energy must be non-zero and non-negative (got 0.0).  MonoCut with id "173ba4fa-bab6-b572-ca33-fd240a7279e5" will not be mixed in.
2021-08-25 00:09:50,069 INFO [train.py:450] Epoch 1, batch 9760, batch avg loss 0.3745, total avg loss: 0.3460, batch size: 40
2021-08-25 00:09:58,226 INFO [train.py:450] Epoch 1, batch 9770, batch avg loss 0.3842, total avg loss: 0.3466, batch size: 38
2021-08-25 00:10:05,624 INFO [train.py:450] Epoch 1, batch 9780, batch avg loss 0.3965, total avg loss: 0.3468, batch size: 39
2021-08-25 00:10:13,955 INFO [train.py:450] Epoch 1, batch 9790, batch avg loss 0.4048, total avg loss: 0.3472, batch size: 40
2021-08-25 00:10:22,036 INFO [train.py:450] Epoch 1, batch 9800, batch avg loss 0.3728, total avg loss: 0.3472, batch size: 39
2021-08-25 00:10:30,487 INFO [train.py:450] Epoch 1, batch 9810, batch avg loss 0.2995, total avg loss: 0.3368, batch size: 37
2021-08-25 00:10:38,647 INFO [train.py:450] Epoch 1, batch 9820, batch avg loss 0.3221, total avg loss: 0.3360, batch size: 39
2021-08-25 00:10:46,584 INFO [train.py:450] Epoch 1, batch 9830, batch avg loss 0.3196, total avg loss: 0.3374, batch size: 39
2021-08-25 00:10:54,803 INFO [train.py:450] Epoch 1, batch 9840, batch avg loss 0.3364, total avg loss: 0.3410, batch size: 41
2021-08-25 00:11:03,062 INFO [train.py:450] Epoch 1, batch 9850, batch avg loss 0.3416, total avg loss: 0.3403, batch size: 38
2021-08-25 00:11:10,835 INFO [train.py:450] Epoch 1, batch 9860, batch avg loss 0.3534, total avg loss: 0.3440, batch size: 39
2021-08-25 00:11:18,903 INFO [train.py:450] Epoch 1, batch 9870, batch avg loss 0.3323, total avg loss: 0.3428, batch size: 41
2021-08-25 00:11:28,417 INFO [train.py:450] Epoch 1, batch 9880, batch avg loss 0.2911, total avg loss: 0.3413, batch size: 43
2021-08-25 00:11:36,611 INFO [train.py:450] Epoch 1, batch 9890, batch avg loss 0.3248, total avg loss: 0.3414, batch size: 38
2021-08-25 00:11:48,622 INFO [train.py:450] Epoch 1, batch 9900, batch avg loss 0.3508, total avg loss: 0.3415, batch size: 44
2021-08-25 00:11:56,972 INFO [train.py:450] Epoch 1, batch 9910, batch avg loss 0.3468, total avg loss: 0.3419, batch size: 41
2021-08-25 00:12:05,100 INFO [train.py:450] Epoch 1, batch 9920, batch avg loss 0.3984, total avg loss: 0.3429, batch size: 41
2021-08-25 00:12:13,162 INFO [train.py:450] Epoch 1, batch 9930, batch avg loss 0.3300, total avg loss: 0.3428, batch size: 44
2021-08-25 00:12:21,529 INFO [train.py:450] Epoch 1, batch 9940, batch avg loss 0.3561, total avg loss: 0.3420, batch size: 41
2021-08-25 00:12:29,695 INFO [train.py:450] Epoch 1, batch 9950, batch avg loss 0.3824, total avg loss: 0.3425, batch size: 38
2021-08-25 00:12:37,672 INFO [train.py:450] Epoch 1, batch 9960, batch avg loss 0.3719, total avg loss: 0.3420, batch size: 40
2021-08-25 00:12:45,659 INFO [train.py:450] Epoch 1, batch 9970, batch avg loss 0.3157, total avg loss: 0.3427, batch size: 39
2021-08-25 00:12:53,303 INFO [train.py:450] Epoch 1, batch 9980, batch avg loss 0.3379, total avg loss: 0.3424, batch size: 37
2021-08-25 00:13:01,207 INFO [train.py:450] Epoch 1, batch 9990, batch avg loss 0.3194, total avg loss: 0.3426, batch size: 42
2021-08-25 00:13:08,892 INFO [train.py:450] Epoch 1, batch 10000, batch avg loss 0.3453, total avg loss: 0.3432, batch size: 40
2021-08-25 00:13:47,817 INFO [train.py:482] Epoch 1, valid loss 0.2506, best valid loss: 0.2506 best valid epoch: 1
2021-08-25 00:13:53,770 INFO [train.py:450] Epoch 1, batch 10010, batch avg loss 0.3124, total avg loss: 0.3442, batch size: 39
2021-08-25 00:14:01,788 INFO [train.py:450] Epoch 1, batch 10020, batch avg loss 0.3275, total avg loss: 0.3430, batch size: 38
2021-08-25 00:14:09,678 INFO [train.py:450] Epoch 1, batch 10030, batch avg loss 0.3074, total avg loss: 0.3370, batch size: 41
2021-08-25 00:14:17,447 INFO [train.py:450] Epoch 1, batch 10040, batch avg loss 0.3494, total avg loss: 0.3391, batch size: 41
2021-08-25 00:14:25,760 INFO [train.py:450] Epoch 1, batch 10050, batch avg loss 0.3374, total avg loss: 0.3410, batch size: 41
2021-08-25 00:14:34,093 INFO [train.py:450] Epoch 1, batch 10060, batch avg loss 0.3429, total avg loss: 0.3419, batch size: 40
2021-08-25 00:14:41,889 INFO [train.py:450] Epoch 1, batch 10070, batch avg loss 0.3105, total avg loss: 0.3417, batch size: 41
2021-08-25 00:14:49,507 INFO [train.py:450] Epoch 1, batch 10080, batch avg loss 0.3561, total avg loss: 0.3411, batch size: 40
2021-08-25 00:14:57,138 INFO [train.py:450] Epoch 1, batch 10090, batch avg loss 0.4241, total avg loss: 0.3422, batch size: 42
2021-08-25 00:15:04,721 INFO [train.py:450] Epoch 1, batch 10100, batch avg loss 0.4191, total avg loss: 0.3428, batch size: 40
2021-08-25 00:15:12,085 INFO [train.py:450] Epoch 1, batch 10110, batch avg loss 0.3075, total avg loss: 0.3432, batch size: 38
2021-08-25 00:15:19,228 INFO [train.py:450] Epoch 1, batch 10120, batch avg loss 0.3092, total avg loss: 0.3422, batch size: 42
2021-08-25 00:15:26,893 INFO [train.py:450] Epoch 1, batch 10130, batch avg loss 0.3477, total avg loss: 0.3425, batch size: 39
2021-08-25 00:15:34,632 INFO [train.py:450] Epoch 1, batch 10140, batch avg loss 0.2883, total avg loss: 0.3426, batch size: 39
2021-08-25 00:15:42,219 INFO [train.py:450] Epoch 1, batch 10150, batch avg loss 0.4279, total avg loss: 0.3431, batch size: 40
2021-08-25 00:15:51,396 INFO [train.py:450] Epoch 1, batch 10160, batch avg loss 0.3552, total avg loss: 0.3437, batch size: 37
2021-08-25 00:16:00,426 INFO [train.py:450] Epoch 1, batch 10170, batch avg loss 0.3255, total avg loss: 0.3439, batch size: 38
2021-08-25 00:16:09,682 INFO [train.py:450] Epoch 1, batch 10180, batch avg loss 0.3193, total avg loss: 0.3431, batch size: 41
2021-08-25 00:16:17,314 INFO [train.py:450] Epoch 1, batch 10190, batch avg loss 0.3482, total avg loss: 0.3429, batch size: 38
2021-08-25 00:16:25,728 INFO [train.py:450] Epoch 1, batch 10200, batch avg loss 0.3075, total avg loss: 0.3432, batch size: 41
2021-08-25 00:16:33,158 INFO [train.py:450] Epoch 1, batch 10210, batch avg loss 0.3709, total avg loss: 0.3529, batch size: 38
2021-08-25 00:16:40,880 INFO [train.py:450] Epoch 1, batch 10220, batch avg loss 0.3637, total avg loss: 0.3625, batch size: 40
2021-08-25 00:16:48,639 INFO [train.py:450] Epoch 1, batch 10230, batch avg loss 0.3571, total avg loss: 0.3605, batch size: 39
2021-08-25 00:16:56,375 INFO [train.py:450] Epoch 1, batch 10240, batch avg loss 0.3785, total avg loss: 0.3590, batch size: 39
2021-08-25 00:17:03,825 INFO [train.py:450] Epoch 1, batch 10250, batch avg loss 0.3571, total avg loss: 0.3576, batch size: 41
2021-08-25 00:17:11,653 INFO [train.py:450] Epoch 1, batch 10260, batch avg loss 0.3277, total avg loss: 0.3545, batch size: 40
2021-08-25 00:17:19,299 INFO [train.py:450] Epoch 1, batch 10270, batch avg loss 0.2987, total avg loss: 0.3525, batch size: 40
2021-08-25 00:17:26,683 INFO [train.py:450] Epoch 1, batch 10280, batch avg loss 0.3969, total avg loss: 0.3505, batch size: 38
2021-08-25 00:17:34,653 INFO [train.py:450] Epoch 1, batch 10290, batch avg loss 0.3231, total avg loss: 0.3479, batch size: 43
2021-08-25 00:17:42,504 INFO [train.py:450] Epoch 1, batch 10300, batch avg loss 0.3546, total avg loss: 0.3486, batch size: 42
2021-08-25 00:17:49,376 INFO [train.py:450] Epoch 1, batch 10310, batch avg loss 0.3760, total avg loss: 0.3501, batch size: 38
2021-08-25 00:17:57,140 INFO [train.py:450] Epoch 1, batch 10320, batch avg loss 0.3261, total avg loss: 0.3503, batch size: 39
2021-08-25 00:18:04,829 INFO [train.py:450] Epoch 1, batch 10330, batch avg loss 0.3762, total avg loss: 0.3511, batch size: 39
2021-08-25 00:18:12,387 INFO [train.py:450] Epoch 1, batch 10340, batch avg loss 0.3236, total avg loss: 0.3498, batch size: 41
2021-08-25 00:18:20,153 INFO [train.py:450] Epoch 1, batch 10350, batch avg loss 0.3304, total avg loss: 0.3504, batch size: 39
2021-08-25 00:18:28,086 INFO [train.py:450] Epoch 1, batch 10360, batch avg loss 0.3247, total avg loss: 0.3507, batch size: 37
2021-08-25 00:18:35,415 INFO [train.py:450] Epoch 1, batch 10370, batch avg loss 0.3512, total avg loss: 0.3491, batch size: 41
2021-08-25 00:18:42,799 INFO [train.py:450] Epoch 1, batch 10380, batch avg loss 0.3639, total avg loss: 0.3486, batch size: 40
2021-08-25 00:18:50,647 INFO [train.py:450] Epoch 1, batch 10390, batch avg loss 0.3391, total avg loss: 0.3474, batch size: 40
2021-08-25 00:18:58,397 INFO [train.py:450] Epoch 1, batch 10400, batch avg loss 0.3621, total avg loss: 0.3475, batch size: 44
2021-08-25 00:19:05,768 INFO [train.py:450] Epoch 1, batch 10410, batch avg loss 0.3182, total avg loss: 0.3511, batch size: 43
2021-08-25 00:19:13,084 INFO [train.py:450] Epoch 1, batch 10420, batch avg loss 0.3168, total avg loss: 0.3440, batch size: 37
2021-08-25 00:19:20,331 INFO [train.py:450] Epoch 1, batch 10430, batch avg loss 0.3736, total avg loss: 0.3426, batch size: 37
2021-08-25 00:19:27,800 INFO [train.py:450] Epoch 1, batch 10440, batch avg loss 0.3557, total avg loss: 0.3412, batch size: 40
2021-08-25 00:19:36,219 INFO [train.py:450] Epoch 1, batch 10450, batch avg loss 0.3232, total avg loss: 0.3401, batch size: 41
2021-08-25 00:19:43,272 INFO [train.py:450] Epoch 1, batch 10460, batch avg loss 0.3035, total avg loss: 0.3401, batch size: 37
2021-08-25 00:19:55,010 INFO [train.py:450] Epoch 1, batch 10470, batch avg loss 0.3407, total avg loss: 0.3400, batch size: 37
2021-08-25 00:20:02,496 INFO [train.py:450] Epoch 1, batch 10480, batch avg loss 0.3445, total avg loss: 0.3403, batch size: 42
2021-08-25 00:20:10,550 INFO [train.py:450] Epoch 1, batch 10490, batch avg loss 0.3519, total avg loss: 0.3404, batch size: 40
2021-08-25 00:20:18,161 INFO [train.py:450] Epoch 1, batch 10500, batch avg loss 0.2915, total avg loss: 0.3399, batch size: 40
2021-08-25 00:20:25,336 INFO [train.py:450] Epoch 1, batch 10510, batch avg loss 0.3277, total avg loss: 0.3401, batch size: 40
2021-08-25 00:20:32,698 INFO [train.py:450] Epoch 1, batch 10520, batch avg loss 0.3118, total avg loss: 0.3402, batch size: 38
2021-08-25 00:20:40,000 INFO [train.py:450] Epoch 1, batch 10530, batch avg loss 0.3534, total avg loss: 0.3402, batch size: 39
2021-08-25 00:20:47,716 INFO [train.py:450] Epoch 1, batch 10540, batch avg loss 0.2922, total avg loss: 0.3398, batch size: 44
2021-08-25 00:20:55,393 INFO [train.py:450] Epoch 1, batch 10550, batch avg loss 0.3345, total avg loss: 0.3402, batch size: 42
2021-08-25 00:21:02,408 INFO [train.py:450] Epoch 1, batch 10560, batch avg loss 0.3764, total avg loss: 0.3410, batch size: 38
2021-08-25 00:21:09,395 INFO [train.py:450] Epoch 1, batch 10570, batch avg loss 0.4195, total avg loss: 0.3420, batch size: 40
2021-08-25 00:21:16,348 INFO [train.py:450] Epoch 1, batch 10580, batch avg loss 0.3468, total avg loss: 0.3410, batch size: 42
2021-08-25 00:21:20,976 WARNING [cut.py:1694] To perform mix, energy must be non-zero and non-negative (got 0.0).  MonoCut with id "62b87913-aca5-2efc-a64e-f2132f37401c" will not be mixed in.
2021-08-25 00:21:23,667 INFO [train.py:450] Epoch 1, batch 10590, batch avg loss 0.3254, total avg loss: 0.3409, batch size: 36
2021-08-25 00:21:31,539 INFO [train.py:450] Epoch 1, batch 10600, batch avg loss 0.3391, total avg loss: 0.3419, batch size: 39
2021-08-25 00:21:38,689 INFO [train.py:450] Epoch 1, batch 10610, batch avg loss 0.3769, total avg loss: 0.3336, batch size: 39
2021-08-25 00:21:46,059 INFO [train.py:450] Epoch 1, batch 10620, batch avg loss 0.3007, total avg loss: 0.3361, batch size: 39
2021-08-25 00:21:53,084 INFO [train.py:450] Epoch 1, batch 10630, batch avg loss 0.3791, total avg loss: 0.3443, batch size: 38
2021-08-25 00:22:00,619 INFO [train.py:450] Epoch 1, batch 10640, batch avg loss 0.3910, total avg loss: 0.3437, batch size: 39
2021-08-25 00:22:07,726 INFO [train.py:450] Epoch 1, batch 10650, batch avg loss 0.3642, total avg loss: 0.3420, batch size: 37
2021-08-25 00:22:15,141 INFO [train.py:450] Epoch 1, batch 10660, batch avg loss 0.3385, total avg loss: 0.3421, batch size: 37
2021-08-25 00:22:22,037 INFO [train.py:450] Epoch 1, batch 10670, batch avg loss 0.3082, total avg loss: 0.3419, batch size: 39
2021-08-25 00:22:29,328 INFO [train.py:450] Epoch 1, batch 10680, batch avg loss 0.3552, total avg loss: 0.3425, batch size: 41
2021-08-25 00:22:36,375 INFO [train.py:450] Epoch 1, batch 10690, batch avg loss 0.3464, total avg loss: 0.3423, batch size: 40
2021-08-25 00:22:42,983 INFO [train.py:450] Epoch 1, batch 10700, batch avg loss 0.3542, total avg loss: 0.3427, batch size: 39
2021-08-25 00:22:50,522 INFO [train.py:450] Epoch 1, batch 10710, batch avg loss 0.3919, total avg loss: 0.3444, batch size: 41
2021-08-25 00:22:57,704 INFO [train.py:450] Epoch 1, batch 10720, batch avg loss 0.4015, total avg loss: 0.3436, batch size: 35
2021-08-25 00:23:05,457 INFO [train.py:450] Epoch 1, batch 10730, batch avg loss 0.3426, total avg loss: 0.3432, batch size: 40
2021-08-25 00:23:12,849 INFO [train.py:450] Epoch 1, batch 10740, batch avg loss 0.3891, total avg loss: 0.3441, batch size: 42
2021-08-25 00:23:19,748 INFO [train.py:450] Epoch 1, batch 10750, batch avg loss 0.3458, total avg loss: 0.3441, batch size: 37
2021-08-25 00:23:26,752 INFO [train.py:450] Epoch 1, batch 10760, batch avg loss 0.3263, total avg loss: 0.3446, batch size: 40
2021-08-25 00:23:33,647 INFO [train.py:450] Epoch 1, batch 10770, batch avg loss 0.2841, total avg loss: 0.3439, batch size: 38
2021-08-25 00:23:40,821 INFO [train.py:450] Epoch 1, batch 10780, batch avg loss 0.3408, total avg loss: 0.3442, batch size: 41
2021-08-25 00:23:49,085 INFO [train.py:450] Epoch 1, batch 10790, batch avg loss 0.3692, total avg loss: 0.3438, batch size: 39
2021-08-25 00:23:56,706 INFO [train.py:450] Epoch 1, batch 10800, batch avg loss 0.3159, total avg loss: 0.3429, batch size: 39
2021-08-25 00:24:06,354 INFO [train.py:450] Epoch 1, batch 10810, batch avg loss 0.3319, total avg loss: 0.3367, batch size: 40
2021-08-25 00:24:13,667 INFO [train.py:450] Epoch 1, batch 10820, batch avg loss 0.3822, total avg loss: 0.3444, batch size: 42
2021-08-25 00:24:21,528 INFO [train.py:450] Epoch 1, batch 10830, batch avg loss 0.3380, total avg loss: 0.3413, batch size: 41
2021-08-25 00:24:28,907 INFO [train.py:450] Epoch 1, batch 10840, batch avg loss 0.3794, total avg loss: 0.3441, batch size: 40
2021-08-25 00:24:36,162 INFO [train.py:450] Epoch 1, batch 10850, batch avg loss 0.3033, total avg loss: 0.3420, batch size: 40
2021-08-25 00:24:43,166 INFO [train.py:450] Epoch 1, batch 10860, batch avg loss 0.3150, total avg loss: 0.3442, batch size: 36
2021-08-25 00:24:50,058 INFO [train.py:450] Epoch 1, batch 10870, batch avg loss 0.3186, total avg loss: 0.3435, batch size: 38
2021-08-25 00:24:57,402 INFO [train.py:450] Epoch 1, batch 10880, batch avg loss 0.3409, total avg loss: 0.3435, batch size: 40
2021-08-25 00:25:04,190 INFO [train.py:450] Epoch 1, batch 10890, batch avg loss 0.4121, total avg loss: 0.3445, batch size: 40
2021-08-25 00:25:11,213 INFO [train.py:450] Epoch 1, batch 10900, batch avg loss 0.3555, total avg loss: 0.3442, batch size: 38
2021-08-25 00:25:18,066 INFO [train.py:450] Epoch 1, batch 10910, batch avg loss 0.3290, total avg loss: 0.3433, batch size: 41
2021-08-25 00:25:24,889 INFO [train.py:450] Epoch 1, batch 10920, batch avg loss 0.3401, total avg loss: 0.3448, batch size: 48
2021-08-25 00:25:31,656 INFO [train.py:450] Epoch 1, batch 10930, batch avg loss 0.3371, total avg loss: 0.3435, batch size: 40
2021-08-25 00:25:38,836 INFO [train.py:450] Epoch 1, batch 10940, batch avg loss 0.3651, total avg loss: 0.3430, batch size: 40
2021-08-25 00:25:46,465 INFO [train.py:450] Epoch 1, batch 10950, batch avg loss 0.3361, total avg loss: 0.3434, batch size: 39
2021-08-25 00:25:53,543 INFO [train.py:450] Epoch 1, batch 10960, batch avg loss 0.2923, total avg loss: 0.3433, batch size: 38
2021-08-25 00:26:01,333 INFO [train.py:450] Epoch 1, batch 10970, batch avg loss 0.3328, total avg loss: 0.3433, batch size: 40
2021-08-25 00:26:08,264 INFO [train.py:450] Epoch 1, batch 10980, batch avg loss 0.3382, total avg loss: 0.3432, batch size: 41
2021-08-25 00:26:15,174 INFO [train.py:450] Epoch 1, batch 10990, batch avg loss 0.3176, total avg loss: 0.3431, batch size: 40
2021-08-25 00:26:22,022 INFO [train.py:450] Epoch 1, batch 11000, batch avg loss 0.3564, total avg loss: 0.3424, batch size: 44
2021-08-25 00:26:59,999 INFO [train.py:482] Epoch 1, valid loss 0.2488, best valid loss: 0.2488 best valid epoch: 1
2021-08-25 00:27:05,910 INFO [train.py:450] Epoch 1, batch 11010, batch avg loss 0.3153, total avg loss: 0.3495, batch size: 39
2021-08-25 00:27:12,695 INFO [train.py:450] Epoch 1, batch 11020, batch avg loss 0.3966, total avg loss: 0.3465, batch size: 38
2021-08-25 00:27:19,306 INFO [train.py:450] Epoch 1, batch 11030, batch avg loss 0.3351, total avg loss: 0.3465, batch size: 41
2021-08-25 00:27:26,480 INFO [train.py:450] Epoch 1, batch 11040, batch avg loss 0.3596, total avg loss: 0.3507, batch size: 44
2021-08-25 00:27:33,898 INFO [train.py:450] Epoch 1, batch 11050, batch avg loss 0.3203, total avg loss: 0.3538, batch size: 40
2021-08-25 00:27:40,940 INFO [train.py:450] Epoch 1, batch 11060, batch avg loss 0.3317, total avg loss: 0.3503, batch size: 37
2021-08-25 00:27:48,403 INFO [train.py:450] Epoch 1, batch 11070, batch avg loss 0.3353, total avg loss: 0.3502, batch size: 43
2021-08-25 00:27:55,688 INFO [train.py:450] Epoch 1, batch 11080, batch avg loss 0.3224, total avg loss: 0.3491, batch size: 40
2021-08-25 00:28:02,002 INFO [train.py:450] Epoch 1, batch 11090, batch avg loss 0.3838, total avg loss: 0.3483, batch size: 38
2021-08-25 00:28:08,103 INFO [train.py:450] Epoch 1, batch 11100, batch avg loss 0.4298, total avg loss: 0.3497, batch size: 40
2021-08-25 00:28:14,793 INFO [train.py:450] Epoch 1, batch 11110, batch avg loss 0.3649, total avg loss: 0.3495, batch size: 40
2021-08-25 00:28:21,841 INFO [train.py:450] Epoch 1, batch 11120, batch avg loss 0.3689, total avg loss: 0.3490, batch size: 40
2021-08-25 00:28:28,856 INFO [train.py:450] Epoch 1, batch 11130, batch avg loss 0.3331, total avg loss: 0.3500, batch size: 39
2021-08-25 00:28:36,207 INFO [train.py:450] Epoch 1, batch 11140, batch avg loss 0.3794, total avg loss: 0.3488, batch size: 40
2021-08-25 00:28:43,834 INFO [train.py:450] Epoch 1, batch 11150, batch avg loss 0.3596, total avg loss: 0.3493, batch size: 39
2021-08-25 00:28:52,227 INFO [train.py:450] Epoch 1, batch 11160, batch avg loss 0.3318, total avg loss: 0.3490, batch size: 41
2021-08-25 00:29:01,179 INFO [train.py:450] Epoch 1, batch 11170, batch avg loss 0.3864, total avg loss: 0.3504, batch size: 37
2021-08-25 00:29:08,204 INFO [train.py:450] Epoch 1, batch 11180, batch avg loss 0.3718, total avg loss: 0.3502, batch size: 42
2021-08-25 00:29:15,327 INFO [train.py:450] Epoch 1, batch 11190, batch avg loss 0.3247, total avg loss: 0.3500, batch size: 40
2021-08-25 00:29:22,244 INFO [train.py:450] Epoch 1, batch 11200, batch avg loss 0.4130, total avg loss: 0.3500, batch size: 40
2021-08-25 00:29:29,007 INFO [train.py:450] Epoch 1, batch 11210, batch avg loss 0.3689, total avg loss: 0.3615, batch size: 41
2021-08-25 00:29:35,604 INFO [train.py:450] Epoch 1, batch 11220, batch avg loss 0.3082, total avg loss: 0.3555, batch size: 39
2021-08-25 00:29:42,572 INFO [train.py:450] Epoch 1, batch 11230, batch avg loss 0.3435, total avg loss: 0.3517, batch size: 43
2021-08-25 00:29:49,376 INFO [train.py:450] Epoch 1, batch 11240, batch avg loss 0.3824, total avg loss: 0.3552, batch size: 38
2021-08-25 00:29:56,272 INFO [train.py:450] Epoch 1, batch 11250, batch avg loss 0.4319, total avg loss: 0.3554, batch size: 42
2021-08-25 00:30:03,189 INFO [train.py:450] Epoch 1, batch 11260, batch avg loss 0.4335, total avg loss: 0.3565, batch size: 39
2021-08-25 00:30:09,555 INFO [train.py:450] Epoch 1, batch 11270, batch avg loss 0.3243, total avg loss: 0.3561, batch size: 36
2021-08-25 00:30:17,063 INFO [train.py:450] Epoch 1, batch 11280, batch avg loss 0.3436, total avg loss: 0.3549, batch size: 44
2021-08-25 00:30:23,639 INFO [train.py:450] Epoch 1, batch 11290, batch avg loss 0.2804, total avg loss: 0.3524, batch size: 38
2021-08-25 00:30:30,443 INFO [train.py:450] Epoch 1, batch 11300, batch avg loss 0.3446, total avg loss: 0.3513, batch size: 38
2021-08-25 00:30:37,108 INFO [train.py:450] Epoch 1, batch 11310, batch avg loss 0.3652, total avg loss: 0.3531, batch size: 41
2021-08-25 00:30:44,000 INFO [train.py:450] Epoch 1, batch 11320, batch avg loss 0.3579, total avg loss: 0.3512, batch size: 38
2021-08-25 00:30:51,221 INFO [train.py:450] Epoch 1, batch 11330, batch avg loss 0.3397, total avg loss: 0.3519, batch size: 38
2021-08-25 00:30:58,661 INFO [train.py:450] Epoch 1, batch 11340, batch avg loss 0.3835, total avg loss: 0.3511, batch size: 42
2021-08-25 00:31:05,222 INFO [train.py:450] Epoch 1, batch 11350, batch avg loss 0.3511, total avg loss: 0.3515, batch size: 42
2021-08-25 00:31:11,877 INFO [train.py:450] Epoch 1, batch 11360, batch avg loss 0.3149, total avg loss: 0.3513, batch size: 41
2021-08-25 00:31:18,595 INFO [train.py:450] Epoch 1, batch 11370, batch avg loss 0.3314, total avg loss: 0.3514, batch size: 38
2021-08-25 00:31:25,104 INFO [train.py:450] Epoch 1, batch 11380, batch avg loss 0.3898, total avg loss: 0.3497, batch size: 37
2021-08-25 00:31:31,752 INFO [train.py:450] Epoch 1, batch 11390, batch avg loss 0.3506, total avg loss: 0.3505, batch size: 38
2021-08-25 00:31:38,135 INFO [train.py:450] Epoch 1, batch 11400, batch avg loss 0.3468, total avg loss: 0.3500, batch size: 37
2021-08-25 00:31:44,868 INFO [train.py:450] Epoch 1, batch 11410, batch avg loss 0.3889, total avg loss: 0.3608, batch size: 41
2021-08-25 00:31:51,567 INFO [train.py:450] Epoch 1, batch 11420, batch avg loss 0.3013, total avg loss: 0.3523, batch size: 38
2021-08-25 00:31:58,465 INFO [train.py:450] Epoch 1, batch 11430, batch avg loss 0.3182, total avg loss: 0.3474, batch size: 38
2021-08-25 00:32:04,872 INFO [train.py:450] Epoch 1, batch 11440, batch avg loss 0.3781, total avg loss: 0.3447, batch size: 39
2021-08-25 00:32:11,649 INFO [train.py:450] Epoch 1, batch 11450, batch avg loss 0.3890, total avg loss: 0.3474, batch size: 43
2021-08-25 00:32:18,718 INFO [train.py:450] Epoch 1, batch 11460, batch avg loss 0.3307, total avg loss: 0.3480, batch size: 41
2021-08-25 00:32:25,391 INFO [train.py:450] Epoch 1, batch 11470, batch avg loss 0.3284, total avg loss: 0.3471, batch size: 40
2021-08-25 00:32:31,677 INFO [train.py:450] Epoch 1, batch 11480, batch avg loss 0.3774, total avg loss: 0.3477, batch size: 37
2021-08-25 00:32:37,828 INFO [train.py:450] Epoch 1, batch 11490, batch avg loss 0.3374, total avg loss: 0.3469, batch size: 38
2021-08-25 00:32:44,226 INFO [train.py:450] Epoch 1, batch 11500, batch avg loss 0.3310, total avg loss: 0.3471, batch size: 35
2021-08-25 00:32:50,892 INFO [train.py:450] Epoch 1, batch 11510, batch avg loss 0.3184, total avg loss: 0.3465, batch size: 41
2021-08-25 00:32:57,606 INFO [train.py:450] Epoch 1, batch 11520, batch avg loss 0.3354, total avg loss: 0.3473, batch size: 38
2021-08-25 00:33:04,383 INFO [train.py:450] Epoch 1, batch 11530, batch avg loss 0.3952, total avg loss: 0.3480, batch size: 43
2021-08-25 00:33:12,292 INFO [train.py:450] Epoch 1, batch 11540, batch avg loss 0.3103, total avg loss: 0.3481, batch size: 40
2021-08-25 00:33:18,657 INFO [train.py:450] Epoch 1, batch 11550, batch avg loss 0.3213, total avg loss: 0.3480, batch size: 39
2021-08-25 00:33:28,432 INFO [train.py:450] Epoch 1, batch 11560, batch avg loss 0.3058, total avg loss: 0.3468, batch size: 40
2021-08-25 00:33:35,018 INFO [train.py:450] Epoch 1, batch 11570, batch avg loss 0.3446, total avg loss: 0.3467, batch size: 43
2021-08-25 00:33:41,718 INFO [train.py:450] Epoch 1, batch 11580, batch avg loss 0.3712, total avg loss: 0.3467, batch size: 41
2021-08-25 00:33:48,098 INFO [train.py:450] Epoch 1, batch 11590, batch avg loss 0.3677, total avg loss: 0.3468, batch size: 40
2021-08-25 00:33:54,910 INFO [train.py:450] Epoch 1, batch 11600, batch avg loss 0.3641, total avg loss: 0.3469, batch size: 39
2021-08-25 00:34:01,580 INFO [train.py:450] Epoch 1, batch 11610, batch avg loss 0.3641, total avg loss: 0.3502, batch size: 40
2021-08-25 00:34:08,355 INFO [train.py:450] Epoch 1, batch 11620, batch avg loss 0.3304, total avg loss: 0.3471, batch size: 40
2021-08-25 00:34:14,476 INFO [train.py:450] Epoch 1, batch 11630, batch avg loss 0.3258, total avg loss: 0.3453, batch size: 40
2021-08-25 00:34:21,034 INFO [train.py:450] Epoch 1, batch 11640, batch avg loss 0.3554, total avg loss: 0.3459, batch size: 36
2021-08-25 00:34:27,521 INFO [train.py:450] Epoch 1, batch 11650, batch avg loss 0.3500, total avg loss: 0.3433, batch size: 38
2021-08-25 00:34:33,752 INFO [train.py:450] Epoch 1, batch 11660, batch avg loss 0.3979, total avg loss: 0.3457, batch size: 36
2021-08-25 00:34:40,426 INFO [train.py:450] Epoch 1, batch 11670, batch avg loss 0.2970, total avg loss: 0.3440, batch size: 38
2021-08-25 00:34:47,141 INFO [train.py:450] Epoch 1, batch 11680, batch avg loss 0.3205, total avg loss: 0.3447, batch size: 43
2021-08-25 00:34:53,548 INFO [train.py:450] Epoch 1, batch 11690, batch avg loss 0.3215, total avg loss: 0.3453, batch size: 38
2021-08-25 00:35:00,645 INFO [train.py:450] Epoch 1, batch 11700, batch avg loss 0.3600, total avg loss: 0.3449, batch size: 38
2021-08-25 00:35:07,436 INFO [train.py:450] Epoch 1, batch 11710, batch avg loss 0.3693, total avg loss: 0.3443, batch size: 43
2021-08-25 00:35:14,011 INFO [train.py:450] Epoch 1, batch 11720, batch avg loss 0.4377, total avg loss: 0.3448, batch size: 37
2021-08-25 00:35:20,563 INFO [train.py:450] Epoch 1, batch 11730, batch avg loss 0.3774, total avg loss: 0.3451, batch size: 39
2021-08-25 00:35:26,963 INFO [train.py:450] Epoch 1, batch 11740, batch avg loss 0.3587, total avg loss: 0.3445, batch size: 41
2021-08-25 00:35:33,518 INFO [train.py:450] Epoch 1, batch 11750, batch avg loss 0.3231, total avg loss: 0.3462, batch size: 45
2021-08-25 00:35:40,191 INFO [train.py:450] Epoch 1, batch 11760, batch avg loss 0.4083, total avg loss: 0.3464, batch size: 38
2021-08-25 00:35:46,747 INFO [train.py:450] Epoch 1, batch 11770, batch avg loss 0.3058, total avg loss: 0.3452, batch size: 40
2021-08-25 00:35:53,217 INFO [train.py:450] Epoch 1, batch 11780, batch avg loss 0.2999, total avg loss: 0.3446, batch size: 39
2021-08-25 00:36:00,233 INFO [train.py:450] Epoch 1, batch 11790, batch avg loss 0.3515, total avg loss: 0.3445, batch size: 43
2021-08-25 00:36:06,963 INFO [train.py:450] Epoch 1, batch 11800, batch avg loss 0.3119, total avg loss: 0.3443, batch size: 41
2021-08-25 00:36:13,651 INFO [train.py:450] Epoch 1, batch 11810, batch avg loss 0.3480, total avg loss: 0.3293, batch size: 40
2021-08-25 00:36:20,624 INFO [train.py:450] Epoch 1, batch 11820, batch avg loss 0.3301, total avg loss: 0.3420, batch size: 42
2021-08-25 00:36:27,390 INFO [train.py:450] Epoch 1, batch 11830, batch avg loss 0.3307, total avg loss: 0.3408, batch size: 40
2021-08-25 00:36:34,073 INFO [train.py:450] Epoch 1, batch 11840, batch avg loss 0.3291, total avg loss: 0.3417, batch size: 39
2021-08-25 00:36:40,526 INFO [train.py:450] Epoch 1, batch 11850, batch avg loss 0.3311, total avg loss: 0.3442, batch size: 37
2021-08-25 00:36:47,738 INFO [train.py:450] Epoch 1, batch 11860, batch avg loss 0.3442, total avg loss: 0.3459, batch size: 40
2021-08-25 00:36:54,262 INFO [train.py:450] Epoch 1, batch 11870, batch avg loss 0.3744, total avg loss: 0.3460, batch size: 39
2021-08-25 00:37:00,634 INFO [train.py:450] Epoch 1, batch 11880, batch avg loss 0.3231, total avg loss: 0.3456, batch size: 41
2021-08-25 00:37:07,290 INFO [train.py:450] Epoch 1, batch 11890, batch avg loss 0.3483, total avg loss: 0.3467, batch size: 39
2021-08-25 00:37:14,099 INFO [train.py:450] Epoch 1, batch 11900, batch avg loss 0.2974, total avg loss: 0.3448, batch size: 40
2021-08-25 00:37:20,429 INFO [train.py:450] Epoch 1, batch 11910, batch avg loss 0.3108, total avg loss: 0.3450, batch size: 39
2021-08-25 00:37:26,748 INFO [train.py:450] Epoch 1, batch 11920, batch avg loss 0.3976, total avg loss: 0.3464, batch size: 40
2021-08-25 00:37:33,695 INFO [train.py:450] Epoch 1, batch 11930, batch avg loss 0.3610, total avg loss: 0.3463, batch size: 46
2021-08-25 00:37:40,236 INFO [train.py:450] Epoch 1, batch 11940, batch avg loss 0.3694, total avg loss: 0.3459, batch size: 41
2021-08-25 00:37:48,341 INFO [train.py:450] Epoch 1, batch 11950, batch avg loss 0.3394, total avg loss: 0.3461, batch size: 39
2021-08-25 00:37:54,474 INFO [train.py:450] Epoch 1, batch 11960, batch avg loss 0.3422, total avg loss: 0.3462, batch size: 37
2021-08-25 00:38:04,570 INFO [train.py:450] Epoch 1, batch 11970, batch avg loss 0.3686, total avg loss: 0.3463, batch size: 39
2021-08-25 00:38:10,867 INFO [train.py:450] Epoch 1, batch 11980, batch avg loss 0.3739, total avg loss: 0.3460, batch size: 39
2021-08-25 00:38:17,671 INFO [train.py:450] Epoch 1, batch 11990, batch avg loss 0.3952, total avg loss: 0.3454, batch size: 40
2021-08-25 00:38:24,215 INFO [train.py:450] Epoch 1, batch 12000, batch avg loss 0.3631, total avg loss: 0.3448, batch size: 40
2021-08-25 00:39:03,444 INFO [train.py:482] Epoch 1, valid loss 0.2523, best valid loss: 0.2488 best valid epoch: 1
2021-08-25 00:39:09,495 INFO [train.py:450] Epoch 1, batch 12010, batch avg loss 0.3313, total avg loss: 0.3549, batch size: 38
2021-08-25 00:39:15,400 INFO [train.py:450] Epoch 1, batch 12020, batch avg loss 0.3544, total avg loss: 0.3521, batch size: 42
2021-08-25 00:39:21,963 INFO [train.py:450] Epoch 1, batch 12030, batch avg loss 0.3702, total avg loss: 0.3540, batch size: 39
2021-08-25 00:39:28,540 INFO [train.py:450] Epoch 1, batch 12040, batch avg loss 0.3423, total avg loss: 0.3543, batch size: 39
2021-08-25 00:39:35,518 INFO [train.py:450] Epoch 1, batch 12050, batch avg loss 0.3395, total avg loss: 0.3510, batch size: 39
2021-08-25 00:39:41,966 INFO [train.py:450] Epoch 1, batch 12060, batch avg loss 0.3106, total avg loss: 0.3509, batch size: 40
2021-08-25 00:39:48,737 INFO [train.py:450] Epoch 1, batch 12070, batch avg loss 0.3667, total avg loss: 0.3509, batch size: 38
2021-08-25 00:39:55,390 INFO [train.py:450] Epoch 1, batch 12080, batch avg loss 0.3584, total avg loss: 0.3496, batch size: 40
2021-08-25 00:40:02,615 INFO [train.py:450] Epoch 1, batch 12090, batch avg loss 0.3203, total avg loss: 0.3488, batch size: 37
2021-08-25 00:40:09,629 INFO [train.py:450] Epoch 1, batch 12100, batch avg loss 0.3662, total avg loss: 0.3482, batch size: 38
2021-08-25 00:40:16,023 INFO [train.py:450] Epoch 1, batch 12110, batch avg loss 0.3602, total avg loss: 0.3477, batch size: 38
2021-08-25 00:40:22,719 INFO [train.py:450] Epoch 1, batch 12120, batch avg loss 0.3046, total avg loss: 0.3475, batch size: 40
2021-08-25 00:40:29,496 INFO [train.py:450] Epoch 1, batch 12130, batch avg loss 0.4276, total avg loss: 0.3487, batch size: 40
2021-08-25 00:40:35,958 INFO [train.py:450] Epoch 1, batch 12140, batch avg loss 0.3482, total avg loss: 0.3496, batch size: 39
2021-08-25 00:40:43,100 INFO [train.py:450] Epoch 1, batch 12150, batch avg loss 0.3416, total avg loss: 0.3487, batch size: 40
2021-08-25 00:40:49,802 INFO [train.py:450] Epoch 1, batch 12160, batch avg loss 0.3205, total avg loss: 0.3494, batch size: 36
2021-08-25 00:40:57,075 INFO [train.py:450] Epoch 1, batch 12170, batch avg loss 0.3150, total avg loss: 0.3498, batch size: 40
2021-08-25 00:41:03,477 INFO [train.py:450] Epoch 1, batch 12180, batch avg loss 0.3427, total avg loss: 0.3499, batch size: 43
2021-08-25 00:41:10,323 INFO [train.py:450] Epoch 1, batch 12190, batch avg loss 0.3836, total avg loss: 0.3504, batch size: 42
2021-08-25 00:41:16,945 INFO [train.py:450] Epoch 1, batch 12200, batch avg loss 0.3978, total avg loss: 0.3510, batch size: 37
2021-08-25 00:41:24,153 INFO [train.py:450] Epoch 1, batch 12210, batch avg loss 0.3350, total avg loss: 0.3530, batch size: 36
2021-08-25 00:41:31,183 INFO [train.py:450] Epoch 1, batch 12220, batch avg loss 0.2842, total avg loss: 0.3569, batch size: 38
2021-08-25 00:41:37,674 INFO [train.py:450] Epoch 1, batch 12230, batch avg loss 0.3447, total avg loss: 0.3491, batch size: 36
2021-08-25 00:41:44,261 INFO [train.py:450] Epoch 1, batch 12240, batch avg loss 0.3338, total avg loss: 0.3466, batch size: 40
2021-08-25 00:41:52,448 INFO [train.py:450] Epoch 1, batch 12250, batch avg loss 0.3637, total avg loss: 0.3485, batch size: 40
2021-08-25 00:42:00,057 INFO [train.py:450] Epoch 1, batch 12260, batch avg loss 0.3359, total avg loss: 0.3480, batch size: 42
2021-08-25 00:42:07,858 INFO [train.py:450] Epoch 1, batch 12270, batch avg loss 0.3303, total avg loss: 0.3452, batch size: 39
2021-08-25 00:42:14,734 INFO [train.py:450] Epoch 1, batch 12280, batch avg loss 0.3662, total avg loss: 0.3447, batch size: 37
2021-08-25 00:42:20,524 WARNING [cut.py:1694] To perform mix, energy must be non-zero and non-negative (got 0.0).  MonoCut with id "a445f344-0f34-36ca-7201-049680852ca5" will not be mixed in.
2021-08-25 00:42:20,911 INFO [train.py:450] Epoch 1, batch 12290, batch avg loss 0.4010, total avg loss: 0.3449, batch size: 38
2021-08-25 00:42:27,492 INFO [train.py:450] Epoch 1, batch 12300, batch avg loss 0.3743, total avg loss: 0.3454, batch size: 42
2021-08-25 00:42:34,438 INFO [train.py:450] Epoch 1, batch 12310, batch avg loss 0.3633, total avg loss: 0.3481, batch size: 40
2021-08-25 00:42:40,972 INFO [train.py:450] Epoch 1, batch 12320, batch avg loss 0.3028, total avg loss: 0.3473, batch size: 38
2021-08-25 00:42:47,901 INFO [train.py:450] Epoch 1, batch 12330, batch avg loss 0.3533, total avg loss: 0.3484, batch size: 41
2021-08-25 00:42:54,618 INFO [train.py:450] Epoch 1, batch 12340, batch avg loss 0.3576, total avg loss: 0.3477, batch size: 38
2021-08-25 00:43:00,552 WARNING [cut.py:1694] To perform mix, energy must be non-zero and non-negative (got 0.0).  MonoCut with id "53660e15-c223-c12b-102e-a65cd901b154" will not be mixed in.
2021-08-25 00:43:01,372 INFO [train.py:450] Epoch 1, batch 12350, batch avg loss 0.3091, total avg loss: 0.3469, batch size: 40
2021-08-25 00:43:07,953 INFO [train.py:450] Epoch 1, batch 12360, batch avg loss 0.3345, total avg loss: 0.3468, batch size: 39
2021-08-25 00:43:14,789 INFO [train.py:450] Epoch 1, batch 12370, batch avg loss 0.2928, total avg loss: 0.3465, batch size: 39
2021-08-25 00:43:21,873 INFO [train.py:450] Epoch 1, batch 12380, batch avg loss 0.3920, total avg loss: 0.3480, batch size: 39
2021-08-25 00:43:28,358 INFO [train.py:450] Epoch 1, batch 12390, batch avg loss 0.3550, total avg loss: 0.3479, batch size: 43
2021-08-25 00:43:35,301 INFO [train.py:450] Epoch 1, batch 12400, batch avg loss 0.3901, total avg loss: 0.3482, batch size: 38
2021-08-25 00:43:42,226 INFO [train.py:450] Epoch 1, batch 12410, batch avg loss 0.3405, total avg loss: 0.3544, batch size: 39
2021-08-25 00:43:49,679 INFO [train.py:450] Epoch 1, batch 12420, batch avg loss 0.3667, total avg loss: 0.3510, batch size: 42
2021-08-25 00:43:56,507 INFO [train.py:450] Epoch 1, batch 12430, batch avg loss 0.3377, total avg loss: 0.3466, batch size: 38
2021-08-25 00:44:03,331 INFO [train.py:450] Epoch 1, batch 12440, batch avg loss 0.3358, total avg loss: 0.3480, batch size: 40
2021-08-25 00:44:10,213 INFO [train.py:450] Epoch 1, batch 12450, batch avg loss 0.3149, total avg loss: 0.3471, batch size: 37
2021-08-25 00:44:16,920 INFO [train.py:450] Epoch 1, batch 12460, batch avg loss 0.3792, total avg loss: 0.3449, batch size: 39
2021-08-25 00:44:24,191 INFO [train.py:450] Epoch 1, batch 12470, batch avg loss 0.3601, total avg loss: 0.3435, batch size: 39
2021-08-25 00:44:30,813 INFO [train.py:450] Epoch 1, batch 12480, batch avg loss 0.3376, total avg loss: 0.3455, batch size: 39
2021-08-25 00:44:37,122 INFO [train.py:450] Epoch 1, batch 12490, batch avg loss 0.3210, total avg loss: 0.3441, batch size: 40
2021-08-25 00:44:44,012 INFO [train.py:450] Epoch 1, batch 12500, batch avg loss 0.3192, total avg loss: 0.3453, batch size: 41
2021-08-25 00:44:50,612 INFO [train.py:450] Epoch 1, batch 12510, batch avg loss 0.3405, total avg loss: 0.3450, batch size: 43
2021-08-25 00:44:57,515 INFO [train.py:450] Epoch 1, batch 12520, batch avg loss 0.3401, total avg loss: 0.3444, batch size: 41
2021-08-25 00:45:04,375 INFO [train.py:450] Epoch 1, batch 12530, batch avg loss 0.3558, total avg loss: 0.3445, batch size: 41
2021-08-25 00:45:10,970 INFO [train.py:450] Epoch 1, batch 12540, batch avg loss 0.3624, total avg loss: 0.3438, batch size: 40
2021-08-25 00:45:18,000 INFO [train.py:450] Epoch 1, batch 12550, batch avg loss 0.3208, total avg loss: 0.3448, batch size: 41
2021-08-25 00:45:25,119 INFO [train.py:450] Epoch 1, batch 12560, batch avg loss 0.3336, total avg loss: 0.3449, batch size: 42
2021-08-25 00:45:31,616 INFO [train.py:450] Epoch 1, batch 12570, batch avg loss 0.4212, total avg loss: 0.3451, batch size: 38
2021-08-25 00:45:38,263 INFO [train.py:450] Epoch 1, batch 12580, batch avg loss 0.3276, total avg loss: 0.3457, batch size: 37
2021-08-25 00:45:45,442 INFO [train.py:450] Epoch 1, batch 12590, batch avg loss 0.2830, total avg loss: 0.3460, batch size: 38
2021-08-25 00:45:52,812 INFO [train.py:450] Epoch 1, batch 12600, batch avg loss 0.3398, total avg loss: 0.3455, batch size: 40
2021-08-25 00:45:59,994 INFO [train.py:450] Epoch 1, batch 12610, batch avg loss 0.4389, total avg loss: 0.3471, batch size: 42
2021-08-25 00:46:06,867 INFO [train.py:450] Epoch 1, batch 12620, batch avg loss 0.2912, total avg loss: 0.3379, batch size: 43
2021-08-25 00:46:14,025 INFO [train.py:450] Epoch 1, batch 12630, batch avg loss 0.3208, total avg loss: 0.3416, batch size: 37
2021-08-25 00:46:20,483 INFO [train.py:450] Epoch 1, batch 12640, batch avg loss 0.3366, total avg loss: 0.3420, batch size: 40
2021-08-25 00:46:28,314 INFO [train.py:450] Epoch 1, batch 12650, batch avg loss 0.2732, total avg loss: 0.3422, batch size: 40
2021-08-25 00:46:35,348 INFO [train.py:450] Epoch 1, batch 12660, batch avg loss 0.3419, total avg loss: 0.3457, batch size: 39
2021-08-25 00:46:43,681 INFO [train.py:450] Epoch 1, batch 12670, batch avg loss 0.3299, total avg loss: 0.3476, batch size: 41
2021-08-25 00:46:53,361 INFO [train.py:450] Epoch 1, batch 12680, batch avg loss 0.3468, total avg loss: 0.3472, batch size: 40
2021-08-25 00:47:00,084 INFO [train.py:450] Epoch 1, batch 12690, batch avg loss 0.3910, total avg loss: 0.3469, batch size: 37
2021-08-25 00:47:07,170 INFO [train.py:450] Epoch 1, batch 12700, batch avg loss 0.3258, total avg loss: 0.3452, batch size: 38
2021-08-25 00:47:13,949 INFO [train.py:450] Epoch 1, batch 12710, batch avg loss 0.3101, total avg loss: 0.3458, batch size: 39
2021-08-25 00:47:21,058 INFO [train.py:450] Epoch 1, batch 12720, batch avg loss 0.3452, total avg loss: 0.3461, batch size: 40
2021-08-25 00:47:27,975 INFO [train.py:450] Epoch 1, batch 12730, batch avg loss 0.3032, total avg loss: 0.3456, batch size: 40
2021-08-25 00:47:34,885 INFO [train.py:450] Epoch 1, batch 12740, batch avg loss 0.2933, total avg loss: 0.3448, batch size: 38
2021-08-25 00:47:41,710 INFO [train.py:450] Epoch 1, batch 12750, batch avg loss 0.2873, total avg loss: 0.3438, batch size: 41
2021-08-25 00:47:48,896 INFO [train.py:450] Epoch 1, batch 12760, batch avg loss 0.3208, total avg loss: 0.3441, batch size: 42
2021-08-25 00:47:55,480 INFO [train.py:450] Epoch 1, batch 12770, batch avg loss 0.2951, total avg loss: 0.3432, batch size: 41
2021-08-25 00:48:02,091 INFO [train.py:450] Epoch 1, batch 12780, batch avg loss 0.3690, total avg loss: 0.3444, batch size: 44
2021-08-25 00:48:09,201 INFO [train.py:450] Epoch 1, batch 12790, batch avg loss 0.3579, total avg loss: 0.3445, batch size: 42
2021-08-25 00:48:16,244 INFO [train.py:450] Epoch 1, batch 12800, batch avg loss 0.3481, total avg loss: 0.3444, batch size: 41
2021-08-25 00:48:23,500 INFO [train.py:450] Epoch 1, batch 12810, batch avg loss 0.3887, total avg loss: 0.3753, batch size: 38
2021-08-25 00:48:30,336 INFO [train.py:450] Epoch 1, batch 12820, batch avg loss 0.3066, total avg loss: 0.3540, batch size: 42
2021-08-25 00:48:37,823 INFO [train.py:450] Epoch 1, batch 12830, batch avg loss 0.3621, total avg loss: 0.3481, batch size: 42
2021-08-25 00:48:44,466 INFO [train.py:450] Epoch 1, batch 12840, batch avg loss 0.2897, total avg loss: 0.3448, batch size: 40
2021-08-25 00:48:51,433 INFO [train.py:450] Epoch 1, batch 12850, batch avg loss 0.3468, total avg loss: 0.3454, batch size: 42
2021-08-25 00:48:58,212 INFO [train.py:450] Epoch 1, batch 12860, batch avg loss 0.3586, total avg loss: 0.3460, batch size: 39
2021-08-25 00:49:04,946 INFO [train.py:450] Epoch 1, batch 12870, batch avg loss 0.3996, total avg loss: 0.3470, batch size: 41
2021-08-25 00:49:11,376 INFO [train.py:450] Epoch 1, batch 12880, batch avg loss 0.3869, total avg loss: 0.3482, batch size: 37
2021-08-25 00:49:18,976 INFO [train.py:450] Epoch 1, batch 12890, batch avg loss 0.3300, total avg loss: 0.3485, batch size: 42
2021-08-25 00:49:26,085 INFO [train.py:450] Epoch 1, batch 12900, batch avg loss 0.3537, total avg loss: 0.3470, batch size: 38
2021-08-25 00:49:33,227 INFO [train.py:450] Epoch 1, batch 12910, batch avg loss 0.3051, total avg loss: 0.3468, batch size: 42
2021-08-25 00:49:40,619 INFO [train.py:450] Epoch 1, batch 12920, batch avg loss 0.4117, total avg loss: 0.3474, batch size: 41
2021-08-25 00:49:47,547 INFO [train.py:450] Epoch 1, batch 12930, batch avg loss 0.3415, total avg loss: 0.3480, batch size: 39
2021-08-25 00:49:54,948 INFO [train.py:450] Epoch 1, batch 12940, batch avg loss 0.3693, total avg loss: 0.3492, batch size: 40
2021-08-25 00:50:02,399 INFO [train.py:450] Epoch 1, batch 12950, batch avg loss 0.3609, total avg loss: 0.3492, batch size: 38
2021-08-25 00:50:09,411 INFO [train.py:450] Epoch 1, batch 12960, batch avg loss 0.3090, total avg loss: 0.3494, batch size: 40
2021-08-25 00:50:17,030 INFO [train.py:450] Epoch 1, batch 12970, batch avg loss 0.3465, total avg loss: 0.3490, batch size: 41
2021-08-25 00:50:24,241 INFO [train.py:450] Epoch 1, batch 12980, batch avg loss 0.3506, total avg loss: 0.3489, batch size: 39
2021-08-25 00:50:31,248 INFO [train.py:450] Epoch 1, batch 12990, batch avg loss 0.3065, total avg loss: 0.3483, batch size: 39
2021-08-25 00:50:38,355 INFO [train.py:450] Epoch 1, batch 13000, batch avg loss 0.3091, total avg loss: 0.3488, batch size: 38
2021-08-25 00:51:17,390 INFO [train.py:482] Epoch 1, valid loss 0.2470, best valid loss: 0.2470 best valid epoch: 1
2021-08-25 00:51:23,116 INFO [train.py:450] Epoch 1, batch 13010, batch avg loss 0.3490, total avg loss: 0.3240, batch size: 41
2021-08-25 00:51:30,631 INFO [train.py:450] Epoch 1, batch 13020, batch avg loss 0.3201, total avg loss: 0.3370, batch size: 38
2021-08-25 00:51:38,238 INFO [train.py:450] Epoch 1, batch 13030, batch avg loss 0.2963, total avg loss: 0.3388, batch size: 41
2021-08-25 00:51:45,728 INFO [train.py:450] Epoch 1, batch 13040, batch avg loss 0.3618, total avg loss: 0.3443, batch size: 39
2021-08-25 00:51:53,294 INFO [train.py:450] Epoch 1, batch 13050, batch avg loss 0.3477, total avg loss: 0.3486, batch size: 42
2021-08-25 00:52:00,608 INFO [train.py:450] Epoch 1, batch 13060, batch avg loss 0.3823, total avg loss: 0.3502, batch size: 40
2021-08-25 00:52:08,742 INFO [train.py:450] Epoch 1, batch 13070, batch avg loss 0.3454, total avg loss: 0.3508, batch size: 40
2021-08-25 00:52:16,188 INFO [train.py:450] Epoch 1, batch 13080, batch avg loss 0.3478, total avg loss: 0.3502, batch size: 42
2021-08-25 00:52:23,618 INFO [train.py:450] Epoch 1, batch 13090, batch avg loss 0.4040, total avg loss: 0.3523, batch size: 37
2021-08-25 00:52:30,915 INFO [train.py:450] Epoch 1, batch 13100, batch avg loss 0.3334, total avg loss: 0.3534, batch size: 41
2021-08-25 00:52:38,029 INFO [train.py:450] Epoch 1, batch 13110, batch avg loss 0.3190, total avg loss: 0.3519, batch size: 38
2021-08-25 00:52:45,123 INFO [train.py:450] Epoch 1, batch 13120, batch avg loss 0.3181, total avg loss: 0.3503, batch size: 38
2021-08-25 00:52:52,756 INFO [train.py:450] Epoch 1, batch 13130, batch avg loss 0.3995, total avg loss: 0.3505, batch size: 39
2021-08-25 00:52:59,844 INFO [train.py:450] Epoch 1, batch 13140, batch avg loss 0.3518, total avg loss: 0.3496, batch size: 43
2021-08-25 00:53:07,531 INFO [train.py:450] Epoch 1, batch 13150, batch avg loss 0.4041, total avg loss: 0.3492, batch size: 42
2021-08-25 00:53:15,355 INFO [train.py:450] Epoch 1, batch 13160, batch avg loss 0.3625, total avg loss: 0.3488, batch size: 37
2021-08-25 00:53:22,856 INFO [train.py:450] Epoch 1, batch 13170, batch avg loss 0.3617, total avg loss: 0.3483, batch size: 43
2021-08-25 00:53:30,213 INFO [train.py:450] Epoch 1, batch 13180, batch avg loss 0.3306, total avg loss: 0.3478, batch size: 38
2021-08-25 00:53:38,637 INFO [train.py:450] Epoch 1, batch 13190, batch avg loss 0.3358, total avg loss: 0.3474, batch size: 38
2021-08-25 00:53:46,067 INFO [train.py:450] Epoch 1, batch 13200, batch avg loss 0.3418, total avg loss: 0.3470, batch size: 40
2021-08-25 00:53:53,170 INFO [train.py:450] Epoch 1, batch 13210, batch avg loss 0.3399, total avg loss: 0.3325, batch size: 39
2021-08-25 00:54:00,701 INFO [train.py:450] Epoch 1, batch 13220, batch avg loss 0.3645, total avg loss: 0.3411, batch size: 38
2021-08-25 00:54:07,684 INFO [train.py:450] Epoch 1, batch 13230, batch avg loss 0.3270, total avg loss: 0.3389, batch size: 37
2021-08-25 00:54:15,106 INFO [train.py:450] Epoch 1, batch 13240, batch avg loss 0.3130, total avg loss: 0.3403, batch size: 36
2021-08-25 00:54:22,629 INFO [train.py:450] Epoch 1, batch 13250, batch avg loss 0.3404, total avg loss: 0.3390, batch size: 39
2021-08-25 00:54:29,646 INFO [train.py:450] Epoch 1, batch 13260, batch avg loss 0.3637, total avg loss: 0.3400, batch size: 42
2021-08-25 00:54:36,956 INFO [train.py:450] Epoch 1, batch 13270, batch avg loss 0.3577, total avg loss: 0.3399, batch size: 41
2021-08-25 00:54:44,032 INFO [train.py:450] Epoch 1, batch 13280, batch avg loss 0.3447, total avg loss: 0.3406, batch size: 40
2021-08-25 00:54:51,680 INFO [train.py:450] Epoch 1, batch 13290, batch avg loss 0.3298, total avg loss: 0.3395, batch size: 38
2021-08-25 00:54:58,828 INFO [train.py:450] Epoch 1, batch 13300, batch avg loss 0.4170, total avg loss: 0.3398, batch size: 36
2021-08-25 00:55:05,968 INFO [train.py:450] Epoch 1, batch 13310, batch avg loss 0.3253, total avg loss: 0.3388, batch size: 42
2021-08-25 00:55:12,825 INFO [train.py:450] Epoch 1, batch 13320, batch avg loss 0.3375, total avg loss: 0.3405, batch size: 41
2021-08-25 00:55:20,431 INFO [train.py:450] Epoch 1, batch 13330, batch avg loss 0.3605, total avg loss: 0.3414, batch size: 40
2021-08-25 00:55:27,578 INFO [train.py:450] Epoch 1, batch 13340, batch avg loss 0.3413, total avg loss: 0.3426, batch size: 38
2021-08-25 00:55:34,705 INFO [train.py:450] Epoch 1, batch 13350, batch avg loss 0.3426, total avg loss: 0.3428, batch size: 37
2021-08-25 00:55:41,997 INFO [train.py:450] Epoch 1, batch 13360, batch avg loss 0.3200, total avg loss: 0.3429, batch size: 43
2021-08-25 00:55:50,833 INFO [train.py:450] Epoch 1, batch 13370, batch avg loss 0.3445, total avg loss: 0.3432, batch size: 40
2021-08-25 00:55:59,046 INFO [train.py:450] Epoch 1, batch 13380, batch avg loss 0.3953, total avg loss: 0.3432, batch size: 41
2021-08-25 00:56:08,579 INFO [train.py:450] Epoch 1, batch 13390, batch avg loss 0.4006, total avg loss: 0.3438, batch size: 42
2021-08-25 00:56:16,115 INFO [train.py:450] Epoch 1, batch 13400, batch avg loss 0.3922, total avg loss: 0.3446, batch size: 39
2021-08-25 00:56:23,010 INFO [train.py:450] Epoch 1, batch 13410, batch avg loss 0.3259, total avg loss: 0.3292, batch size: 38
2021-08-25 00:56:29,801 INFO [train.py:450] Epoch 1, batch 13420, batch avg loss 0.3284, total avg loss: 0.3308, batch size: 39
2021-08-25 00:56:37,238 INFO [train.py:450] Epoch 1, batch 13430, batch avg loss 0.3056, total avg loss: 0.3369, batch size: 41
2021-08-25 00:56:44,053 INFO [train.py:450] Epoch 1, batch 13440, batch avg loss 0.3926, total avg loss: 0.3447, batch size: 41
2021-08-25 00:56:51,260 INFO [train.py:450] Epoch 1, batch 13450, batch avg loss 0.3297, total avg loss: 0.3446, batch size: 40
2021-08-25 00:56:58,282 INFO [train.py:450] Epoch 1, batch 13460, batch avg loss 0.3544, total avg loss: 0.3466, batch size: 41
2021-08-25 00:57:05,635 INFO [train.py:450] Epoch 1, batch 13470, batch avg loss 0.3395, total avg loss: 0.3471, batch size: 40
2021-08-25 00:57:12,796 INFO [train.py:450] Epoch 1, batch 13480, batch avg loss 0.3986, total avg loss: 0.3479, batch size: 42
2021-08-25 00:57:19,259 INFO [train.py:450] Epoch 1, batch 13490, batch avg loss 0.3761, total avg loss: 0.3480, batch size: 42
2021-08-25 00:57:26,697 INFO [train.py:450] Epoch 1, batch 13500, batch avg loss 0.3483, total avg loss: 0.3477, batch size: 42
2021-08-25 00:57:33,571 INFO [train.py:450] Epoch 1, batch 13510, batch avg loss 0.3845, total avg loss: 0.3479, batch size: 43
2021-08-25 00:57:40,729 INFO [train.py:450] Epoch 1, batch 13520, batch avg loss 0.3678, total avg loss: 0.3479, batch size: 41
2021-08-25 00:57:48,165 INFO [train.py:450] Epoch 1, batch 13530, batch avg loss 0.3495, total avg loss: 0.3476, batch size: 39
2021-08-25 00:57:52,832 WARNING [cut.py:1694] To perform mix, energy must be non-zero and non-negative (got 0.0).  MonoCut with id "4c436f05-5376-5ee1-737b-e936cc1bd47a" will not be mixed in.
2021-08-25 00:57:55,544 INFO [train.py:450] Epoch 1, batch 13540, batch avg loss 0.3324, total avg loss: 0.3468, batch size: 41
2021-08-25 00:58:02,866 INFO [train.py:450] Epoch 1, batch 13550, batch avg loss 0.2883, total avg loss: 0.3472, batch size: 40
2021-08-25 00:58:10,646 INFO [train.py:450] Epoch 1, batch 13560, batch avg loss 0.4246, total avg loss: 0.3483, batch size: 43
2021-08-25 00:58:17,942 INFO [train.py:450] Epoch 1, batch 13570, batch avg loss 0.3745, total avg loss: 0.3482, batch size: 39
2021-08-25 00:58:26,274 INFO [train.py:450] Epoch 1, batch 13580, batch avg loss 0.3356, total avg loss: 0.3475, batch size: 40
2021-08-25 00:58:33,199 INFO [train.py:450] Epoch 1, batch 13590, batch avg loss 0.3185, total avg loss: 0.3467, batch size: 41
2021-08-25 00:58:40,997 INFO [train.py:450] Epoch 1, batch 13600, batch avg loss 0.3460, total avg loss: 0.3458, batch size: 38
2021-08-25 00:58:49,466 INFO [train.py:450] Epoch 1, batch 13610, batch avg loss 0.3322, total avg loss: 0.3559, batch size: 39
2021-08-25 00:58:57,760 INFO [train.py:450] Epoch 1, batch 13620, batch avg loss 0.3323, total avg loss: 0.3481, batch size: 43
2021-08-25 00:59:05,538 INFO [train.py:450] Epoch 1, batch 13630, batch avg loss 0.3166, total avg loss: 0.3417, batch size: 41
2021-08-25 00:59:13,440 INFO [train.py:450] Epoch 1, batch 13640, batch avg loss 0.3722, total avg loss: 0.3417, batch size: 44
2021-08-25 00:59:21,393 INFO [train.py:450] Epoch 1, batch 13650, batch avg loss 0.3958, total avg loss: 0.3430, batch size: 39
2021-08-25 00:59:30,021 INFO [train.py:450] Epoch 1, batch 13660, batch avg loss 0.3221, total avg loss: 0.3448, batch size: 45
2021-08-25 00:59:37,935 INFO [train.py:450] Epoch 1, batch 13670, batch avg loss 0.3096, total avg loss: 0.3418, batch size: 41
2021-08-25 00:59:46,804 INFO [train.py:450] Epoch 1, batch 13680, batch avg loss 0.3465, total avg loss: 0.3421, batch size: 41
2021-08-25 00:59:54,608 INFO [train.py:450] Epoch 1, batch 13690, batch avg loss 0.3209, total avg loss: 0.3427, batch size: 40
2021-08-25 01:00:02,519 INFO [train.py:450] Epoch 1, batch 13700, batch avg loss 0.3575, total avg loss: 0.3422, batch size: 37
2021-08-25 01:00:11,215 INFO [train.py:450] Epoch 1, batch 13710, batch avg loss 0.3819, total avg loss: 0.3434, batch size: 43
2021-08-25 01:00:19,406 INFO [train.py:450] Epoch 1, batch 13720, batch avg loss 0.3962, total avg loss: 0.3430, batch size: 44
2021-08-25 01:00:29,338 INFO [train.py:450] Epoch 1, batch 13730, batch avg loss 0.3977, total avg loss: 0.3438, batch size: 42
2021-08-25 01:00:37,340 INFO [train.py:450] Epoch 1, batch 13740, batch avg loss 0.3364, total avg loss: 0.3449, batch size: 42
2021-08-25 01:00:49,702 INFO [train.py:450] Epoch 1, batch 13750, batch avg loss 0.3095, total avg loss: 0.3450, batch size: 38
2021-08-25 01:00:57,648 INFO [train.py:450] Epoch 1, batch 13760, batch avg loss 0.3215, total avg loss: 0.3439, batch size: 39
2021-08-25 01:01:05,933 INFO [train.py:450] Epoch 1, batch 13770, batch avg loss 0.3243, total avg loss: 0.3431, batch size: 39
2021-08-25 01:01:14,431 INFO [train.py:450] Epoch 1, batch 13780, batch avg loss 0.3420, total avg loss: 0.3436, batch size: 39
2021-08-25 01:01:21,774 INFO [train.py:450] Epoch 1, batch 13790, batch avg loss 0.3182, total avg loss: 0.3434, batch size: 41
2021-08-25 01:01:29,750 INFO [train.py:450] Epoch 1, batch 13800, batch avg loss 0.3537, total avg loss: 0.3442, batch size: 40
2021-08-25 01:01:37,846 INFO [train.py:450] Epoch 1, batch 13810, batch avg loss 0.3817, total avg loss: 0.3443, batch size: 41
2021-08-25 01:01:45,822 INFO [train.py:450] Epoch 1, batch 13820, batch avg loss 0.3100, total avg loss: 0.3492, batch size: 38
2021-08-25 01:01:54,105 INFO [train.py:450] Epoch 1, batch 13830, batch avg loss 0.3210, total avg loss: 0.3475, batch size: 38
2021-08-25 01:02:01,826 INFO [train.py:450] Epoch 1, batch 13840, batch avg loss 0.3164, total avg loss: 0.3473, batch size: 39
2021-08-25 01:02:09,867 INFO [train.py:450] Epoch 1, batch 13850, batch avg loss 0.3323, total avg loss: 0.3438, batch size: 39
2021-08-25 01:02:17,446 INFO [train.py:450] Epoch 1, batch 13860, batch avg loss 0.3038, total avg loss: 0.3446, batch size: 42
2021-08-25 01:02:25,407 INFO [train.py:450] Epoch 1, batch 13870, batch avg loss 0.3630, total avg loss: 0.3447, batch size: 39
2021-08-25 01:02:33,097 INFO [train.py:450] Epoch 1, batch 13880, batch avg loss 0.3350, total avg loss: 0.3432, batch size: 39
2021-08-25 01:02:40,791 INFO [train.py:450] Epoch 1, batch 13890, batch avg loss 0.3278, total avg loss: 0.3429, batch size: 38
2021-08-25 01:02:48,948 INFO [train.py:450] Epoch 1, batch 13900, batch avg loss 0.3290, total avg loss: 0.3439, batch size: 41
2021-08-25 01:02:56,895 INFO [train.py:450] Epoch 1, batch 13910, batch avg loss 0.2901, total avg loss: 0.3439, batch size: 39
2021-08-25 01:03:06,409 INFO [train.py:450] Epoch 1, batch 13920, batch avg loss 0.3288, total avg loss: 0.3441, batch size: 43
2021-08-25 01:03:14,323 INFO [train.py:450] Epoch 1, batch 13930, batch avg loss 0.3227, total avg loss: 0.3442, batch size: 41
2021-08-25 01:03:25,383 INFO [train.py:450] Epoch 1, batch 13940, batch avg loss 0.3458, total avg loss: 0.3448, batch size: 39
2021-08-25 01:03:32,695 INFO [train.py:450] Epoch 1, batch 13950, batch avg loss 0.3305, total avg loss: 0.3455, batch size: 41
2021-08-25 01:03:41,129 INFO [train.py:450] Epoch 1, batch 13960, batch avg loss 0.3773, total avg loss: 0.3457, batch size: 40
2021-08-25 01:03:49,349 INFO [train.py:450] Epoch 1, batch 13970, batch avg loss 0.3447, total avg loss: 0.3450, batch size: 40
2021-08-25 01:03:57,045 INFO [train.py:450] Epoch 1, batch 13980, batch avg loss 0.3479, total avg loss: 0.3444, batch size: 41
2021-08-25 01:04:04,858 INFO [train.py:450] Epoch 1, batch 13990, batch avg loss 0.3173, total avg loss: 0.3443, batch size: 38
2021-08-25 01:04:11,933 INFO [train.py:450] Epoch 1, batch 14000, batch avg loss 0.3158, total avg loss: 0.3435, batch size: 39
2021-08-25 01:04:50,970 INFO [train.py:482] Epoch 1, valid loss 0.2486, best valid loss: 0.2470 best valid epoch: 1
2021-08-25 01:05:05,273 INFO [train.py:450] Epoch 1, batch 14010, batch avg loss 0.3534, total avg loss: 0.3438, batch size: 42
2021-08-25 01:05:11,965 INFO [train.py:450] Epoch 1, batch 14020, batch avg loss 0.3363, total avg loss: 0.3395, batch size: 41
2021-08-25 01:05:19,669 INFO [train.py:450] Epoch 1, batch 14030, batch avg loss 0.2939, total avg loss: 0.3383, batch size: 39
2021-08-25 01:05:27,483 INFO [train.py:450] Epoch 1, batch 14040, batch avg loss 0.3629, total avg loss: 0.3361, batch size: 37
2021-08-25 01:05:35,346 INFO [train.py:450] Epoch 1, batch 14050, batch avg loss 0.3076, total avg loss: 0.3359, batch size: 43
2021-08-25 01:05:43,212 INFO [train.py:450] Epoch 1, batch 14060, batch avg loss 0.3018, total avg loss: 0.3365, batch size: 37
2021-08-25 01:05:50,718 INFO [train.py:450] Epoch 1, batch 14070, batch avg loss 0.3289, total avg loss: 0.3366, batch size: 36
2021-08-25 01:05:58,282 INFO [train.py:450] Epoch 1, batch 14080, batch avg loss 0.4009, total avg loss: 0.3368, batch size: 41
2021-08-25 01:06:05,814 INFO [train.py:450] Epoch 1, batch 14090, batch avg loss 0.3531, total avg loss: 0.3380, batch size: 40
2021-08-25 01:06:13,191 INFO [train.py:450] Epoch 1, batch 14100, batch avg loss 0.3954, total avg loss: 0.3391, batch size: 41
2021-08-25 01:06:20,916 INFO [train.py:450] Epoch 1, batch 14110, batch avg loss 0.2997, total avg loss: 0.3388, batch size: 42
2021-08-25 01:06:28,957 INFO [train.py:450] Epoch 1, batch 14120, batch avg loss 0.3309, total avg loss: 0.3406, batch size: 43
2021-08-25 01:06:36,356 INFO [train.py:450] Epoch 1, batch 14130, batch avg loss 0.2966, total avg loss: 0.3395, batch size: 43
2021-08-25 01:06:44,421 INFO [train.py:450] Epoch 1, batch 14140, batch avg loss 0.2804, total avg loss: 0.3388, batch size: 43
2021-08-25 01:06:51,956 INFO [train.py:450] Epoch 1, batch 14150, batch avg loss 0.3885, total avg loss: 0.3388, batch size: 40
2021-08-25 01:06:59,115 INFO [train.py:450] Epoch 1, batch 14160, batch avg loss 0.3430, total avg loss: 0.3389, batch size: 39
2021-08-25 01:07:07,160 INFO [train.py:450] Epoch 1, batch 14170, batch avg loss 0.3712, total avg loss: 0.3387, batch size: 41
2021-08-25 01:07:14,678 INFO [train.py:450] Epoch 1, batch 14180, batch avg loss 0.3391, total avg loss: 0.3391, batch size: 42
2021-08-25 01:07:22,823 INFO [train.py:450] Epoch 1, batch 14190, batch avg loss 0.3412, total avg loss: 0.3392, batch size: 40
2021-08-25 01:07:30,086 INFO [train.py:450] Epoch 1, batch 14200, batch avg loss 0.3024, total avg loss: 0.3394, batch size: 40
2021-08-25 01:07:37,381 INFO [train.py:450] Epoch 1, batch 14210, batch avg loss 0.3048, total avg loss: 0.3505, batch size: 36
2021-08-25 01:07:46,973 INFO [train.py:450] Epoch 1, batch 14220, batch avg loss 0.3665, total avg loss: 0.3509, batch size: 38
2021-08-25 01:07:56,502 INFO [train.py:450] Epoch 1, batch 14230, batch avg loss 0.3208, total avg loss: 0.3465, batch size: 40
2021-08-25 01:08:04,235 INFO [train.py:450] Epoch 1, batch 14240, batch avg loss 0.3311, total avg loss: 0.3418, batch size: 41
2021-08-25 01:08:12,613 INFO [train.py:450] Epoch 1, batch 14250, batch avg loss 0.2894, total avg loss: 0.3408, batch size: 43
2021-08-25 01:08:20,152 INFO [train.py:450] Epoch 1, batch 14260, batch avg loss 0.3414, total avg loss: 0.3422, batch size: 39
2021-08-25 01:08:27,811 INFO [train.py:450] Epoch 1, batch 14270, batch avg loss 0.3415, total avg loss: 0.3433, batch size: 45
2021-08-25 01:08:34,547 INFO [train.py:450] Epoch 1, batch 14280, batch avg loss 0.3400, total avg loss: 0.3425, batch size: 39
2021-08-25 01:08:42,208 INFO [train.py:450] Epoch 1, batch 14290, batch avg loss 0.3586, total avg loss: 0.3445, batch size: 40
2021-08-25 01:08:49,676 INFO [train.py:450] Epoch 1, batch 14300, batch avg loss 0.3114, total avg loss: 0.3425, batch size: 37
2021-08-25 01:08:57,857 INFO [train.py:450] Epoch 1, batch 14310, batch avg loss 0.3524, total avg loss: 0.3424, batch size: 38
2021-08-25 01:09:05,238 INFO [train.py:450] Epoch 1, batch 14320, batch avg loss 0.3148, total avg loss: 0.3419, batch size: 39
2021-08-25 01:09:12,462 INFO [train.py:450] Epoch 1, batch 14330, batch avg loss 0.3214, total avg loss: 0.3410, batch size: 43
2021-08-25 01:09:19,405 INFO [train.py:450] Epoch 1, batch 14340, batch avg loss 0.3548, total avg loss: 0.3411, batch size: 40
2021-08-25 01:09:26,949 INFO [train.py:450] Epoch 1, batch 14350, batch avg loss 0.3317, total avg loss: 0.3416, batch size: 43
2021-08-25 01:09:34,353 INFO [train.py:450] Epoch 1, batch 14360, batch avg loss 0.3868, total avg loss: 0.3419, batch size: 45
2021-08-25 01:09:41,808 INFO [train.py:450] Epoch 1, batch 14370, batch avg loss 0.3379, total avg loss: 0.3417, batch size: 38
2021-08-25 01:09:48,597 INFO [train.py:450] Epoch 1, batch 14380, batch avg loss 0.3105, total avg loss: 0.3424, batch size: 37
2021-08-25 01:09:55,879 INFO [train.py:450] Epoch 1, batch 14390, batch avg loss 0.3451, total avg loss: 0.3417, batch size: 48
2021-08-25 01:10:03,543 INFO [train.py:450] Epoch 1, batch 14400, batch avg loss 0.3283, total avg loss: 0.3407, batch size: 40
2021-08-25 01:10:10,693 INFO [train.py:450] Epoch 1, batch 14410, batch avg loss 0.2967, total avg loss: 0.3348, batch size: 39
2021-08-25 01:10:19,190 INFO [train.py:450] Epoch 1, batch 14420, batch avg loss 0.3638, total avg loss: 0.3434, batch size: 43
2021-08-25 01:10:26,276 INFO [train.py:450] Epoch 1, batch 14430, batch avg loss 0.2717, total avg loss: 0.3425, batch size: 39
2021-08-25 01:10:33,717 INFO [train.py:450] Epoch 1, batch 14440, batch avg loss 0.3450, total avg loss: 0.3383, batch size: 39
2021-08-25 01:10:41,527 INFO [train.py:450] Epoch 1, batch 14450, batch avg loss 0.3493, total avg loss: 0.3374, batch size: 37
2021-08-25 01:10:49,148 INFO [train.py:450] Epoch 1, batch 14460, batch avg loss 0.2862, total avg loss: 0.3360, batch size: 40
2021-08-25 01:10:56,232 INFO [train.py:450] Epoch 1, batch 14470, batch avg loss 0.3102, total avg loss: 0.3351, batch size: 40
2021-08-25 01:11:03,058 INFO [train.py:450] Epoch 1, batch 14480, batch avg loss 0.3605, total avg loss: 0.3374, batch size: 41
2021-08-25 01:11:10,210 INFO [train.py:450] Epoch 1, batch 14490, batch avg loss 0.3478, total avg loss: 0.3385, batch size: 38
2021-08-25 01:11:17,443 INFO [train.py:450] Epoch 1, batch 14500, batch avg loss 0.3136, total avg loss: 0.3371, batch size: 39
2021-08-25 01:11:24,839 INFO [train.py:450] Epoch 1, batch 14510, batch avg loss 0.4454, total avg loss: 0.3382, batch size: 38
2021-08-25 01:11:32,080 INFO [train.py:450] Epoch 1, batch 14520, batch avg loss 0.3573, total avg loss: 0.3387, batch size: 42
2021-08-25 01:11:38,986 INFO [train.py:450] Epoch 1, batch 14530, batch avg loss 0.3789, total avg loss: 0.3390, batch size: 40
2021-08-25 01:11:46,157 INFO [train.py:450] Epoch 1, batch 14540, batch avg loss 0.3365, total avg loss: 0.3392, batch size: 42
2021-08-25 01:11:53,491 INFO [train.py:450] Epoch 1, batch 14550, batch avg loss 0.3432, total avg loss: 0.3394, batch size: 43
2021-08-25 01:12:01,276 INFO [train.py:450] Epoch 1, batch 14560, batch avg loss 0.3215, total avg loss: 0.3403, batch size: 38
2021-08-25 01:12:09,033 INFO [train.py:450] Epoch 1, batch 14570, batch avg loss 0.3460, total avg loss: 0.3397, batch size: 38
2021-08-25 01:12:18,821 INFO [train.py:450] Epoch 1, batch 14580, batch avg loss 0.3249, total avg loss: 0.3394, batch size: 41
2021-08-25 01:12:26,303 INFO [train.py:450] Epoch 1, batch 14590, batch avg loss 0.3749, total avg loss: 0.3394, batch size: 40
2021-08-25 01:12:36,797 INFO [train.py:450] Epoch 1, batch 14600, batch avg loss 0.3287, total avg loss: 0.3400, batch size: 41
2021-08-25 01:12:44,218 INFO [train.py:450] Epoch 1, batch 14610, batch avg loss 0.3848, total avg loss: 0.3448, batch size: 43
2021-08-25 01:12:51,444 INFO [train.py:450] Epoch 1, batch 14620, batch avg loss 0.2999, total avg loss: 0.3385, batch size: 37
2021-08-25 01:12:59,761 INFO [train.py:450] Epoch 1, batch 14630, batch avg loss 0.3404, total avg loss: 0.3390, batch size: 37
2021-08-25 01:13:07,753 INFO [train.py:450] Epoch 1, batch 14640, batch avg loss 0.2962, total avg loss: 0.3396, batch size: 40
2021-08-25 01:13:15,460 INFO [train.py:450] Epoch 1, batch 14650, batch avg loss 0.3544, total avg loss: 0.3386, batch size: 38
2021-08-25 01:13:22,978 INFO [train.py:450] Epoch 1, batch 14660, batch avg loss 0.3356, total avg loss: 0.3396, batch size: 40
2021-08-25 01:13:30,577 INFO [train.py:450] Epoch 1, batch 14670, batch avg loss 0.2899, total avg loss: 0.3391, batch size: 41
2021-08-25 01:13:38,264 INFO [train.py:450] Epoch 1, batch 14680, batch avg loss 0.4273, total avg loss: 0.3415, batch size: 37
2021-08-25 01:13:45,488 INFO [train.py:450] Epoch 1, batch 14690, batch avg loss 0.3392, total avg loss: 0.3415, batch size: 40
2021-08-25 01:13:52,688 INFO [train.py:450] Epoch 1, batch 14700, batch avg loss 0.3334, total avg loss: 0.3421, batch size: 43
2021-08-25 01:13:59,815 INFO [train.py:450] Epoch 1, batch 14710, batch avg loss 0.3722, total avg loss: 0.3432, batch size: 41
2021-08-25 01:14:07,597 INFO [train.py:450] Epoch 1, batch 14720, batch avg loss 0.4169, total avg loss: 0.3439, batch size: 42
2021-08-25 01:14:14,666 INFO [train.py:450] Epoch 1, batch 14730, batch avg loss 0.3335, total avg loss: 0.3448, batch size: 44
2021-08-25 01:14:21,961 INFO [train.py:450] Epoch 1, batch 14740, batch avg loss 0.3692, total avg loss: 0.3438, batch size: 41
2021-08-25 01:14:28,909 INFO [train.py:450] Epoch 1, batch 14750, batch avg loss 0.3246, total avg loss: 0.3435, batch size: 38
2021-08-25 01:14:36,076 INFO [train.py:450] Epoch 1, batch 14760, batch avg loss 0.3400, total avg loss: 0.3438, batch size: 42
2021-08-25 01:14:42,982 INFO [train.py:450] Epoch 1, batch 14770, batch avg loss 0.3234, total avg loss: 0.3445, batch size: 38
2021-08-25 01:14:49,839 INFO [train.py:450] Epoch 1, batch 14780, batch avg loss 0.3095, total avg loss: 0.3439, batch size: 41
2021-08-25 01:14:56,382 INFO [train.py:450] Epoch 1, batch 14790, batch avg loss 0.3007, total avg loss: 0.3437, batch size: 39
2021-08-25 01:15:03,144 INFO [train.py:450] Epoch 1, batch 14800, batch avg loss 0.2945, total avg loss: 0.3435, batch size: 42
2021-08-25 01:15:10,550 INFO [train.py:450] Epoch 1, batch 14810, batch avg loss 0.3324, total avg loss: 0.3245, batch size: 42
2021-08-25 01:15:17,486 INFO [train.py:450] Epoch 1, batch 14820, batch avg loss 0.3276, total avg loss: 0.3286, batch size: 40
2021-08-25 01:15:24,296 INFO [train.py:450] Epoch 1, batch 14830, batch avg loss 0.3213, total avg loss: 0.3346, batch size: 38
2021-08-25 01:15:31,368 INFO [train.py:450] Epoch 1, batch 14840, batch avg loss 0.3318, total avg loss: 0.3320, batch size: 39
2021-08-25 01:15:38,170 INFO [train.py:450] Epoch 1, batch 14850, batch avg loss 0.3157, total avg loss: 0.3358, batch size: 40
2021-08-25 01:15:44,844 INFO [train.py:450] Epoch 1, batch 14860, batch avg loss 0.3651, total avg loss: 0.3370, batch size: 37
2021-08-25 01:15:52,087 INFO [train.py:450] Epoch 1, batch 14870, batch avg loss 0.3932, total avg loss: 0.3371, batch size: 37
2021-08-25 01:16:00,776 INFO [train.py:450] Epoch 1, batch 14880, batch avg loss 0.3440, total avg loss: 0.3373, batch size: 36
2021-08-25 01:16:07,465 INFO [train.py:450] Epoch 1, batch 14890, batch avg loss 0.3335, total avg loss: 0.3377, batch size: 43
2021-08-25 01:16:16,837 INFO [train.py:450] Epoch 1, batch 14900, batch avg loss 0.3289, total avg loss: 0.3383, batch size: 38
2021-08-25 01:16:24,306 INFO [train.py:450] Epoch 1, batch 14910, batch avg loss 0.3662, total avg loss: 0.3385, batch size: 40
2021-08-25 01:16:31,240 INFO [train.py:450] Epoch 1, batch 14920, batch avg loss 0.3619, total avg loss: 0.3377, batch size: 39
2021-08-25 01:16:38,325 INFO [train.py:450] Epoch 1, batch 14930, batch avg loss 0.3657, total avg loss: 0.3382, batch size: 39
2021-08-25 01:16:45,648 INFO [train.py:450] Epoch 1, batch 14940, batch avg loss 0.3694, total avg loss: 0.3384, batch size: 42
2021-08-25 01:16:53,205 INFO [train.py:450] Epoch 1, batch 14950, batch avg loss 0.3847, total avg loss: 0.3390, batch size: 40
2021-08-25 01:17:00,224 INFO [train.py:450] Epoch 1, batch 14960, batch avg loss 0.3228, total avg loss: 0.3385, batch size: 39
2021-08-25 01:17:06,972 INFO [train.py:450] Epoch 1, batch 14970, batch avg loss 0.3361, total avg loss: 0.3388, batch size: 39
2021-08-25 01:17:13,444 INFO [train.py:450] Epoch 1, batch 14980, batch avg loss 0.3922, total avg loss: 0.3395, batch size: 39
2021-08-25 01:17:20,573 INFO [train.py:450] Epoch 1, batch 14990, batch avg loss 0.4489, total avg loss: 0.3399, batch size: 44
2021-08-25 01:17:27,641 INFO [train.py:450] Epoch 1, batch 15000, batch avg loss 0.3501, total avg loss: 0.3398, batch size: 40
2021-08-25 01:18:05,587 INFO [train.py:482] Epoch 1, valid loss 0.2464, best valid loss: 0.2464 best valid epoch: 1
2021-08-25 01:18:11,638 INFO [train.py:450] Epoch 1, batch 15010, batch avg loss 0.3598, total avg loss: 0.3456, batch size: 43
2021-08-25 01:18:18,121 INFO [train.py:450] Epoch 1, batch 15020, batch avg loss 0.3640, total avg loss: 0.3396, batch size: 39
2021-08-25 01:18:24,961 INFO [train.py:450] Epoch 1, batch 15030, batch avg loss 0.3615, total avg loss: 0.3478, batch size: 38
2021-08-25 01:18:31,167 INFO [train.py:450] Epoch 1, batch 15040, batch avg loss 0.3246, total avg loss: 0.3481, batch size: 36
2021-08-25 01:18:38,243 INFO [train.py:450] Epoch 1, batch 15050, batch avg loss 0.3884, total avg loss: 0.3491, batch size: 41
2021-08-25 01:18:44,809 INFO [train.py:450] Epoch 1, batch 15060, batch avg loss 0.3572, total avg loss: 0.3462, batch size: 42
2021-08-25 01:18:52,014 INFO [train.py:450] Epoch 1, batch 15070, batch avg loss 0.3835, total avg loss: 0.3474, batch size: 45
2021-08-25 01:18:58,851 INFO [train.py:450] Epoch 1, batch 15080, batch avg loss 0.3702, total avg loss: 0.3471, batch size: 40
2021-08-25 01:19:05,961 INFO [train.py:450] Epoch 1, batch 15090, batch avg loss 0.3268, total avg loss: 0.3464, batch size: 40
2021-08-25 01:19:12,520 INFO [train.py:450] Epoch 1, batch 15100, batch avg loss 0.3533, total avg loss: 0.3463, batch size: 41
2021-08-25 01:19:19,880 INFO [train.py:450] Epoch 1, batch 15110, batch avg loss 0.3436, total avg loss: 0.3451, batch size: 39
2021-08-25 01:19:26,748 INFO [train.py:450] Epoch 1, batch 15120, batch avg loss 0.3582, total avg loss: 0.3455, batch size: 39
2021-08-25 01:19:33,341 INFO [train.py:450] Epoch 1, batch 15130, batch avg loss 0.4297, total avg loss: 0.3474, batch size: 39
2021-08-25 01:19:40,711 INFO [train.py:450] Epoch 1, batch 15140, batch avg loss 0.3346, total avg loss: 0.3458, batch size: 38
2021-08-25 01:19:47,979 INFO [train.py:450] Epoch 1, batch 15150, batch avg loss 0.3523, total avg loss: 0.3460, batch size: 41
2021-08-25 01:19:54,839 INFO [train.py:450] Epoch 1, batch 15160, batch avg loss 0.2720, total avg loss: 0.3452, batch size: 37
2021-08-25 01:20:01,443 INFO [train.py:450] Epoch 1, batch 15170, batch avg loss 0.3013, total avg loss: 0.3458, batch size: 37
2021-08-25 01:20:08,295 INFO [train.py:450] Epoch 1, batch 15180, batch avg loss 0.3216, total avg loss: 0.3454, batch size: 39
2021-08-25 01:20:15,718 INFO [train.py:450] Epoch 1, batch 15190, batch avg loss 0.3579, total avg loss: 0.3447, batch size: 41
2021-08-25 01:20:22,020 INFO [train.py:450] Epoch 1, batch 15200, batch avg loss 0.3364, total avg loss: 0.3446, batch size: 38
2021-08-25 01:20:32,473 INFO [train.py:450] Epoch 1, batch 15210, batch avg loss 0.3164, total avg loss: 0.3379, batch size: 41
2021-08-25 01:20:38,908 INFO [train.py:450] Epoch 1, batch 15220, batch avg loss 0.3292, total avg loss: 0.3379, batch size: 38
2021-08-25 01:20:45,806 INFO [train.py:450] Epoch 1, batch 15230, batch avg loss 0.3536, total avg loss: 0.3313, batch size: 43
2021-08-25 01:20:52,831 INFO [train.py:450] Epoch 1, batch 15240, batch avg loss 0.3283, total avg loss: 0.3308, batch size: 43
2021-08-25 01:20:59,191 INFO [train.py:450] Epoch 1, batch 15250, batch avg loss 0.3309, total avg loss: 0.3330, batch size: 42
2021-08-25 01:21:05,505 INFO [train.py:450] Epoch 1, batch 15260, batch avg loss 0.3591, total avg loss: 0.3363, batch size: 41
2021-08-25 01:21:12,723 INFO [train.py:450] Epoch 1, batch 15270, batch avg loss 0.3426, total avg loss: 0.3367, batch size: 42
2021-08-25 01:21:19,598 INFO [train.py:450] Epoch 1, batch 15280, batch avg loss 0.3685, total avg loss: 0.3374, batch size: 38
2021-08-25 01:21:26,160 INFO [train.py:450] Epoch 1, batch 15290, batch avg loss 0.3219, total avg loss: 0.3371, batch size: 40
2021-08-25 01:21:33,504 INFO [train.py:450] Epoch 1, batch 15300, batch avg loss 0.4283, total avg loss: 0.3387, batch size: 40
2021-08-25 01:21:35,802 WARNING [cut.py:1694] To perform mix, energy must be non-zero and non-negative (got 0.0).  MonoCut with id "6008a9e1-1e4e-d0f3-3d93-44d1b687aeee" will not be mixed in.
2021-08-25 01:21:40,117 INFO [train.py:450] Epoch 1, batch 15310, batch avg loss 0.3413, total avg loss: 0.3370, batch size: 41
2021-08-25 01:21:43,764 WARNING [cut.py:1694] To perform mix, energy must be non-zero and non-negative (got 0.0).  MonoCut with id "f45f0a2e-fa87-c636-2bf8-95b6daeda4ef" will not be mixed in.
2021-08-25 01:21:46,958 INFO [train.py:450] Epoch 1, batch 15320, batch avg loss 0.2921, total avg loss: 0.3373, batch size: 40
2021-08-25 01:21:53,706 INFO [train.py:450] Epoch 1, batch 15330, batch avg loss 0.3313, total avg loss: 0.3381, batch size: 36
2021-08-25 01:22:00,375 INFO [train.py:450] Epoch 1, batch 15340, batch avg loss 0.3537, total avg loss: 0.3381, batch size: 43
2021-08-25 01:22:06,655 INFO [train.py:450] Epoch 1, batch 15350, batch avg loss 0.2833, total avg loss: 0.3373, batch size: 38
2021-08-25 01:22:13,496 INFO [train.py:450] Epoch 1, batch 15360, batch avg loss 0.3480, total avg loss: 0.3377, batch size: 40
2021-08-25 01:22:20,297 INFO [train.py:450] Epoch 1, batch 15370, batch avg loss 0.3705, total avg loss: 0.3381, batch size: 40
2021-08-25 01:22:26,946 INFO [train.py:450] Epoch 1, batch 15380, batch avg loss 0.3433, total avg loss: 0.3380, batch size: 39
2021-08-25 01:22:34,080 INFO [train.py:450] Epoch 1, batch 15390, batch avg loss 0.3549, total avg loss: 0.3376, batch size: 44
2021-08-25 01:22:40,894 INFO [train.py:450] Epoch 1, batch 15400, batch avg loss 0.4184, total avg loss: 0.3383, batch size: 43
2021-08-25 01:22:47,012 INFO [train.py:450] Epoch 1, batch 15410, batch avg loss 0.3133, total avg loss: 0.3281, batch size: 40
2021-08-25 01:22:54,238 INFO [train.py:450] Epoch 1, batch 15420, batch avg loss 0.3005, total avg loss: 0.3371, batch size: 40
2021-08-25 01:23:00,825 INFO [train.py:450] Epoch 1, batch 15430, batch avg loss 0.3493, total avg loss: 0.3379, batch size: 42
2021-08-25 01:23:08,091 INFO [train.py:450] Epoch 1, batch 15440, batch avg loss 0.3134, total avg loss: 0.3341, batch size: 39
2021-08-25 01:23:13,897 INFO [train.py:450] Epoch 1, batch 15450, batch avg loss 0.3128, total avg loss: 0.3352, batch size: 38
2021-08-25 01:23:20,873 INFO [train.py:450] Epoch 1, batch 15460, batch avg loss 0.2800, total avg loss: 0.3353, batch size: 38
2021-08-25 01:23:27,439 INFO [train.py:450] Epoch 1, batch 15470, batch avg loss 0.4077, total avg loss: 0.3362, batch size: 42
2021-08-25 01:23:34,420 INFO [train.py:450] Epoch 1, batch 15480, batch avg loss 0.3509, total avg loss: 0.3372, batch size: 42
2021-08-25 01:23:40,898 INFO [train.py:450] Epoch 1, batch 15490, batch avg loss 0.3212, total avg loss: 0.3372, batch size: 39
2021-08-25 01:23:47,032 INFO [train.py:450] Epoch 1, batch 15500, batch avg loss 0.3153, total avg loss: 0.3368, batch size: 40
2021-08-25 01:23:53,628 INFO [train.py:450] Epoch 1, batch 15510, batch avg loss 0.3491, total avg loss: 0.3371, batch size: 36
2021-08-25 01:24:00,452 INFO [train.py:450] Epoch 1, batch 15520, batch avg loss 0.2905, total avg loss: 0.3382, batch size: 37
2021-08-25 01:24:07,169 INFO [train.py:450] Epoch 1, batch 15530, batch avg loss 0.3291, total avg loss: 0.3392, batch size: 37
2021-08-25 01:24:13,651 INFO [train.py:450] Epoch 1, batch 15540, batch avg loss 0.3147, total avg loss: 0.3394, batch size: 40
2021-08-25 01:24:20,137 INFO [train.py:450] Epoch 1, batch 15550, batch avg loss 0.3059, total avg loss: 0.3400, batch size: 38
2021-08-25 01:24:27,259 INFO [train.py:450] Epoch 1, batch 15560, batch avg loss 0.3631, total avg loss: 0.3402, batch size: 39
2021-08-25 01:24:34,175 INFO [train.py:450] Epoch 1, batch 15570, batch avg loss 0.3261, total avg loss: 0.3405, batch size: 40
2021-08-25 01:24:40,706 INFO [train.py:450] Epoch 1, batch 15580, batch avg loss 0.3402, total avg loss: 0.3403, batch size: 42
2021-08-25 01:24:48,885 INFO [train.py:450] Epoch 1, batch 15590, batch avg loss 0.2978, total avg loss: 0.3398, batch size: 39
2021-08-25 01:24:55,547 INFO [train.py:450] Epoch 1, batch 15600, batch avg loss 0.3161, total avg loss: 0.3398, batch size: 42
2021-08-25 01:25:06,438 INFO [train.py:450] Epoch 1, batch 15610, batch avg loss 0.3527, total avg loss: 0.3471, batch size: 44
2021-08-25 01:25:13,362 INFO [train.py:450] Epoch 1, batch 15620, batch avg loss 0.3563, total avg loss: 0.3431, batch size: 42
2021-08-25 01:25:17,809 WARNING [cut.py:1694] To perform mix, energy must be non-zero and non-negative (got 0.0).  MonoCut with id "5a05760c-a2e7-a249-718a-631e91a99c78" will not be mixed in.
2021-08-25 01:25:20,512 INFO [train.py:450] Epoch 1, batch 15630, batch avg loss 0.3834, total avg loss: 0.3418, batch size: 39
2021-08-25 01:25:27,783 INFO [train.py:450] Epoch 1, batch 15640, batch avg loss 0.2840, total avg loss: 0.3417, batch size: 40
2021-08-25 01:25:35,174 INFO [train.py:450] Epoch 1, batch 15650, batch avg loss 0.3299, total avg loss: 0.3432, batch size: 38
2021-08-25 01:25:42,268 INFO [train.py:450] Epoch 1, batch 15660, batch avg loss 0.3428, total avg loss: 0.3444, batch size: 40
2021-08-25 01:25:48,911 INFO [train.py:450] Epoch 1, batch 15670, batch avg loss 0.3783, total avg loss: 0.3444, batch size: 37
2021-08-25 01:25:56,231 INFO [train.py:450] Epoch 1, batch 15680, batch avg loss 0.3700, total avg loss: 0.3439, batch size: 37
2021-08-25 01:26:03,080 INFO [train.py:450] Epoch 1, batch 15690, batch avg loss 0.4077, total avg loss: 0.3424, batch size: 41
2021-08-25 01:26:09,996 INFO [train.py:450] Epoch 1, batch 15700, batch avg loss 0.3360, total avg loss: 0.3429, batch size: 39
2021-08-25 01:26:16,831 INFO [train.py:450] Epoch 1, batch 15710, batch avg loss 0.3581, total avg loss: 0.3445, batch size: 42
2021-08-25 01:26:23,329 INFO [train.py:450] Epoch 1, batch 15720, batch avg loss 0.3142, total avg loss: 0.3433, batch size: 37
2021-08-25 01:26:30,462 INFO [train.py:450] Epoch 1, batch 15730, batch avg loss 0.3885, total avg loss: 0.3442, batch size: 41
2021-08-25 01:26:37,060 INFO [train.py:450] Epoch 1, batch 15740, batch avg loss 0.3697, total avg loss: 0.3431, batch size: 37
2021-08-25 01:26:43,521 INFO [train.py:450] Epoch 1, batch 15750, batch avg loss 0.3608, total avg loss: 0.3420, batch size: 38
2021-08-25 01:26:49,777 INFO [train.py:450] Epoch 1, batch 15760, batch avg loss 0.3233, total avg loss: 0.3417, batch size: 44
2021-08-25 01:26:56,255 INFO [train.py:450] Epoch 1, batch 15770, batch avg loss 0.3119, total avg loss: 0.3414, batch size: 39
2021-08-25 01:27:02,755 INFO [train.py:450] Epoch 1, batch 15780, batch avg loss 0.3406, total avg loss: 0.3420, batch size: 38
2021-08-25 01:27:09,441 INFO [train.py:450] Epoch 1, batch 15790, batch avg loss 0.3336, total avg loss: 0.3421, batch size: 40
2021-08-25 01:27:16,463 INFO [train.py:450] Epoch 1, batch 15800, batch avg loss 0.3046, total avg loss: 0.3423, batch size: 35
2021-08-25 01:27:23,045 INFO [train.py:450] Epoch 1, batch 15810, batch avg loss 0.3061, total avg loss: 0.3451, batch size: 40
2021-08-25 01:27:29,373 INFO [train.py:450] Epoch 1, batch 15820, batch avg loss 0.2920, total avg loss: 0.3363, batch size: 36
2021-08-25 01:27:36,394 INFO [train.py:450] Epoch 1, batch 15830, batch avg loss 0.3512, total avg loss: 0.3406, batch size: 36
2021-08-25 01:27:43,766 INFO [train.py:450] Epoch 1, batch 15840, batch avg loss 0.2985, total avg loss: 0.3401, batch size: 38
2021-08-25 01:27:50,421 INFO [train.py:450] Epoch 1, batch 15850, batch avg loss 0.3341, total avg loss: 0.3398, batch size: 40
2021-08-25 01:27:56,960 INFO [train.py:450] Epoch 1, batch 15860, batch avg loss 0.3477, total avg loss: 0.3384, batch size: 39
2021-08-25 01:28:04,062 INFO [train.py:450] Epoch 1, batch 15870, batch avg loss 0.3362, total avg loss: 0.3389, batch size: 38
2021-08-25 01:28:10,776 INFO [train.py:450] Epoch 1, batch 15880, batch avg loss 0.3365, total avg loss: 0.3410, batch size: 37
2021-08-25 01:28:17,329 INFO [train.py:450] Epoch 1, batch 15890, batch avg loss 0.3722, total avg loss: 0.3411, batch size: 38
2021-08-25 01:28:24,103 INFO [train.py:450] Epoch 1, batch 15900, batch avg loss 0.3255, total avg loss: 0.3430, batch size: 36
2021-08-25 01:28:30,692 INFO [train.py:450] Epoch 1, batch 15910, batch avg loss 0.4077, total avg loss: 0.3431, batch size: 38
2021-08-25 01:28:37,394 INFO [train.py:450] Epoch 1, batch 15920, batch avg loss 0.3481, total avg loss: 0.3450, batch size: 36
2021-08-25 01:28:43,967 INFO [train.py:450] Epoch 1, batch 15930, batch avg loss 0.3460, total avg loss: 0.3451, batch size: 40
2021-08-25 01:28:50,838 INFO [train.py:450] Epoch 1, batch 15940, batch avg loss 0.3324, total avg loss: 0.3446, batch size: 40
2021-08-25 01:28:57,790 INFO [train.py:450] Epoch 1, batch 15950, batch avg loss 0.3602, total avg loss: 0.3439, batch size: 41
2021-08-25 01:29:04,146 INFO [train.py:450] Epoch 1, batch 15960, batch avg loss 0.3177, total avg loss: 0.3434, batch size: 43
2021-08-25 01:29:11,450 INFO [train.py:450] Epoch 1, batch 15970, batch avg loss 0.3510, total avg loss: 0.3427, batch size: 45
2021-08-25 01:29:18,579 INFO [train.py:450] Epoch 1, batch 15980, batch avg loss 0.2982, total avg loss: 0.3423, batch size: 39
2021-08-25 01:29:27,739 INFO [train.py:450] Epoch 1, batch 15990, batch avg loss 0.3186, total avg loss: 0.3424, batch size: 39
2021-08-25 01:29:36,181 INFO [train.py:450] Epoch 1, batch 16000, batch avg loss 0.2959, total avg loss: 0.3413, batch size: 42
2021-08-25 01:30:15,016 INFO [train.py:482] Epoch 1, valid loss 0.2462, best valid loss: 0.2462 best valid epoch: 1
2021-08-25 01:30:20,871 INFO [train.py:450] Epoch 1, batch 16010, batch avg loss 0.3623, total avg loss: 0.3604, batch size: 40
2021-08-25 01:30:28,773 INFO [train.py:450] Epoch 1, batch 16020, batch avg loss 0.3351, total avg loss: 0.3562, batch size: 40
2021-08-25 01:30:35,593 INFO [train.py:450] Epoch 1, batch 16030, batch avg loss 0.3028, total avg loss: 0.3504, batch size: 45
2021-08-25 01:30:42,506 INFO [train.py:450] Epoch 1, batch 16040, batch avg loss 0.2824, total avg loss: 0.3439, batch size: 40
2021-08-25 01:30:48,543 INFO [train.py:450] Epoch 1, batch 16050, batch avg loss 0.3763, total avg loss: 0.3452, batch size: 44
2021-08-25 01:30:55,307 INFO [train.py:450] Epoch 1, batch 16060, batch avg loss 0.3549, total avg loss: 0.3434, batch size: 40
2021-08-25 01:31:01,910 INFO [train.py:450] Epoch 1, batch 16070, batch avg loss 0.3451, total avg loss: 0.3413, batch size: 42
2021-08-25 01:31:08,799 INFO [train.py:450] Epoch 1, batch 16080, batch avg loss 0.4174, total avg loss: 0.3441, batch size: 39
2021-08-25 01:31:15,543 INFO [train.py:450] Epoch 1, batch 16090, batch avg loss 0.2886, total avg loss: 0.3445, batch size: 43
2021-08-25 01:31:22,455 INFO [train.py:450] Epoch 1, batch 16100, batch avg loss 0.3189, total avg loss: 0.3450, batch size: 41
2021-08-25 01:31:29,634 INFO [train.py:450] Epoch 1, batch 16110, batch avg loss 0.3289, total avg loss: 0.3434, batch size: 42
2021-08-25 01:31:37,229 INFO [train.py:450] Epoch 1, batch 16120, batch avg loss 0.3471, total avg loss: 0.3445, batch size: 42
2021-08-25 01:31:43,958 INFO [train.py:450] Epoch 1, batch 16130, batch avg loss 0.4607, total avg loss: 0.3470, batch size: 39
2021-08-25 01:31:51,099 INFO [train.py:450] Epoch 1, batch 16140, batch avg loss 0.3478, total avg loss: 0.3465, batch size: 40
2021-08-25 01:31:57,677 INFO [train.py:450] Epoch 1, batch 16150, batch avg loss 0.2813, total avg loss: 0.3470, batch size: 40
2021-08-25 01:32:04,643 INFO [train.py:450] Epoch 1, batch 16160, batch avg loss 0.3514, total avg loss: 0.3455, batch size: 44
2021-08-25 01:32:11,516 INFO [train.py:450] Epoch 1, batch 16170, batch avg loss 0.3065, total avg loss: 0.3458, batch size: 36
2021-08-25 01:32:18,361 INFO [train.py:450] Epoch 1, batch 16180, batch avg loss 0.3344, total avg loss: 0.3458, batch size: 39
2021-08-25 01:32:25,661 INFO [train.py:450] Epoch 1, batch 16190, batch avg loss 0.3567, total avg loss: 0.3464, batch size: 40
2021-08-25 01:32:32,866 INFO [train.py:450] Epoch 1, batch 16200, batch avg loss 0.3186, total avg loss: 0.3464, batch size: 42
2021-08-25 01:32:39,577 INFO [train.py:450] Epoch 1, batch 16210, batch avg loss 0.4473, total avg loss: 0.3467, batch size: 35
2021-08-25 01:32:46,948 INFO [train.py:450] Epoch 1, batch 16220, batch avg loss 0.3235, total avg loss: 0.3448, batch size: 40
2021-08-25 01:32:53,923 INFO [train.py:450] Epoch 1, batch 16230, batch avg loss 0.3514, total avg loss: 0.3470, batch size: 37
2021-08-25 01:33:01,068 INFO [train.py:450] Epoch 1, batch 16240, batch avg loss 0.3689, total avg loss: 0.3443, batch size: 43
2021-08-25 01:33:08,312 INFO [train.py:450] Epoch 1, batch 16250, batch avg loss 0.2981, total avg loss: 0.3458, batch size: 43
2021-08-25 01:33:15,121 INFO [train.py:450] Epoch 1, batch 16260, batch avg loss 0.4100, total avg loss: 0.3465, batch size: 37
2021-08-25 01:33:22,771 INFO [train.py:450] Epoch 1, batch 16270, batch avg loss 0.3630, total avg loss: 0.3479, batch size: 40
2021-08-25 01:33:29,991 INFO [train.py:450] Epoch 1, batch 16280, batch avg loss 0.2959, total avg loss: 0.3452, batch size: 40
2021-08-25 01:33:37,022 INFO [train.py:450] Epoch 1, batch 16290, batch avg loss 0.3185, total avg loss: 0.3421, batch size: 36
2021-08-25 01:33:45,788 INFO [train.py:450] Epoch 1, batch 16300, batch avg loss 0.3543, total avg loss: 0.3415, batch size: 41
2021-08-25 01:33:53,437 INFO [train.py:450] Epoch 1, batch 16310, batch avg loss 0.3671, total avg loss: 0.3413, batch size: 38
2021-08-25 01:34:04,473 INFO [train.py:450] Epoch 1, batch 16320, batch avg loss 0.3654, total avg loss: 0.3418, batch size: 43
2021-08-25 01:34:11,041 INFO [train.py:450] Epoch 1, batch 16330, batch avg loss 0.3432, total avg loss: 0.3424, batch size: 38
2021-08-25 01:34:18,411 INFO [train.py:450] Epoch 1, batch 16340, batch avg loss 0.3212, total avg loss: 0.3421, batch size: 38
2021-08-25 01:34:25,533 INFO [train.py:450] Epoch 1, batch 16350, batch avg loss 0.4018, total avg loss: 0.3423, batch size: 40
2021-08-25 01:34:32,730 INFO [train.py:450] Epoch 1, batch 16360, batch avg loss 0.2881, total avg loss: 0.3423, batch size: 43
2021-08-25 01:34:39,866 INFO [train.py:450] Epoch 1, batch 16370, batch avg loss 0.3005, total avg loss: 0.3413, batch size: 37
2021-08-25 01:34:47,561 INFO [train.py:450] Epoch 1, batch 16380, batch avg loss 0.3485, total avg loss: 0.3414, batch size: 39
2021-08-25 01:34:54,668 INFO [train.py:450] Epoch 1, batch 16390, batch avg loss 0.3740, total avg loss: 0.3407, batch size: 42
2021-08-25 01:35:01,284 INFO [train.py:450] Epoch 1, batch 16400, batch avg loss 0.3051, total avg loss: 0.3404, batch size: 38
2021-08-25 01:35:08,258 INFO [train.py:450] Epoch 1, batch 16410, batch avg loss 0.3240, total avg loss: 0.3232, batch size: 39
2021-08-25 01:35:15,445 INFO [train.py:450] Epoch 1, batch 16420, batch avg loss 0.3447, total avg loss: 0.3337, batch size: 39
2021-08-25 01:35:22,635 INFO [train.py:450] Epoch 1, batch 16430, batch avg loss 0.3152, total avg loss: 0.3379, batch size: 41
2021-08-25 01:35:29,212 INFO [train.py:450] Epoch 1, batch 16440, batch avg loss 0.3319, total avg loss: 0.3366, batch size: 39
2021-08-25 01:35:36,642 INFO [train.py:450] Epoch 1, batch 16450, batch avg loss 0.3374, total avg loss: 0.3400, batch size: 45
2021-08-25 01:35:43,490 INFO [train.py:450] Epoch 1, batch 16460, batch avg loss 0.3309, total avg loss: 0.3400, batch size: 42
2021-08-25 01:35:50,482 INFO [train.py:450] Epoch 1, batch 16470, batch avg loss 0.3498, total avg loss: 0.3377, batch size: 39
2021-08-25 01:35:57,853 INFO [train.py:450] Epoch 1, batch 16480, batch avg loss 0.3475, total avg loss: 0.3390, batch size: 37
2021-08-25 01:36:04,536 INFO [train.py:450] Epoch 1, batch 16490, batch avg loss 0.3544, total avg loss: 0.3381, batch size: 44
2021-08-25 01:36:11,709 INFO [train.py:450] Epoch 1, batch 16500, batch avg loss 0.3997, total avg loss: 0.3376, batch size: 39
2021-08-25 01:36:18,824 INFO [train.py:450] Epoch 1, batch 16510, batch avg loss 0.3109, total avg loss: 0.3390, batch size: 39
2021-08-25 01:36:25,900 INFO [train.py:450] Epoch 1, batch 16520, batch avg loss 0.3741, total avg loss: 0.3390, batch size: 40
2021-08-25 01:36:32,556 INFO [train.py:450] Epoch 1, batch 16530, batch avg loss 0.3749, total avg loss: 0.3398, batch size: 39
2021-08-25 01:36:39,478 INFO [train.py:450] Epoch 1, batch 16540, batch avg loss 0.3218, total avg loss: 0.3404, batch size: 40
2021-08-25 01:36:46,434 INFO [train.py:450] Epoch 1, batch 16550, batch avg loss 0.3195, total avg loss: 0.3396, batch size: 43
2021-08-25 01:36:53,180 INFO [train.py:450] Epoch 1, batch 16560, batch avg loss 0.3583, total avg loss: 0.3398, batch size: 37
2021-08-25 01:36:59,542 INFO [train.py:450] Epoch 1, batch 16570, batch avg loss 0.3798, total avg loss: 0.3397, batch size: 42
2021-08-25 01:37:06,962 INFO [train.py:450] Epoch 1, batch 16580, batch avg loss 0.3695, total avg loss: 0.3404, batch size: 46
2021-08-25 01:37:13,618 INFO [train.py:450] Epoch 1, batch 16590, batch avg loss 0.2934, total avg loss: 0.3402, batch size: 40
2021-08-25 01:37:20,498 INFO [train.py:450] Epoch 1, batch 16600, batch avg loss 0.3459, total avg loss: 0.3409, batch size: 42
2021-08-25 01:37:27,899 INFO [train.py:450] Epoch 1, batch 16610, batch avg loss 0.3508, total avg loss: 0.3385, batch size: 44
2021-08-25 01:37:34,857 INFO [train.py:450] Epoch 1, batch 16620, batch avg loss 0.3404, total avg loss: 0.3430, batch size: 39
2021-08-25 01:37:42,344 INFO [train.py:450] Epoch 1, batch 16630, batch avg loss 0.3302, total avg loss: 0.3477, batch size: 38
2021-08-25 01:37:50,288 INFO [train.py:450] Epoch 1, batch 16640, batch avg loss 0.3467, total avg loss: 0.3454, batch size: 41
2021-08-25 01:37:56,572 INFO [train.py:450] Epoch 1, batch 16650, batch avg loss 0.3292, total avg loss: 0.3452, batch size: 43
2021-08-25 01:38:06,518 INFO [train.py:450] Epoch 1, batch 16660, batch avg loss 0.3592, total avg loss: 0.3457, batch size: 42
2021-08-25 01:38:13,438 INFO [train.py:450] Epoch 1, batch 16670, batch avg loss 0.3263, total avg loss: 0.3464, batch size: 41
2021-08-25 01:38:20,246 INFO [train.py:450] Epoch 1, batch 16680, batch avg loss 0.3137, total avg loss: 0.3441, batch size: 41
2021-08-25 01:38:27,625 INFO [train.py:450] Epoch 1, batch 16690, batch avg loss 0.3604, total avg loss: 0.3442, batch size: 40
2021-08-25 01:38:34,494 INFO [train.py:450] Epoch 1, batch 16700, batch avg loss 0.3749, total avg loss: 0.3449, batch size: 48
2021-08-25 01:38:41,517 INFO [train.py:450] Epoch 1, batch 16710, batch avg loss 0.3597, total avg loss: 0.3447, batch size: 41
2021-08-25 01:38:48,282 INFO [train.py:450] Epoch 1, batch 16720, batch avg loss 0.3545, total avg loss: 0.3443, batch size: 40
2021-08-25 01:38:55,363 INFO [train.py:450] Epoch 1, batch 16730, batch avg loss 0.3252, total avg loss: 0.3436, batch size: 40
2021-08-25 01:39:02,343 INFO [train.py:450] Epoch 1, batch 16740, batch avg loss 0.3568, total avg loss: 0.3433, batch size: 41
2021-08-25 01:39:09,528 INFO [train.py:450] Epoch 1, batch 16750, batch avg loss 0.3237, total avg loss: 0.3430, batch size: 40
2021-08-25 01:39:15,961 INFO [train.py:450] Epoch 1, batch 16760, batch avg loss 0.3471, total avg loss: 0.3423, batch size: 42
2021-08-25 01:39:22,511 INFO [train.py:450] Epoch 1, batch 16770, batch avg loss 0.3470, total avg loss: 0.3426, batch size: 39
2021-08-25 01:39:29,405 INFO [train.py:450] Epoch 1, batch 16780, batch avg loss 0.2918, total avg loss: 0.3423, batch size: 41
2021-08-25 01:39:36,872 INFO [train.py:450] Epoch 1, batch 16790, batch avg loss 0.3533, total avg loss: 0.3427, batch size: 40
2021-08-25 01:39:43,564 INFO [train.py:450] Epoch 1, batch 16800, batch avg loss 0.3415, total avg loss: 0.3423, batch size: 40
2021-08-25 01:39:50,531 INFO [train.py:450] Epoch 1, batch 16810, batch avg loss 0.3140, total avg loss: 0.3326, batch size: 40
2021-08-25 01:39:57,393 INFO [train.py:450] Epoch 1, batch 16820, batch avg loss 0.2977, total avg loss: 0.3329, batch size: 38
2021-08-25 01:40:04,731 INFO [train.py:450] Epoch 1, batch 16830, batch avg loss 0.2951, total avg loss: 0.3446, batch size: 37
2021-08-25 01:40:11,422 INFO [train.py:450] Epoch 1, batch 16840, batch avg loss 0.3859, total avg loss: 0.3470, batch size: 41
2021-08-25 01:40:18,324 INFO [train.py:450] Epoch 1, batch 16850, batch avg loss 0.3674, total avg loss: 0.3487, batch size: 39
2021-08-25 01:40:25,077 INFO [train.py:450] Epoch 1, batch 16860, batch avg loss 0.2967, total avg loss: 0.3449, batch size: 40
2021-08-25 01:40:32,430 INFO [train.py:450] Epoch 1, batch 16870, batch avg loss 0.3225, total avg loss: 0.3442, batch size: 37
2021-08-25 01:40:39,165 INFO [train.py:450] Epoch 1, batch 16880, batch avg loss 0.4196, total avg loss: 0.3446, batch size: 43
2021-08-25 01:40:45,972 INFO [train.py:450] Epoch 1, batch 16890, batch avg loss 0.3507, total avg loss: 0.3460, batch size: 39
2021-08-25 01:40:52,802 INFO [train.py:450] Epoch 1, batch 16900, batch avg loss 0.3360, total avg loss: 0.3451, batch size: 37
2021-08-25 01:40:59,307 INFO [train.py:450] Epoch 1, batch 16910, batch avg loss 0.3679, total avg loss: 0.3447, batch size: 38
2021-08-25 01:41:04,504 WARNING [cut.py:1694] To perform mix, energy must be non-zero and non-negative (got 0.0).  MonoCut with id "36b3a9db-3d99-c142-c1ba-b4ac20402b59" will not be mixed in.
2021-08-25 01:41:06,164 INFO [train.py:450] Epoch 1, batch 16920, batch avg loss 0.3250, total avg loss: 0.3467, batch size: 39
2021-08-25 01:41:13,281 INFO [train.py:450] Epoch 1, batch 16930, batch avg loss 0.3318, total avg loss: 0.3467, batch size: 38
2021-08-25 01:41:19,673 INFO [train.py:450] Epoch 1, batch 16940, batch avg loss 0.3555, total avg loss: 0.3467, batch size: 39
2021-08-25 01:41:26,544 INFO [train.py:450] Epoch 1, batch 16950, batch avg loss 0.3015, total avg loss: 0.3451, batch size: 44
2021-08-25 01:41:33,080 INFO [train.py:450] Epoch 1, batch 16960, batch avg loss 0.3018, total avg loss: 0.3445, batch size: 37
2021-08-25 01:41:39,962 INFO [train.py:450] Epoch 1, batch 16970, batch avg loss 0.3240, total avg loss: 0.3442, batch size: 41
2021-08-25 01:41:46,274 INFO [train.py:450] Epoch 1, batch 16980, batch avg loss 0.3257, total avg loss: 0.3431, batch size: 38
2021-08-25 01:41:53,193 INFO [train.py:450] Epoch 1, batch 16990, batch avg loss 0.3206, total avg loss: 0.3436, batch size: 44
2021-08-25 01:41:59,522 INFO [train.py:450] Epoch 1, batch 17000, batch avg loss 0.3016, total avg loss: 0.3425, batch size: 37
2021-08-25 01:42:37,417 INFO [train.py:482] Epoch 1, valid loss 0.2467, best valid loss: 0.2462 best valid epoch: 1
2021-08-25 01:42:44,692 INFO [train.py:450] Epoch 1, batch 17010, batch avg loss 0.3665, total avg loss: 0.3575, batch size: 38
2021-08-25 01:42:51,497 INFO [train.py:450] Epoch 1, batch 17020, batch avg loss 0.3528, total avg loss: 0.3508, batch size: 39
2021-08-25 01:42:58,185 INFO [train.py:450] Epoch 1, batch 17030, batch avg loss 0.3951, total avg loss: 0.3462, batch size: 40
2021-08-25 01:43:04,980 INFO [train.py:450] Epoch 1, batch 17040, batch avg loss 0.3507, total avg loss: 0.3448, batch size: 38
2021-08-25 01:43:11,998 INFO [train.py:450] Epoch 1, batch 17050, batch avg loss 0.3644, total avg loss: 0.3434, batch size: 39
2021-08-25 01:43:18,702 INFO [train.py:450] Epoch 1, batch 17060, batch avg loss 0.3709, total avg loss: 0.3433, batch size: 41
2021-08-25 01:43:25,627 INFO [train.py:450] Epoch 1, batch 17070, batch avg loss 0.3430, total avg loss: 0.3458, batch size: 40
2021-08-25 01:43:32,615 INFO [train.py:450] Epoch 1, batch 17080, batch avg loss 0.3474, total avg loss: 0.3492, batch size: 42
2021-08-25 01:43:39,204 INFO [train.py:450] Epoch 1, batch 17090, batch avg loss 0.3850, total avg loss: 0.3531, batch size: 42
2021-08-25 01:43:45,996 INFO [train.py:450] Epoch 1, batch 17100, batch avg loss 0.3592, total avg loss: 0.3544, batch size: 40
2021-08-25 01:43:52,525 INFO [train.py:450] Epoch 1, batch 17110, batch avg loss 0.3539, total avg loss: 0.3544, batch size: 40
2021-08-25 01:43:59,349 INFO [train.py:450] Epoch 1, batch 17120, batch avg loss 0.2953, total avg loss: 0.3529, batch size: 39
2021-08-25 01:44:06,084 INFO [train.py:450] Epoch 1, batch 17130, batch avg loss 0.3852, total avg loss: 0.3526, batch size: 41
2021-08-25 01:44:12,448 INFO [train.py:450] Epoch 1, batch 17140, batch avg loss 0.3591, total avg loss: 0.3518, batch size: 38
2021-08-25 01:44:19,343 INFO [train.py:450] Epoch 1, batch 17150, batch avg loss 0.3813, total avg loss: 0.3519, batch size: 40
2021-08-25 01:44:25,798 INFO [train.py:450] Epoch 1, batch 17160, batch avg loss 0.3785, total avg loss: 0.3540, batch size: 39
2021-08-25 01:44:32,331 INFO [train.py:450] Epoch 1, batch 17170, batch avg loss 0.3350, total avg loss: 0.3534, batch size: 42
2021-08-25 01:44:39,380 INFO [train.py:450] Epoch 1, batch 17180, batch avg loss 0.3636, total avg loss: 0.3531, batch size: 43
2021-08-25 01:44:45,768 INFO [train.py:450] Epoch 1, batch 17190, batch avg loss 0.3242, total avg loss: 0.3528, batch size: 43
2021-08-25 01:44:52,293 INFO [train.py:450] Epoch 1, batch 17200, batch avg loss 0.3726, total avg loss: 0.3525, batch size: 43
2021-08-25 01:44:58,719 INFO [train.py:450] Epoch 1, batch 17210, batch avg loss 0.3125, total avg loss: 0.3500, batch size: 40
2021-08-25 01:45:05,553 INFO [train.py:450] Epoch 1, batch 17220, batch avg loss 0.3413, total avg loss: 0.3544, batch size: 38
2021-08-25 01:45:12,262 INFO [train.py:450] Epoch 1, batch 17230, batch avg loss 0.3243, total avg loss: 0.3508, batch size: 38
2021-08-25 01:45:18,725 INFO [train.py:450] Epoch 1, batch 17240, batch avg loss 0.3278, total avg loss: 0.3474, batch size: 42
2021-08-25 01:45:24,925 INFO [train.py:450] Epoch 1, batch 17250, batch avg loss 0.3157, total avg loss: 0.3469, batch size: 38
2021-08-25 01:45:30,990 INFO [train.py:450] Epoch 1, batch 17260, batch avg loss 0.3831, total avg loss: 0.3460, batch size: 40
2021-08-25 01:45:37,704 INFO [train.py:450] Epoch 1, batch 17270, batch avg loss 0.3281, total avg loss: 0.3433, batch size: 37
2021-08-25 01:45:44,005 INFO [train.py:450] Epoch 1, batch 17280, batch avg loss 0.4030, total avg loss: 0.3427, batch size: 42
2021-08-25 01:45:50,606 INFO [train.py:450] Epoch 1, batch 17290, batch avg loss 0.3430, total avg loss: 0.3427, batch size: 41
2021-08-25 01:45:57,051 INFO [train.py:450] Epoch 1, batch 17300, batch avg loss 0.3281, total avg loss: 0.3433, batch size: 41
2021-08-25 01:46:03,830 INFO [train.py:450] Epoch 1, batch 17310, batch avg loss 0.3573, total avg loss: 0.3432, batch size: 40
2021-08-25 01:46:09,877 INFO [train.py:450] Epoch 1, batch 17320, batch avg loss 0.3754, total avg loss: 0.3441, batch size: 39
2021-08-25 01:46:15,934 INFO [train.py:450] Epoch 1, batch 17330, batch avg loss 0.3006, total avg loss: 0.3433, batch size: 39
2021-08-25 01:46:22,686 INFO [train.py:450] Epoch 1, batch 17340, batch avg loss 0.2857, total avg loss: 0.3436, batch size: 40
2021-08-25 01:46:29,297 INFO [train.py:450] Epoch 1, batch 17350, batch avg loss 0.3262, total avg loss: 0.3455, batch size: 38
2021-08-25 01:46:35,686 INFO [train.py:450] Epoch 1, batch 17360, batch avg loss 0.3359, total avg loss: 0.3453, batch size: 38
2021-08-25 01:46:42,043 INFO [train.py:450] Epoch 1, batch 17370, batch avg loss 0.3842, total avg loss: 0.3457, batch size: 37
2021-08-25 01:46:49,298 INFO [train.py:450] Epoch 1, batch 17380, batch avg loss 0.3173, total avg loss: 0.3456, batch size: 37
2021-08-25 01:46:56,049 INFO [train.py:450] Epoch 1, batch 17390, batch avg loss 0.2877, total avg loss: 0.3451, batch size: 37
2021-08-25 01:47:02,604 INFO [train.py:450] Epoch 1, batch 17400, batch avg loss 0.3295, total avg loss: 0.3451, batch size: 40
2021-08-25 01:47:10,463 INFO [train.py:450] Epoch 1, batch 17410, batch avg loss 0.3626, total avg loss: 0.3469, batch size: 39
2021-08-25 01:47:16,434 INFO [train.py:450] Epoch 1, batch 17420, batch avg loss 0.3253, total avg loss: 0.3446, batch size: 40
2021-08-25 01:47:26,192 INFO [train.py:450] Epoch 1, batch 17430, batch avg loss 0.3416, total avg loss: 0.3368, batch size: 38
2021-08-25 01:47:32,203 INFO [train.py:450] Epoch 1, batch 17440, batch avg loss 0.3361, total avg loss: 0.3401, batch size: 41
2021-08-25 01:47:38,924 INFO [train.py:450] Epoch 1, batch 17450, batch avg loss 0.3018, total avg loss: 0.3429, batch size: 40
2021-08-25 01:47:45,393 INFO [train.py:450] Epoch 1, batch 17460, batch avg loss 0.2837, total avg loss: 0.3420, batch size: 37
2021-08-25 01:47:52,124 INFO [train.py:450] Epoch 1, batch 17470, batch avg loss 0.2908, total avg loss: 0.3424, batch size: 40
2021-08-25 01:47:59,204 INFO [train.py:450] Epoch 1, batch 17480, batch avg loss 0.3637, total avg loss: 0.3442, batch size: 41
2021-08-25 01:48:05,701 INFO [train.py:450] Epoch 1, batch 17490, batch avg loss 0.3016, total avg loss: 0.3453, batch size: 37
2021-08-25 01:48:12,366 INFO [train.py:450] Epoch 1, batch 17500, batch avg loss 0.3606, total avg loss: 0.3465, batch size: 40
2021-08-25 01:48:18,869 INFO [train.py:450] Epoch 1, batch 17510, batch avg loss 0.2612, total avg loss: 0.3465, batch size: 38
2021-08-25 01:48:25,291 INFO [train.py:450] Epoch 1, batch 17520, batch avg loss 0.3291, total avg loss: 0.3457, batch size: 40
2021-08-25 01:48:31,676 INFO [train.py:450] Epoch 1, batch 17530, batch avg loss 0.3325, total avg loss: 0.3448, batch size: 40
2021-08-25 01:48:38,533 INFO [train.py:450] Epoch 1, batch 17540, batch avg loss 0.3241, total avg loss: 0.3445, batch size: 41
2021-08-25 01:48:45,300 INFO [train.py:450] Epoch 1, batch 17550, batch avg loss 0.3582, total avg loss: 0.3448, batch size: 39
2021-08-25 01:48:51,705 INFO [train.py:450] Epoch 1, batch 17560, batch avg loss 0.3631, total avg loss: 0.3449, batch size: 41
2021-08-25 01:48:57,841 INFO [train.py:450] Epoch 1, batch 17570, batch avg loss 0.3170, total avg loss: 0.3445, batch size: 37
2021-08-25 01:49:04,611 INFO [train.py:450] Epoch 1, batch 17580, batch avg loss 0.4088, total avg loss: 0.3449, batch size: 40
2021-08-25 01:49:10,846 INFO [train.py:450] Epoch 1, batch 17590, batch avg loss 0.4652, total avg loss: 0.3465, batch size: 39
2021-08-25 01:49:17,470 INFO [train.py:450] Epoch 1, batch 17600, batch avg loss 0.3356, total avg loss: 0.3489, batch size: 41
2021-08-25 01:49:24,281 INFO [train.py:450] Epoch 1, batch 17610, batch avg loss 0.3131, total avg loss: 0.3469, batch size: 39
2021-08-25 01:49:30,699 INFO [train.py:450] Epoch 1, batch 17620, batch avg loss 0.3384, total avg loss: 0.3517, batch size: 44
2021-08-25 01:49:37,395 INFO [train.py:450] Epoch 1, batch 17630, batch avg loss 0.3317, total avg loss: 0.3530, batch size: 38
2021-08-25 01:49:43,765 INFO [train.py:450] Epoch 1, batch 17640, batch avg loss 0.4258, total avg loss: 0.3555, batch size: 41
2021-08-25 01:49:50,267 INFO [train.py:450] Epoch 1, batch 17650, batch avg loss 0.2823, total avg loss: 0.3507, batch size: 39
2021-08-25 01:49:57,001 INFO [train.py:450] Epoch 1, batch 17660, batch avg loss 0.3360, total avg loss: 0.3491, batch size: 37
2021-08-25 01:50:03,176 INFO [train.py:450] Epoch 1, batch 17670, batch avg loss 0.2888, total avg loss: 0.3470, batch size: 40
2021-08-25 01:50:09,735 INFO [train.py:450] Epoch 1, batch 17680, batch avg loss 0.3027, total avg loss: 0.3464, batch size: 39
2021-08-25 01:50:16,175 INFO [train.py:450] Epoch 1, batch 17690, batch avg loss 0.3253, total avg loss: 0.3463, batch size: 41
2021-08-25 01:50:18,087 WARNING [cut.py:1694] To perform mix, energy must be non-zero and non-negative (got 0.0).  MonoCut with id "ed1a81d6-6c4c-d584-56f9-1aa0c3b5240b" will not be mixed in.
2021-08-25 01:50:22,388 INFO [train.py:450] Epoch 1, batch 17700, batch avg loss 0.3282, total avg loss: 0.3446, batch size: 40
2021-08-25 01:50:29,229 INFO [train.py:450] Epoch 1, batch 17710, batch avg loss 0.3012, total avg loss: 0.3448, batch size: 39
2021-08-25 01:50:36,366 INFO [train.py:450] Epoch 1, batch 17720, batch avg loss 0.3254, total avg loss: 0.3442, batch size: 39
2021-08-25 01:50:43,454 INFO [train.py:450] Epoch 1, batch 17730, batch avg loss 0.3898, total avg loss: 0.3453, batch size: 43
2021-08-25 01:50:50,372 INFO [train.py:450] Epoch 1, batch 17740, batch avg loss 0.3391, total avg loss: 0.3454, batch size: 39
2021-08-25 01:50:56,094 WARNING [cut.py:1694] To perform mix, energy must be non-zero and non-negative (got 0.0).  MonoCut with id "ad099000-59c0-7441-20cb-b4a82f56cbca" will not be mixed in.
2021-08-25 01:50:56,907 INFO [train.py:450] Epoch 1, batch 17750, batch avg loss 0.3085, total avg loss: 0.3453, batch size: 38
2021-08-25 01:51:03,232 INFO [train.py:450] Epoch 1, batch 17760, batch avg loss 0.3887, total avg loss: 0.3456, batch size: 39
2021-08-25 01:51:07,984 WARNING [cut.py:1694] To perform mix, energy must be non-zero and non-negative (got 0.0).  MonoCut with id "c1997600-3bb1-3da7-066f-3dcba487dd59" will not be mixed in.
2021-08-25 01:51:09,801 INFO [train.py:450] Epoch 1, batch 17770, batch avg loss 0.3858, total avg loss: 0.3470, batch size: 39
2021-08-25 01:51:16,141 INFO [train.py:450] Epoch 1, batch 17780, batch avg loss 0.3195, total avg loss: 0.3472, batch size: 40
2021-08-25 01:51:22,378 INFO [train.py:450] Epoch 1, batch 17790, batch avg loss 0.3289, total avg loss: 0.3469, batch size: 38
2021-08-25 01:51:28,629 INFO [train.py:450] Epoch 1, batch 17800, batch avg loss 0.3199, total avg loss: 0.3475, batch size: 37
2021-08-25 01:51:35,246 INFO [train.py:450] Epoch 1, batch 17810, batch avg loss 0.3300, total avg loss: 0.3433, batch size: 38
2021-08-25 01:51:41,971 INFO [train.py:450] Epoch 1, batch 17820, batch avg loss 0.4084, total avg loss: 0.3534, batch size: 40
2021-08-25 01:51:49,985 INFO [train.py:450] Epoch 1, batch 17830, batch avg loss 0.3251, total avg loss: 0.3527, batch size: 41
2021-08-25 01:51:56,696 INFO [train.py:450] Epoch 1, batch 17840, batch avg loss 0.3076, total avg loss: 0.3486, batch size: 38
2021-08-25 01:52:06,605 INFO [train.py:450] Epoch 1, batch 17850, batch avg loss 0.3778, total avg loss: 0.3493, batch size: 40
2021-08-25 01:52:13,204 INFO [train.py:450] Epoch 1, batch 17860, batch avg loss 0.3345, total avg loss: 0.3457, batch size: 39
2021-08-25 01:52:19,751 INFO [train.py:450] Epoch 1, batch 17870, batch avg loss 0.3566, total avg loss: 0.3453, batch size: 43
2021-08-25 01:52:26,678 INFO [train.py:450] Epoch 1, batch 17880, batch avg loss 0.3426, total avg loss: 0.3457, batch size: 36
2021-08-25 01:52:33,450 INFO [train.py:450] Epoch 1, batch 17890, batch avg loss 0.3471, total avg loss: 0.3452, batch size: 37
2021-08-25 01:52:39,514 INFO [train.py:450] Epoch 1, batch 17900, batch avg loss 0.3191, total avg loss: 0.3444, batch size: 40
2021-08-25 01:52:45,993 INFO [train.py:450] Epoch 1, batch 17910, batch avg loss 0.3287, total avg loss: 0.3436, batch size: 38
2021-08-25 01:52:52,690 INFO [train.py:450] Epoch 1, batch 17920, batch avg loss 0.2881, total avg loss: 0.3439, batch size: 41
2021-08-25 01:52:59,754 INFO [train.py:450] Epoch 1, batch 17930, batch avg loss 0.3472, total avg loss: 0.3435, batch size: 42
2021-08-25 01:53:06,475 INFO [train.py:450] Epoch 1, batch 17940, batch avg loss 0.2999, total avg loss: 0.3436, batch size: 40
2021-08-25 01:53:12,654 INFO [train.py:450] Epoch 1, batch 17950, batch avg loss 0.3283, total avg loss: 0.3433, batch size: 37
2021-08-25 01:53:18,945 INFO [train.py:450] Epoch 1, batch 17960, batch avg loss 0.3106, total avg loss: 0.3426, batch size: 44
2021-08-25 01:53:25,080 INFO [train.py:450] Epoch 1, batch 17970, batch avg loss 0.3215, total avg loss: 0.3424, batch size: 40
2021-08-25 01:53:31,775 INFO [train.py:450] Epoch 1, batch 17980, batch avg loss 0.3002, total avg loss: 0.3418, batch size: 38
2021-08-25 01:53:38,357 INFO [train.py:450] Epoch 1, batch 17990, batch avg loss 0.3121, total avg loss: 0.3419, batch size: 41
2021-08-25 01:53:44,679 INFO [train.py:450] Epoch 1, batch 18000, batch avg loss 0.3249, total avg loss: 0.3407, batch size: 38
2021-08-25 01:54:23,627 INFO [train.py:482] Epoch 1, valid loss 0.2475, best valid loss: 0.2462 best valid epoch: 1
2021-08-25 01:54:29,480 INFO [train.py:450] Epoch 1, batch 18010, batch avg loss 0.3751, total avg loss: 0.3549, batch size: 37
2021-08-25 01:54:35,184 INFO [train.py:450] Epoch 1, batch 18020, batch avg loss 0.3223, total avg loss: 0.3452, batch size: 40
2021-08-25 01:54:41,361 INFO [train.py:450] Epoch 1, batch 18030, batch avg loss 0.3649, total avg loss: 0.3444, batch size: 40
2021-08-25 01:54:48,253 INFO [train.py:450] Epoch 1, batch 18040, batch avg loss 0.3037, total avg loss: 0.3417, batch size: 38
2021-08-25 01:54:54,873 INFO [train.py:450] Epoch 1, batch 18050, batch avg loss 0.3310, total avg loss: 0.3388, batch size: 41
2021-08-25 01:55:01,675 INFO [train.py:450] Epoch 1, batch 18060, batch avg loss 0.3358, total avg loss: 0.3404, batch size: 44
2021-08-25 01:55:07,884 INFO [train.py:450] Epoch 1, batch 18070, batch avg loss 0.3613, total avg loss: 0.3419, batch size: 40
2021-08-25 01:55:13,783 INFO [train.py:450] Epoch 1, batch 18080, batch avg loss 0.3663, total avg loss: 0.3410, batch size: 39
2021-08-25 01:55:20,330 INFO [train.py:450] Epoch 1, batch 18090, batch avg loss 0.3489, total avg loss: 0.3407, batch size: 39
2021-08-25 01:55:26,447 INFO [train.py:450] Epoch 1, batch 18100, batch avg loss 0.2912, total avg loss: 0.3407, batch size: 39
2021-08-25 01:55:33,493 INFO [train.py:450] Epoch 1, batch 18110, batch avg loss 0.3519, total avg loss: 0.3409, batch size: 41
2021-08-25 01:55:39,418 INFO [train.py:450] Epoch 1, batch 18120, batch avg loss 0.3566, total avg loss: 0.3410, batch size: 38
2021-08-25 01:55:46,006 INFO [train.py:450] Epoch 1, batch 18130, batch avg loss 0.3741, total avg loss: 0.3408, batch size: 38
2021-08-25 01:55:52,754 INFO [train.py:450] Epoch 1, batch 18140, batch avg loss 0.3164, total avg loss: 0.3400, batch size: 43
2021-08-25 01:55:58,986 INFO [train.py:450] Epoch 1, batch 18150, batch avg loss 0.3428, total avg loss: 0.3403, batch size: 41
2021-08-25 01:56:05,736 INFO [train.py:450] Epoch 1, batch 18160, batch avg loss 0.3094, total avg loss: 0.3400, batch size: 38
2021-08-25 01:56:11,795 INFO [train.py:450] Epoch 1, batch 18170, batch avg loss 0.3192, total avg loss: 0.3397, batch size: 42
2021-08-25 01:56:18,214 INFO [train.py:450] Epoch 1, batch 18180, batch avg loss 0.3161, total avg loss: 0.3404, batch size: 40
2021-08-25 01:56:26,476 INFO [train.py:450] Epoch 1, batch 18190, batch avg loss 0.3576, total avg loss: 0.3407, batch size: 38
2021-08-25 01:56:32,771 INFO [train.py:450] Epoch 1, batch 18200, batch avg loss 0.3334, total avg loss: 0.3416, batch size: 39
2021-08-25 01:56:41,386 INFO [train.py:450] Epoch 1, batch 18210, batch avg loss 0.3687, total avg loss: 0.3542, batch size: 41
2021-08-25 01:56:48,795 INFO [train.py:450] Epoch 1, batch 18220, batch avg loss 0.3631, total avg loss: 0.3585, batch size: 42
2021-08-25 01:56:55,528 INFO [train.py:450] Epoch 1, batch 18230, batch avg loss 0.3133, total avg loss: 0.3554, batch size: 38
2021-08-25 01:57:01,582 INFO [train.py:450] Epoch 1, batch 18240, batch avg loss 0.3273, total avg loss: 0.3484, batch size: 38
2021-08-25 01:57:07,893 INFO [train.py:450] Epoch 1, batch 18250, batch avg loss 0.3738, total avg loss: 0.3488, batch size: 38
2021-08-25 01:57:14,097 INFO [train.py:450] Epoch 1, batch 18260, batch avg loss 0.3502, total avg loss: 0.3493, batch size: 38
2021-08-25 01:57:20,524 INFO [train.py:450] Epoch 1, batch 18270, batch avg loss 0.3271, total avg loss: 0.3461, batch size: 40
2021-08-25 01:57:26,744 INFO [train.py:450] Epoch 1, batch 18280, batch avg loss 0.3301, total avg loss: 0.3450, batch size: 42
2021-08-25 01:57:33,091 INFO [train.py:450] Epoch 1, batch 18290, batch avg loss 0.2917, total avg loss: 0.3436, batch size: 40
2021-08-25 01:57:39,314 INFO [train.py:450] Epoch 1, batch 18300, batch avg loss 0.3357, total avg loss: 0.3441, batch size: 42
2021-08-25 01:57:45,716 INFO [train.py:450] Epoch 1, batch 18310, batch avg loss 0.3339, total avg loss: 0.3444, batch size: 41
2021-08-25 01:57:52,121 INFO [train.py:450] Epoch 1, batch 18320, batch avg loss 0.2871, total avg loss: 0.3466, batch size: 42
2021-08-25 01:57:58,586 INFO [train.py:450] Epoch 1, batch 18330, batch avg loss 0.3004, total avg loss: 0.3459, batch size: 39
2021-08-25 01:58:04,897 INFO [train.py:450] Epoch 1, batch 18340, batch avg loss 0.3245, total avg loss: 0.3456, batch size: 36
2021-08-25 01:58:10,981 INFO [train.py:450] Epoch 1, batch 18350, batch avg loss 0.4327, total avg loss: 0.3464, batch size: 37
2021-08-25 01:58:17,509 INFO [train.py:450] Epoch 1, batch 18360, batch avg loss 0.3511, total avg loss: 0.3464, batch size: 40
2021-08-25 01:58:23,994 INFO [train.py:450] Epoch 1, batch 18370, batch avg loss 0.3270, total avg loss: 0.3469, batch size: 38
2021-08-25 01:58:30,683 INFO [train.py:450] Epoch 1, batch 18380, batch avg loss 0.3077, total avg loss: 0.3469, batch size: 38
2021-08-25 01:58:37,192 INFO [train.py:450] Epoch 1, batch 18390, batch avg loss 0.3068, total avg loss: 0.3463, batch size: 42
2021-08-25 01:58:43,541 INFO [train.py:450] Epoch 1, batch 18400, batch avg loss 0.3348, total avg loss: 0.3462, batch size: 42
2021-08-25 01:58:49,966 INFO [train.py:450] Epoch 1, batch 18410, batch avg loss 0.3718, total avg loss: 0.3600, batch size: 38
2021-08-25 01:58:56,215 INFO [train.py:450] Epoch 1, batch 18420, batch avg loss 0.3361, total avg loss: 0.3434, batch size: 40
2021-08-25 01:59:02,433 INFO [train.py:450] Epoch 1, batch 18430, batch avg loss 0.3799, total avg loss: 0.3472, batch size: 36
2021-08-25 01:59:09,493 INFO [train.py:450] Epoch 1, batch 18440, batch avg loss 0.3939, total avg loss: 0.3470, batch size: 39
2021-08-25 01:59:15,799 INFO [train.py:450] Epoch 1, batch 18450, batch avg loss 0.3652, total avg loss: 0.3458, batch size: 39
2021-08-25 01:59:22,357 INFO [train.py:450] Epoch 1, batch 18460, batch avg loss 0.3470, total avg loss: 0.3442, batch size: 41
2021-08-25 01:59:28,810 INFO [train.py:450] Epoch 1, batch 18470, batch avg loss 0.3316, total avg loss: 0.3427, batch size: 45
2021-08-25 01:59:35,104 INFO [train.py:450] Epoch 1, batch 18480, batch avg loss 0.3405, total avg loss: 0.3426, batch size: 41
2021-08-25 01:59:41,786 INFO [train.py:450] Epoch 1, batch 18490, batch avg loss 0.3006, total avg loss: 0.3427, batch size: 40
2021-08-25 01:59:48,254 INFO [train.py:450] Epoch 1, batch 18500, batch avg loss 0.3713, total avg loss: 0.3425, batch size: 37
2021-08-25 01:59:55,056 INFO [train.py:450] Epoch 1, batch 18510, batch avg loss 0.3289, total avg loss: 0.3427, batch size: 43
2021-08-25 02:00:01,550 INFO [train.py:450] Epoch 1, batch 18520, batch avg loss 0.3248, total avg loss: 0.3415, batch size: 36
2021-08-25 02:00:08,082 INFO [train.py:450] Epoch 1, batch 18530, batch avg loss 0.3321, total avg loss: 0.3415, batch size: 39
2021-08-25 02:00:14,278 INFO [train.py:450] Epoch 1, batch 18540, batch avg loss 0.3367, total avg loss: 0.3414, batch size: 40
2021-08-25 02:00:20,907 INFO [train.py:450] Epoch 1, batch 18550, batch avg loss 0.3395, total avg loss: 0.3423, batch size: 43
2021-08-25 02:00:27,199 INFO [train.py:450] Epoch 1, batch 18560, batch avg loss 0.4165, total avg loss: 0.3419, batch size: 41
2021-08-25 02:00:33,199 INFO [train.py:450] Epoch 1, batch 18570, batch avg loss 0.3740, total avg loss: 0.3425, batch size: 40
2021-08-25 02:00:40,150 INFO [train.py:450] Epoch 1, batch 18580, batch avg loss 0.3217, total avg loss: 0.3430, batch size: 40
2021-08-25 02:00:47,231 INFO [train.py:450] Epoch 1, batch 18590, batch avg loss 0.4032, total avg loss: 0.3439, batch size: 43
2021-08-25 02:00:54,193 INFO [train.py:450] Epoch 1, batch 18600, batch avg loss 0.3276, total avg loss: 0.3443, batch size: 44
2021-08-25 02:01:00,247 INFO [train.py:450] Epoch 1, batch 18610, batch avg loss 0.3131, total avg loss: 0.3251, batch size: 40
2021-08-25 02:01:08,477 INFO [train.py:450] Epoch 1, batch 18620, batch avg loss 0.3113, total avg loss: 0.3345, batch size: 40
2021-08-25 02:01:14,824 INFO [train.py:450] Epoch 1, batch 18630, batch avg loss 0.3216, total avg loss: 0.3351, batch size: 40
2021-08-25 02:01:24,657 INFO [train.py:450] Epoch 1, batch 18640, batch avg loss 0.3528, total avg loss: 0.3359, batch size: 42
2021-08-25 02:01:31,034 INFO [train.py:450] Epoch 1, batch 18650, batch avg loss 0.3219, total avg loss: 0.3380, batch size: 40
2021-08-25 02:01:37,257 INFO [train.py:450] Epoch 1, batch 18660, batch avg loss 0.3680, total avg loss: 0.3392, batch size: 44
2021-08-25 02:01:43,226 INFO [train.py:450] Epoch 1, batch 18670, batch avg loss 0.3805, total avg loss: 0.3400, batch size: 39
2021-08-25 02:01:49,310 INFO [train.py:450] Epoch 1, batch 18680, batch avg loss 0.3273, total avg loss: 0.3409, batch size: 38
2021-08-25 02:01:55,447 INFO [train.py:450] Epoch 1, batch 18690, batch avg loss 0.3417, total avg loss: 0.3405, batch size: 42
2021-08-25 02:02:01,638 INFO [train.py:450] Epoch 1, batch 18700, batch avg loss 0.3536, total avg loss: 0.3413, batch size: 39
2021-08-25 02:02:08,167 INFO [train.py:450] Epoch 1, batch 18710, batch avg loss 0.3998, total avg loss: 0.3420, batch size: 40
2021-08-25 02:02:14,474 INFO [train.py:450] Epoch 1, batch 18720, batch avg loss 0.3785, total avg loss: 0.3431, batch size: 39
2021-08-25 02:02:21,028 INFO [train.py:450] Epoch 1, batch 18730, batch avg loss 0.4039, total avg loss: 0.3442, batch size: 40
2021-08-25 02:02:27,570 INFO [train.py:450] Epoch 1, batch 18740, batch avg loss 0.3179, total avg loss: 0.3442, batch size: 37
2021-08-25 02:02:34,580 INFO [train.py:450] Epoch 1, batch 18750, batch avg loss 0.3190, total avg loss: 0.3435, batch size: 40
2021-08-25 02:02:40,596 INFO [train.py:450] Epoch 1, batch 18760, batch avg loss 0.3386, total avg loss: 0.3433, batch size: 42
2021-08-25 02:02:46,839 INFO [train.py:450] Epoch 1, batch 18770, batch avg loss 0.3529, total avg loss: 0.3431, batch size: 41
2021-08-25 02:02:53,299 INFO [train.py:450] Epoch 1, batch 18780, batch avg loss 0.2770, total avg loss: 0.3424, batch size: 40
2021-08-25 02:03:00,059 INFO [train.py:450] Epoch 1, batch 18790, batch avg loss 0.3514, total avg loss: 0.3420, batch size: 38
2021-08-25 02:03:06,297 INFO [train.py:450] Epoch 1, batch 18800, batch avg loss 0.3418, total avg loss: 0.3415, batch size: 40
2021-08-25 02:03:13,119 INFO [train.py:450] Epoch 1, batch 18810, batch avg loss 0.3656, total avg loss: 0.3444, batch size: 40
2021-08-25 02:03:19,234 INFO [train.py:450] Epoch 1, batch 18820, batch avg loss 0.3950, total avg loss: 0.3528, batch size: 41
2021-08-25 02:03:25,748 INFO [train.py:450] Epoch 1, batch 18830, batch avg loss 0.3909, total avg loss: 0.3491, batch size: 39
2021-08-25 02:03:32,064 INFO [train.py:450] Epoch 1, batch 18840, batch avg loss 0.3796, total avg loss: 0.3521, batch size: 42
2021-08-25 02:03:38,467 INFO [train.py:450] Epoch 1, batch 18850, batch avg loss 0.3129, total avg loss: 0.3480, batch size: 38
2021-08-25 02:03:44,586 INFO [train.py:450] Epoch 1, batch 18860, batch avg loss 0.3021, total avg loss: 0.3455, batch size: 38
2021-08-25 02:03:50,954 INFO [train.py:450] Epoch 1, batch 18870, batch avg loss 0.3282, total avg loss: 0.3476, batch size: 38
2021-08-25 02:03:57,038 INFO [train.py:450] Epoch 1, batch 18880, batch avg loss 0.3239, total avg loss: 0.3470, batch size: 39
2021-08-25 02:04:03,348 INFO [train.py:450] Epoch 1, batch 18890, batch avg loss 0.3435, total avg loss: 0.3459, batch size: 37
2021-08-25 02:04:09,795 INFO [train.py:450] Epoch 1, batch 18900, batch avg loss 0.3317, total avg loss: 0.3482, batch size: 44
2021-08-25 02:04:16,498 INFO [train.py:450] Epoch 1, batch 18910, batch avg loss 0.3480, total avg loss: 0.3477, batch size: 39
2021-08-25 02:04:23,122 INFO [train.py:450] Epoch 1, batch 18920, batch avg loss 0.3512, total avg loss: 0.3476, batch size: 41
2021-08-25 02:04:29,384 INFO [train.py:450] Epoch 1, batch 18930, batch avg loss 0.3503, total avg loss: 0.3468, batch size: 39
2021-08-25 02:04:35,982 INFO [train.py:450] Epoch 1, batch 18940, batch avg loss 0.3779, total avg loss: 0.3480, batch size: 39
2021-08-25 02:04:42,711 INFO [train.py:450] Epoch 1, batch 18950, batch avg loss 0.3467, total avg loss: 0.3479, batch size: 38
2021-08-25 02:04:49,573 INFO [train.py:450] Epoch 1, batch 18960, batch avg loss 0.3088, total avg loss: 0.3473, batch size: 39
2021-08-25 02:04:55,398 INFO [train.py:450] Epoch 1, batch 18970, batch avg loss 0.3205, total avg loss: 0.3475, batch size: 40
2021-08-25 02:05:01,411 INFO [train.py:450] Epoch 1, batch 18980, batch avg loss 0.3179, total avg loss: 0.3474, batch size: 43
2021-08-25 02:05:07,895 INFO [train.py:450] Epoch 1, batch 18990, batch avg loss 0.3450, total avg loss: 0.3476, batch size: 38
2021-08-25 02:05:13,947 INFO [train.py:450] Epoch 1, batch 19000, batch avg loss 0.3319, total avg loss: 0.3474, batch size: 39
2021-08-25 02:05:51,682 INFO [train.py:482] Epoch 1, valid loss 0.2448, best valid loss: 0.2448 best valid epoch: 1
2021-08-25 02:06:00,026 INFO [train.py:450] Epoch 1, batch 19010, batch avg loss 0.3475, total avg loss: 0.3271, batch size: 41
2021-08-25 02:06:06,070 INFO [train.py:450] Epoch 1, batch 19020, batch avg loss 0.3422, total avg loss: 0.3347, batch size: 40
2021-08-25 02:06:12,627 INFO [train.py:450] Epoch 1, batch 19030, batch avg loss 0.2999, total avg loss: 0.3384, batch size: 39
2021-08-25 02:06:18,798 INFO [train.py:450] Epoch 1, batch 19040, batch avg loss 0.3630, total avg loss: 0.3385, batch size: 43
2021-08-25 02:06:25,070 INFO [train.py:450] Epoch 1, batch 19050, batch avg loss 0.3349, total avg loss: 0.3422, batch size: 42
2021-08-25 02:06:31,345 INFO [train.py:450] Epoch 1, batch 19060, batch avg loss 0.4071, total avg loss: 0.3459, batch size: 45
2021-08-25 02:06:37,234 INFO [train.py:450] Epoch 1, batch 19070, batch avg loss 0.3201, total avg loss: 0.3464, batch size: 39
2021-08-25 02:06:43,342 INFO [train.py:450] Epoch 1, batch 19080, batch avg loss 0.3660, total avg loss: 0.3445, batch size: 41
2021-08-25 02:06:49,246 INFO [train.py:450] Epoch 1, batch 19090, batch avg loss 0.3370, total avg loss: 0.3455, batch size: 42
2021-08-25 02:06:55,556 INFO [train.py:450] Epoch 1, batch 19100, batch avg loss 0.3099, total avg loss: 0.3440, batch size: 37
2021-08-25 02:07:02,042 INFO [train.py:450] Epoch 1, batch 19110, batch avg loss 0.3263, total avg loss: 0.3448, batch size: 41
2021-08-25 02:07:07,911 INFO [train.py:450] Epoch 1, batch 19120, batch avg loss 0.3738, total avg loss: 0.3445, batch size: 38
2021-08-25 02:07:13,907 INFO [train.py:450] Epoch 1, batch 19130, batch avg loss 0.3360, total avg loss: 0.3429, batch size: 38
2021-08-25 02:07:20,512 INFO [train.py:450] Epoch 1, batch 19140, batch avg loss 0.2764, total avg loss: 0.3432, batch size: 39
2021-08-25 02:07:26,909 INFO [train.py:450] Epoch 1, batch 19150, batch avg loss 0.3257, total avg loss: 0.3430, batch size: 38
2021-08-25 02:07:33,644 INFO [train.py:450] Epoch 1, batch 19160, batch avg loss 0.3551, total avg loss: 0.3427, batch size: 38
2021-08-25 02:07:40,464 INFO [train.py:450] Epoch 1, batch 19170, batch avg loss 0.3246, total avg loss: 0.3427, batch size: 40
2021-08-25 02:07:46,954 INFO [train.py:450] Epoch 1, batch 19180, batch avg loss 0.3365, total avg loss: 0.3429, batch size: 42
2021-08-25 02:07:53,125 INFO [train.py:450] Epoch 1, batch 19190, batch avg loss 0.3162, total avg loss: 0.3429, batch size: 40
2021-08-25 02:07:59,686 INFO [train.py:450] Epoch 1, batch 19200, batch avg loss 0.3306, total avg loss: 0.3429, batch size: 37
2021-08-25 02:08:06,382 INFO [train.py:450] Epoch 1, batch 19210, batch avg loss 0.3488, total avg loss: 0.3523, batch size: 41
2021-08-25 02:08:12,786 INFO [train.py:450] Epoch 1, batch 19220, batch avg loss 0.3732, total avg loss: 0.3521, batch size: 38
2021-08-25 02:08:19,079 INFO [train.py:450] Epoch 1, batch 19230, batch avg loss 0.3509, total avg loss: 0.3473, batch size: 36
2021-08-25 02:08:25,388 INFO [train.py:450] Epoch 1, batch 19240, batch avg loss 0.3565, total avg loss: 0.3457, batch size: 41
2021-08-25 02:08:31,985 INFO [train.py:450] Epoch 1, batch 19250, batch avg loss 0.3165, total avg loss: 0.3455, batch size: 41
2021-08-25 02:08:38,129 INFO [train.py:450] Epoch 1, batch 19260, batch avg loss 0.3556, total avg loss: 0.3434, batch size: 38
2021-08-25 02:08:44,121 INFO [train.py:450] Epoch 1, batch 19270, batch avg loss 0.2957, total avg loss: 0.3431, batch size: 40
2021-08-25 02:08:50,547 INFO [train.py:450] Epoch 1, batch 19280, batch avg loss 0.3532, total avg loss: 0.3416, batch size: 39
2021-08-25 02:08:56,520 INFO [train.py:450] Epoch 1, batch 19290, batch avg loss 0.3134, total avg loss: 0.3409, batch size: 39
2021-08-25 02:09:03,104 INFO [train.py:450] Epoch 1, batch 19300, batch avg loss 0.3718, total avg loss: 0.3423, batch size: 36
2021-08-25 02:09:09,606 INFO [train.py:450] Epoch 1, batch 19310, batch avg loss 0.3545, total avg loss: 0.3416, batch size: 40
2021-08-25 02:09:16,140 INFO [train.py:450] Epoch 1, batch 19320, batch avg loss 0.3327, total avg loss: 0.3418, batch size: 39
2021-08-25 02:09:22,058 INFO [train.py:450] Epoch 1, batch 19330, batch avg loss 0.3350, total avg loss: 0.3425, batch size: 42
2021-08-25 02:09:28,524 INFO [train.py:450] Epoch 1, batch 19340, batch avg loss 0.3832, total avg loss: 0.3435, batch size: 41
2021-08-25 02:09:34,926 INFO [train.py:450] Epoch 1, batch 19350, batch avg loss 0.3653, total avg loss: 0.3446, batch size: 42
2021-08-25 02:09:40,994 INFO [train.py:450] Epoch 1, batch 19360, batch avg loss 0.3371, total avg loss: 0.3443, batch size: 42
2021-08-25 02:09:46,998 INFO [train.py:450] Epoch 1, batch 19370, batch avg loss 0.4045, total avg loss: 0.3452, batch size: 37
2021-08-25 02:09:53,191 INFO [train.py:450] Epoch 1, batch 19380, batch avg loss 0.3406, total avg loss: 0.3446, batch size: 42
2021-08-25 02:10:00,086 INFO [train.py:450] Epoch 1, batch 19390, batch avg loss 0.3748, total avg loss: 0.3451, batch size: 41
2021-08-25 02:10:06,606 INFO [train.py:450] Epoch 1, batch 19400, batch avg loss 0.3292, total avg loss: 0.3446, batch size: 42
2021-08-25 02:10:12,701 INFO [train.py:450] Epoch 1, batch 19410, batch avg loss 0.3769, total avg loss: 0.3493, batch size: 40
2021-08-25 02:10:19,210 INFO [train.py:450] Epoch 1, batch 19420, batch avg loss 0.3525, total avg loss: 0.3424, batch size: 39
2021-08-25 02:10:26,572 INFO [train.py:450] Epoch 1, batch 19430, batch avg loss 0.3704, total avg loss: 0.3472, batch size: 41
2021-08-25 02:10:32,826 INFO [train.py:450] Epoch 1, batch 19440, batch avg loss 0.3832, total avg loss: 0.3480, batch size: 40
2021-08-25 02:10:42,951 INFO [train.py:450] Epoch 1, batch 19450, batch avg loss 0.3556, total avg loss: 0.3497, batch size: 43
2021-08-25 02:10:49,165 INFO [train.py:450] Epoch 1, batch 19460, batch avg loss 0.3388, total avg loss: 0.3501, batch size: 37
2021-08-25 02:10:56,056 INFO [train.py:450] Epoch 1, batch 19470, batch avg loss 0.4220, total avg loss: 0.3488, batch size: 42
2021-08-25 02:11:02,515 INFO [train.py:450] Epoch 1, batch 19480, batch avg loss 0.3326, total avg loss: 0.3479, batch size: 38
2021-08-25 02:11:09,026 INFO [train.py:450] Epoch 1, batch 19490, batch avg loss 0.3444, total avg loss: 0.3475, batch size: 38
2021-08-25 02:11:15,376 INFO [train.py:450] Epoch 1, batch 19500, batch avg loss 0.3662, total avg loss: 0.3461, batch size: 40
2021-08-25 02:11:22,265 INFO [train.py:450] Epoch 1, batch 19510, batch avg loss 0.3336, total avg loss: 0.3463, batch size: 38
2021-08-25 02:11:29,376 INFO [train.py:450] Epoch 1, batch 19520, batch avg loss 0.3312, total avg loss: 0.3463, batch size: 42
2021-08-25 02:11:35,928 INFO [train.py:450] Epoch 1, batch 19530, batch avg loss 0.3449, total avg loss: 0.3459, batch size: 40
2021-08-25 02:11:42,065 INFO [train.py:450] Epoch 1, batch 19540, batch avg loss 0.3463, total avg loss: 0.3449, batch size: 41
2021-08-25 02:11:48,639 INFO [train.py:450] Epoch 1, batch 19550, batch avg loss 0.3447, total avg loss: 0.3438, batch size: 41
2021-08-25 02:11:54,672 INFO [train.py:450] Epoch 1, batch 19560, batch avg loss 0.2814, total avg loss: 0.3427, batch size: 39
2021-08-25 02:12:00,965 INFO [train.py:450] Epoch 1, batch 19570, batch avg loss 0.3343, total avg loss: 0.3422, batch size: 39
2021-08-25 02:12:07,367 INFO [train.py:450] Epoch 1, batch 19580, batch avg loss 0.3719, total avg loss: 0.3428, batch size: 40
2021-08-25 02:12:14,372 INFO [train.py:450] Epoch 1, batch 19590, batch avg loss 0.2838, total avg loss: 0.3429, batch size: 39
2021-08-25 02:12:20,458 INFO [train.py:450] Epoch 1, batch 19600, batch avg loss 0.3386, total avg loss: 0.3420, batch size: 39
2021-08-25 02:12:26,846 INFO [train.py:450] Epoch 1, batch 19610, batch avg loss 0.3240, total avg loss: 0.3486, batch size: 40
2021-08-25 02:12:33,135 INFO [train.py:450] Epoch 1, batch 19620, batch avg loss 0.3660, total avg loss: 0.3450, batch size: 42
2021-08-25 02:12:39,506 INFO [train.py:450] Epoch 1, batch 19630, batch avg loss 0.3421, total avg loss: 0.3457, batch size: 36
2021-08-25 02:12:45,924 INFO [train.py:450] Epoch 1, batch 19640, batch avg loss 0.3031, total avg loss: 0.3441, batch size: 41
2021-08-25 02:12:53,880 INFO [train.py:450] Epoch 1, batch 19650, batch avg loss 0.3412, total avg loss: 0.3416, batch size: 38
2021-08-25 02:13:00,379 INFO [train.py:450] Epoch 1, batch 19660, batch avg loss 0.3140, total avg loss: 0.3413, batch size: 39
2021-08-25 02:13:07,232 INFO [train.py:450] Epoch 1, batch 19670, batch avg loss 0.3346, total avg loss: 0.3435, batch size: 41
2021-08-25 02:13:13,604 INFO [train.py:450] Epoch 1, batch 19680, batch avg loss 0.3536, total avg loss: 0.3434, batch size: 37
2021-08-25 02:13:20,221 INFO [train.py:450] Epoch 1, batch 19690, batch avg loss 0.3208, total avg loss: 0.3431, batch size: 42
2021-08-25 02:13:26,712 INFO [train.py:450] Epoch 1, batch 19700, batch avg loss 0.3520, total avg loss: 0.3428, batch size: 37
2021-08-25 02:13:33,377 INFO [train.py:450] Epoch 1, batch 19710, batch avg loss 0.3355, total avg loss: 0.3434, batch size: 40
2021-08-25 02:13:40,110 INFO [train.py:450] Epoch 1, batch 19720, batch avg loss 0.3477, total avg loss: 0.3442, batch size: 40
2021-08-25 02:13:46,365 INFO [train.py:450] Epoch 1, batch 19730, batch avg loss 0.3090, total avg loss: 0.3434, batch size: 38
2021-08-25 02:13:53,129 INFO [train.py:450] Epoch 1, batch 19740, batch avg loss 0.3346, total avg loss: 0.3447, batch size: 39
2021-08-25 02:13:59,823 INFO [train.py:450] Epoch 1, batch 19750, batch avg loss 0.3482, total avg loss: 0.3440, batch size: 41
2021-08-25 02:14:05,895 INFO [train.py:450] Epoch 1, batch 19760, batch avg loss 0.4155, total avg loss: 0.3436, batch size: 42
2021-08-25 02:14:13,081 INFO [train.py:450] Epoch 1, batch 19770, batch avg loss 0.3725, total avg loss: 0.3434, batch size: 40
2021-08-25 02:14:19,702 INFO [train.py:450] Epoch 1, batch 19780, batch avg loss 0.3778, total avg loss: 0.3440, batch size: 39
2021-08-25 02:14:27,616 INFO [train.py:450] Epoch 1, batch 19790, batch avg loss 0.2868, total avg loss: 0.3436, batch size: 38
2021-08-25 02:14:35,704 WARNING [cut.py:1694] To perform mix, energy must be non-zero and non-negative (got 0.0).  MonoCut with id "f33932c3-3a04-0e97-3e75-c2d25494ec54" will not be mixed in.
2021-08-25 02:14:36,164 INFO [train.py:450] Epoch 1, batch 19800, batch avg loss 0.3657, total avg loss: 0.3431, batch size: 40
2021-08-25 02:14:43,217 INFO [train.py:450] Epoch 1, batch 19810, batch avg loss 0.3244, total avg loss: 0.3376, batch size: 43
2021-08-25 02:14:50,436 INFO [train.py:450] Epoch 1, batch 19820, batch avg loss 0.3653, total avg loss: 0.3375, batch size: 40
2021-08-25 02:14:57,601 INFO [train.py:450] Epoch 1, batch 19830, batch avg loss 0.3749, total avg loss: 0.3395, batch size: 41
2021-08-25 02:15:04,404 INFO [train.py:450] Epoch 1, batch 19840, batch avg loss 0.3880, total avg loss: 0.3435, batch size: 42
2021-08-25 02:15:10,870 INFO [train.py:450] Epoch 1, batch 19850, batch avg loss 0.3355, total avg loss: 0.3439, batch size: 42
2021-08-25 02:15:17,441 INFO [train.py:450] Epoch 1, batch 19860, batch avg loss 0.3407, total avg loss: 0.3430, batch size: 37
2021-08-25 02:15:24,158 INFO [train.py:450] Epoch 1, batch 19870, batch avg loss 0.3707, total avg loss: 0.3436, batch size: 37
2021-08-25 02:15:32,057 INFO [train.py:450] Epoch 1, batch 19880, batch avg loss 0.3840, total avg loss: 0.3456, batch size: 39
2021-08-25 02:15:38,903 INFO [train.py:450] Epoch 1, batch 19890, batch avg loss 0.2946, total avg loss: 0.3454, batch size: 38
2021-08-25 02:15:45,351 INFO [train.py:450] Epoch 1, batch 19900, batch avg loss 0.3614, total avg loss: 0.3479, batch size: 40
2021-08-25 02:15:51,948 INFO [train.py:450] Epoch 1, batch 19910, batch avg loss 0.3419, total avg loss: 0.3485, batch size: 39
2021-08-25 02:15:59,007 INFO [train.py:450] Epoch 1, batch 19920, batch avg loss 0.3295, total avg loss: 0.3481, batch size: 41
2021-08-25 02:16:05,566 INFO [train.py:450] Epoch 1, batch 19930, batch avg loss 0.3493, total avg loss: 0.3485, batch size: 40
2021-08-25 02:16:12,426 INFO [train.py:450] Epoch 1, batch 19940, batch avg loss 0.3722, total avg loss: 0.3484, batch size: 43
2021-08-25 02:16:19,095 INFO [train.py:450] Epoch 1, batch 19950, batch avg loss 0.4022, total avg loss: 0.3485, batch size: 38
2021-08-25 02:16:25,319 INFO [train.py:450] Epoch 1, batch 19960, batch avg loss 0.3009, total avg loss: 0.3486, batch size: 38
2021-08-25 02:16:32,266 INFO [train.py:450] Epoch 1, batch 19970, batch avg loss 0.3881, total avg loss: 0.3480, batch size: 42
2021-08-25 02:16:39,200 INFO [train.py:450] Epoch 1, batch 19980, batch avg loss 0.3543, total avg loss: 0.3475, batch size: 41
2021-08-25 02:16:46,217 INFO [train.py:450] Epoch 1, batch 19990, batch avg loss 0.3136, total avg loss: 0.3470, batch size: 40
2021-08-25 02:16:53,170 INFO [train.py:450] Epoch 1, batch 20000, batch avg loss 0.3387, total avg loss: 0.3466, batch size: 40
2021-08-25 02:17:31,964 INFO [train.py:482] Epoch 1, valid loss 0.2470, best valid loss: 0.2448 best valid epoch: 1
2021-08-25 02:17:37,931 INFO [train.py:450] Epoch 1, batch 20010, batch avg loss 0.3162, total avg loss: 0.3413, batch size: 41
2021-08-25 02:17:44,202 INFO [train.py:450] Epoch 1, batch 20020, batch avg loss 0.3232, total avg loss: 0.3346, batch size: 40
2021-08-25 02:17:50,932 INFO [train.py:450] Epoch 1, batch 20030, batch avg loss 0.3530, total avg loss: 0.3385, batch size: 46
2021-08-25 02:17:57,599 INFO [train.py:450] Epoch 1, batch 20040, batch avg loss 0.3776, total avg loss: 0.3433, batch size: 40
2021-08-25 02:18:05,042 INFO [train.py:450] Epoch 1, batch 20050, batch avg loss 0.3293, total avg loss: 0.3425, batch size: 40
2021-08-25 02:18:11,427 INFO [train.py:450] Epoch 1, batch 20060, batch avg loss 0.3548, total avg loss: 0.3430, batch size: 38
2021-08-25 02:18:18,410 INFO [train.py:450] Epoch 1, batch 20070, batch avg loss 0.3532, total avg loss: 0.3443, batch size: 41
2021-08-25 02:18:24,954 INFO [train.py:450] Epoch 1, batch 20080, batch avg loss 0.3245, total avg loss: 0.3423, batch size: 40
2021-08-25 02:18:31,776 INFO [train.py:450] Epoch 1, batch 20090, batch avg loss 0.3320, total avg loss: 0.3416, batch size: 39
2021-08-25 02:18:38,999 INFO [train.py:450] Epoch 1, batch 20100, batch avg loss 0.3550, total avg loss: 0.3427, batch size: 41
2021-08-25 02:18:45,334 INFO [train.py:450] Epoch 1, batch 20110, batch avg loss 0.3234, total avg loss: 0.3433, batch size: 41
2021-08-25 02:18:53,848 INFO [train.py:450] Epoch 1, batch 20120, batch avg loss 0.3385, total avg loss: 0.3431, batch size: 41
2021-08-25 02:19:01,017 INFO [train.py:450] Epoch 1, batch 20130, batch avg loss 0.3676, total avg loss: 0.3441, batch size: 40
2021-08-25 02:19:11,586 INFO [train.py:450] Epoch 1, batch 20140, batch avg loss 0.3281, total avg loss: 0.3447, batch size: 40
2021-08-25 02:19:18,583 INFO [train.py:450] Epoch 1, batch 20150, batch avg loss 0.3310, total avg loss: 0.3447, batch size: 40
2021-08-25 02:19:25,668 INFO [train.py:450] Epoch 1, batch 20160, batch avg loss 0.3536, total avg loss: 0.3435, batch size: 41
2021-08-25 02:19:32,573 INFO [train.py:450] Epoch 1, batch 20170, batch avg loss 0.3065, total avg loss: 0.3428, batch size: 40
2021-08-25 02:19:39,421 INFO [train.py:450] Epoch 1, batch 20180, batch avg loss 0.3678, total avg loss: 0.3419, batch size: 36
2021-08-25 02:19:46,069 INFO [train.py:450] Epoch 1, batch 20190, batch avg loss 0.3112, total avg loss: 0.3419, batch size: 40
2021-08-25 02:19:52,842 INFO [train.py:450] Epoch 1, batch 20200, batch avg loss 0.4183, total avg loss: 0.3415, batch size: 38
2021-08-25 02:20:00,467 INFO [train.py:450] Epoch 1, batch 20210, batch avg loss 0.3013, total avg loss: 0.3393, batch size: 39
2021-08-25 02:20:07,084 INFO [train.py:450] Epoch 1, batch 20220, batch avg loss 0.3567, total avg loss: 0.3405, batch size: 39
2021-08-25 02:20:10,467 WARNING [cut.py:1694] To perform mix, energy must be non-zero and non-negative (got 0.0).  MonoCut with id "8b6d4226-9e38-848d-4424-e9bf917ae832" will not be mixed in.
2021-08-25 02:20:13,802 INFO [train.py:450] Epoch 1, batch 20230, batch avg loss 0.3088, total avg loss: 0.3389, batch size: 38
2021-08-25 02:20:20,305 INFO [train.py:450] Epoch 1, batch 20240, batch avg loss 0.3672, total avg loss: 0.3398, batch size: 37
2021-08-25 02:20:27,708 INFO [train.py:450] Epoch 1, batch 20250, batch avg loss 0.3080, total avg loss: 0.3402, batch size: 40
2021-08-25 02:20:34,579 INFO [train.py:450] Epoch 1, batch 20260, batch avg loss 0.3077, total avg loss: 0.3390, batch size: 41
2021-08-25 02:20:41,104 INFO [train.py:450] Epoch 1, batch 20270, batch avg loss 0.3183, total avg loss: 0.3387, batch size: 38
2021-08-25 02:20:48,200 INFO [train.py:450] Epoch 1, batch 20280, batch avg loss 0.3433, total avg loss: 0.3409, batch size: 40
2021-08-25 02:20:55,229 INFO [train.py:450] Epoch 1, batch 20290, batch avg loss 0.3239, total avg loss: 0.3394, batch size: 42
2021-08-25 02:21:02,089 INFO [train.py:450] Epoch 1, batch 20300, batch avg loss 0.3301, total avg loss: 0.3397, batch size: 35
2021-08-25 02:21:08,763 INFO [train.py:450] Epoch 1, batch 20310, batch avg loss 0.3479, total avg loss: 0.3405, batch size: 41
2021-08-25 02:21:15,405 INFO [train.py:450] Epoch 1, batch 20320, batch avg loss 0.3376, total avg loss: 0.3424, batch size: 37
2021-08-25 02:21:22,187 INFO [train.py:450] Epoch 1, batch 20330, batch avg loss 0.3871, total avg loss: 0.3423, batch size: 41
2021-08-25 02:21:28,866 INFO [train.py:450] Epoch 1, batch 20340, batch avg loss 0.4135, total avg loss: 0.3423, batch size: 40
2021-08-25 02:21:35,613 INFO [train.py:450] Epoch 1, batch 20350, batch avg loss 0.3610, total avg loss: 0.3423, batch size: 40
2021-08-25 02:21:42,553 INFO [train.py:450] Epoch 1, batch 20360, batch avg loss 0.3090, total avg loss: 0.3424, batch size: 41
2021-08-25 02:21:49,680 INFO [train.py:450] Epoch 1, batch 20370, batch avg loss 0.3672, total avg loss: 0.3419, batch size: 44
2021-08-25 02:21:56,747 INFO [train.py:450] Epoch 1, batch 20380, batch avg loss 0.3117, total avg loss: 0.3422, batch size: 39
2021-08-25 02:22:04,374 INFO [train.py:450] Epoch 1, batch 20390, batch avg loss 0.3858, total avg loss: 0.3426, batch size: 39
2021-08-25 02:22:11,151 INFO [train.py:450] Epoch 1, batch 20400, batch avg loss 0.3279, total avg loss: 0.3433, batch size: 40
2021-08-25 02:22:18,140 INFO [train.py:450] Epoch 1, batch 20410, batch avg loss 0.3323, total avg loss: 0.3547, batch size: 42
2021-08-25 02:22:24,569 INFO [train.py:450] Epoch 1, batch 20420, batch avg loss 0.3597, total avg loss: 0.3525, batch size: 37
2021-08-25 02:22:32,031 INFO [train.py:450] Epoch 1, batch 20430, batch avg loss 0.3668, total avg loss: 0.3493, batch size: 38
2021-08-25 02:22:39,007 INFO [train.py:450] Epoch 1, batch 20440, batch avg loss 0.3616, total avg loss: 0.3533, batch size: 39
2021-08-25 02:22:46,071 INFO [train.py:450] Epoch 1, batch 20450, batch avg loss 0.3685, total avg loss: 0.3526, batch size: 36
2021-08-25 02:22:53,226 INFO [train.py:450] Epoch 1, batch 20460, batch avg loss 0.3650, total avg loss: 0.3523, batch size: 42
2021-08-25 02:23:00,435 INFO [train.py:450] Epoch 1, batch 20470, batch avg loss 0.3251, total avg loss: 0.3491, batch size: 44
2021-08-25 02:23:08,060 INFO [train.py:450] Epoch 1, batch 20480, batch avg loss 0.3233, total avg loss: 0.3496, batch size: 41
2021-08-25 02:23:16,899 INFO [train.py:450] Epoch 1, batch 20490, batch avg loss 0.3088, total avg loss: 0.3479, batch size: 38
2021-08-25 02:23:23,832 INFO [train.py:450] Epoch 1, batch 20500, batch avg loss 0.3456, total avg loss: 0.3477, batch size: 41
2021-08-25 02:23:34,260 INFO [train.py:450] Epoch 1, batch 20510, batch avg loss 0.3574, total avg loss: 0.3477, batch size: 39
2021-08-25 02:23:41,688 INFO [train.py:450] Epoch 1, batch 20520, batch avg loss 0.3318, total avg loss: 0.3456, batch size: 42
2021-08-25 02:23:49,256 INFO [train.py:450] Epoch 1, batch 20530, batch avg loss 0.3508, total avg loss: 0.3464, batch size: 39
2021-08-25 02:23:56,245 INFO [train.py:450] Epoch 1, batch 20540, batch avg loss 0.3535, total avg loss: 0.3459, batch size: 40
2021-08-25 02:24:04,155 INFO [train.py:450] Epoch 1, batch 20550, batch avg loss 0.3338, total avg loss: 0.3459, batch size: 38
2021-08-25 02:24:11,736 INFO [train.py:450] Epoch 1, batch 20560, batch avg loss 0.3376, total avg loss: 0.3460, batch size: 41
2021-08-25 02:24:19,661 INFO [train.py:450] Epoch 1, batch 20570, batch avg loss 0.2835, total avg loss: 0.3451, batch size: 38
2021-08-25 02:24:27,195 INFO [train.py:450] Epoch 1, batch 20580, batch avg loss 0.4027, total avg loss: 0.3452, batch size: 41
2021-08-25 02:24:34,991 INFO [train.py:450] Epoch 1, batch 20590, batch avg loss 0.4204, total avg loss: 0.3450, batch size: 40
2021-08-25 02:24:42,376 INFO [train.py:450] Epoch 1, batch 20600, batch avg loss 0.3575, total avg loss: 0.3448, batch size: 41
2021-08-25 02:24:49,966 INFO [train.py:450] Epoch 1, batch 20610, batch avg loss 0.3657, total avg loss: 0.3310, batch size: 37
2021-08-25 02:24:57,516 INFO [train.py:450] Epoch 1, batch 20620, batch avg loss 0.3116, total avg loss: 0.3420, batch size: 40
2021-08-25 02:25:05,332 INFO [train.py:450] Epoch 1, batch 20630, batch avg loss 0.3651, total avg loss: 0.3471, batch size: 37
2021-08-25 02:25:12,531 INFO [train.py:450] Epoch 1, batch 20640, batch avg loss 0.3394, total avg loss: 0.3483, batch size: 41
2021-08-25 02:25:20,449 INFO [train.py:450] Epoch 1, batch 20650, batch avg loss 0.3153, total avg loss: 0.3487, batch size: 41
2021-08-25 02:25:28,038 INFO [train.py:450] Epoch 1, batch 20660, batch avg loss 0.3894, total avg loss: 0.3498, batch size: 40
2021-08-25 02:25:35,772 INFO [train.py:450] Epoch 1, batch 20670, batch avg loss 0.3249, total avg loss: 0.3477, batch size: 42
2021-08-25 02:25:43,272 INFO [train.py:450] Epoch 1, batch 20680, batch avg loss 0.3861, total avg loss: 0.3488, batch size: 36
2021-08-25 02:25:50,984 INFO [train.py:450] Epoch 1, batch 20690, batch avg loss 0.3488, total avg loss: 0.3490, batch size: 40
2021-08-25 02:25:58,795 INFO [train.py:450] Epoch 1, batch 20700, batch avg loss 0.3846, total avg loss: 0.3500, batch size: 38
2021-08-25 02:26:06,042 INFO [train.py:450] Epoch 1, batch 20710, batch avg loss 0.3845, total avg loss: 0.3529, batch size: 36
2021-08-25 02:26:14,310 INFO [train.py:450] Epoch 1, batch 20720, batch avg loss 0.3677, total avg loss: 0.3549, batch size: 38
2021-08-25 02:26:22,041 INFO [train.py:450] Epoch 1, batch 20730, batch avg loss 0.4246, total avg loss: 0.3554, batch size: 43
2021-08-25 02:26:30,272 INFO [train.py:450] Epoch 1, batch 20740, batch avg loss 0.3410, total avg loss: 0.3553, batch size: 42
2021-08-25 02:26:37,712 INFO [train.py:450] Epoch 1, batch 20750, batch avg loss 0.3162, total avg loss: 0.3539, batch size: 41
2021-08-25 02:26:45,191 INFO [train.py:450] Epoch 1, batch 20760, batch avg loss 0.3523, total avg loss: 0.3538, batch size: 38
2021-08-25 02:26:52,811 INFO [train.py:450] Epoch 1, batch 20770, batch avg loss 0.3064, total avg loss: 0.3536, batch size: 40
2021-08-25 02:27:00,692 INFO [train.py:450] Epoch 1, batch 20780, batch avg loss 0.3340, total avg loss: 0.3535, batch size: 44
2021-08-25 02:27:08,517 INFO [train.py:450] Epoch 1, batch 20790, batch avg loss 0.3199, total avg loss: 0.3530, batch size: 44
2021-08-25 02:27:17,744 INFO [train.py:450] Epoch 1, batch 20800, batch avg loss 0.3160, total avg loss: 0.3528, batch size: 37
2021-08-25 02:27:25,377 INFO [train.py:450] Epoch 1, batch 20810, batch avg loss 0.3258, total avg loss: 0.3312, batch size: 42
2021-08-25 02:27:36,151 INFO [train.py:450] Epoch 1, batch 20820, batch avg loss 0.3527, total avg loss: 0.3439, batch size: 39
2021-08-25 02:27:44,345 INFO [train.py:450] Epoch 1, batch 20830, batch avg loss 0.3421, total avg loss: 0.3435, batch size: 40
2021-08-25 02:27:52,319 INFO [train.py:450] Epoch 1, batch 20840, batch avg loss 0.3696, total avg loss: 0.3491, batch size: 37
2021-08-25 02:28:01,238 INFO [train.py:450] Epoch 1, batch 20850, batch avg loss 0.3025, total avg loss: 0.3442, batch size: 42
2021-08-25 02:28:08,769 INFO [train.py:450] Epoch 1, batch 20860, batch avg loss 0.3087, total avg loss: 0.3442, batch size: 38
2021-08-25 02:28:16,273 INFO [train.py:450] Epoch 1, batch 20870, batch avg loss 0.3768, total avg loss: 0.3452, batch size: 40
2021-08-25 02:28:23,829 INFO [train.py:450] Epoch 1, batch 20880, batch avg loss 0.3263, total avg loss: 0.3428, batch size: 37
2021-08-25 02:28:31,441 INFO [train.py:450] Epoch 1, batch 20890, batch avg loss 0.3100, total avg loss: 0.3423, batch size: 42
2021-08-25 02:28:38,758 INFO [train.py:450] Epoch 1, batch 20900, batch avg loss 0.3415, total avg loss: 0.3417, batch size: 41
2021-08-25 02:28:46,271 INFO [train.py:450] Epoch 1, batch 20910, batch avg loss 0.3253, total avg loss: 0.3420, batch size: 39
2021-08-25 02:28:53,772 INFO [train.py:450] Epoch 1, batch 20920, batch avg loss 0.3210, total avg loss: 0.3424, batch size: 41
2021-08-25 02:29:01,416 INFO [train.py:450] Epoch 1, batch 20930, batch avg loss 0.3426, total avg loss: 0.3436, batch size: 38
2021-08-25 02:29:08,659 INFO [train.py:450] Epoch 1, batch 20940, batch avg loss 0.3929, total avg loss: 0.3452, batch size: 40
2021-08-25 02:29:16,304 INFO [train.py:450] Epoch 1, batch 20950, batch avg loss 0.3526, total avg loss: 0.3444, batch size: 42
2021-08-25 02:29:23,791 INFO [train.py:450] Epoch 1, batch 20960, batch avg loss 0.3652, total avg loss: 0.3446, batch size: 41
2021-08-25 02:29:31,003 INFO [train.py:450] Epoch 1, batch 20970, batch avg loss 0.3664, total avg loss: 0.3439, batch size: 40
2021-08-25 02:29:38,190 INFO [train.py:450] Epoch 1, batch 20980, batch avg loss 0.3121, total avg loss: 0.3438, batch size: 40
2021-08-25 02:29:45,199 INFO [train.py:450] Epoch 1, batch 20990, batch avg loss 0.3896, total avg loss: 0.3447, batch size: 39
2021-08-25 02:29:52,732 INFO [train.py:450] Epoch 1, batch 21000, batch avg loss 0.3125, total avg loss: 0.3450, batch size: 39
2021-08-25 02:30:31,237 INFO [train.py:482] Epoch 1, valid loss 0.2473, best valid loss: 0.2448 best valid epoch: 1
2021-08-25 02:30:37,156 INFO [train.py:450] Epoch 1, batch 21010, batch avg loss 0.3583, total avg loss: 0.3434, batch size: 39
2021-08-25 02:30:44,502 INFO [train.py:450] Epoch 1, batch 21020, batch avg loss 0.3164, total avg loss: 0.3534, batch size: 39
2021-08-25 02:30:52,500 INFO [train.py:450] Epoch 1, batch 21030, batch avg loss 0.3913, total avg loss: 0.3463, batch size: 42
2021-08-25 02:30:59,872 INFO [train.py:450] Epoch 1, batch 21040, batch avg loss 0.3153, total avg loss: 0.3422, batch size: 37
2021-08-25 02:31:07,480 INFO [train.py:450] Epoch 1, batch 21050, batch avg loss 0.3550, total avg loss: 0.3425, batch size: 38
2021-08-25 02:31:14,710 INFO [train.py:450] Epoch 1, batch 21060, batch avg loss 0.3447, total avg loss: 0.3418, batch size: 39
2021-08-25 02:31:21,930 INFO [train.py:450] Epoch 1, batch 21070, batch avg loss 0.3241, total avg loss: 0.3405, batch size: 40
2021-08-25 02:31:30,480 INFO [train.py:450] Epoch 1, batch 21080, batch avg loss 0.3779, total avg loss: 0.3441, batch size: 37
2021-08-25 02:31:39,065 INFO [train.py:450] Epoch 1, batch 21090, batch avg loss 0.3900, total avg loss: 0.3437, batch size: 40
2021-08-25 02:31:49,206 INFO [train.py:450] Epoch 1, batch 21100, batch avg loss 0.4008, total avg loss: 0.3439, batch size: 41
2021-08-25 02:31:56,466 INFO [train.py:450] Epoch 1, batch 21110, batch avg loss 0.3555, total avg loss: 0.3432, batch size: 46
2021-08-25 02:32:04,103 INFO [train.py:450] Epoch 1, batch 21120, batch avg loss 0.3318, total avg loss: 0.3413, batch size: 40
2021-08-25 02:32:11,427 INFO [train.py:450] Epoch 1, batch 21130, batch avg loss 0.3608, total avg loss: 0.3417, batch size: 38
2021-08-25 02:32:25,437 INFO [train.py:450] Epoch 1, batch 21140, batch avg loss 0.3394, total avg loss: 0.3419, batch size: 42
2021-08-25 02:32:32,954 INFO [train.py:450] Epoch 1, batch 21150, batch avg loss 0.3435, total avg loss: 0.3425, batch size: 42
2021-08-25 02:32:40,317 INFO [train.py:450] Epoch 1, batch 21160, batch avg loss 0.3532, total avg loss: 0.3420, batch size: 38
2021-08-25 02:32:47,734 INFO [train.py:450] Epoch 1, batch 21170, batch avg loss 0.3674, total avg loss: 0.3420, batch size: 40
2021-08-25 02:32:55,404 INFO [train.py:450] Epoch 1, batch 21180, batch avg loss 0.3235, total avg loss: 0.3422, batch size: 37
2021-08-25 02:33:02,685 INFO [checkpoint.py:62] Saving checkpoint to tdnn_lstm_ctc/exp/epoch-1.pt
2021-08-25 02:33:05,153 INFO [train.py:563] epoch 2, lr: 0.001
2021-08-25 02:33:17,497 INFO [train.py:450] Epoch 2, batch 0, batch avg loss 0.3477, total avg loss: 0.3477, batch size: 42
2021-08-25 02:33:36,468 INFO [train.py:450] Epoch 2, batch 10, batch avg loss 0.3552, total avg loss: 0.3532, batch size: 40
2021-08-25 02:33:53,390 INFO [train.py:450] Epoch 2, batch 20, batch avg loss 0.3477, total avg loss: 0.3496, batch size: 41
2021-08-25 02:34:09,039 INFO [train.py:450] Epoch 2, batch 30, batch avg loss 0.3172, total avg loss: 0.3476, batch size: 38
2021-08-25 02:34:25,186 INFO [train.py:450] Epoch 2, batch 40, batch avg loss 0.3445, total avg loss: 0.3480, batch size: 39
2021-08-25 02:34:39,959 INFO [train.py:450] Epoch 2, batch 50, batch avg loss 0.3492, total avg loss: 0.3469, batch size: 38
2021-08-25 02:34:56,069 INFO [train.py:450] Epoch 2, batch 60, batch avg loss 0.3428, total avg loss: 0.3447, batch size: 38
2021-08-25 02:35:11,559 INFO [train.py:450] Epoch 2, batch 70, batch avg loss 0.3799, total avg loss: 0.3444, batch size: 40
2021-08-25 02:35:26,456 INFO [train.py:450] Epoch 2, batch 80, batch avg loss 0.3413, total avg loss: 0.3439, batch size: 46
2021-08-25 02:35:40,679 INFO [train.py:450] Epoch 2, batch 90, batch avg loss 0.3287, total avg loss: 0.3445, batch size: 40
2021-08-25 02:35:54,659 INFO [train.py:450] Epoch 2, batch 100, batch avg loss 0.3468, total avg loss: 0.3441, batch size: 42
2021-08-25 02:36:09,986 INFO [train.py:450] Epoch 2, batch 110, batch avg loss 0.3678, total avg loss: 0.3451, batch size: 37
2021-08-25 02:36:27,170 INFO [train.py:450] Epoch 2, batch 120, batch avg loss 0.3374, total avg loss: 0.3452, batch size: 39
2021-08-25 02:36:40,209 INFO [train.py:450] Epoch 2, batch 130, batch avg loss 0.2700, total avg loss: 0.3448, batch size: 41
2021-08-25 02:36:52,779 INFO [train.py:450] Epoch 2, batch 140, batch avg loss 0.3171, total avg loss: 0.3451, batch size: 38
2021-08-25 02:37:05,330 INFO [train.py:450] Epoch 2, batch 150, batch avg loss 0.3571, total avg loss: 0.3447, batch size: 36
2021-08-25 02:37:17,896 INFO [train.py:450] Epoch 2, batch 160, batch avg loss 0.2893, total avg loss: 0.3443, batch size: 41
2021-08-25 02:37:30,915 INFO [train.py:450] Epoch 2, batch 170, batch avg loss 0.3999, total avg loss: 0.3460, batch size: 39
2021-08-25 02:37:43,365 INFO [train.py:450] Epoch 2, batch 180, batch avg loss 0.3406, total avg loss: 0.3461, batch size: 40
2021-08-25 02:37:55,739 INFO [train.py:450] Epoch 2, batch 190, batch avg loss 0.3364, total avg loss: 0.3460, batch size: 42
2021-08-25 02:38:07,640 INFO [train.py:450] Epoch 2, batch 200, batch avg loss 0.3317, total avg loss: 0.3454, batch size: 39
2021-08-25 02:38:19,276 INFO [train.py:450] Epoch 2, batch 210, batch avg loss 0.3120, total avg loss: 0.3312, batch size: 39
2021-08-25 02:38:31,373 INFO [train.py:450] Epoch 2, batch 220, batch avg loss 0.3597, total avg loss: 0.3302, batch size: 38
2021-08-25 02:38:43,522 INFO [train.py:450] Epoch 2, batch 230, batch avg loss 0.3581, total avg loss: 0.3338, batch size: 38
2021-08-25 02:38:54,236 INFO [train.py:450] Epoch 2, batch 240, batch avg loss 0.3723, total avg loss: 0.3342, batch size: 41
2021-08-25 02:39:05,742 INFO [train.py:450] Epoch 2, batch 250, batch avg loss 0.3492, total avg loss: 0.3358, batch size: 38
2021-08-25 02:39:16,784 INFO [train.py:450] Epoch 2, batch 260, batch avg loss 0.3348, total avg loss: 0.3375, batch size: 41
2021-08-25 02:39:27,298 INFO [train.py:450] Epoch 2, batch 270, batch avg loss 0.3226, total avg loss: 0.3387, batch size: 40
2021-08-25 02:39:38,470 INFO [train.py:450] Epoch 2, batch 280, batch avg loss 0.3610, total avg loss: 0.3382, batch size: 41
2021-08-25 02:39:49,435 INFO [train.py:450] Epoch 2, batch 290, batch avg loss 0.3913, total avg loss: 0.3404, batch size: 40
2021-08-25 02:40:00,201 INFO [train.py:450] Epoch 2, batch 300, batch avg loss 0.3514, total avg loss: 0.3429, batch size: 39
2021-08-25 02:40:10,209 INFO [train.py:450] Epoch 2, batch 310, batch avg loss 0.2985, total avg loss: 0.3416, batch size: 41
2021-08-25 02:40:20,132 INFO [train.py:450] Epoch 2, batch 320, batch avg loss 0.3238, total avg loss: 0.3414, batch size: 37
2021-08-25 02:40:30,329 INFO [train.py:450] Epoch 2, batch 330, batch avg loss 0.3036, total avg loss: 0.3416, batch size: 38
2021-08-25 02:40:42,254 INFO [train.py:450] Epoch 2, batch 340, batch avg loss 0.2831, total avg loss: 0.3405, batch size: 38
2021-08-25 02:40:56,955 INFO [train.py:450] Epoch 2, batch 350, batch avg loss 0.3666, total avg loss: 0.3402, batch size: 38
2021-08-25 02:41:06,916 INFO [train.py:450] Epoch 2, batch 360, batch avg loss 0.4251, total avg loss: 0.3407, batch size: 44
2021-08-25 02:41:17,384 INFO [train.py:450] Epoch 2, batch 370, batch avg loss 0.3948, total avg loss: 0.3421, batch size: 37
2021-08-25 02:41:27,328 INFO [train.py:450] Epoch 2, batch 380, batch avg loss 0.3450, total avg loss: 0.3432, batch size: 38
2021-08-25 02:41:36,869 INFO [train.py:450] Epoch 2, batch 390, batch avg loss 0.3686, total avg loss: 0.3418, batch size: 41
2021-08-25 02:41:46,738 INFO [train.py:450] Epoch 2, batch 400, batch avg loss 0.3233, total avg loss: 0.3419, batch size: 41
2021-08-25 02:41:57,119 INFO [train.py:450] Epoch 2, batch 410, batch avg loss 0.3322, total avg loss: 0.3484, batch size: 39
2021-08-25 02:42:07,250 INFO [train.py:450] Epoch 2, batch 420, batch avg loss 0.3292, total avg loss: 0.3422, batch size: 37
2021-08-25 02:42:16,974 INFO [train.py:450] Epoch 2, batch 430, batch avg loss 0.3312, total avg loss: 0.3374, batch size: 38
2021-08-25 02:42:26,542 INFO [train.py:450] Epoch 2, batch 440, batch avg loss 0.3505, total avg loss: 0.3380, batch size: 42
2021-08-25 02:42:36,737 INFO [train.py:450] Epoch 2, batch 450, batch avg loss 0.3360, total avg loss: 0.3388, batch size: 41
2021-08-25 02:42:46,925 INFO [train.py:450] Epoch 2, batch 460, batch avg loss 0.3135, total avg loss: 0.3405, batch size: 39
2021-08-25 02:42:57,207 INFO [train.py:450] Epoch 2, batch 470, batch avg loss 0.4083, total avg loss: 0.3416, batch size: 41
2021-08-25 02:43:06,649 INFO [train.py:450] Epoch 2, batch 480, batch avg loss 0.3191, total avg loss: 0.3400, batch size: 40
2021-08-25 02:43:16,741 INFO [train.py:450] Epoch 2, batch 490, batch avg loss 0.3482, total avg loss: 0.3408, batch size: 38
2021-08-25 02:43:26,488 INFO [train.py:450] Epoch 2, batch 500, batch avg loss 0.3676, total avg loss: 0.3409, batch size: 42
2021-08-25 02:43:35,835 INFO [train.py:450] Epoch 2, batch 510, batch avg loss 0.3459, total avg loss: 0.3416, batch size: 39
2021-08-25 02:43:45,922 INFO [train.py:450] Epoch 2, batch 520, batch avg loss 0.3580, total avg loss: 0.3409, batch size: 39
2021-08-25 02:43:55,343 INFO [train.py:450] Epoch 2, batch 530, batch avg loss 0.3371, total avg loss: 0.3413, batch size: 41
2021-08-25 02:44:04,981 INFO [train.py:450] Epoch 2, batch 540, batch avg loss 0.4089, total avg loss: 0.3410, batch size: 39
2021-08-25 02:44:14,211 INFO [train.py:450] Epoch 2, batch 550, batch avg loss 0.3512, total avg loss: 0.3413, batch size: 40
2021-08-25 02:44:23,434 INFO [train.py:450] Epoch 2, batch 560, batch avg loss 0.3123, total avg loss: 0.3412, batch size: 39
2021-08-25 02:44:32,874 INFO [train.py:450] Epoch 2, batch 570, batch avg loss 0.3876, total avg loss: 0.3417, batch size: 40
2021-08-25 02:44:42,086 INFO [train.py:450] Epoch 2, batch 580, batch avg loss 0.3361, total avg loss: 0.3421, batch size: 38
2021-08-25 02:44:51,754 INFO [train.py:450] Epoch 2, batch 590, batch avg loss 0.3754, total avg loss: 0.3429, batch size: 40
2021-08-25 02:45:01,320 INFO [train.py:450] Epoch 2, batch 600, batch avg loss 0.3381, total avg loss: 0.3432, batch size: 42
2021-08-25 02:45:11,542 INFO [train.py:450] Epoch 2, batch 610, batch avg loss 0.3406, total avg loss: 0.3683, batch size: 44
2021-08-25 02:45:21,582 INFO [train.py:450] Epoch 2, batch 620, batch avg loss 0.3327, total avg loss: 0.3565, batch size: 43
2021-08-25 02:45:34,880 INFO [train.py:450] Epoch 2, batch 630, batch avg loss 0.3371, total avg loss: 0.3471, batch size: 42
2021-08-25 02:45:43,803 INFO [train.py:450] Epoch 2, batch 640, batch avg loss 0.3753, total avg loss: 0.3442, batch size: 42
2021-08-25 02:45:52,802 INFO [train.py:450] Epoch 2, batch 650, batch avg loss 0.3429, total avg loss: 0.3446, batch size: 40
2021-08-25 02:46:02,022 INFO [train.py:450] Epoch 2, batch 660, batch avg loss 0.3115, total avg loss: 0.3422, batch size: 41
2021-08-25 02:46:11,374 INFO [train.py:450] Epoch 2, batch 670, batch avg loss 0.3259, total avg loss: 0.3406, batch size: 42
2021-08-25 02:46:20,164 INFO [train.py:450] Epoch 2, batch 680, batch avg loss 0.2966, total avg loss: 0.3396, batch size: 38
2021-08-25 02:46:30,435 INFO [train.py:450] Epoch 2, batch 690, batch avg loss 0.2951, total avg loss: 0.3393, batch size: 37
2021-08-25 02:46:40,045 INFO [train.py:450] Epoch 2, batch 700, batch avg loss 0.3206, total avg loss: 0.3396, batch size: 37
2021-08-25 02:46:49,496 INFO [train.py:450] Epoch 2, batch 710, batch avg loss 0.3319, total avg loss: 0.3402, batch size: 38
2021-08-25 02:46:57,943 INFO [train.py:450] Epoch 2, batch 720, batch avg loss 0.3523, total avg loss: 0.3406, batch size: 40
2021-08-25 02:47:07,852 INFO [train.py:450] Epoch 2, batch 730, batch avg loss 0.3883, total avg loss: 0.3421, batch size: 38
2021-08-25 02:47:17,464 INFO [train.py:450] Epoch 2, batch 740, batch avg loss 0.3467, total avg loss: 0.3424, batch size: 39
2021-08-25 02:47:27,510 INFO [train.py:450] Epoch 2, batch 750, batch avg loss 0.3437, total avg loss: 0.3418, batch size: 43
2021-08-25 02:47:36,884 INFO [train.py:450] Epoch 2, batch 760, batch avg loss 0.3060, total avg loss: 0.3424, batch size: 40
2021-08-25 02:47:45,719 INFO [train.py:450] Epoch 2, batch 770, batch avg loss 0.3739, total avg loss: 0.3431, batch size: 39
2021-08-25 02:47:54,841 INFO [train.py:450] Epoch 2, batch 780, batch avg loss 0.3707, total avg loss: 0.3432, batch size: 37
2021-08-25 02:48:03,693 INFO [train.py:450] Epoch 2, batch 790, batch avg loss 0.3168, total avg loss: 0.3437, batch size: 39
2021-08-25 02:48:13,216 INFO [train.py:450] Epoch 2, batch 800, batch avg loss 0.3700, total avg loss: 0.3433, batch size: 46
2021-08-25 02:48:22,707 INFO [train.py:450] Epoch 2, batch 810, batch avg loss 0.3810, total avg loss: 0.3888, batch size: 41
2021-08-25 02:48:31,989 INFO [train.py:450] Epoch 2, batch 820, batch avg loss 0.3314, total avg loss: 0.3593, batch size: 39
2021-08-25 02:48:40,641 INFO [train.py:450] Epoch 2, batch 830, batch avg loss 0.3150, total avg loss: 0.3488, batch size: 40
2021-08-25 02:48:49,837 INFO [train.py:450] Epoch 2, batch 840, batch avg loss 0.3084, total avg loss: 0.3469, batch size: 40
2021-08-25 02:48:59,136 INFO [train.py:450] Epoch 2, batch 850, batch avg loss 0.3060, total avg loss: 0.3436, batch size: 36
2021-08-25 02:49:07,603 INFO [train.py:450] Epoch 2, batch 860, batch avg loss 0.3674, total avg loss: 0.3424, batch size: 40
2021-08-25 02:49:16,492 INFO [train.py:450] Epoch 2, batch 870, batch avg loss 0.3260, total avg loss: 0.3415, batch size: 40
2021-08-25 02:49:25,949 INFO [train.py:450] Epoch 2, batch 880, batch avg loss 0.3475, total avg loss: 0.3410, batch size: 41
2021-08-25 02:49:34,744 INFO [train.py:450] Epoch 2, batch 890, batch avg loss 0.3487, total avg loss: 0.3389, batch size: 37
2021-08-25 02:49:44,905 INFO [train.py:450] Epoch 2, batch 900, batch avg loss 0.3334, total avg loss: 0.3395, batch size: 39
2021-08-25 02:49:54,467 INFO [train.py:450] Epoch 2, batch 910, batch avg loss 0.3332, total avg loss: 0.3381, batch size: 38
2021-08-25 02:50:07,702 INFO [train.py:450] Epoch 2, batch 920, batch avg loss 0.3976, total avg loss: 0.3370, batch size: 37
2021-08-25 02:50:16,844 INFO [train.py:450] Epoch 2, batch 930, batch avg loss 0.3223, total avg loss: 0.3360, batch size: 38
2021-08-25 02:50:26,009 INFO [train.py:450] Epoch 2, batch 940, batch avg loss 0.3587, total avg loss: 0.3366, batch size: 41
2021-08-25 02:50:36,004 INFO [train.py:450] Epoch 2, batch 950, batch avg loss 0.3581, total avg loss: 0.3367, batch size: 41
2021-08-25 02:50:44,947 INFO [train.py:450] Epoch 2, batch 960, batch avg loss 0.3619, total avg loss: 0.3367, batch size: 42
2021-08-25 02:50:54,110 INFO [train.py:450] Epoch 2, batch 970, batch avg loss 0.3500, total avg loss: 0.3373, batch size: 43
2021-08-25 02:51:03,368 INFO [train.py:450] Epoch 2, batch 980, batch avg loss 0.3834, total avg loss: 0.3378, batch size: 43
2021-08-25 02:51:12,787 INFO [train.py:450] Epoch 2, batch 990, batch avg loss 0.3260, total avg loss: 0.3376, batch size: 40
2021-08-25 02:51:22,228 INFO [train.py:450] Epoch 2, batch 1000, batch avg loss 0.2947, total avg loss: 0.3378, batch size: 37
2021-08-25 02:52:02,523 INFO [train.py:482] Epoch 2, valid loss 0.2458, best valid loss: 0.2448 best valid epoch: 1
2021-08-25 02:52:09,533 INFO [train.py:450] Epoch 2, batch 1010, batch avg loss 0.3233, total avg loss: 0.3471, batch size: 39
2021-08-25 02:52:19,379 INFO [train.py:450] Epoch 2, batch 1020, batch avg loss 0.3579, total avg loss: 0.3527, batch size: 41
2021-08-25 02:52:19,684 WARNING [cut.py:1694] To perform mix, energy must be non-zero and non-negative (got 0.0).  MonoCut with id "d72bd339-a78b-0067-f65a-e40856c25e11" will not be mixed in.
2021-08-25 02:52:29,106 INFO [train.py:450] Epoch 2, batch 1030, batch avg loss 0.2951, total avg loss: 0.3401, batch size: 40
2021-08-25 02:52:38,070 INFO [train.py:450] Epoch 2, batch 1040, batch avg loss 0.3477, total avg loss: 0.3373, batch size: 43
2021-08-25 02:52:47,343 INFO [train.py:450] Epoch 2, batch 1050, batch avg loss 0.3105, total avg loss: 0.3407, batch size: 39
2021-08-25 02:52:56,484 INFO [train.py:450] Epoch 2, batch 1060, batch avg loss 0.3181, total avg loss: 0.3398, batch size: 39
2021-08-25 02:53:05,047 INFO [train.py:450] Epoch 2, batch 1070, batch avg loss 0.3092, total avg loss: 0.3412, batch size: 39
2021-08-25 02:53:14,357 INFO [train.py:450] Epoch 2, batch 1080, batch avg loss 0.3864, total avg loss: 0.3436, batch size: 38
2021-08-25 02:53:22,871 INFO [train.py:450] Epoch 2, batch 1090, batch avg loss 0.2989, total avg loss: 0.3439, batch size: 35
2021-08-25 02:53:31,160 INFO [train.py:450] Epoch 2, batch 1100, batch avg loss 0.3079, total avg loss: 0.3429, batch size: 39
2021-08-25 02:53:39,790 INFO [train.py:450] Epoch 2, batch 1110, batch avg loss 0.3855, total avg loss: 0.3439, batch size: 46
2021-08-25 02:53:49,004 INFO [train.py:450] Epoch 2, batch 1120, batch avg loss 0.3484, total avg loss: 0.3439, batch size: 42
2021-08-25 02:53:59,166 INFO [train.py:450] Epoch 2, batch 1130, batch avg loss 0.3742, total avg loss: 0.3445, batch size: 41
2021-08-25 02:54:09,999 INFO [train.py:450] Epoch 2, batch 1140, batch avg loss 0.3014, total avg loss: 0.3440, batch size: 41
2021-08-25 02:54:21,715 INFO [train.py:450] Epoch 2, batch 1150, batch avg loss 0.3511, total avg loss: 0.3442, batch size: 40
2021-08-25 02:54:32,806 INFO [train.py:450] Epoch 2, batch 1160, batch avg loss 0.2994, total avg loss: 0.3433, batch size: 39
2021-08-25 02:54:41,735 INFO [train.py:450] Epoch 2, batch 1170, batch avg loss 0.3425, total avg loss: 0.3438, batch size: 42
2021-08-25 02:54:51,574 INFO [train.py:450] Epoch 2, batch 1180, batch avg loss 0.3869, total avg loss: 0.3438, batch size: 48
2021-08-25 02:55:00,424 INFO [train.py:450] Epoch 2, batch 1190, batch avg loss 0.2882, total avg loss: 0.3432, batch size: 38
2021-08-25 02:55:09,597 INFO [train.py:450] Epoch 2, batch 1200, batch avg loss 0.3292, total avg loss: 0.3428, batch size: 43
2021-08-25 02:55:18,460 INFO [train.py:450] Epoch 2, batch 1210, batch avg loss 0.3151, total avg loss: 0.3455, batch size: 39
2021-08-25 02:55:28,159 INFO [train.py:450] Epoch 2, batch 1220, batch avg loss 0.3466, total avg loss: 0.3482, batch size: 39
2021-08-25 02:55:36,941 INFO [train.py:450] Epoch 2, batch 1230, batch avg loss 0.3443, total avg loss: 0.3434, batch size: 41
2021-08-25 02:55:45,728 INFO [train.py:450] Epoch 2, batch 1240, batch avg loss 0.3643, total avg loss: 0.3450, batch size: 40
2021-08-25 02:55:55,140 INFO [train.py:450] Epoch 2, batch 1250, batch avg loss 0.3208, total avg loss: 0.3448, batch size: 40
2021-08-25 02:56:04,967 INFO [train.py:450] Epoch 2, batch 1260, batch avg loss 0.3035, total avg loss: 0.3465, batch size: 40
2021-08-25 02:56:13,791 INFO [train.py:450] Epoch 2, batch 1270, batch avg loss 0.2840, total avg loss: 0.3457, batch size: 40
2021-08-25 02:56:22,418 INFO [train.py:450] Epoch 2, batch 1280, batch avg loss 0.4049, total avg loss: 0.3441, batch size: 43
2021-08-25 02:56:31,361 INFO [train.py:450] Epoch 2, batch 1290, batch avg loss 0.3468, total avg loss: 0.3440, batch size: 39
2021-08-25 02:56:40,377 INFO [train.py:450] Epoch 2, batch 1300, batch avg loss 0.3535, total avg loss: 0.3450, batch size: 40
2021-08-25 02:56:48,940 INFO [train.py:450] Epoch 2, batch 1310, batch avg loss 0.3911, total avg loss: 0.3462, batch size: 37
2021-08-25 02:56:57,822 INFO [train.py:450] Epoch 2, batch 1320, batch avg loss 0.2975, total avg loss: 0.3451, batch size: 42
2021-08-25 02:57:06,495 INFO [train.py:450] Epoch 2, batch 1330, batch avg loss 0.3822, total avg loss: 0.3455, batch size: 38
2021-08-25 02:57:14,989 INFO [train.py:450] Epoch 2, batch 1340, batch avg loss 0.3302, total avg loss: 0.3462, batch size: 42
2021-08-25 02:57:23,513 INFO [train.py:450] Epoch 2, batch 1350, batch avg loss 0.3434, total avg loss: 0.3460, batch size: 42
2021-08-25 02:57:32,190 INFO [train.py:450] Epoch 2, batch 1360, batch avg loss 0.2988, total avg loss: 0.3467, batch size: 39
2021-08-25 02:57:41,070 INFO [train.py:450] Epoch 2, batch 1370, batch avg loss 0.3553, total avg loss: 0.3473, batch size: 36
2021-08-25 02:57:49,715 INFO [train.py:450] Epoch 2, batch 1380, batch avg loss 0.3114, total avg loss: 0.3481, batch size: 37
2021-08-25 02:57:58,723 INFO [train.py:450] Epoch 2, batch 1390, batch avg loss 0.3584, total avg loss: 0.3476, batch size: 42
2021-08-25 02:58:07,389 INFO [train.py:450] Epoch 2, batch 1400, batch avg loss 0.2978, total avg loss: 0.3469, batch size: 39
2021-08-25 02:58:17,974 INFO [train.py:450] Epoch 2, batch 1410, batch avg loss 0.3354, total avg loss: 0.3466, batch size: 39
2021-08-25 02:58:28,393 INFO [train.py:450] Epoch 2, batch 1420, batch avg loss 0.3240, total avg loss: 0.3424, batch size: 38
2021-08-25 02:58:39,025 INFO [train.py:450] Epoch 2, batch 1430, batch avg loss 0.3486, total avg loss: 0.3418, batch size: 38
2021-08-25 02:58:47,881 INFO [train.py:450] Epoch 2, batch 1440, batch avg loss 0.3472, total avg loss: 0.3432, batch size: 40
2021-08-25 02:58:56,980 INFO [train.py:450] Epoch 2, batch 1450, batch avg loss 0.3321, total avg loss: 0.3424, batch size: 45
2021-08-25 02:59:05,833 INFO [train.py:450] Epoch 2, batch 1460, batch avg loss 0.3418, total avg loss: 0.3422, batch size: 36
2021-08-25 02:59:14,839 INFO [train.py:450] Epoch 2, batch 1470, batch avg loss 0.3314, total avg loss: 0.3414, batch size: 42
2021-08-25 02:59:23,437 INFO [train.py:450] Epoch 2, batch 1480, batch avg loss 0.3319, total avg loss: 0.3427, batch size: 40
2021-08-25 02:59:32,018 INFO [train.py:450] Epoch 2, batch 1490, batch avg loss 0.2824, total avg loss: 0.3402, batch size: 44
2021-08-25 02:59:40,554 INFO [train.py:450] Epoch 2, batch 1500, batch avg loss 0.3797, total avg loss: 0.3411, batch size: 45
2021-08-25 02:59:49,679 INFO [train.py:450] Epoch 2, batch 1510, batch avg loss 0.3322, total avg loss: 0.3408, batch size: 38
2021-08-25 02:59:58,246 INFO [train.py:450] Epoch 2, batch 1520, batch avg loss 0.3286, total avg loss: 0.3392, batch size: 37
2021-08-25 03:00:07,373 INFO [train.py:450] Epoch 2, batch 1530, batch avg loss 0.2937, total avg loss: 0.3397, batch size: 39
2021-08-25 03:00:15,718 WARNING [cut.py:1694] To perform mix, energy must be non-zero and non-negative (got 0.0).  MonoCut with id "83e45e24-a1b0-2520-fbf0-0620ad7f8803" will not be mixed in.
2021-08-25 03:00:15,949 INFO [train.py:450] Epoch 2, batch 1540, batch avg loss 0.3163, total avg loss: 0.3395, batch size: 40
2021-08-25 03:00:24,369 INFO [train.py:450] Epoch 2, batch 1550, batch avg loss 0.3686, total avg loss: 0.3411, batch size: 44
2021-08-25 03:00:32,897 INFO [train.py:450] Epoch 2, batch 1560, batch avg loss 0.3735, total avg loss: 0.3410, batch size: 43
2021-08-25 03:00:41,617 INFO [train.py:450] Epoch 2, batch 1570, batch avg loss 0.3332, total avg loss: 0.3410, batch size: 44
2021-08-25 03:00:50,250 INFO [train.py:450] Epoch 2, batch 1580, batch avg loss 0.3200, total avg loss: 0.3410, batch size: 38
2021-08-25 03:00:58,960 INFO [train.py:450] Epoch 2, batch 1590, batch avg loss 0.3369, total avg loss: 0.3409, batch size: 41
2021-08-25 03:01:07,350 INFO [train.py:450] Epoch 2, batch 1600, batch avg loss 0.3456, total avg loss: 0.3422, batch size: 39
2021-08-25 03:01:15,967 INFO [train.py:450] Epoch 2, batch 1610, batch avg loss 0.4226, total avg loss: 0.3514, batch size: 38
2021-08-25 03:01:24,773 INFO [train.py:450] Epoch 2, batch 1620, batch avg loss 0.3408, total avg loss: 0.3534, batch size: 40
2021-08-25 03:01:33,581 INFO [train.py:450] Epoch 2, batch 1630, batch avg loss 0.3049, total avg loss: 0.3481, batch size: 40
2021-08-25 03:01:44,341 INFO [train.py:450] Epoch 2, batch 1640, batch avg loss 0.3259, total avg loss: 0.3470, batch size: 42
2021-08-25 03:01:52,504 INFO [train.py:450] Epoch 2, batch 1650, batch avg loss 0.3361, total avg loss: 0.3429, batch size: 43
2021-08-25 03:02:03,914 INFO [train.py:450] Epoch 2, batch 1660, batch avg loss 0.3519, total avg loss: 0.3415, batch size: 39
2021-08-25 03:02:12,533 INFO [train.py:450] Epoch 2, batch 1670, batch avg loss 0.2954, total avg loss: 0.3400, batch size: 45
2021-08-25 03:02:21,260 INFO [train.py:450] Epoch 2, batch 1680, batch avg loss 0.3317, total avg loss: 0.3415, batch size: 41
2021-08-25 03:02:29,759 INFO [train.py:450] Epoch 2, batch 1690, batch avg loss 0.3035, total avg loss: 0.3404, batch size: 38
2021-08-25 03:02:38,066 INFO [train.py:450] Epoch 2, batch 1700, batch avg loss 0.3425, total avg loss: 0.3402, batch size: 44
2021-08-25 03:02:46,426 INFO [train.py:450] Epoch 2, batch 1710, batch avg loss 0.3736, total avg loss: 0.3405, batch size: 39
2021-08-25 03:02:54,631 INFO [train.py:450] Epoch 2, batch 1720, batch avg loss 0.3616, total avg loss: 0.3412, batch size: 43
2021-08-25 03:03:02,761 INFO [train.py:450] Epoch 2, batch 1730, batch avg loss 0.4181, total avg loss: 0.3420, batch size: 39
2021-08-25 03:03:11,054 INFO [train.py:450] Epoch 2, batch 1740, batch avg loss 0.3432, total avg loss: 0.3422, batch size: 40
2021-08-25 03:03:19,674 INFO [train.py:450] Epoch 2, batch 1750, batch avg loss 0.3164, total avg loss: 0.3420, batch size: 40
2021-08-25 03:03:27,846 INFO [train.py:450] Epoch 2, batch 1760, batch avg loss 0.3100, total avg loss: 0.3424, batch size: 45
2021-08-25 03:03:36,361 INFO [train.py:450] Epoch 2, batch 1770, batch avg loss 0.3257, total avg loss: 0.3438, batch size: 42
2021-08-25 03:03:44,942 INFO [train.py:450] Epoch 2, batch 1780, batch avg loss 0.3510, total avg loss: 0.3440, batch size: 40
2021-08-25 03:03:53,051 INFO [train.py:450] Epoch 2, batch 1790, batch avg loss 0.3429, total avg loss: 0.3441, batch size: 41
2021-08-25 03:04:01,299 INFO [train.py:450] Epoch 2, batch 1800, batch avg loss 0.3360, total avg loss: 0.3438, batch size: 39
2021-08-25 03:04:09,788 INFO [train.py:450] Epoch 2, batch 1810, batch avg loss 0.3131, total avg loss: 0.3265, batch size: 40
2021-08-25 03:04:17,681 INFO [train.py:450] Epoch 2, batch 1820, batch avg loss 0.4127, total avg loss: 0.3413, batch size: 41
2021-08-25 03:04:26,459 INFO [train.py:450] Epoch 2, batch 1830, batch avg loss 0.3112, total avg loss: 0.3384, batch size: 39
2021-08-25 03:04:34,722 INFO [train.py:450] Epoch 2, batch 1840, batch avg loss 0.3244, total avg loss: 0.3378, batch size: 37
2021-08-25 03:04:42,868 INFO [train.py:450] Epoch 2, batch 1850, batch avg loss 0.3407, total avg loss: 0.3368, batch size: 44
2021-08-25 03:04:51,046 INFO [train.py:450] Epoch 2, batch 1860, batch avg loss 0.3060, total avg loss: 0.3376, batch size: 38
2021-08-25 03:04:59,820 INFO [train.py:450] Epoch 2, batch 1870, batch avg loss 0.3723, total avg loss: 0.3382, batch size: 42
2021-08-25 03:05:08,855 INFO [train.py:450] Epoch 2, batch 1880, batch avg loss 0.3312, total avg loss: 0.3369, batch size: 38
2021-08-25 03:05:17,196 INFO [train.py:450] Epoch 2, batch 1890, batch avg loss 0.3525, total avg loss: 0.3376, batch size: 38
2021-08-25 03:05:25,423 INFO [train.py:450] Epoch 2, batch 1900, batch avg loss 0.3570, total avg loss: 0.3382, batch size: 44
2021-08-25 03:05:35,082 INFO [train.py:450] Epoch 2, batch 1910, batch avg loss 0.3487, total avg loss: 0.3374, batch size: 40
2021-08-25 03:05:43,330 INFO [train.py:450] Epoch 2, batch 1920, batch avg loss 0.2908, total avg loss: 0.3374, batch size: 37
2021-08-25 03:05:55,387 INFO [train.py:450] Epoch 2, batch 1930, batch avg loss 0.3436, total avg loss: 0.3365, batch size: 38
2021-08-25 03:06:04,001 INFO [train.py:450] Epoch 2, batch 1940, batch avg loss 0.3438, total avg loss: 0.3365, batch size: 41
2021-08-25 03:06:12,749 INFO [train.py:450] Epoch 2, batch 1950, batch avg loss 0.3088, total avg loss: 0.3365, batch size: 37
2021-08-25 03:06:21,145 INFO [train.py:450] Epoch 2, batch 1960, batch avg loss 0.3454, total avg loss: 0.3365, batch size: 39
2021-08-25 03:06:29,408 INFO [train.py:450] Epoch 2, batch 1970, batch avg loss 0.3526, total avg loss: 0.3361, batch size: 41
2021-08-25 03:06:38,040 INFO [train.py:450] Epoch 2, batch 1980, batch avg loss 0.2898, total avg loss: 0.3361, batch size: 38
2021-08-25 03:06:46,591 INFO [train.py:450] Epoch 2, batch 1990, batch avg loss 0.3311, total avg loss: 0.3358, batch size: 40
2021-08-25 03:06:54,185 INFO [train.py:450] Epoch 2, batch 2000, batch avg loss 0.3846, total avg loss: 0.3361, batch size: 40
2021-08-25 03:07:34,947 INFO [train.py:482] Epoch 2, valid loss 0.2463, best valid loss: 0.2448 best valid epoch: 1
2021-08-25 03:07:41,398 INFO [train.py:450] Epoch 2, batch 2010, batch avg loss 0.3250, total avg loss: 0.3546, batch size: 41
2021-08-25 03:07:49,830 INFO [train.py:450] Epoch 2, batch 2020, batch avg loss 0.3214, total avg loss: 0.3396, batch size: 39
2021-08-25 03:07:58,449 INFO [train.py:450] Epoch 2, batch 2030, batch avg loss 0.3527, total avg loss: 0.3387, batch size: 43
2021-08-25 03:08:06,450 INFO [train.py:450] Epoch 2, batch 2040, batch avg loss 0.3396, total avg loss: 0.3401, batch size: 40
2021-08-25 03:08:14,558 INFO [train.py:450] Epoch 2, batch 2050, batch avg loss 0.3848, total avg loss: 0.3459, batch size: 40
2021-08-25 03:08:23,057 INFO [train.py:450] Epoch 2, batch 2060, batch avg loss 0.3794, total avg loss: 0.3456, batch size: 40
2021-08-25 03:08:30,685 INFO [train.py:450] Epoch 2, batch 2070, batch avg loss 0.3195, total avg loss: 0.3452, batch size: 40
2021-08-25 03:08:39,343 INFO [train.py:450] Epoch 2, batch 2080, batch avg loss 0.3849, total avg loss: 0.3449, batch size: 40
2021-08-25 03:08:47,606 INFO [train.py:450] Epoch 2, batch 2090, batch avg loss 0.3484, total avg loss: 0.3424, batch size: 39
2021-08-25 03:08:55,954 INFO [train.py:450] Epoch 2, batch 2100, batch avg loss 0.3384, total avg loss: 0.3437, batch size: 35
2021-08-25 03:09:04,878 INFO [train.py:450] Epoch 2, batch 2110, batch avg loss 0.2938, total avg loss: 0.3449, batch size: 39
2021-08-25 03:09:12,914 INFO [train.py:450] Epoch 2, batch 2120, batch avg loss 0.3867, total avg loss: 0.3448, batch size: 36
2021-08-25 03:09:20,700 INFO [train.py:450] Epoch 2, batch 2130, batch avg loss 0.3951, total avg loss: 0.3448, batch size: 42
2021-08-25 03:09:29,454 INFO [train.py:450] Epoch 2, batch 2140, batch avg loss 0.3105, total avg loss: 0.3445, batch size: 37
2021-08-25 03:09:37,153 INFO [train.py:450] Epoch 2, batch 2150, batch avg loss 0.3162, total avg loss: 0.3435, batch size: 39
2021-08-25 03:09:46,621 INFO [train.py:450] Epoch 2, batch 2160, batch avg loss 0.3613, total avg loss: 0.3434, batch size: 43
2021-08-25 03:09:54,430 INFO [train.py:450] Epoch 2, batch 2170, batch avg loss 0.3342, total avg loss: 0.3428, batch size: 41
2021-08-25 03:10:05,799 INFO [train.py:450] Epoch 2, batch 2180, batch avg loss 0.3314, total avg loss: 0.3433, batch size: 38
2021-08-25 03:10:14,095 INFO [train.py:450] Epoch 2, batch 2190, batch avg loss 0.3988, total avg loss: 0.3434, batch size: 39
2021-08-25 03:10:22,620 INFO [train.py:450] Epoch 2, batch 2200, batch avg loss 0.3361, total avg loss: 0.3430, batch size: 42
2021-08-25 03:10:31,100 INFO [train.py:450] Epoch 2, batch 2210, batch avg loss 0.3255, total avg loss: 0.3347, batch size: 40
2021-08-25 03:10:39,133 INFO [train.py:450] Epoch 2, batch 2220, batch avg loss 0.3181, total avg loss: 0.3423, batch size: 39
2021-08-25 03:10:47,315 INFO [train.py:450] Epoch 2, batch 2230, batch avg loss 0.2833, total avg loss: 0.3481, batch size: 38
2021-08-25 03:10:56,266 INFO [train.py:450] Epoch 2, batch 2240, batch avg loss 0.3559, total avg loss: 0.3479, batch size: 38
2021-08-25 03:11:04,269 INFO [train.py:450] Epoch 2, batch 2250, batch avg loss 0.3730, total avg loss: 0.3483, batch size: 41
2021-08-25 03:11:12,157 INFO [train.py:450] Epoch 2, batch 2260, batch avg loss 0.2905, total avg loss: 0.3474, batch size: 37
2021-08-25 03:11:20,623 INFO [train.py:450] Epoch 2, batch 2270, batch avg loss 0.3986, total avg loss: 0.3472, batch size: 40
2021-08-25 03:11:29,045 INFO [train.py:450] Epoch 2, batch 2280, batch avg loss 0.3606, total avg loss: 0.3447, batch size: 40
2021-08-25 03:11:37,123 INFO [train.py:450] Epoch 2, batch 2290, batch avg loss 0.3522, total avg loss: 0.3444, batch size: 41
2021-08-25 03:11:44,529 INFO [train.py:450] Epoch 2, batch 2300, batch avg loss 0.3429, total avg loss: 0.3463, batch size: 38
2021-08-25 03:11:52,983 INFO [train.py:450] Epoch 2, batch 2310, batch avg loss 0.3947, total avg loss: 0.3463, batch size: 44
2021-08-25 03:12:01,086 INFO [train.py:450] Epoch 2, batch 2320, batch avg loss 0.3024, total avg loss: 0.3452, batch size: 39
2021-08-25 03:12:09,271 INFO [train.py:450] Epoch 2, batch 2330, batch avg loss 0.3984, total avg loss: 0.3449, batch size: 44
2021-08-25 03:12:17,470 INFO [train.py:450] Epoch 2, batch 2340, batch avg loss 0.3556, total avg loss: 0.3445, batch size: 38
2021-08-25 03:12:25,330 INFO [train.py:450] Epoch 2, batch 2350, batch avg loss 0.3005, total avg loss: 0.3438, batch size: 40
2021-08-25 03:12:34,047 INFO [train.py:450] Epoch 2, batch 2360, batch avg loss 0.2944, total avg loss: 0.3430, batch size: 41
2021-08-25 03:12:42,218 INFO [train.py:450] Epoch 2, batch 2370, batch avg loss 0.3406, total avg loss: 0.3429, batch size: 39
2021-08-25 03:12:49,714 INFO [train.py:450] Epoch 2, batch 2380, batch avg loss 0.3384, total avg loss: 0.3423, batch size: 34
2021-08-25 03:12:58,166 INFO [train.py:450] Epoch 2, batch 2390, batch avg loss 0.4098, total avg loss: 0.3425, batch size: 37
2021-08-25 03:13:06,412 INFO [train.py:450] Epoch 2, batch 2400, batch avg loss 0.3353, total avg loss: 0.3425, batch size: 41
2021-08-25 03:13:14,659 INFO [train.py:450] Epoch 2, batch 2410, batch avg loss 0.3535, total avg loss: 0.3335, batch size: 40
2021-08-25 03:13:22,671 INFO [train.py:450] Epoch 2, batch 2420, batch avg loss 0.3701, total avg loss: 0.3338, batch size: 36
2021-08-25 03:13:30,544 INFO [train.py:450] Epoch 2, batch 2430, batch avg loss 0.3607, total avg loss: 0.3338, batch size: 41
2021-08-25 03:13:39,001 INFO [train.py:450] Epoch 2, batch 2440, batch avg loss 0.3606, total avg loss: 0.3349, batch size: 39
2021-08-25 03:13:48,946 INFO [train.py:450] Epoch 2, batch 2450, batch avg loss 0.3439, total avg loss: 0.3361, batch size: 37
2021-08-25 03:13:57,123 INFO [train.py:450] Epoch 2, batch 2460, batch avg loss 0.3508, total avg loss: 0.3380, batch size: 39
2021-08-25 03:14:09,138 INFO [train.py:450] Epoch 2, batch 2470, batch avg loss 0.3177, total avg loss: 0.3372, batch size: 38
2021-08-25 03:14:17,221 INFO [train.py:450] Epoch 2, batch 2480, batch avg loss 0.2762, total avg loss: 0.3357, batch size: 41
2021-08-25 03:14:25,916 INFO [train.py:450] Epoch 2, batch 2490, batch avg loss 0.2975, total avg loss: 0.3364, batch size: 41
2021-08-25 03:14:33,885 INFO [train.py:450] Epoch 2, batch 2500, batch avg loss 0.3358, total avg loss: 0.3375, batch size: 45
2021-08-25 03:14:42,304 INFO [train.py:450] Epoch 2, batch 2510, batch avg loss 0.3281, total avg loss: 0.3367, batch size: 38
2021-08-25 03:14:50,544 INFO [train.py:450] Epoch 2, batch 2520, batch avg loss 0.3621, total avg loss: 0.3368, batch size: 37
2021-08-25 03:14:58,644 INFO [train.py:450] Epoch 2, batch 2530, batch avg loss 0.3508, total avg loss: 0.3362, batch size: 40
2021-08-25 03:15:06,796 INFO [train.py:450] Epoch 2, batch 2540, batch avg loss 0.3632, total avg loss: 0.3377, batch size: 43
2021-08-25 03:15:14,759 INFO [train.py:450] Epoch 2, batch 2550, batch avg loss 0.3335, total avg loss: 0.3384, batch size: 44
2021-08-25 03:15:23,516 INFO [train.py:450] Epoch 2, batch 2560, batch avg loss 0.3312, total avg loss: 0.3391, batch size: 43
2021-08-25 03:15:31,992 INFO [train.py:450] Epoch 2, batch 2570, batch avg loss 0.2890, total avg loss: 0.3391, batch size: 43
2021-08-25 03:15:40,679 INFO [train.py:450] Epoch 2, batch 2580, batch avg loss 0.4276, total avg loss: 0.3402, batch size: 39
2021-08-25 03:15:48,953 INFO [train.py:450] Epoch 2, batch 2590, batch avg loss 0.3292, total avg loss: 0.3405, batch size: 37
2021-08-25 03:15:57,179 INFO [train.py:450] Epoch 2, batch 2600, batch avg loss 0.3446, total avg loss: 0.3403, batch size: 41
2021-08-25 03:16:05,392 INFO [train.py:450] Epoch 2, batch 2610, batch avg loss 0.3926, total avg loss: 0.3443, batch size: 43
2021-08-25 03:16:13,366 INFO [train.py:450] Epoch 2, batch 2620, batch avg loss 0.3384, total avg loss: 0.3409, batch size: 38
2021-08-25 03:16:21,576 INFO [train.py:450] Epoch 2, batch 2630, batch avg loss 0.3482, total avg loss: 0.3388, batch size: 38
2021-08-25 03:16:29,398 INFO [train.py:450] Epoch 2, batch 2640, batch avg loss 0.3105, total avg loss: 0.3401, batch size: 38
2021-08-25 03:16:37,769 INFO [train.py:450] Epoch 2, batch 2650, batch avg loss 0.3400, total avg loss: 0.3383, batch size: 39
2021-08-25 03:16:45,937 INFO [train.py:450] Epoch 2, batch 2660, batch avg loss 0.3090, total avg loss: 0.3383, batch size: 41
2021-08-25 03:16:53,966 INFO [train.py:450] Epoch 2, batch 2670, batch avg loss 0.3319, total avg loss: 0.3365, batch size: 40
2021-08-25 03:17:02,506 INFO [train.py:450] Epoch 2, batch 2680, batch avg loss 0.3324, total avg loss: 0.3357, batch size: 39
2021-08-25 03:17:10,788 INFO [train.py:450] Epoch 2, batch 2690, batch avg loss 0.3458, total avg loss: 0.3353, batch size: 38
2021-08-25 03:17:18,748 INFO [train.py:450] Epoch 2, batch 2700, batch avg loss 0.2948, total avg loss: 0.3341, batch size: 41
2021-08-25 03:17:27,222 INFO [train.py:450] Epoch 2, batch 2710, batch avg loss 0.3365, total avg loss: 0.3359, batch size: 34
2021-08-25 03:17:35,563 INFO [train.py:450] Epoch 2, batch 2720, batch avg loss 0.3887, total avg loss: 0.3371, batch size: 40
2021-08-25 03:17:44,020 INFO [train.py:450] Epoch 2, batch 2730, batch avg loss 0.3377, total avg loss: 0.3379, batch size: 40
2021-08-25 03:17:51,962 INFO [train.py:450] Epoch 2, batch 2740, batch avg loss 0.3645, total avg loss: 0.3385, batch size: 36
2021-08-25 03:18:00,055 INFO [train.py:450] Epoch 2, batch 2750, batch avg loss 0.3136, total avg loss: 0.3391, batch size: 40
2021-08-25 03:18:08,298 INFO [train.py:450] Epoch 2, batch 2760, batch avg loss 0.2996, total avg loss: 0.3392, batch size: 37
2021-08-25 03:18:18,420 INFO [train.py:450] Epoch 2, batch 2770, batch avg loss 0.3088, total avg loss: 0.3407, batch size: 38
2021-08-25 03:18:29,371 INFO [train.py:450] Epoch 2, batch 2780, batch avg loss 0.2826, total avg loss: 0.3412, batch size: 39
2021-08-25 03:18:39,006 INFO [train.py:450] Epoch 2, batch 2790, batch avg loss 0.4057, total avg loss: 0.3425, batch size: 41
2021-08-25 03:18:47,589 INFO [train.py:450] Epoch 2, batch 2800, batch avg loss 0.3450, total avg loss: 0.3431, batch size: 42
2021-08-25 03:18:56,224 INFO [train.py:450] Epoch 2, batch 2810, batch avg loss 0.3413, total avg loss: 0.3507, batch size: 39
2021-08-25 03:19:04,473 INFO [train.py:450] Epoch 2, batch 2820, batch avg loss 0.3931, total avg loss: 0.3438, batch size: 40
2021-08-25 03:19:12,922 INFO [train.py:450] Epoch 2, batch 2830, batch avg loss 0.3091, total avg loss: 0.3461, batch size: 39
2021-08-25 03:19:21,605 INFO [train.py:450] Epoch 2, batch 2840, batch avg loss 0.3267, total avg loss: 0.3448, batch size: 37
2021-08-25 03:19:29,843 INFO [train.py:450] Epoch 2, batch 2850, batch avg loss 0.3397, total avg loss: 0.3425, batch size: 42
2021-08-25 03:19:38,135 INFO [train.py:450] Epoch 2, batch 2860, batch avg loss 0.4336, total avg loss: 0.3437, batch size: 37
2021-08-25 03:19:45,918 INFO [train.py:450] Epoch 2, batch 2870, batch avg loss 0.3124, total avg loss: 0.3442, batch size: 41
2021-08-25 03:19:54,477 INFO [train.py:450] Epoch 2, batch 2880, batch avg loss 0.3353, total avg loss: 0.3437, batch size: 44
2021-08-25 03:20:03,192 INFO [train.py:450] Epoch 2, batch 2890, batch avg loss 0.3519, total avg loss: 0.3445, batch size: 39
2021-08-25 03:20:11,506 INFO [train.py:450] Epoch 2, batch 2900, batch avg loss 0.3137, total avg loss: 0.3453, batch size: 38
2021-08-25 03:20:19,657 INFO [train.py:450] Epoch 2, batch 2910, batch avg loss 0.3765, total avg loss: 0.3453, batch size: 44
2021-08-25 03:20:28,502 INFO [train.py:450] Epoch 2, batch 2920, batch avg loss 0.3030, total avg loss: 0.3451, batch size: 42
2021-08-25 03:20:37,136 INFO [train.py:450] Epoch 2, batch 2930, batch avg loss 0.3186, total avg loss: 0.3448, batch size: 39
2021-08-25 03:20:45,703 INFO [train.py:450] Epoch 2, batch 2940, batch avg loss 0.3684, total avg loss: 0.3446, batch size: 44
2021-08-25 03:20:53,833 INFO [train.py:450] Epoch 2, batch 2950, batch avg loss 0.3809, total avg loss: 0.3455, batch size: 38
2021-08-25 03:21:02,045 INFO [train.py:450] Epoch 2, batch 2960, batch avg loss 0.3671, total avg loss: 0.3455, batch size: 40
2021-08-25 03:21:10,230 INFO [train.py:450] Epoch 2, batch 2970, batch avg loss 0.2877, total avg loss: 0.3450, batch size: 41
2021-08-25 03:21:17,711 INFO [train.py:450] Epoch 2, batch 2980, batch avg loss 0.3737, total avg loss: 0.3446, batch size: 36
2021-08-25 03:21:25,374 INFO [train.py:450] Epoch 2, batch 2990, batch avg loss 0.3749, total avg loss: 0.3442, batch size: 38
2021-08-25 03:21:34,112 INFO [train.py:450] Epoch 2, batch 3000, batch avg loss 0.2972, total avg loss: 0.3437, batch size: 37
2021-08-25 03:22:12,958 INFO [train.py:482] Epoch 2, valid loss 0.2442, best valid loss: 0.2442 best valid epoch: 2
2021-08-25 03:22:19,168 INFO [train.py:450] Epoch 2, batch 3010, batch avg loss 0.3278, total avg loss: 0.3517, batch size: 41
2021-08-25 03:22:30,909 INFO [train.py:450] Epoch 2, batch 3020, batch avg loss 0.3379, total avg loss: 0.3513, batch size: 43
2021-08-25 03:22:38,926 INFO [train.py:450] Epoch 2, batch 3030, batch avg loss 0.3318, total avg loss: 0.3457, batch size: 38
2021-08-25 03:22:47,872 INFO [train.py:450] Epoch 2, batch 3040, batch avg loss 0.3699, total avg loss: 0.3469, batch size: 39
2021-08-25 03:22:56,277 INFO [train.py:450] Epoch 2, batch 3050, batch avg loss 0.3317, total avg loss: 0.3480, batch size: 41
2021-08-25 03:23:04,593 INFO [train.py:450] Epoch 2, batch 3060, batch avg loss 0.3704, total avg loss: 0.3511, batch size: 43
2021-08-25 03:23:13,354 INFO [train.py:450] Epoch 2, batch 3070, batch avg loss 0.3152, total avg loss: 0.3501, batch size: 39
2021-08-25 03:23:22,029 INFO [train.py:450] Epoch 2, batch 3080, batch avg loss 0.3205, total avg loss: 0.3500, batch size: 41
2021-08-25 03:23:29,978 INFO [train.py:450] Epoch 2, batch 3090, batch avg loss 0.2986, total avg loss: 0.3492, batch size: 38
2021-08-25 03:23:38,348 INFO [train.py:450] Epoch 2, batch 3100, batch avg loss 0.3101, total avg loss: 0.3481, batch size: 44
2021-08-25 03:23:46,494 INFO [train.py:450] Epoch 2, batch 3110, batch avg loss 0.3434, total avg loss: 0.3479, batch size: 41
2021-08-25 03:23:55,296 INFO [train.py:450] Epoch 2, batch 3120, batch avg loss 0.4246, total avg loss: 0.3487, batch size: 44
2021-08-25 03:24:03,387 INFO [train.py:450] Epoch 2, batch 3130, batch avg loss 0.3771, total avg loss: 0.3487, batch size: 40
2021-08-25 03:24:11,961 INFO [train.py:450] Epoch 2, batch 3140, batch avg loss 0.2703, total avg loss: 0.3472, batch size: 37
2021-08-25 03:24:20,289 INFO [train.py:450] Epoch 2, batch 3150, batch avg loss 0.3291, total avg loss: 0.3469, batch size: 47
2021-08-25 03:24:27,990 INFO [train.py:450] Epoch 2, batch 3160, batch avg loss 0.3629, total avg loss: 0.3478, batch size: 42
2021-08-25 03:24:36,176 INFO [train.py:450] Epoch 2, batch 3170, batch avg loss 0.3562, total avg loss: 0.3478, batch size: 40
2021-08-25 03:24:44,254 INFO [train.py:450] Epoch 2, batch 3180, batch avg loss 0.3340, total avg loss: 0.3470, batch size: 41
2021-08-25 03:24:52,612 INFO [train.py:450] Epoch 2, batch 3190, batch avg loss 0.3499, total avg loss: 0.3476, batch size: 36
2021-08-25 03:25:00,673 INFO [train.py:450] Epoch 2, batch 3200, batch avg loss 0.3346, total avg loss: 0.3470, batch size: 42
2021-08-25 03:25:08,360 INFO [train.py:450] Epoch 2, batch 3210, batch avg loss 0.3681, total avg loss: 0.3564, batch size: 42
2021-08-25 03:25:16,461 INFO [train.py:450] Epoch 2, batch 3220, batch avg loss 0.2827, total avg loss: 0.3412, batch size: 38
2021-08-25 03:25:24,197 INFO [train.py:450] Epoch 2, batch 3230, batch avg loss 0.3916, total avg loss: 0.3452, batch size: 37
2021-08-25 03:25:32,197 INFO [train.py:450] Epoch 2, batch 3240, batch avg loss 0.3753, total avg loss: 0.3448, batch size: 39
2021-08-25 03:25:40,208 INFO [train.py:450] Epoch 2, batch 3250, batch avg loss 0.3624, total avg loss: 0.3450, batch size: 46
2021-08-25 03:25:48,538 INFO [train.py:450] Epoch 2, batch 3260, batch avg loss 0.3730, total avg loss: 0.3469, batch size: 41
2021-08-25 03:25:56,303 INFO [train.py:450] Epoch 2, batch 3270, batch avg loss 0.3297, total avg loss: 0.3495, batch size: 41
2021-08-25 03:26:04,134 INFO [train.py:450] Epoch 2, batch 3280, batch avg loss 0.3452, total avg loss: 0.3482, batch size: 41
2021-08-25 03:26:12,124 INFO [train.py:450] Epoch 2, batch 3290, batch avg loss 0.3531, total avg loss: 0.3456, batch size: 39
2021-08-25 03:26:20,217 INFO [train.py:450] Epoch 2, batch 3300, batch avg loss 0.3137, total avg loss: 0.3472, batch size: 39
2021-08-25 03:26:28,317 INFO [train.py:450] Epoch 2, batch 3310, batch avg loss 0.3444, total avg loss: 0.3484, batch size: 36
2021-08-25 03:26:38,090 INFO [train.py:450] Epoch 2, batch 3320, batch avg loss 0.3440, total avg loss: 0.3478, batch size: 36
2021-08-25 03:26:45,588 INFO [train.py:450] Epoch 2, batch 3330, batch avg loss 0.3242, total avg loss: 0.3469, batch size: 40
2021-08-25 03:26:56,464 INFO [train.py:450] Epoch 2, batch 3340, batch avg loss 0.3312, total avg loss: 0.3450, batch size: 39
2021-08-25 03:27:03,670 INFO [train.py:450] Epoch 2, batch 3350, batch avg loss 0.3710, total avg loss: 0.3449, batch size: 40
2021-08-25 03:27:11,862 INFO [train.py:450] Epoch 2, batch 3360, batch avg loss 0.3662, total avg loss: 0.3442, batch size: 38
2021-08-25 03:27:20,366 INFO [train.py:450] Epoch 2, batch 3370, batch avg loss 0.3424, total avg loss: 0.3438, batch size: 43
2021-08-25 03:27:28,216 INFO [train.py:450] Epoch 2, batch 3380, batch avg loss 0.3418, total avg loss: 0.3431, batch size: 43
2021-08-25 03:27:36,082 INFO [train.py:450] Epoch 2, batch 3390, batch avg loss 0.3123, total avg loss: 0.3431, batch size: 38
2021-08-25 03:27:44,193 INFO [train.py:450] Epoch 2, batch 3400, batch avg loss 0.3515, total avg loss: 0.3422, batch size: 40
2021-08-25 03:27:52,734 INFO [train.py:450] Epoch 2, batch 3410, batch avg loss 0.3853, total avg loss: 0.3439, batch size: 41
2021-08-25 03:28:00,537 INFO [train.py:450] Epoch 2, batch 3420, batch avg loss 0.3522, total avg loss: 0.3433, batch size: 39
2021-08-25 03:28:08,732 INFO [train.py:450] Epoch 2, batch 3430, batch avg loss 0.3491, total avg loss: 0.3433, batch size: 36
2021-08-25 03:28:16,517 INFO [train.py:450] Epoch 2, batch 3440, batch avg loss 0.3364, total avg loss: 0.3443, batch size: 39
2021-08-25 03:28:24,574 INFO [train.py:450] Epoch 2, batch 3450, batch avg loss 0.3697, total avg loss: 0.3461, batch size: 38
2021-08-25 03:28:33,163 INFO [train.py:450] Epoch 2, batch 3460, batch avg loss 0.3614, total avg loss: 0.3454, batch size: 40
2021-08-25 03:28:41,315 INFO [train.py:450] Epoch 2, batch 3470, batch avg loss 0.3227, total avg loss: 0.3418, batch size: 41
2021-08-25 03:28:49,387 INFO [train.py:450] Epoch 2, batch 3480, batch avg loss 0.3380, total avg loss: 0.3406, batch size: 43
2021-08-25 03:28:57,766 INFO [train.py:450] Epoch 2, batch 3490, batch avg loss 0.3120, total avg loss: 0.3428, batch size: 40
2021-08-25 03:29:06,279 INFO [train.py:450] Epoch 2, batch 3500, batch avg loss 0.2804, total avg loss: 0.3413, batch size: 39
2021-08-25 03:29:14,530 INFO [train.py:450] Epoch 2, batch 3510, batch avg loss 0.3407, total avg loss: 0.3410, batch size: 40
2021-08-25 03:29:22,635 INFO [train.py:450] Epoch 2, batch 3520, batch avg loss 0.2999, total avg loss: 0.3409, batch size: 41
2021-08-25 03:29:30,178 INFO [train.py:450] Epoch 2, batch 3530, batch avg loss 0.3529, total avg loss: 0.3423, batch size: 38
2021-08-25 03:29:37,789 INFO [train.py:450] Epoch 2, batch 3540, batch avg loss 0.3112, total avg loss: 0.3409, batch size: 38
2021-08-25 03:29:46,100 INFO [train.py:450] Epoch 2, batch 3550, batch avg loss 0.3308, total avg loss: 0.3400, batch size: 38
2021-08-25 03:29:53,954 INFO [train.py:450] Epoch 2, batch 3560, batch avg loss 0.3061, total avg loss: 0.3401, batch size: 40
2021-08-25 03:30:01,900 INFO [train.py:450] Epoch 2, batch 3570, batch avg loss 0.3539, total avg loss: 0.3399, batch size: 41
2021-08-25 03:30:09,659 INFO [train.py:450] Epoch 2, batch 3580, batch avg loss 0.3354, total avg loss: 0.3395, batch size: 44
2021-08-25 03:30:17,690 INFO [train.py:450] Epoch 2, batch 3590, batch avg loss 0.4262, total avg loss: 0.3396, batch size: 41
2021-08-25 03:30:25,784 INFO [train.py:450] Epoch 2, batch 3600, batch avg loss 0.3098, total avg loss: 0.3400, batch size: 41
2021-08-25 03:30:32,905 INFO [train.py:450] Epoch 2, batch 3610, batch avg loss 0.3609, total avg loss: 0.3558, batch size: 39
2021-08-25 03:30:40,771 INFO [train.py:450] Epoch 2, batch 3620, batch avg loss 0.3165, total avg loss: 0.3536, batch size: 40
2021-08-25 03:30:50,372 INFO [train.py:450] Epoch 2, batch 3630, batch avg loss 0.3365, total avg loss: 0.3477, batch size: 37
2021-08-25 03:30:58,045 INFO [train.py:450] Epoch 2, batch 3640, batch avg loss 0.3588, total avg loss: 0.3479, batch size: 39
2021-08-25 03:31:08,029 INFO [train.py:450] Epoch 2, batch 3650, batch avg loss 0.2888, total avg loss: 0.3432, batch size: 39
2021-08-25 03:31:16,186 INFO [train.py:450] Epoch 2, batch 3660, batch avg loss 0.2837, total avg loss: 0.3432, batch size: 38
2021-08-25 03:31:24,349 INFO [train.py:450] Epoch 2, batch 3670, batch avg loss 0.3349, total avg loss: 0.3411, batch size: 38
2021-08-25 03:31:32,702 INFO [train.py:450] Epoch 2, batch 3680, batch avg loss 0.3162, total avg loss: 0.3425, batch size: 40
2021-08-25 03:31:41,388 INFO [train.py:450] Epoch 2, batch 3690, batch avg loss 0.3428, total avg loss: 0.3435, batch size: 40
2021-08-25 03:31:49,136 INFO [train.py:450] Epoch 2, batch 3700, batch avg loss 0.4067, total avg loss: 0.3433, batch size: 43
2021-08-25 03:31:57,196 INFO [train.py:450] Epoch 2, batch 3710, batch avg loss 0.3220, total avg loss: 0.3433, batch size: 40
2021-08-25 03:32:05,048 INFO [train.py:450] Epoch 2, batch 3720, batch avg loss 0.3516, total avg loss: 0.3435, batch size: 39
2021-08-25 03:32:13,195 INFO [train.py:450] Epoch 2, batch 3730, batch avg loss 0.3522, total avg loss: 0.3443, batch size: 39
2021-08-25 03:32:21,555 INFO [train.py:450] Epoch 2, batch 3740, batch avg loss 0.2808, total avg loss: 0.3439, batch size: 41
2021-08-25 03:32:29,697 INFO [train.py:450] Epoch 2, batch 3750, batch avg loss 0.3384, total avg loss: 0.3436, batch size: 43
2021-08-25 03:32:37,265 INFO [train.py:450] Epoch 2, batch 3760, batch avg loss 0.3723, total avg loss: 0.3433, batch size: 42
2021-08-25 03:32:45,574 INFO [train.py:450] Epoch 2, batch 3770, batch avg loss 0.3188, total avg loss: 0.3419, batch size: 41
2021-08-25 03:32:53,222 INFO [train.py:450] Epoch 2, batch 3780, batch avg loss 0.3090, total avg loss: 0.3429, batch size: 39
2021-08-25 03:33:01,316 INFO [train.py:450] Epoch 2, batch 3790, batch avg loss 0.3311, total avg loss: 0.3438, batch size: 42
2021-08-25 03:33:09,433 INFO [train.py:450] Epoch 2, batch 3800, batch avg loss 0.3506, total avg loss: 0.3435, batch size: 41
2021-08-25 03:33:17,669 INFO [train.py:450] Epoch 2, batch 3810, batch avg loss 0.3284, total avg loss: 0.3421, batch size: 40
2021-08-25 03:33:25,570 INFO [train.py:450] Epoch 2, batch 3820, batch avg loss 0.3151, total avg loss: 0.3441, batch size: 37
2021-08-25 03:33:33,293 INFO [train.py:450] Epoch 2, batch 3830, batch avg loss 0.4161, total avg loss: 0.3462, batch size: 38
2021-08-25 03:33:41,540 INFO [train.py:450] Epoch 2, batch 3840, batch avg loss 0.3519, total avg loss: 0.3448, batch size: 41
2021-08-25 03:33:48,819 INFO [train.py:450] Epoch 2, batch 3850, batch avg loss 0.3553, total avg loss: 0.3430, batch size: 43
2021-08-25 03:33:56,777 INFO [train.py:450] Epoch 2, batch 3860, batch avg loss 0.3641, total avg loss: 0.3447, batch size: 39
2021-08-25 03:34:04,171 WARNING [cut.py:1694] To perform mix, energy must be non-zero and non-negative (got 0.0).  MonoCut with id "5e41a17e-90b4-3429-e4fc-4a42c154ff6d" will not be mixed in.
2021-08-25 03:34:04,682 INFO [train.py:450] Epoch 2, batch 3870, batch avg loss 0.3357, total avg loss: 0.3447, batch size: 44
2021-08-25 03:34:12,417 INFO [train.py:450] Epoch 2, batch 3880, batch avg loss 0.3194, total avg loss: 0.3430, batch size: 38
2021-08-25 03:34:20,296 INFO [train.py:450] Epoch 2, batch 3890, batch avg loss 0.3435, total avg loss: 0.3431, batch size: 36
2021-08-25 03:34:28,935 INFO [train.py:450] Epoch 2, batch 3900, batch avg loss 0.3752, total avg loss: 0.3437, batch size: 43
2021-08-25 03:34:37,451 INFO [train.py:450] Epoch 2, batch 3910, batch avg loss 0.3814, total avg loss: 0.3454, batch size: 43
2021-08-25 03:34:45,349 INFO [train.py:450] Epoch 2, batch 3920, batch avg loss 0.3610, total avg loss: 0.3459, batch size: 39
2021-08-25 03:34:54,020 INFO [train.py:450] Epoch 2, batch 3930, batch avg loss 0.3522, total avg loss: 0.3449, batch size: 38
2021-08-25 03:35:01,470 INFO [train.py:450] Epoch 2, batch 3940, batch avg loss 0.3360, total avg loss: 0.3443, batch size: 38
2021-08-25 03:35:09,456 INFO [train.py:450] Epoch 2, batch 3950, batch avg loss 0.3076, total avg loss: 0.3433, batch size: 45
2021-08-25 03:35:17,094 INFO [train.py:450] Epoch 2, batch 3960, batch avg loss 0.3221, total avg loss: 0.3428, batch size: 41
2021-08-25 03:35:26,787 INFO [train.py:450] Epoch 2, batch 3970, batch avg loss 0.3543, total avg loss: 0.3420, batch size: 41
2021-08-25 03:35:36,283 INFO [train.py:450] Epoch 2, batch 3980, batch avg loss 0.3366, total avg loss: 0.3418, batch size: 41
2021-08-25 03:35:45,201 INFO [train.py:450] Epoch 2, batch 3990, batch avg loss 0.3149, total avg loss: 0.3411, batch size: 43
2021-08-25 03:35:52,941 INFO [train.py:450] Epoch 2, batch 4000, batch avg loss 0.3679, total avg loss: 0.3416, batch size: 42
2021-08-25 03:36:32,655 INFO [train.py:482] Epoch 2, valid loss 0.2482, best valid loss: 0.2442 best valid epoch: 2
2021-08-25 03:36:38,733 INFO [train.py:450] Epoch 2, batch 4010, batch avg loss 0.3445, total avg loss: 0.3422, batch size: 41
2021-08-25 03:36:46,603 INFO [train.py:450] Epoch 2, batch 4020, batch avg loss 0.3839, total avg loss: 0.3413, batch size: 42
2021-08-25 03:36:54,922 INFO [train.py:450] Epoch 2, batch 4030, batch avg loss 0.3627, total avg loss: 0.3405, batch size: 40
2021-08-25 03:37:02,697 INFO [train.py:450] Epoch 2, batch 4040, batch avg loss 0.3249, total avg loss: 0.3405, batch size: 38
2021-08-25 03:37:10,118 INFO [train.py:450] Epoch 2, batch 4050, batch avg loss 0.3144, total avg loss: 0.3407, batch size: 38
2021-08-25 03:37:17,885 INFO [train.py:450] Epoch 2, batch 4060, batch avg loss 0.3118, total avg loss: 0.3414, batch size: 41
2021-08-25 03:37:25,946 INFO [train.py:450] Epoch 2, batch 4070, batch avg loss 0.3166, total avg loss: 0.3419, batch size: 36
2021-08-25 03:37:33,766 INFO [train.py:450] Epoch 2, batch 4080, batch avg loss 0.4126, total avg loss: 0.3446, batch size: 41
2021-08-25 03:37:41,872 INFO [train.py:450] Epoch 2, batch 4090, batch avg loss 0.3365, total avg loss: 0.3417, batch size: 42
2021-08-25 03:37:50,192 INFO [train.py:450] Epoch 2, batch 4100, batch avg loss 0.3622, total avg loss: 0.3413, batch size: 44
2021-08-25 03:37:57,789 INFO [train.py:450] Epoch 2, batch 4110, batch avg loss 0.3301, total avg loss: 0.3402, batch size: 38
2021-08-25 03:38:05,823 INFO [train.py:450] Epoch 2, batch 4120, batch avg loss 0.3531, total avg loss: 0.3396, batch size: 40
2021-08-25 03:38:13,535 INFO [train.py:450] Epoch 2, batch 4130, batch avg loss 0.3120, total avg loss: 0.3387, batch size: 36
2021-08-25 03:38:21,316 INFO [train.py:450] Epoch 2, batch 4140, batch avg loss 0.3403, total avg loss: 0.3382, batch size: 37
2021-08-25 03:38:29,381 INFO [train.py:450] Epoch 2, batch 4150, batch avg loss 0.3491, total avg loss: 0.3374, batch size: 40
2021-08-25 03:38:36,877 INFO [train.py:450] Epoch 2, batch 4160, batch avg loss 0.3261, total avg loss: 0.3381, batch size: 39
2021-08-25 03:38:44,912 INFO [train.py:450] Epoch 2, batch 4170, batch avg loss 0.3197, total avg loss: 0.3380, batch size: 37
2021-08-25 03:38:53,620 INFO [train.py:450] Epoch 2, batch 4180, batch avg loss 0.3413, total avg loss: 0.3377, batch size: 39
2021-08-25 03:39:01,427 INFO [train.py:450] Epoch 2, batch 4190, batch avg loss 0.3195, total avg loss: 0.3375, batch size: 39
2021-08-25 03:39:09,264 INFO [train.py:450] Epoch 2, batch 4200, batch avg loss 0.3555, total avg loss: 0.3367, batch size: 39
2021-08-25 03:39:16,830 INFO [train.py:450] Epoch 2, batch 4210, batch avg loss 0.3337, total avg loss: 0.3352, batch size: 43
2021-08-25 03:39:24,624 INFO [train.py:450] Epoch 2, batch 4220, batch avg loss 0.3715, total avg loss: 0.3332, batch size: 40
2021-08-25 03:39:33,962 INFO [train.py:450] Epoch 2, batch 4230, batch avg loss 0.3054, total avg loss: 0.3340, batch size: 40
2021-08-25 03:39:43,348 INFO [train.py:450] Epoch 2, batch 4240, batch avg loss 0.3551, total avg loss: 0.3394, batch size: 39
2021-08-25 03:39:51,472 INFO [train.py:450] Epoch 2, batch 4250, batch avg loss 0.3064, total avg loss: 0.3407, batch size: 40
2021-08-25 03:39:59,430 INFO [train.py:450] Epoch 2, batch 4260, batch avg loss 0.3076, total avg loss: 0.3397, batch size: 41
2021-08-25 03:40:07,570 INFO [train.py:450] Epoch 2, batch 4270, batch avg loss 0.3392, total avg loss: 0.3425, batch size: 40
2021-08-25 03:40:15,669 INFO [train.py:450] Epoch 2, batch 4280, batch avg loss 0.3862, total avg loss: 0.3424, batch size: 38
2021-08-25 03:40:23,458 INFO [train.py:450] Epoch 2, batch 4290, batch avg loss 0.3553, total avg loss: 0.3455, batch size: 37
2021-08-25 03:40:31,238 INFO [train.py:450] Epoch 2, batch 4300, batch avg loss 0.3595, total avg loss: 0.3447, batch size: 39
2021-08-25 03:40:38,527 INFO [train.py:450] Epoch 2, batch 4310, batch avg loss 0.3541, total avg loss: 0.3447, batch size: 39
2021-08-25 03:40:46,446 INFO [train.py:450] Epoch 2, batch 4320, batch avg loss 0.3622, total avg loss: 0.3440, batch size: 41
2021-08-25 03:40:54,129 INFO [train.py:450] Epoch 2, batch 4330, batch avg loss 0.3706, total avg loss: 0.3438, batch size: 38
2021-08-25 03:41:01,393 INFO [train.py:450] Epoch 2, batch 4340, batch avg loss 0.3158, total avg loss: 0.3444, batch size: 40
2021-08-25 03:41:08,784 INFO [train.py:450] Epoch 2, batch 4350, batch avg loss 0.3786, total avg loss: 0.3441, batch size: 39
2021-08-25 03:41:17,126 INFO [train.py:450] Epoch 2, batch 4360, batch avg loss 0.3901, total avg loss: 0.3436, batch size: 41
2021-08-25 03:41:24,733 INFO [train.py:450] Epoch 2, batch 4370, batch avg loss 0.3729, total avg loss: 0.3448, batch size: 40
2021-08-25 03:41:32,454 INFO [train.py:450] Epoch 2, batch 4380, batch avg loss 0.3410, total avg loss: 0.3445, batch size: 42
2021-08-25 03:41:39,995 INFO [train.py:450] Epoch 2, batch 4390, batch avg loss 0.3203, total avg loss: 0.3445, batch size: 41
2021-08-25 03:41:47,877 INFO [train.py:450] Epoch 2, batch 4400, batch avg loss 0.4142, total avg loss: 0.3447, batch size: 45
2021-08-25 03:41:55,934 INFO [train.py:450] Epoch 2, batch 4410, batch avg loss 0.3246, total avg loss: 0.3345, batch size: 41
2021-08-25 03:42:03,450 INFO [train.py:450] Epoch 2, batch 4420, batch avg loss 0.4352, total avg loss: 0.3432, batch size: 39
2021-08-25 03:42:11,282 INFO [train.py:450] Epoch 2, batch 4430, batch avg loss 0.3828, total avg loss: 0.3426, batch size: 40
2021-08-25 03:42:19,407 INFO [train.py:450] Epoch 2, batch 4440, batch avg loss 0.3785, total avg loss: 0.3411, batch size: 42
2021-08-25 03:42:27,191 INFO [train.py:450] Epoch 2, batch 4450, batch avg loss 0.3071, total avg loss: 0.3372, batch size: 39
2021-08-25 03:42:35,432 INFO [train.py:450] Epoch 2, batch 4460, batch avg loss 0.3958, total avg loss: 0.3386, batch size: 39
2021-08-25 03:42:43,534 INFO [train.py:450] Epoch 2, batch 4470, batch avg loss 0.4006, total avg loss: 0.3394, batch size: 40
2021-08-25 03:42:51,575 INFO [train.py:450] Epoch 2, batch 4480, batch avg loss 0.3732, total avg loss: 0.3417, batch size: 43
2021-08-25 03:42:59,697 INFO [train.py:450] Epoch 2, batch 4490, batch avg loss 0.3302, total avg loss: 0.3427, batch size: 45
2021-08-25 03:43:07,831 INFO [train.py:450] Epoch 2, batch 4500, batch avg loss 0.4090, total avg loss: 0.3434, batch size: 41
2021-08-25 03:43:15,681 INFO [train.py:450] Epoch 2, batch 4510, batch avg loss 0.3332, total avg loss: 0.3440, batch size: 39
2021-08-25 03:43:23,571 INFO [train.py:450] Epoch 2, batch 4520, batch avg loss 0.3926, total avg loss: 0.3437, batch size: 41
2021-08-25 03:43:32,862 INFO [train.py:450] Epoch 2, batch 4530, batch avg loss 0.3809, total avg loss: 0.3447, batch size: 43
2021-08-25 03:43:42,760 INFO [train.py:450] Epoch 2, batch 4540, batch avg loss 0.3863, total avg loss: 0.3450, batch size: 41
2021-08-25 03:43:51,263 INFO [train.py:450] Epoch 2, batch 4550, batch avg loss 0.3523, total avg loss: 0.3451, batch size: 37
2021-08-25 03:43:59,300 INFO [train.py:450] Epoch 2, batch 4560, batch avg loss 0.3376, total avg loss: 0.3452, batch size: 40
2021-08-25 03:44:06,595 INFO [train.py:450] Epoch 2, batch 4570, batch avg loss 0.3214, total avg loss: 0.3454, batch size: 41
2021-08-25 03:44:14,432 INFO [train.py:450] Epoch 2, batch 4580, batch avg loss 0.4607, total avg loss: 0.3464, batch size: 40
2021-08-25 03:44:21,902 INFO [train.py:450] Epoch 2, batch 4590, batch avg loss 0.3293, total avg loss: 0.3459, batch size: 37
2021-08-25 03:44:29,115 INFO [train.py:450] Epoch 2, batch 4600, batch avg loss 0.3454, total avg loss: 0.3455, batch size: 38
2021-08-25 03:44:36,556 INFO [train.py:450] Epoch 2, batch 4610, batch avg loss 0.3545, total avg loss: 0.3284, batch size: 37
2021-08-25 03:44:44,420 INFO [train.py:450] Epoch 2, batch 4620, batch avg loss 0.4239, total avg loss: 0.3335, batch size: 39
2021-08-25 03:44:52,281 INFO [train.py:450] Epoch 2, batch 4630, batch avg loss 0.3357, total avg loss: 0.3359, batch size: 41
2021-08-25 03:44:59,984 INFO [train.py:450] Epoch 2, batch 4640, batch avg loss 0.3009, total avg loss: 0.3351, batch size: 43
2021-08-25 03:45:07,335 INFO [train.py:450] Epoch 2, batch 4650, batch avg loss 0.3394, total avg loss: 0.3365, batch size: 37
2021-08-25 03:45:14,936 INFO [train.py:450] Epoch 2, batch 4660, batch avg loss 0.3161, total avg loss: 0.3393, batch size: 38
2021-08-25 03:45:22,588 INFO [train.py:450] Epoch 2, batch 4670, batch avg loss 0.3140, total avg loss: 0.3405, batch size: 41
2021-08-25 03:45:30,332 INFO [train.py:450] Epoch 2, batch 4680, batch avg loss 0.3642, total avg loss: 0.3411, batch size: 41
2021-08-25 03:45:38,277 INFO [train.py:450] Epoch 2, batch 4690, batch avg loss 0.3636, total avg loss: 0.3402, batch size: 41
2021-08-25 03:45:46,291 INFO [train.py:450] Epoch 2, batch 4700, batch avg loss 0.3314, total avg loss: 0.3402, batch size: 40
2021-08-25 03:45:53,667 INFO [train.py:450] Epoch 2, batch 4710, batch avg loss 0.3265, total avg loss: 0.3397, batch size: 39
2021-08-25 03:46:01,560 INFO [train.py:450] Epoch 2, batch 4720, batch avg loss 0.3578, total avg loss: 0.3399, batch size: 38
2021-08-25 03:46:09,911 INFO [train.py:450] Epoch 2, batch 4730, batch avg loss 0.3118, total avg loss: 0.3402, batch size: 42
2021-08-25 03:46:17,598 INFO [train.py:450] Epoch 2, batch 4740, batch avg loss 0.3934, total avg loss: 0.3409, batch size: 40
2021-08-25 03:46:25,979 INFO [train.py:450] Epoch 2, batch 4750, batch avg loss 0.3782, total avg loss: 0.3398, batch size: 40
2021-08-25 03:46:33,240 INFO [train.py:450] Epoch 2, batch 4760, batch avg loss 0.3524, total avg loss: 0.3397, batch size: 39
2021-08-25 03:46:40,566 INFO [train.py:450] Epoch 2, batch 4770, batch avg loss 0.3727, total avg loss: 0.3409, batch size: 36
2021-08-25 03:46:48,253 INFO [train.py:450] Epoch 2, batch 4780, batch avg loss 0.3793, total avg loss: 0.3405, batch size: 42
2021-08-25 03:46:56,066 INFO [train.py:450] Epoch 2, batch 4790, batch avg loss 0.3653, total avg loss: 0.3406, batch size: 43
2021-08-25 03:47:03,460 INFO [train.py:450] Epoch 2, batch 4800, batch avg loss 0.3495, total avg loss: 0.3403, batch size: 38
2021-08-25 03:47:11,233 INFO [train.py:450] Epoch 2, batch 4810, batch avg loss 0.3579, total avg loss: 0.3472, batch size: 38
2021-08-25 03:47:18,692 INFO [train.py:450] Epoch 2, batch 4820, batch avg loss 0.3060, total avg loss: 0.3440, batch size: 40
2021-08-25 03:47:26,869 INFO [train.py:450] Epoch 2, batch 4830, batch avg loss 0.3310, total avg loss: 0.3401, batch size: 41
2021-08-25 03:47:34,802 INFO [train.py:450] Epoch 2, batch 4840, batch avg loss 0.3804, total avg loss: 0.3412, batch size: 41
2021-08-25 03:47:42,732 INFO [train.py:450] Epoch 2, batch 4850, batch avg loss 0.3259, total avg loss: 0.3388, batch size: 43
2021-08-25 03:47:50,109 INFO [train.py:450] Epoch 2, batch 4860, batch avg loss 0.3801, total avg loss: 0.3403, batch size: 41
2021-08-25 03:47:57,353 INFO [train.py:450] Epoch 2, batch 4870, batch avg loss 0.3823, total avg loss: 0.3414, batch size: 41
2021-08-25 03:48:07,690 INFO [train.py:450] Epoch 2, batch 4880, batch avg loss 0.3153, total avg loss: 0.3403, batch size: 46
2021-08-25 03:48:17,458 INFO [train.py:450] Epoch 2, batch 4890, batch avg loss 0.3712, total avg loss: 0.3411, batch size: 40
2021-08-25 03:48:25,255 INFO [train.py:450] Epoch 2, batch 4900, batch avg loss 0.3378, total avg loss: 0.3415, batch size: 40
2021-08-25 03:48:32,349 INFO [train.py:450] Epoch 2, batch 4910, batch avg loss 0.3481, total avg loss: 0.3430, batch size: 39
2021-08-25 03:48:40,782 INFO [train.py:450] Epoch 2, batch 4920, batch avg loss 0.3549, total avg loss: 0.3413, batch size: 45
2021-08-25 03:48:48,332 INFO [train.py:450] Epoch 2, batch 4930, batch avg loss 0.3394, total avg loss: 0.3428, batch size: 39
2021-08-25 03:48:56,303 INFO [train.py:450] Epoch 2, batch 4940, batch avg loss 0.3452, total avg loss: 0.3427, batch size: 42
2021-08-25 03:49:03,861 INFO [train.py:450] Epoch 2, batch 4950, batch avg loss 0.3710, total avg loss: 0.3437, batch size: 40
2021-08-25 03:49:11,498 INFO [train.py:450] Epoch 2, batch 4960, batch avg loss 0.3665, total avg loss: 0.3446, batch size: 40
2021-08-25 03:49:19,925 INFO [train.py:450] Epoch 2, batch 4970, batch avg loss 0.3156, total avg loss: 0.3446, batch size: 39
2021-08-25 03:49:27,349 INFO [train.py:450] Epoch 2, batch 4980, batch avg loss 0.3114, total avg loss: 0.3450, batch size: 42
2021-08-25 03:49:35,097 INFO [train.py:450] Epoch 2, batch 4990, batch avg loss 0.3791, total avg loss: 0.3455, batch size: 41
2021-08-25 03:49:42,710 INFO [train.py:450] Epoch 2, batch 5000, batch avg loss 0.3598, total avg loss: 0.3465, batch size: 39
2021-08-25 03:50:23,122 INFO [train.py:482] Epoch 2, valid loss 0.2557, best valid loss: 0.2442 best valid epoch: 2
2021-08-25 03:50:29,054 INFO [train.py:450] Epoch 2, batch 5010, batch avg loss 0.3539, total avg loss: 0.3563, batch size: 37
2021-08-25 03:50:36,480 INFO [train.py:450] Epoch 2, batch 5020, batch avg loss 0.3274, total avg loss: 0.3590, batch size: 40
2021-08-25 03:50:44,314 INFO [train.py:450] Epoch 2, batch 5030, batch avg loss 0.3752, total avg loss: 0.3599, batch size: 43
2021-08-25 03:50:51,596 INFO [train.py:450] Epoch 2, batch 5040, batch avg loss 0.3395, total avg loss: 0.3617, batch size: 39
2021-08-25 03:50:59,071 INFO [train.py:450] Epoch 2, batch 5050, batch avg loss 0.3828, total avg loss: 0.3622, batch size: 42
2021-08-25 03:51:06,357 INFO [train.py:450] Epoch 2, batch 5060, batch avg loss 0.3324, total avg loss: 0.3569, batch size: 40
2021-08-25 03:51:13,749 INFO [train.py:450] Epoch 2, batch 5070, batch avg loss 0.3178, total avg loss: 0.3531, batch size: 36
2021-08-25 03:51:21,064 INFO [train.py:450] Epoch 2, batch 5080, batch avg loss 0.2805, total avg loss: 0.3494, batch size: 38
2021-08-25 03:51:28,875 INFO [train.py:450] Epoch 2, batch 5090, batch avg loss 0.2952, total avg loss: 0.3499, batch size: 36
2021-08-25 03:51:36,508 INFO [train.py:450] Epoch 2, batch 5100, batch avg loss 0.3624, total avg loss: 0.3508, batch size: 42
2021-08-25 03:51:44,297 INFO [train.py:450] Epoch 2, batch 5110, batch avg loss 0.3743, total avg loss: 0.3515, batch size: 41
2021-08-25 03:51:53,141 INFO [train.py:450] Epoch 2, batch 5120, batch avg loss 0.3006, total avg loss: 0.3503, batch size: 40
2021-08-25 03:52:00,735 INFO [train.py:450] Epoch 2, batch 5130, batch avg loss 0.3417, total avg loss: 0.3489, batch size: 40
2021-08-25 03:52:11,990 INFO [train.py:450] Epoch 2, batch 5140, batch avg loss 0.3542, total avg loss: 0.3488, batch size: 43
2021-08-25 03:52:19,042 INFO [train.py:450] Epoch 2, batch 5150, batch avg loss 0.3939, total avg loss: 0.3501, batch size: 38
2021-08-25 03:52:26,464 INFO [train.py:450] Epoch 2, batch 5160, batch avg loss 0.3745, total avg loss: 0.3516, batch size: 42
2021-08-25 03:52:33,576 INFO [train.py:450] Epoch 2, batch 5170, batch avg loss 0.3500, total avg loss: 0.3533, batch size: 39
2021-08-25 03:52:40,806 INFO [train.py:450] Epoch 2, batch 5180, batch avg loss 0.3395, total avg loss: 0.3535, batch size: 41
2021-08-25 03:52:48,073 INFO [train.py:450] Epoch 2, batch 5190, batch avg loss 0.3189, total avg loss: 0.3539, batch size: 38
2021-08-25 03:52:55,669 INFO [train.py:450] Epoch 2, batch 5200, batch avg loss 0.3195, total avg loss: 0.3532, batch size: 39
2021-08-25 03:53:02,905 INFO [train.py:450] Epoch 2, batch 5210, batch avg loss 0.2944, total avg loss: 0.3499, batch size: 37
2021-08-25 03:53:10,452 INFO [train.py:450] Epoch 2, batch 5220, batch avg loss 0.3829, total avg loss: 0.3647, batch size: 38
2021-08-25 03:53:17,752 INFO [train.py:450] Epoch 2, batch 5230, batch avg loss 0.3179, total avg loss: 0.3613, batch size: 37
2021-08-25 03:53:25,672 INFO [train.py:450] Epoch 2, batch 5240, batch avg loss 0.3288, total avg loss: 0.3564, batch size: 38
2021-08-25 03:53:32,763 INFO [train.py:450] Epoch 2, batch 5250, batch avg loss 0.2782, total avg loss: 0.3547, batch size: 38
2021-08-25 03:53:39,856 INFO [train.py:450] Epoch 2, batch 5260, batch avg loss 0.3587, total avg loss: 0.3537, batch size: 38
2021-08-25 03:53:47,776 INFO [train.py:450] Epoch 2, batch 5270, batch avg loss 0.3378, total avg loss: 0.3516, batch size: 39
2021-08-25 03:53:55,154 INFO [train.py:450] Epoch 2, batch 5280, batch avg loss 0.3305, total avg loss: 0.3515, batch size: 39
2021-08-25 03:54:02,059 INFO [train.py:450] Epoch 2, batch 5290, batch avg loss 0.3721, total avg loss: 0.3521, batch size: 40
2021-08-25 03:54:09,187 INFO [train.py:450] Epoch 2, batch 5300, batch avg loss 0.3146, total avg loss: 0.3504, batch size: 40
2021-08-25 03:54:16,840 INFO [train.py:450] Epoch 2, batch 5310, batch avg loss 0.3508, total avg loss: 0.3497, batch size: 42
2021-08-25 03:54:23,682 INFO [train.py:450] Epoch 2, batch 5320, batch avg loss 0.2947, total avg loss: 0.3496, batch size: 39
2021-08-25 03:54:31,146 INFO [train.py:450] Epoch 2, batch 5330, batch avg loss 0.3606, total avg loss: 0.3510, batch size: 40
2021-08-25 03:54:38,650 INFO [train.py:450] Epoch 2, batch 5340, batch avg loss 0.3423, total avg loss: 0.3513, batch size: 42
2021-08-25 03:54:46,657 INFO [train.py:450] Epoch 2, batch 5350, batch avg loss 0.3275, total avg loss: 0.3524, batch size: 43
2021-08-25 03:54:53,437 INFO [train.py:450] Epoch 2, batch 5360, batch avg loss 0.3252, total avg loss: 0.3521, batch size: 38
2021-08-25 03:55:01,025 INFO [train.py:450] Epoch 2, batch 5370, batch avg loss 0.3638, total avg loss: 0.3510, batch size: 39
2021-08-25 03:55:08,380 INFO [train.py:450] Epoch 2, batch 5380, batch avg loss 0.3411, total avg loss: 0.3509, batch size: 39
2021-08-25 03:55:15,939 INFO [train.py:450] Epoch 2, batch 5390, batch avg loss 0.3382, total avg loss: 0.3500, batch size: 42
2021-08-25 03:55:23,876 INFO [train.py:450] Epoch 2, batch 5400, batch avg loss 0.3190, total avg loss: 0.3500, batch size: 39
2021-08-25 03:55:31,400 INFO [train.py:450] Epoch 2, batch 5410, batch avg loss 0.3368, total avg loss: 0.3367, batch size: 39
2021-08-25 03:55:38,528 INFO [train.py:450] Epoch 2, batch 5420, batch avg loss 0.3358, total avg loss: 0.3410, batch size: 42
2021-08-25 03:55:46,369 INFO [train.py:450] Epoch 2, batch 5430, batch avg loss 0.4055, total avg loss: 0.3428, batch size: 41
2021-08-25 03:55:53,419 INFO [train.py:450] Epoch 2, batch 5440, batch avg loss 0.3662, total avg loss: 0.3443, batch size: 37
2021-08-25 03:56:02,110 INFO [train.py:450] Epoch 2, batch 5450, batch avg loss 0.3279, total avg loss: 0.3441, batch size: 38
2021-08-25 03:56:09,252 INFO [train.py:450] Epoch 2, batch 5460, batch avg loss 0.3242, total avg loss: 0.3417, batch size: 43
2021-08-25 03:56:17,170 INFO [train.py:450] Epoch 2, batch 5470, batch avg loss 0.3475, total avg loss: 0.3433, batch size: 42
2021-08-25 03:56:26,429 INFO [train.py:450] Epoch 2, batch 5480, batch avg loss 0.3495, total avg loss: 0.3430, batch size: 39
2021-08-25 03:56:36,763 INFO [train.py:450] Epoch 2, batch 5490, batch avg loss 0.2960, total avg loss: 0.3430, batch size: 40
2021-08-25 03:56:45,832 INFO [train.py:450] Epoch 2, batch 5500, batch avg loss 0.3159, total avg loss: 0.3427, batch size: 40
2021-08-25 03:56:53,215 INFO [train.py:450] Epoch 2, batch 5510, batch avg loss 0.3695, total avg loss: 0.3423, batch size: 40
2021-08-25 03:57:00,814 INFO [train.py:450] Epoch 2, batch 5520, batch avg loss 0.3537, total avg loss: 0.3423, batch size: 43
2021-08-25 03:57:08,030 INFO [train.py:450] Epoch 2, batch 5530, batch avg loss 0.3021, total avg loss: 0.3424, batch size: 40
2021-08-25 03:57:15,437 INFO [train.py:450] Epoch 2, batch 5540, batch avg loss 0.3612, total avg loss: 0.3427, batch size: 43
2021-08-25 03:57:23,126 INFO [train.py:450] Epoch 2, batch 5550, batch avg loss 0.3097, total avg loss: 0.3441, batch size: 37
2021-08-25 03:57:30,740 INFO [train.py:450] Epoch 2, batch 5560, batch avg loss 0.3319, total avg loss: 0.3452, batch size: 40
2021-08-25 03:57:38,263 INFO [train.py:450] Epoch 2, batch 5570, batch avg loss 0.3554, total avg loss: 0.3453, batch size: 38
2021-08-25 03:57:45,842 INFO [train.py:450] Epoch 2, batch 5580, batch avg loss 0.3604, total avg loss: 0.3455, batch size: 42
2021-08-25 03:57:54,300 INFO [train.py:450] Epoch 2, batch 5590, batch avg loss 0.3834, total avg loss: 0.3462, batch size: 38
2021-08-25 03:58:01,671 INFO [train.py:450] Epoch 2, batch 5600, batch avg loss 0.3531, total avg loss: 0.3461, batch size: 40
2021-08-25 03:58:08,932 INFO [train.py:450] Epoch 2, batch 5610, batch avg loss 0.3304, total avg loss: 0.3372, batch size: 39
2021-08-25 03:58:16,473 INFO [train.py:450] Epoch 2, batch 5620, batch avg loss 0.2694, total avg loss: 0.3388, batch size: 42
2021-08-25 03:58:23,120 INFO [train.py:450] Epoch 2, batch 5630, batch avg loss 0.3689, total avg loss: 0.3388, batch size: 39
2021-08-25 03:58:30,707 INFO [train.py:450] Epoch 2, batch 5640, batch avg loss 0.3264, total avg loss: 0.3396, batch size: 36
2021-08-25 03:58:37,891 INFO [train.py:450] Epoch 2, batch 5650, batch avg loss 0.3262, total avg loss: 0.3394, batch size: 40
2021-08-25 03:58:45,646 INFO [train.py:450] Epoch 2, batch 5660, batch avg loss 0.3274, total avg loss: 0.3397, batch size: 41
2021-08-25 03:58:52,754 INFO [train.py:450] Epoch 2, batch 5670, batch avg loss 0.3283, total avg loss: 0.3400, batch size: 39
2021-08-25 03:59:00,196 INFO [train.py:450] Epoch 2, batch 5680, batch avg loss 0.3397, total avg loss: 0.3402, batch size: 41
2021-08-25 03:59:07,843 INFO [train.py:450] Epoch 2, batch 5690, batch avg loss 0.3670, total avg loss: 0.3401, batch size: 40
2021-08-25 03:59:15,011 INFO [train.py:450] Epoch 2, batch 5700, batch avg loss 0.3894, total avg loss: 0.3400, batch size: 40
2021-08-25 03:59:21,920 INFO [train.py:450] Epoch 2, batch 5710, batch avg loss 0.4211, total avg loss: 0.3400, batch size: 36
2021-08-25 03:59:29,631 INFO [train.py:450] Epoch 2, batch 5720, batch avg loss 0.3580, total avg loss: 0.3422, batch size: 43
2021-08-25 03:59:36,856 INFO [train.py:450] Epoch 2, batch 5730, batch avg loss 0.3405, total avg loss: 0.3436, batch size: 38
2021-08-25 03:59:45,195 INFO [train.py:450] Epoch 2, batch 5740, batch avg loss 0.3376, total avg loss: 0.3432, batch size: 41
2021-08-25 03:59:52,557 INFO [train.py:450] Epoch 2, batch 5750, batch avg loss 0.3333, total avg loss: 0.3438, batch size: 38
2021-08-25 04:00:00,076 INFO [train.py:450] Epoch 2, batch 5760, batch avg loss 0.3637, total avg loss: 0.3436, batch size: 41
2021-08-25 04:00:07,737 INFO [train.py:450] Epoch 2, batch 5770, batch avg loss 0.3260, total avg loss: 0.3428, batch size: 44
2021-08-25 04:00:15,295 INFO [train.py:450] Epoch 2, batch 5780, batch avg loss 0.3931, total avg loss: 0.3431, batch size: 40
2021-08-25 04:00:23,619 INFO [train.py:450] Epoch 2, batch 5790, batch avg loss 0.3593, total avg loss: 0.3429, batch size: 41
2021-08-25 04:00:32,185 INFO [train.py:450] Epoch 2, batch 5800, batch avg loss 0.3621, total avg loss: 0.3431, batch size: 42
2021-08-25 04:00:41,388 INFO [train.py:450] Epoch 2, batch 5810, batch avg loss 0.3468, total avg loss: 0.3494, batch size: 40
2021-08-25 04:00:49,070 INFO [train.py:450] Epoch 2, batch 5820, batch avg loss 0.3884, total avg loss: 0.3419, batch size: 41
2021-08-25 04:00:56,394 INFO [train.py:450] Epoch 2, batch 5830, batch avg loss 0.2900, total avg loss: 0.3407, batch size: 42
2021-08-25 04:01:03,447 INFO [train.py:450] Epoch 2, batch 5840, batch avg loss 0.3006, total avg loss: 0.3422, batch size: 40
2021-08-25 04:01:10,698 INFO [train.py:450] Epoch 2, batch 5850, batch avg loss 0.3507, total avg loss: 0.3455, batch size: 35
2021-08-25 04:01:17,903 INFO [train.py:450] Epoch 2, batch 5860, batch avg loss 0.3405, total avg loss: 0.3445, batch size: 38
2021-08-25 04:01:25,154 INFO [train.py:450] Epoch 2, batch 5870, batch avg loss 0.3227, total avg loss: 0.3425, batch size: 39
2021-08-25 04:01:32,298 INFO [train.py:450] Epoch 2, batch 5880, batch avg loss 0.3998, total avg loss: 0.3449, batch size: 39
2021-08-25 04:01:39,852 INFO [train.py:450] Epoch 2, batch 5890, batch avg loss 0.2993, total avg loss: 0.3464, batch size: 40
2021-08-25 04:01:48,142 INFO [train.py:450] Epoch 2, batch 5900, batch avg loss 0.3336, total avg loss: 0.3472, batch size: 43
2021-08-25 04:01:55,664 INFO [train.py:450] Epoch 2, batch 5910, batch avg loss 0.3008, total avg loss: 0.3468, batch size: 43
2021-08-25 04:02:03,088 INFO [train.py:450] Epoch 2, batch 5920, batch avg loss 0.2851, total avg loss: 0.3460, batch size: 41
2021-08-25 04:02:10,028 INFO [train.py:450] Epoch 2, batch 5930, batch avg loss 0.3218, total avg loss: 0.3451, batch size: 39
2021-08-25 04:02:17,333 INFO [train.py:450] Epoch 2, batch 5940, batch avg loss 0.3267, total avg loss: 0.3443, batch size: 37
2021-08-25 04:02:25,072 INFO [train.py:450] Epoch 2, batch 5950, batch avg loss 0.3162, total avg loss: 0.3426, batch size: 41
2021-08-25 04:02:32,146 INFO [train.py:450] Epoch 2, batch 5960, batch avg loss 0.3397, total avg loss: 0.3436, batch size: 40
2021-08-25 04:02:40,073 INFO [train.py:450] Epoch 2, batch 5970, batch avg loss 0.3451, total avg loss: 0.3426, batch size: 40
2021-08-25 04:02:47,596 INFO [train.py:450] Epoch 2, batch 5980, batch avg loss 0.3339, total avg loss: 0.3422, batch size: 42
2021-08-25 04:02:55,309 INFO [train.py:450] Epoch 2, batch 5990, batch avg loss 0.4141, total avg loss: 0.3432, batch size: 40
2021-08-25 04:03:02,671 INFO [train.py:450] Epoch 2, batch 6000, batch avg loss 0.3893, total avg loss: 0.3430, batch size: 36
2021-08-25 04:03:41,819 INFO [train.py:482] Epoch 2, valid loss 0.2464, best valid loss: 0.2442 best valid epoch: 2
2021-08-25 04:03:47,783 INFO [train.py:450] Epoch 2, batch 6010, batch avg loss 0.3252, total avg loss: 0.3298, batch size: 40
2021-08-25 04:03:54,564 INFO [train.py:450] Epoch 2, batch 6020, batch avg loss 0.3848, total avg loss: 0.3362, batch size: 42
2021-08-25 04:04:01,610 INFO [train.py:450] Epoch 2, batch 6030, batch avg loss 0.3196, total avg loss: 0.3412, batch size: 38
2021-08-25 04:04:08,891 INFO [train.py:450] Epoch 2, batch 6040, batch avg loss 0.3057, total avg loss: 0.3430, batch size: 37
2021-08-25 04:04:17,719 INFO [train.py:450] Epoch 2, batch 6050, batch avg loss 0.4072, total avg loss: 0.3402, batch size: 40
2021-08-25 04:04:25,113 INFO [train.py:450] Epoch 2, batch 6060, batch avg loss 0.3699, total avg loss: 0.3411, batch size: 40
2021-08-25 04:04:35,096 INFO [train.py:450] Epoch 2, batch 6070, batch avg loss 0.3511, total avg loss: 0.3431, batch size: 39
2021-08-25 04:04:42,315 INFO [train.py:450] Epoch 2, batch 6080, batch avg loss 0.3398, total avg loss: 0.3446, batch size: 41
2021-08-25 04:04:49,499 INFO [train.py:450] Epoch 2, batch 6090, batch avg loss 0.3212, total avg loss: 0.3441, batch size: 42
2021-08-25 04:04:56,959 INFO [train.py:450] Epoch 2, batch 6100, batch avg loss 0.3332, total avg loss: 0.3426, batch size: 39
2021-08-25 04:05:04,289 INFO [train.py:450] Epoch 2, batch 6110, batch avg loss 0.3429, total avg loss: 0.3422, batch size: 41
2021-08-25 04:05:11,989 INFO [train.py:450] Epoch 2, batch 6120, batch avg loss 0.3276, total avg loss: 0.3424, batch size: 42
2021-08-25 04:05:18,912 INFO [train.py:450] Epoch 2, batch 6130, batch avg loss 0.3572, total avg loss: 0.3442, batch size: 38
2021-08-25 04:05:26,425 INFO [train.py:450] Epoch 2, batch 6140, batch avg loss 0.4146, total avg loss: 0.3435, batch size: 42
2021-08-25 04:05:33,450 INFO [train.py:450] Epoch 2, batch 6150, batch avg loss 0.3277, total avg loss: 0.3443, batch size: 40
2021-08-25 04:05:40,255 INFO [train.py:450] Epoch 2, batch 6160, batch avg loss 0.3094, total avg loss: 0.3433, batch size: 40
2021-08-25 04:05:47,300 INFO [train.py:450] Epoch 2, batch 6170, batch avg loss 0.3359, total avg loss: 0.3429, batch size: 37
2021-08-25 04:05:54,388 INFO [train.py:450] Epoch 2, batch 6180, batch avg loss 0.3222, total avg loss: 0.3430, batch size: 41
2021-08-25 04:06:01,654 INFO [train.py:450] Epoch 2, batch 6190, batch avg loss 0.3380, total avg loss: 0.3431, batch size: 43
2021-08-25 04:06:08,928 INFO [train.py:450] Epoch 2, batch 6200, batch avg loss 0.3254, total avg loss: 0.3430, batch size: 37
2021-08-25 04:06:16,145 INFO [train.py:450] Epoch 2, batch 6210, batch avg loss 0.3360, total avg loss: 0.3524, batch size: 36
2021-08-25 04:06:23,716 INFO [train.py:450] Epoch 2, batch 6220, batch avg loss 0.3317, total avg loss: 0.3421, batch size: 39
2021-08-25 04:06:30,776 INFO [train.py:450] Epoch 2, batch 6230, batch avg loss 0.3114, total avg loss: 0.3422, batch size: 40
2021-08-25 04:06:37,708 INFO [train.py:450] Epoch 2, batch 6240, batch avg loss 0.3582, total avg loss: 0.3428, batch size: 39
2021-08-25 04:06:44,657 INFO [train.py:450] Epoch 2, batch 6250, batch avg loss 0.3481, total avg loss: 0.3445, batch size: 41
2021-08-25 04:06:51,560 INFO [train.py:450] Epoch 2, batch 6260, batch avg loss 0.3194, total avg loss: 0.3438, batch size: 41
2021-08-25 04:06:58,825 INFO [train.py:450] Epoch 2, batch 6270, batch avg loss 0.3304, total avg loss: 0.3456, batch size: 37
2021-08-25 04:07:06,069 INFO [train.py:450] Epoch 2, batch 6280, batch avg loss 0.3355, total avg loss: 0.3445, batch size: 39
2021-08-25 04:07:13,407 INFO [train.py:450] Epoch 2, batch 6290, batch avg loss 0.3579, total avg loss: 0.3447, batch size: 41
2021-08-25 04:07:20,845 INFO [train.py:450] Epoch 2, batch 6300, batch avg loss 0.3655, total avg loss: 0.3459, batch size: 39
2021-08-25 04:07:27,547 INFO [train.py:450] Epoch 2, batch 6310, batch avg loss 0.3979, total avg loss: 0.3457, batch size: 40
2021-08-25 04:07:34,611 INFO [train.py:450] Epoch 2, batch 6320, batch avg loss 0.3260, total avg loss: 0.3456, batch size: 43
2021-08-25 04:07:42,062 INFO [train.py:450] Epoch 2, batch 6330, batch avg loss 0.3605, total avg loss: 0.3461, batch size: 39
2021-08-25 04:07:49,141 INFO [train.py:450] Epoch 2, batch 6340, batch avg loss 0.3603, total avg loss: 0.3457, batch size: 37
2021-08-25 04:07:56,432 INFO [train.py:450] Epoch 2, batch 6350, batch avg loss 0.3477, total avg loss: 0.3451, batch size: 41
2021-08-25 04:08:03,766 INFO [train.py:450] Epoch 2, batch 6360, batch avg loss 0.3661, total avg loss: 0.3454, batch size: 41
2021-08-25 04:08:10,655 INFO [train.py:450] Epoch 2, batch 6370, batch avg loss 0.3195, total avg loss: 0.3455, batch size: 37
2021-08-25 04:08:17,146 INFO [train.py:450] Epoch 2, batch 6380, batch avg loss 0.3038, total avg loss: 0.3443, batch size: 41
2021-08-25 04:08:25,777 INFO [train.py:450] Epoch 2, batch 6390, batch avg loss 0.3422, total avg loss: 0.3443, batch size: 41
2021-08-25 04:08:34,299 INFO [train.py:450] Epoch 2, batch 6400, batch avg loss 0.3778, total avg loss: 0.3442, batch size: 44
2021-08-25 04:08:42,626 INFO [train.py:450] Epoch 2, batch 6410, batch avg loss 0.3275, total avg loss: 0.3363, batch size: 41
2021-08-25 04:08:49,454 INFO [train.py:450] Epoch 2, batch 6420, batch avg loss 0.3015, total avg loss: 0.3406, batch size: 39
2021-08-25 04:08:56,648 INFO [train.py:450] Epoch 2, batch 6430, batch avg loss 0.3106, total avg loss: 0.3335, batch size: 39
2021-08-25 04:09:04,342 INFO [train.py:450] Epoch 2, batch 6440, batch avg loss 0.3671, total avg loss: 0.3336, batch size: 41
2021-08-25 04:09:11,440 INFO [train.py:450] Epoch 2, batch 6450, batch avg loss 0.3275, total avg loss: 0.3328, batch size: 39
2021-08-25 04:09:18,907 INFO [train.py:450] Epoch 2, batch 6460, batch avg loss 0.3048, total avg loss: 0.3329, batch size: 40
2021-08-25 04:09:25,521 INFO [train.py:450] Epoch 2, batch 6470, batch avg loss 0.3028, total avg loss: 0.3343, batch size: 37
2021-08-25 04:09:32,559 INFO [train.py:450] Epoch 2, batch 6480, batch avg loss 0.3767, total avg loss: 0.3346, batch size: 41
2021-08-25 04:09:39,742 INFO [train.py:450] Epoch 2, batch 6490, batch avg loss 0.3445, total avg loss: 0.3366, batch size: 40
2021-08-25 04:09:46,384 INFO [train.py:450] Epoch 2, batch 6500, batch avg loss 0.3157, total avg loss: 0.3378, batch size: 36
2021-08-25 04:09:53,447 INFO [train.py:450] Epoch 2, batch 6510, batch avg loss 0.3383, total avg loss: 0.3404, batch size: 38
2021-08-25 04:10:00,395 INFO [train.py:450] Epoch 2, batch 6520, batch avg loss 0.3338, total avg loss: 0.3401, batch size: 39
2021-08-25 04:10:07,195 INFO [train.py:450] Epoch 2, batch 6530, batch avg loss 0.3897, total avg loss: 0.3406, batch size: 38
2021-08-25 04:10:14,583 INFO [train.py:450] Epoch 2, batch 6540, batch avg loss 0.3968, total avg loss: 0.3415, batch size: 43
2021-08-25 04:10:19,873 WARNING [cut.py:1694] To perform mix, energy must be non-zero and non-negative (got 0.0).  MonoCut with id "87727da9-5c00-7686-6331-9e1ff2252f38" will not be mixed in.
2021-08-25 04:10:21,499 INFO [train.py:450] Epoch 2, batch 6550, batch avg loss 0.3212, total avg loss: 0.3421, batch size: 39
2021-08-25 04:10:29,004 INFO [train.py:450] Epoch 2, batch 6560, batch avg loss 0.3654, total avg loss: 0.3425, batch size: 44
2021-08-25 04:10:36,176 INFO [train.py:450] Epoch 2, batch 6570, batch avg loss 0.3530, total avg loss: 0.3407, batch size: 40
2021-08-25 04:10:43,105 INFO [train.py:450] Epoch 2, batch 6580, batch avg loss 0.3011, total avg loss: 0.3411, batch size: 39
2021-08-25 04:10:49,814 INFO [train.py:450] Epoch 2, batch 6590, batch avg loss 0.3818, total avg loss: 0.3402, batch size: 40
2021-08-25 04:10:56,697 INFO [train.py:450] Epoch 2, batch 6600, batch avg loss 0.2895, total avg loss: 0.3399, batch size: 38
2021-08-25 04:11:04,534 INFO [train.py:450] Epoch 2, batch 6610, batch avg loss 0.3401, total avg loss: 0.3328, batch size: 40
2021-08-25 04:11:11,525 INFO [train.py:450] Epoch 2, batch 6620, batch avg loss 0.2720, total avg loss: 0.3345, batch size: 39
2021-08-25 04:11:18,703 INFO [train.py:450] Epoch 2, batch 6630, batch avg loss 0.3268, total avg loss: 0.3419, batch size: 41
2021-08-25 04:11:25,711 INFO [train.py:450] Epoch 2, batch 6640, batch avg loss 0.3303, total avg loss: 0.3391, batch size: 40
2021-08-25 04:11:42,156 INFO [train.py:450] Epoch 2, batch 6650, batch avg loss 0.3984, total avg loss: 0.3384, batch size: 43
2021-08-25 04:11:49,235 INFO [train.py:450] Epoch 2, batch 6660, batch avg loss 0.3531, total avg loss: 0.3385, batch size: 40
2021-08-25 04:11:56,615 INFO [train.py:450] Epoch 2, batch 6670, batch avg loss 0.3726, total avg loss: 0.3397, batch size: 38
2021-08-25 04:12:04,010 INFO [train.py:450] Epoch 2, batch 6680, batch avg loss 0.2941, total avg loss: 0.3400, batch size: 44
2021-08-25 04:12:12,581 INFO [train.py:450] Epoch 2, batch 6690, batch avg loss 0.3396, total avg loss: 0.3415, batch size: 40
2021-08-25 04:12:20,212 INFO [train.py:450] Epoch 2, batch 6700, batch avg loss 0.3617, total avg loss: 0.3424, batch size: 39
2021-08-25 04:12:30,626 INFO [train.py:450] Epoch 2, batch 6710, batch avg loss 0.3374, total avg loss: 0.3431, batch size: 42
2021-08-25 04:12:38,045 INFO [train.py:450] Epoch 2, batch 6720, batch avg loss 0.3490, total avg loss: 0.3425, batch size: 37
2021-08-25 04:12:45,615 INFO [train.py:450] Epoch 2, batch 6730, batch avg loss 0.2964, total avg loss: 0.3423, batch size: 42
2021-08-25 04:12:53,197 INFO [train.py:450] Epoch 2, batch 6740, batch avg loss 0.3428, total avg loss: 0.3416, batch size: 45
2021-08-25 04:12:59,813 INFO [train.py:450] Epoch 2, batch 6750, batch avg loss 0.3553, total avg loss: 0.3416, batch size: 38
2021-08-25 04:13:07,047 INFO [train.py:450] Epoch 2, batch 6760, batch avg loss 0.3748, total avg loss: 0.3415, batch size: 42
2021-08-25 04:13:14,102 INFO [train.py:450] Epoch 2, batch 6770, batch avg loss 0.3377, total avg loss: 0.3418, batch size: 38
2021-08-25 04:13:21,478 INFO [train.py:450] Epoch 2, batch 6780, batch avg loss 0.3197, total avg loss: 0.3417, batch size: 36
2021-08-25 04:13:28,113 INFO [train.py:450] Epoch 2, batch 6790, batch avg loss 0.3612, total avg loss: 0.3416, batch size: 36
2021-08-25 04:13:35,176 INFO [train.py:450] Epoch 2, batch 6800, batch avg loss 0.3419, total avg loss: 0.3416, batch size: 39
2021-08-25 04:13:41,831 INFO [train.py:450] Epoch 2, batch 6810, batch avg loss 0.3662, total avg loss: 0.3298, batch size: 38
2021-08-25 04:13:48,171 WARNING [cut.py:1694] To perform mix, energy must be non-zero and non-negative (got 0.0).  MonoCut with id "80af686f-f8f7-b0a3-6975-f7817760a6da" will not be mixed in.
2021-08-25 04:13:49,278 INFO [train.py:450] Epoch 2, batch 6820, batch avg loss 0.3293, total avg loss: 0.3332, batch size: 42
2021-08-25 04:13:56,337 INFO [train.py:450] Epoch 2, batch 6830, batch avg loss 0.3171, total avg loss: 0.3409, batch size: 38
2021-08-25 04:14:03,689 INFO [train.py:450] Epoch 2, batch 6840, batch avg loss 0.3828, total avg loss: 0.3424, batch size: 41
2021-08-25 04:14:10,454 INFO [train.py:450] Epoch 2, batch 6850, batch avg loss 0.3649, total avg loss: 0.3405, batch size: 39
2021-08-25 04:14:17,548 INFO [train.py:450] Epoch 2, batch 6860, batch avg loss 0.3332, total avg loss: 0.3398, batch size: 41
2021-08-25 04:14:24,631 INFO [train.py:450] Epoch 2, batch 6870, batch avg loss 0.3466, total avg loss: 0.3398, batch size: 42
2021-08-25 04:14:32,244 INFO [train.py:450] Epoch 2, batch 6880, batch avg loss 0.3386, total avg loss: 0.3383, batch size: 39
2021-08-25 04:14:39,900 INFO [train.py:450] Epoch 2, batch 6890, batch avg loss 0.3451, total avg loss: 0.3405, batch size: 38
2021-08-25 04:14:46,960 INFO [train.py:450] Epoch 2, batch 6900, batch avg loss 0.3318, total avg loss: 0.3399, batch size: 36
2021-08-25 04:14:56,813 INFO [train.py:450] Epoch 2, batch 6910, batch avg loss 0.3306, total avg loss: 0.3403, batch size: 37
2021-08-25 04:15:03,765 INFO [train.py:450] Epoch 2, batch 6920, batch avg loss 0.4009, total avg loss: 0.3417, batch size: 38
2021-08-25 04:15:10,726 INFO [train.py:450] Epoch 2, batch 6930, batch avg loss 0.4860, total avg loss: 0.3460, batch size: 42
2021-08-25 04:15:17,901 INFO [train.py:450] Epoch 2, batch 6940, batch avg loss 0.7280, total avg loss: 0.3674, batch size: 41
2021-08-25 04:15:25,255 INFO [train.py:450] Epoch 2, batch 6950, batch avg loss 0.7100, total avg loss: 0.3944, batch size: 42
2021-08-25 04:15:32,114 WARNING [cut.py:1694] To perform mix, energy must be non-zero and non-negative (got 0.0).  MonoCut with id "23b92db5-39c6-d282-19e1-4724c50d425b" will not be mixed in.
2021-08-25 04:15:32,545 INFO [train.py:450] Epoch 2, batch 6960, batch avg loss 0.6905, total avg loss: 0.4131, batch size: 40
2021-08-25 04:15:39,809 INFO [train.py:450] Epoch 2, batch 6970, batch avg loss 0.6751, total avg loss: 0.4315, batch size: 36
2021-08-25 04:15:47,124 INFO [train.py:450] Epoch 2, batch 6980, batch avg loss 0.7048, total avg loss: 0.4459, batch size: 41
2021-08-25 04:15:54,443 INFO [train.py:450] Epoch 2, batch 6990, batch avg loss 0.5676, total avg loss: 0.4533, batch size: 42
2021-08-25 04:16:01,451 INFO [train.py:450] Epoch 2, batch 7000, batch avg loss 0.6358, total avg loss: 0.4606, batch size: 40
2021-08-25 04:16:41,016 INFO [train.py:482] Epoch 2, valid loss 0.5244, best valid loss: 0.2442 best valid epoch: 2
2021-08-25 04:16:46,824 INFO [train.py:450] Epoch 2, batch 7010, batch avg loss 0.5770, total avg loss: 0.5638, batch size: 38
2021-08-25 04:16:53,637 INFO [train.py:450] Epoch 2, batch 7020, batch avg loss 0.4746, total avg loss: 0.5261, batch size: 40
2021-08-25 04:17:00,637 INFO [train.py:450] Epoch 2, batch 7030, batch avg loss 0.3770, total avg loss: 0.4851, batch size: 40
2021-08-25 04:17:07,916 INFO [train.py:450] Epoch 2, batch 7040, batch avg loss 0.3833, total avg loss: 0.4676, batch size: 41
2021-08-25 04:17:15,272 INFO [train.py:450] Epoch 2, batch 7050, batch avg loss 0.4568, total avg loss: 0.4516, batch size: 40
2021-08-25 04:17:22,793 INFO [train.py:450] Epoch 2, batch 7060, batch avg loss 0.4297, total avg loss: 0.4392, batch size: 40
2021-08-25 04:17:29,871 INFO [train.py:450] Epoch 2, batch 7070, batch avg loss 0.3446, total avg loss: 0.4275, batch size: 39
2021-08-25 04:17:36,861 INFO [train.py:450] Epoch 2, batch 7080, batch avg loss 0.3330, total avg loss: 0.4168, batch size: 43
2021-08-25 04:17:44,078 INFO [train.py:450] Epoch 2, batch 7090, batch avg loss 0.3236, total avg loss: 0.4100, batch size: 40
2021-08-25 04:17:51,327 INFO [train.py:450] Epoch 2, batch 7100, batch avg loss 0.3971, total avg loss: 0.4062, batch size: 39
2021-08-25 04:17:57,825 INFO [train.py:450] Epoch 2, batch 7110, batch avg loss 0.3285, total avg loss: 0.4026, batch size: 38
2021-08-25 04:18:04,710 INFO [train.py:450] Epoch 2, batch 7120, batch avg loss 0.3347, total avg loss: 0.3980, batch size: 38
2021-08-25 04:18:11,677 INFO [train.py:450] Epoch 2, batch 7130, batch avg loss 0.3922, total avg loss: 0.3963, batch size: 39
2021-08-25 04:18:18,602 INFO [train.py:450] Epoch 2, batch 7140, batch avg loss 0.3957, total avg loss: 0.3950, batch size: 42
2021-08-25 04:18:25,321 INFO [train.py:450] Epoch 2, batch 7150, batch avg loss 0.4061, total avg loss: 0.3928, batch size: 38
2021-08-25 04:18:32,225 INFO [train.py:450] Epoch 2, batch 7160, batch avg loss 0.3863, total avg loss: 0.3907, batch size: 40
2021-08-25 04:18:39,024 INFO [train.py:450] Epoch 2, batch 7170, batch avg loss 0.3384, total avg loss: 0.3879, batch size: 42
2021-08-25 04:18:46,158 INFO [train.py:450] Epoch 2, batch 7180, batch avg loss 0.3698, total avg loss: 0.3859, batch size: 43
2021-08-25 04:18:53,360 INFO [train.py:450] Epoch 2, batch 7190, batch avg loss 0.3611, total avg loss: 0.3845, batch size: 36
2021-08-25 04:19:00,939 INFO [train.py:450] Epoch 2, batch 7200, batch avg loss 0.4834, total avg loss: 0.3827, batch size: 42
2021-08-25 04:19:08,217 INFO [train.py:450] Epoch 2, batch 7210, batch avg loss 0.3716, total avg loss: 0.3621, batch size: 42
2021-08-25 04:19:15,147 INFO [train.py:450] Epoch 2, batch 7220, batch avg loss 0.3290, total avg loss: 0.3590, batch size: 38
2021-08-25 04:19:22,326 INFO [train.py:450] Epoch 2, batch 7230, batch avg loss 0.3480, total avg loss: 0.3695, batch size: 39
2021-08-25 04:19:30,027 INFO [train.py:450] Epoch 2, batch 7240, batch avg loss 0.3367, total avg loss: 0.3678, batch size: 44
2021-08-25 04:19:37,333 INFO [train.py:450] Epoch 2, batch 7250, batch avg loss 0.3317, total avg loss: 0.3669, batch size: 37
2021-08-25 04:19:44,137 INFO [train.py:450] Epoch 2, batch 7260, batch avg loss 0.3716, total avg loss: 0.3660, batch size: 36
2021-08-25 04:19:52,917 INFO [train.py:450] Epoch 2, batch 7270, batch avg loss 0.3534, total avg loss: 0.3641, batch size: 44
2021-08-25 04:20:00,350 INFO [train.py:450] Epoch 2, batch 7280, batch avg loss 0.3599, total avg loss: 0.3621, batch size: 39
2021-08-25 04:20:10,534 INFO [train.py:450] Epoch 2, batch 7290, batch avg loss 0.3287, total avg loss: 0.3596, batch size: 40
2021-08-25 04:20:18,779 INFO [train.py:450] Epoch 2, batch 7300, batch avg loss 0.3886, total avg loss: 0.3603, batch size: 39
2021-08-25 04:20:25,927 INFO [train.py:450] Epoch 2, batch 7310, batch avg loss 0.3398, total avg loss: 0.3608, batch size: 37
2021-08-25 04:20:32,897 INFO [train.py:450] Epoch 2, batch 7320, batch avg loss 0.3146, total avg loss: 0.3591, batch size: 39
2021-08-25 04:20:40,076 INFO [train.py:450] Epoch 2, batch 7330, batch avg loss 0.3793, total avg loss: 0.3585, batch size: 41
2021-08-25 04:20:47,469 INFO [train.py:450] Epoch 2, batch 7340, batch avg loss 0.3652, total avg loss: 0.3573, batch size: 42
2021-08-25 04:20:54,360 INFO [train.py:450] Epoch 2, batch 7350, batch avg loss 0.3397, total avg loss: 0.3556, batch size: 40
2021-08-25 04:21:00,912 INFO [train.py:450] Epoch 2, batch 7360, batch avg loss 0.3410, total avg loss: 0.3563, batch size: 41
2021-08-25 04:21:08,210 INFO [train.py:450] Epoch 2, batch 7370, batch avg loss 0.3637, total avg loss: 0.3555, batch size: 38
2021-08-25 04:21:15,051 INFO [train.py:450] Epoch 2, batch 7380, batch avg loss 0.3307, total avg loss: 0.3552, batch size: 38
2021-08-25 04:21:22,418 INFO [train.py:450] Epoch 2, batch 7390, batch avg loss 0.3353, total avg loss: 0.3550, batch size: 41
2021-08-25 04:21:29,746 INFO [train.py:450] Epoch 2, batch 7400, batch avg loss 0.3526, total avg loss: 0.3550, batch size: 38
2021-08-25 04:21:36,800 INFO [train.py:450] Epoch 2, batch 7410, batch avg loss 0.3451, total avg loss: 0.3679, batch size: 39
2021-08-25 04:21:43,764 INFO [train.py:450] Epoch 2, batch 7420, batch avg loss 0.4059, total avg loss: 0.3659, batch size: 40
2021-08-25 04:21:51,305 INFO [train.py:450] Epoch 2, batch 7430, batch avg loss 0.3119, total avg loss: 0.3566, batch size: 40
2021-08-25 04:21:58,475 INFO [train.py:450] Epoch 2, batch 7440, batch avg loss 0.3560, total avg loss: 0.3550, batch size: 41
2021-08-25 04:22:05,698 INFO [train.py:450] Epoch 2, batch 7450, batch avg loss 0.3126, total avg loss: 0.3534, batch size: 38
2021-08-25 04:22:12,978 INFO [train.py:450] Epoch 2, batch 7460, batch avg loss 0.4308, total avg loss: 0.3535, batch size: 40
2021-08-25 04:22:20,301 INFO [train.py:450] Epoch 2, batch 7470, batch avg loss 0.3273, total avg loss: 0.3523, batch size: 39
2021-08-25 04:22:27,088 INFO [train.py:450] Epoch 2, batch 7480, batch avg loss 0.3532, total avg loss: 0.3492, batch size: 40
2021-08-25 04:22:34,600 INFO [train.py:450] Epoch 2, batch 7490, batch avg loss 0.3509, total avg loss: 0.3490, batch size: 39
2021-08-25 04:22:42,116 INFO [train.py:450] Epoch 2, batch 7500, batch avg loss 0.3063, total avg loss: 0.3482, batch size: 39
2021-08-25 04:22:48,910 INFO [train.py:450] Epoch 2, batch 7510, batch avg loss 0.3118, total avg loss: 0.3483, batch size: 39
2021-08-25 04:22:56,256 INFO [train.py:450] Epoch 2, batch 7520, batch avg loss 0.3475, total avg loss: 0.3495, batch size: 40
2021-08-25 04:23:03,693 INFO [train.py:450] Epoch 2, batch 7530, batch avg loss 0.3320, total avg loss: 0.3487, batch size: 39
2021-08-25 04:23:11,139 INFO [train.py:450] Epoch 2, batch 7540, batch avg loss 0.3503, total avg loss: 0.3485, batch size: 42
2021-08-25 04:23:17,944 INFO [train.py:450] Epoch 2, batch 7550, batch avg loss 0.3424, total avg loss: 0.3486, batch size: 39
2021-08-25 04:23:24,815 INFO [train.py:450] Epoch 2, batch 7560, batch avg loss 0.2966, total avg loss: 0.3478, batch size: 40
2021-08-25 04:23:33,610 INFO [train.py:450] Epoch 2, batch 7570, batch avg loss 0.3991, total avg loss: 0.3491, batch size: 37
2021-08-25 04:23:42,242 INFO [train.py:450] Epoch 2, batch 7580, batch avg loss 0.3027, total avg loss: 0.3489, batch size: 40
2021-08-25 04:23:50,715 INFO [train.py:450] Epoch 2, batch 7590, batch avg loss 0.3563, total avg loss: 0.3492, batch size: 39
2021-08-25 04:23:57,807 INFO [train.py:450] Epoch 2, batch 7600, batch avg loss 0.3549, total avg loss: 0.3488, batch size: 40
2021-08-25 04:24:04,802 INFO [train.py:450] Epoch 2, batch 7610, batch avg loss 0.3350, total avg loss: 0.3399, batch size: 42
2021-08-25 04:24:12,099 INFO [train.py:450] Epoch 2, batch 7620, batch avg loss 0.3593, total avg loss: 0.3444, batch size: 38
2021-08-25 04:24:19,465 INFO [train.py:450] Epoch 2, batch 7630, batch avg loss 0.3395, total avg loss: 0.3438, batch size: 37
2021-08-25 04:24:26,469 INFO [train.py:450] Epoch 2, batch 7640, batch avg loss 0.2858, total avg loss: 0.3439, batch size: 35
2021-08-25 04:24:33,121 INFO [train.py:450] Epoch 2, batch 7650, batch avg loss 0.4000, total avg loss: 0.3443, batch size: 39
2021-08-25 04:24:40,111 INFO [train.py:450] Epoch 2, batch 7660, batch avg loss 0.3954, total avg loss: 0.3446, batch size: 40
2021-08-25 04:24:47,544 INFO [train.py:450] Epoch 2, batch 7670, batch avg loss 0.3331, total avg loss: 0.3433, batch size: 35
2021-08-25 04:24:54,550 INFO [train.py:450] Epoch 2, batch 7680, batch avg loss 0.2850, total avg loss: 0.3448, batch size: 37
2021-08-25 04:25:01,316 INFO [train.py:450] Epoch 2, batch 7690, batch avg loss 0.4460, total avg loss: 0.3486, batch size: 39
2021-08-25 04:25:08,128 INFO [train.py:450] Epoch 2, batch 7700, batch avg loss 0.3465, total avg loss: 0.3486, batch size: 40
2021-08-25 04:25:15,305 INFO [train.py:450] Epoch 2, batch 7710, batch avg loss 0.3458, total avg loss: 0.3506, batch size: 38
2021-08-25 04:25:22,701 INFO [train.py:450] Epoch 2, batch 7720, batch avg loss 0.3299, total avg loss: 0.3507, batch size: 40
2021-08-25 04:25:29,502 INFO [train.py:450] Epoch 2, batch 7730, batch avg loss 0.3511, total avg loss: 0.3501, batch size: 39
2021-08-25 04:25:36,987 INFO [train.py:450] Epoch 2, batch 7740, batch avg loss 0.3062, total avg loss: 0.3499, batch size: 39
2021-08-25 04:25:43,997 INFO [train.py:450] Epoch 2, batch 7750, batch avg loss 0.3434, total avg loss: 0.3500, batch size: 39
2021-08-25 04:25:50,097 WARNING [cut.py:1694] To perform mix, energy must be non-zero and non-negative (got 0.0).  MonoCut with id "30e52137-174e-c3f3-8426-a262a67fb205" will not be mixed in.
2021-08-25 04:25:50,667 INFO [train.py:450] Epoch 2, batch 7760, batch avg loss 0.3747, total avg loss: 0.3509, batch size: 40
2021-08-25 04:25:57,369 INFO [train.py:450] Epoch 2, batch 7770, batch avg loss 0.3296, total avg loss: 0.3508, batch size: 41
2021-08-25 04:26:04,617 INFO [train.py:450] Epoch 2, batch 7780, batch avg loss 0.3240, total avg loss: 0.3505, batch size: 39
2021-08-25 04:26:12,680 INFO [train.py:450] Epoch 2, batch 7790, batch avg loss 0.3153, total avg loss: 0.3506, batch size: 40
2021-08-25 04:26:20,207 INFO [train.py:450] Epoch 2, batch 7800, batch avg loss 0.3717, total avg loss: 0.3508, batch size: 36
2021-08-25 04:26:27,545 INFO [train.py:450] Epoch 2, batch 7810, batch avg loss 0.4261, total avg loss: 0.3638, batch size: 37
2021-08-25 04:26:34,536 INFO [train.py:450] Epoch 2, batch 7820, batch avg loss 0.4060, total avg loss: 0.3631, batch size: 40
2021-08-25 04:26:41,943 INFO [train.py:450] Epoch 2, batch 7830, batch avg loss 0.3677, total avg loss: 0.3637, batch size: 39
2021-08-25 04:26:49,088 INFO [train.py:450] Epoch 2, batch 7840, batch avg loss 0.3656, total avg loss: 0.3613, batch size: 43
2021-08-25 04:26:56,261 INFO [train.py:450] Epoch 2, batch 7850, batch avg loss 0.3607, total avg loss: 0.3582, batch size: 40
2021-08-25 04:27:03,149 INFO [train.py:450] Epoch 2, batch 7860, batch avg loss 0.3566, total avg loss: 0.3559, batch size: 41
2021-08-25 04:27:09,833 INFO [train.py:450] Epoch 2, batch 7870, batch avg loss 0.3449, total avg loss: 0.3547, batch size: 41
2021-08-25 04:27:16,513 INFO [train.py:450] Epoch 2, batch 7880, batch avg loss 0.3131, total avg loss: 0.3531, batch size: 39
2021-08-25 04:27:24,489 INFO [train.py:450] Epoch 2, batch 7890, batch avg loss 0.3383, total avg loss: 0.3518, batch size: 42
2021-08-25 04:27:32,365 INFO [train.py:450] Epoch 2, batch 7900, batch avg loss 0.3569, total avg loss: 0.3526, batch size: 38
2021-08-25 04:27:40,730 INFO [train.py:450] Epoch 2, batch 7910, batch avg loss 0.3046, total avg loss: 0.3527, batch size: 40
2021-08-25 04:27:49,929 INFO [train.py:450] Epoch 2, batch 7920, batch avg loss 0.3296, total avg loss: 0.3517, batch size: 39
2021-08-25 04:27:58,063 INFO [train.py:450] Epoch 2, batch 7930, batch avg loss 0.3181, total avg loss: 0.3514, batch size: 37
2021-08-25 04:28:05,825 INFO [train.py:450] Epoch 2, batch 7940, batch avg loss 0.3242, total avg loss: 0.3517, batch size: 46
2021-08-25 04:28:12,747 INFO [train.py:450] Epoch 2, batch 7950, batch avg loss 0.3291, total avg loss: 0.3516, batch size: 38
2021-08-25 04:28:20,123 INFO [train.py:450] Epoch 2, batch 7960, batch avg loss 0.3530, total avg loss: 0.3520, batch size: 41
2021-08-25 04:28:26,758 INFO [train.py:450] Epoch 2, batch 7970, batch avg loss 0.2954, total avg loss: 0.3510, batch size: 40
2021-08-25 04:28:33,976 INFO [train.py:450] Epoch 2, batch 7980, batch avg loss 0.3789, total avg loss: 0.3512, batch size: 38
2021-08-25 04:28:41,182 INFO [train.py:450] Epoch 2, batch 7990, batch avg loss 0.3653, total avg loss: 0.3516, batch size: 39
2021-08-25 04:28:48,495 INFO [train.py:450] Epoch 2, batch 8000, batch avg loss 0.3402, total avg loss: 0.3515, batch size: 38
2021-08-25 04:29:26,863 INFO [train.py:482] Epoch 2, valid loss 0.2450, best valid loss: 0.2442 best valid epoch: 2
2021-08-25 04:29:32,746 INFO [train.py:450] Epoch 2, batch 8010, batch avg loss 0.3376, total avg loss: 0.3371, batch size: 40
2021-08-25 04:29:40,002 INFO [train.py:450] Epoch 2, batch 8020, batch avg loss 0.3815, total avg loss: 0.3408, batch size: 39
2021-08-25 04:29:46,559 INFO [train.py:450] Epoch 2, batch 8030, batch avg loss 0.3389, total avg loss: 0.3442, batch size: 37
2021-08-25 04:29:54,038 INFO [train.py:450] Epoch 2, batch 8040, batch avg loss 0.3160, total avg loss: 0.3426, batch size: 40
2021-08-25 04:30:01,348 INFO [train.py:450] Epoch 2, batch 8050, batch avg loss 0.3495, total avg loss: 0.3421, batch size: 37
2021-08-25 04:30:08,800 INFO [train.py:450] Epoch 2, batch 8060, batch avg loss 0.3932, total avg loss: 0.3416, batch size: 37
2021-08-25 04:30:16,227 INFO [train.py:450] Epoch 2, batch 8070, batch avg loss 0.4288, total avg loss: 0.3438, batch size: 37
2021-08-25 04:30:23,317 INFO [train.py:450] Epoch 2, batch 8080, batch avg loss 0.3746, total avg loss: 0.3437, batch size: 38
2021-08-25 04:30:29,827 INFO [train.py:450] Epoch 2, batch 8090, batch avg loss 0.3382, total avg loss: 0.3442, batch size: 40
2021-08-25 04:30:36,990 INFO [train.py:450] Epoch 2, batch 8100, batch avg loss 0.3912, total avg loss: 0.3442, batch size: 40
2021-08-25 04:30:43,985 INFO [train.py:450] Epoch 2, batch 8110, batch avg loss 0.3253, total avg loss: 0.3436, batch size: 37
2021-08-25 04:30:51,006 INFO [train.py:450] Epoch 2, batch 8120, batch avg loss 0.2996, total avg loss: 0.3418, batch size: 42
2021-08-25 04:30:58,046 INFO [train.py:450] Epoch 2, batch 8130, batch avg loss 0.3136, total avg loss: 0.3408, batch size: 40
2021-08-25 04:31:04,974 INFO [train.py:450] Epoch 2, batch 8140, batch avg loss 0.3080, total avg loss: 0.3398, batch size: 39
2021-08-25 04:31:11,905 INFO [train.py:450] Epoch 2, batch 8150, batch avg loss 0.3516, total avg loss: 0.3398, batch size: 41
2021-08-25 04:31:21,611 INFO [train.py:450] Epoch 2, batch 8160, batch avg loss 0.3363, total avg loss: 0.3391, batch size: 39
2021-08-25 04:31:28,961 INFO [train.py:450] Epoch 2, batch 8170, batch avg loss 0.3161, total avg loss: 0.3395, batch size: 38
2021-08-25 04:31:39,135 INFO [train.py:450] Epoch 2, batch 8180, batch avg loss 0.3188, total avg loss: 0.3396, batch size: 37
2021-08-25 04:31:45,644 INFO [train.py:450] Epoch 2, batch 8190, batch avg loss 0.3565, total avg loss: 0.3406, batch size: 39
2021-08-25 04:31:53,002 INFO [train.py:450] Epoch 2, batch 8200, batch avg loss 0.3020, total avg loss: 0.3417, batch size: 39
2021-08-25 04:31:57,384 WARNING [cut.py:1694] To perform mix, energy must be non-zero and non-negative (got 0.0).  MonoCut with id "45687c8a-1a8c-2c01-42a9-a6a7d15b9f30" will not be mixed in.
2021-08-25 04:31:59,848 INFO [train.py:450] Epoch 2, batch 8210, batch avg loss 0.2970, total avg loss: 0.3264, batch size: 42
2021-08-25 04:32:06,955 INFO [train.py:450] Epoch 2, batch 8220, batch avg loss 0.3702, total avg loss: 0.3392, batch size: 42
2021-08-25 04:32:14,552 INFO [train.py:450] Epoch 2, batch 8230, batch avg loss 0.3517, total avg loss: 0.3421, batch size: 40
2021-08-25 04:32:21,664 INFO [train.py:450] Epoch 2, batch 8240, batch avg loss 0.3330, total avg loss: 0.3450, batch size: 39
2021-08-25 04:32:29,066 INFO [train.py:450] Epoch 2, batch 8250, batch avg loss 0.3969, total avg loss: 0.3487, batch size: 40
2021-08-25 04:32:36,648 INFO [train.py:450] Epoch 2, batch 8260, batch avg loss 0.3469, total avg loss: 0.3462, batch size: 41
2021-08-25 04:32:44,688 INFO [train.py:450] Epoch 2, batch 8270, batch avg loss 0.3409, total avg loss: 0.3473, batch size: 40
2021-08-25 04:32:51,638 INFO [train.py:450] Epoch 2, batch 8280, batch avg loss 0.3424, total avg loss: 0.3477, batch size: 36
2021-08-25 04:32:58,764 INFO [train.py:450] Epoch 2, batch 8290, batch avg loss 0.3681, total avg loss: 0.3483, batch size: 41
2021-08-25 04:33:06,006 INFO [train.py:450] Epoch 2, batch 8300, batch avg loss 0.3652, total avg loss: 0.3485, batch size: 39
2021-08-25 04:33:13,283 INFO [train.py:450] Epoch 2, batch 8310, batch avg loss 0.4225, total avg loss: 0.3497, batch size: 41
2021-08-25 04:33:20,803 INFO [train.py:450] Epoch 2, batch 8320, batch avg loss 0.3769, total avg loss: 0.3505, batch size: 41
2021-08-25 04:33:27,749 INFO [train.py:450] Epoch 2, batch 8330, batch avg loss 0.3645, total avg loss: 0.3513, batch size: 43
2021-08-25 04:33:35,104 INFO [train.py:450] Epoch 2, batch 8340, batch avg loss 0.2960, total avg loss: 0.3508, batch size: 41
2021-08-25 04:33:42,144 INFO [train.py:450] Epoch 2, batch 8350, batch avg loss 0.3530, total avg loss: 0.3513, batch size: 38
2021-08-25 04:33:50,171 INFO [train.py:450] Epoch 2, batch 8360, batch avg loss 0.3609, total avg loss: 0.3503, batch size: 43
2021-08-25 04:33:56,841 INFO [train.py:450] Epoch 2, batch 8370, batch avg loss 0.3104, total avg loss: 0.3506, batch size: 36
2021-08-25 04:34:03,939 INFO [train.py:450] Epoch 2, batch 8380, batch avg loss 0.3340, total avg loss: 0.3507, batch size: 40
2021-08-25 04:34:11,559 INFO [train.py:450] Epoch 2, batch 8390, batch avg loss 0.3965, total avg loss: 0.3507, batch size: 44
2021-08-25 04:34:18,779 INFO [train.py:450] Epoch 2, batch 8400, batch avg loss 0.3391, total avg loss: 0.3502, batch size: 38
2021-08-25 04:34:25,600 INFO [train.py:450] Epoch 2, batch 8410, batch avg loss 0.2879, total avg loss: 0.3424, batch size: 42
2021-08-25 04:34:32,594 INFO [train.py:450] Epoch 2, batch 8420, batch avg loss 0.3291, total avg loss: 0.3443, batch size: 41
2021-08-25 04:34:40,274 INFO [train.py:450] Epoch 2, batch 8430, batch avg loss 0.3612, total avg loss: 0.3424, batch size: 39
2021-08-25 04:34:48,503 INFO [train.py:450] Epoch 2, batch 8440, batch avg loss 0.3260, total avg loss: 0.3477, batch size: 42
2021-08-25 04:34:55,253 INFO [train.py:450] Epoch 2, batch 8450, batch avg loss 0.3298, total avg loss: 0.3492, batch size: 37
2021-08-25 04:35:06,527 INFO [train.py:450] Epoch 2, batch 8460, batch avg loss 0.3437, total avg loss: 0.3488, batch size: 39
2021-08-25 04:35:13,648 INFO [train.py:450] Epoch 2, batch 8470, batch avg loss 0.3802, total avg loss: 0.3487, batch size: 43
2021-08-25 04:35:20,914 INFO [train.py:450] Epoch 2, batch 8480, batch avg loss 0.2792, total avg loss: 0.3460, batch size: 38
2021-08-25 04:35:28,223 INFO [train.py:450] Epoch 2, batch 8490, batch avg loss 0.3914, total avg loss: 0.3461, batch size: 40
2021-08-25 04:35:34,914 INFO [train.py:450] Epoch 2, batch 8500, batch avg loss 0.3095, total avg loss: 0.3455, batch size: 40
2021-08-25 04:35:42,125 INFO [train.py:450] Epoch 2, batch 8510, batch avg loss 0.3092, total avg loss: 0.3462, batch size: 38
2021-08-25 04:35:49,869 INFO [train.py:450] Epoch 2, batch 8520, batch avg loss 0.3785, total avg loss: 0.3457, batch size: 41
2021-08-25 04:35:56,857 INFO [train.py:450] Epoch 2, batch 8530, batch avg loss 0.3274, total avg loss: 0.3454, batch size: 37
2021-08-25 04:36:03,836 INFO [train.py:450] Epoch 2, batch 8540, batch avg loss 0.3735, total avg loss: 0.3465, batch size: 39
2021-08-25 04:36:11,377 INFO [train.py:450] Epoch 2, batch 8550, batch avg loss 0.3365, total avg loss: 0.3466, batch size: 41
2021-08-25 04:36:18,021 INFO [train.py:450] Epoch 2, batch 8560, batch avg loss 0.3327, total avg loss: 0.3475, batch size: 40
2021-08-25 04:36:24,694 INFO [train.py:450] Epoch 2, batch 8570, batch avg loss 0.3187, total avg loss: 0.3470, batch size: 38
2021-08-25 04:36:32,362 INFO [train.py:450] Epoch 2, batch 8580, batch avg loss 0.3560, total avg loss: 0.3475, batch size: 35
2021-08-25 04:36:39,416 INFO [train.py:450] Epoch 2, batch 8590, batch avg loss 0.3654, total avg loss: 0.3472, batch size: 39
2021-08-25 04:36:46,369 INFO [train.py:450] Epoch 2, batch 8600, batch avg loss 0.3203, total avg loss: 0.3483, batch size: 38
2021-08-25 04:36:53,401 INFO [train.py:450] Epoch 2, batch 8610, batch avg loss 0.4377, total avg loss: 0.3656, batch size: 41
2021-08-25 04:37:00,809 INFO [train.py:450] Epoch 2, batch 8620, batch avg loss 0.3768, total avg loss: 0.3571, batch size: 40
2021-08-25 04:37:07,836 INFO [train.py:450] Epoch 2, batch 8630, batch avg loss 0.3383, total avg loss: 0.3575, batch size: 39
2021-08-25 04:37:15,226 INFO [train.py:450] Epoch 2, batch 8640, batch avg loss 0.3166, total avg loss: 0.3530, batch size: 39
2021-08-25 04:37:22,339 INFO [train.py:450] Epoch 2, batch 8650, batch avg loss 0.3952, total avg loss: 0.3512, batch size: 43
2021-08-25 04:37:29,636 INFO [train.py:450] Epoch 2, batch 8660, batch avg loss 0.3535, total avg loss: 0.3511, batch size: 40
2021-08-25 04:37:36,675 INFO [train.py:450] Epoch 2, batch 8670, batch avg loss 0.2933, total avg loss: 0.3498, batch size: 40
2021-08-25 04:37:43,566 INFO [train.py:450] Epoch 2, batch 8680, batch avg loss 0.3201, total avg loss: 0.3482, batch size: 43
2021-08-25 04:37:50,520 INFO [train.py:450] Epoch 2, batch 8690, batch avg loss 0.3867, total avg loss: 0.3483, batch size: 39
2021-08-25 04:37:57,909 INFO [train.py:450] Epoch 2, batch 8700, batch avg loss 0.3396, total avg loss: 0.3475, batch size: 39
2021-08-25 04:38:05,619 INFO [train.py:450] Epoch 2, batch 8710, batch avg loss 0.3195, total avg loss: 0.3473, batch size: 40
2021-08-25 04:38:12,527 INFO [train.py:450] Epoch 2, batch 8720, batch avg loss 0.3254, total avg loss: 0.3468, batch size: 39
2021-08-25 04:38:20,248 INFO [train.py:450] Epoch 2, batch 8730, batch avg loss 0.2990, total avg loss: 0.3449, batch size: 40
2021-08-25 04:38:27,153 INFO [train.py:450] Epoch 2, batch 8740, batch avg loss 0.3441, total avg loss: 0.3450, batch size: 37
2021-08-25 04:38:34,344 INFO [train.py:450] Epoch 2, batch 8750, batch avg loss 0.2956, total avg loss: 0.3464, batch size: 40
2021-08-25 04:38:41,103 INFO [train.py:450] Epoch 2, batch 8760, batch avg loss 0.3567, total avg loss: 0.3465, batch size: 43
2021-08-25 04:38:49,846 INFO [train.py:450] Epoch 2, batch 8770, batch avg loss 0.3919, total avg loss: 0.3474, batch size: 42
2021-08-25 04:38:55,970 INFO [train.py:450] Epoch 2, batch 8780, batch avg loss 0.3130, total avg loss: 0.3479, batch size: 38
2021-08-25 04:39:06,608 INFO [train.py:450] Epoch 2, batch 8790, batch avg loss 0.3109, total avg loss: 0.3486, batch size: 40
2021-08-25 04:39:13,851 INFO [train.py:450] Epoch 2, batch 8800, batch avg loss 0.3405, total avg loss: 0.3485, batch size: 38
2021-08-25 04:39:20,669 INFO [train.py:450] Epoch 2, batch 8810, batch avg loss 0.3493, total avg loss: 0.3410, batch size: 40
2021-08-25 04:39:27,584 INFO [train.py:450] Epoch 2, batch 8820, batch avg loss 0.2965, total avg loss: 0.3389, batch size: 44
2021-08-25 04:39:34,886 INFO [train.py:450] Epoch 2, batch 8830, batch avg loss 0.3307, total avg loss: 0.3476, batch size: 39
2021-08-25 04:39:41,971 INFO [train.py:450] Epoch 2, batch 8840, batch avg loss 0.3583, total avg loss: 0.3467, batch size: 38
2021-08-25 04:39:48,750 INFO [train.py:450] Epoch 2, batch 8850, batch avg loss 0.3444, total avg loss: 0.3451, batch size: 37
2021-08-25 04:39:55,499 INFO [train.py:450] Epoch 2, batch 8860, batch avg loss 0.3146, total avg loss: 0.3415, batch size: 41
2021-08-25 04:40:02,508 INFO [train.py:450] Epoch 2, batch 8870, batch avg loss 0.3869, total avg loss: 0.3428, batch size: 38
2021-08-25 04:40:09,820 INFO [train.py:450] Epoch 2, batch 8880, batch avg loss 0.3384, total avg loss: 0.3436, batch size: 42
2021-08-25 04:40:16,796 INFO [train.py:450] Epoch 2, batch 8890, batch avg loss 0.3365, total avg loss: 0.3436, batch size: 41
2021-08-25 04:40:23,621 INFO [train.py:450] Epoch 2, batch 8900, batch avg loss 0.3548, total avg loss: 0.3455, batch size: 40
2021-08-25 04:40:31,671 INFO [train.py:450] Epoch 2, batch 8910, batch avg loss 0.3634, total avg loss: 0.3448, batch size: 41
2021-08-25 04:40:38,510 INFO [train.py:450] Epoch 2, batch 8920, batch avg loss 0.3439, total avg loss: 0.3448, batch size: 39
2021-08-25 04:40:45,369 INFO [train.py:450] Epoch 2, batch 8930, batch avg loss 0.3294, total avg loss: 0.3455, batch size: 42
2021-08-25 04:40:52,626 INFO [train.py:450] Epoch 2, batch 8940, batch avg loss 0.3337, total avg loss: 0.3457, batch size: 40
2021-08-25 04:40:59,613 INFO [train.py:450] Epoch 2, batch 8950, batch avg loss 0.3294, total avg loss: 0.3451, batch size: 43
2021-08-25 04:41:06,454 INFO [train.py:450] Epoch 2, batch 8960, batch avg loss 0.2746, total avg loss: 0.3443, batch size: 39
2021-08-25 04:41:07,478 WARNING [cut.py:1694] To perform mix, energy must be non-zero and non-negative (got 0.0).  MonoCut with id "f9c94fc5-e813-8bc7-4912-5e3f01d70466" will not be mixed in.
2021-08-25 04:41:13,209 INFO [train.py:450] Epoch 2, batch 8970, batch avg loss 0.3519, total avg loss: 0.3432, batch size: 38
2021-08-25 04:41:20,319 INFO [train.py:450] Epoch 2, batch 8980, batch avg loss 0.3237, total avg loss: 0.3435, batch size: 42
2021-08-25 04:41:27,649 INFO [train.py:450] Epoch 2, batch 8990, batch avg loss 0.3291, total avg loss: 0.3443, batch size: 38
2021-08-25 04:41:34,512 INFO [train.py:450] Epoch 2, batch 9000, batch avg loss 0.3708, total avg loss: 0.3445, batch size: 40
2021-08-25 04:42:14,058 INFO [train.py:482] Epoch 2, valid loss 0.2470, best valid loss: 0.2442 best valid epoch: 2
2021-08-25 04:42:22,987 INFO [train.py:450] Epoch 2, batch 9010, batch avg loss 0.3461, total avg loss: 0.3493, batch size: 41
2021-08-25 04:42:29,275 INFO [train.py:450] Epoch 2, batch 9020, batch avg loss 0.3274, total avg loss: 0.3348, batch size: 37
2021-08-25 04:42:36,269 INFO [train.py:450] Epoch 2, batch 9030, batch avg loss 0.3196, total avg loss: 0.3395, batch size: 36
2021-08-25 04:42:43,105 INFO [train.py:450] Epoch 2, batch 9040, batch avg loss 0.3866, total avg loss: 0.3397, batch size: 41
2021-08-25 04:42:50,084 INFO [train.py:450] Epoch 2, batch 9050, batch avg loss 0.3839, total avg loss: 0.3456, batch size: 39
2021-08-25 04:42:56,915 INFO [train.py:450] Epoch 2, batch 9060, batch avg loss 0.3485, total avg loss: 0.3450, batch size: 37
2021-08-25 04:43:04,280 INFO [train.py:450] Epoch 2, batch 9070, batch avg loss 0.3783, total avg loss: 0.3458, batch size: 38
2021-08-25 04:43:11,744 INFO [train.py:450] Epoch 2, batch 9080, batch avg loss 0.3714, total avg loss: 0.3453, batch size: 41
2021-08-25 04:43:17,785 INFO [train.py:450] Epoch 2, batch 9090, batch avg loss 0.3167, total avg loss: 0.3457, batch size: 38
2021-08-25 04:43:24,836 INFO [train.py:450] Epoch 2, batch 9100, batch avg loss 0.3583, total avg loss: 0.3444, batch size: 40
2021-08-25 04:43:31,550 INFO [train.py:450] Epoch 2, batch 9110, batch avg loss 0.3343, total avg loss: 0.3435, batch size: 39
2021-08-25 04:43:38,272 INFO [train.py:450] Epoch 2, batch 9120, batch avg loss 0.3757, total avg loss: 0.3441, batch size: 43
2021-08-25 04:43:44,931 INFO [train.py:450] Epoch 2, batch 9130, batch avg loss 0.3884, total avg loss: 0.3439, batch size: 40
2021-08-25 04:43:52,044 INFO [train.py:450] Epoch 2, batch 9140, batch avg loss 0.3350, total avg loss: 0.3439, batch size: 40
2021-08-25 04:43:58,773 INFO [train.py:450] Epoch 2, batch 9150, batch avg loss 0.3878, total avg loss: 0.3429, batch size: 44
2021-08-25 04:44:06,108 INFO [train.py:450] Epoch 2, batch 9160, batch avg loss 0.3170, total avg loss: 0.3426, batch size: 35
2021-08-25 04:44:13,143 INFO [train.py:450] Epoch 2, batch 9170, batch avg loss 0.3592, total avg loss: 0.3432, batch size: 39
2021-08-25 04:44:20,063 INFO [train.py:450] Epoch 2, batch 9180, batch avg loss 0.3431, total avg loss: 0.3446, batch size: 36
2021-08-25 04:44:27,006 INFO [train.py:450] Epoch 2, batch 9190, batch avg loss 0.3442, total avg loss: 0.3440, batch size: 41
2021-08-25 04:44:34,003 INFO [train.py:450] Epoch 2, batch 9200, batch avg loss 0.3104, total avg loss: 0.3441, batch size: 40
2021-08-25 04:44:41,335 INFO [train.py:450] Epoch 2, batch 9210, batch avg loss 0.3300, total avg loss: 0.3379, batch size: 38
2021-08-25 04:44:48,199 INFO [train.py:450] Epoch 2, batch 9220, batch avg loss 0.3890, total avg loss: 0.3403, batch size: 38
2021-08-25 04:44:55,220 INFO [train.py:450] Epoch 2, batch 9230, batch avg loss 0.3704, total avg loss: 0.3446, batch size: 41
2021-08-25 04:45:02,391 INFO [train.py:450] Epoch 2, batch 9240, batch avg loss 0.3466, total avg loss: 0.3444, batch size: 39
2021-08-25 04:45:09,169 INFO [train.py:450] Epoch 2, batch 9250, batch avg loss 0.3424, total avg loss: 0.3426, batch size: 39
2021-08-25 04:45:15,900 INFO [train.py:450] Epoch 2, batch 9260, batch avg loss 0.2979, total avg loss: 0.3430, batch size: 38
2021-08-25 04:45:22,851 INFO [train.py:450] Epoch 2, batch 9270, batch avg loss 0.3186, total avg loss: 0.3417, batch size: 37
2021-08-25 04:45:29,752 INFO [train.py:450] Epoch 2, batch 9280, batch avg loss 0.3135, total avg loss: 0.3436, batch size: 40
2021-08-25 04:45:36,977 INFO [train.py:450] Epoch 2, batch 9290, batch avg loss 0.2836, total avg loss: 0.3426, batch size: 38
2021-08-25 04:45:43,914 INFO [train.py:450] Epoch 2, batch 9300, batch avg loss 0.3079, total avg loss: 0.3414, batch size: 38
2021-08-25 04:45:52,700 INFO [train.py:450] Epoch 2, batch 9310, batch avg loss 0.3397, total avg loss: 0.3425, batch size: 41
2021-08-25 04:45:59,697 INFO [train.py:450] Epoch 2, batch 9320, batch avg loss 0.3060, total avg loss: 0.3423, batch size: 38
2021-08-25 04:46:09,360 INFO [train.py:450] Epoch 2, batch 9330, batch avg loss 0.4371, total avg loss: 0.3429, batch size: 37
2021-08-25 04:46:16,420 INFO [train.py:450] Epoch 2, batch 9340, batch avg loss 0.2942, total avg loss: 0.3427, batch size: 38
2021-08-25 04:46:23,280 INFO [train.py:450] Epoch 2, batch 9350, batch avg loss 0.3900, total avg loss: 0.3434, batch size: 42
2021-08-25 04:46:30,210 INFO [train.py:450] Epoch 2, batch 9360, batch avg loss 0.3077, total avg loss: 0.3439, batch size: 40
2021-08-25 04:46:36,759 INFO [train.py:450] Epoch 2, batch 9370, batch avg loss 0.3928, total avg loss: 0.3455, batch size: 37
2021-08-25 04:46:43,886 INFO [train.py:450] Epoch 2, batch 9380, batch avg loss 0.3671, total avg loss: 0.3464, batch size: 38
2021-08-25 04:46:50,912 INFO [train.py:450] Epoch 2, batch 9390, batch avg loss 0.3209, total avg loss: 0.3462, batch size: 42
2021-08-25 04:46:58,191 INFO [train.py:450] Epoch 2, batch 9400, batch avg loss 0.3573, total avg loss: 0.3460, batch size: 40
2021-08-25 04:47:05,753 INFO [train.py:450] Epoch 2, batch 9410, batch avg loss 0.4115, total avg loss: 0.3523, batch size: 40
2021-08-25 04:47:12,294 INFO [train.py:450] Epoch 2, batch 9420, batch avg loss 0.3269, total avg loss: 0.3422, batch size: 39
2021-08-25 04:47:19,123 INFO [train.py:450] Epoch 2, batch 9430, batch avg loss 0.3291, total avg loss: 0.3441, batch size: 40
2021-08-25 04:47:26,015 INFO [train.py:450] Epoch 2, batch 9440, batch avg loss 0.3677, total avg loss: 0.3493, batch size: 41
2021-08-25 04:47:32,916 INFO [train.py:450] Epoch 2, batch 9450, batch avg loss 0.3318, total avg loss: 0.3469, batch size: 39
2021-08-25 04:47:40,225 INFO [train.py:450] Epoch 2, batch 9460, batch avg loss 0.3534, total avg loss: 0.3445, batch size: 42
2021-08-25 04:47:47,431 INFO [train.py:450] Epoch 2, batch 9470, batch avg loss 0.3528, total avg loss: 0.3472, batch size: 44
2021-08-25 04:47:54,170 INFO [train.py:450] Epoch 2, batch 9480, batch avg loss 0.3849, total avg loss: 0.3465, batch size: 40
2021-08-25 04:48:01,683 INFO [train.py:450] Epoch 2, batch 9490, batch avg loss 0.3226, total avg loss: 0.3448, batch size: 40
2021-08-25 04:48:08,326 INFO [train.py:450] Epoch 2, batch 9500, batch avg loss 0.3126, total avg loss: 0.3442, batch size: 41
2021-08-25 04:48:15,546 INFO [train.py:450] Epoch 2, batch 9510, batch avg loss 0.3500, total avg loss: 0.3431, batch size: 39
2021-08-25 04:48:22,046 INFO [train.py:450] Epoch 2, batch 9520, batch avg loss 0.3092, total avg loss: 0.3431, batch size: 38
2021-08-25 04:48:28,604 INFO [train.py:450] Epoch 2, batch 9530, batch avg loss 0.3314, total avg loss: 0.3430, batch size: 40
2021-08-25 04:48:35,407 INFO [train.py:450] Epoch 2, batch 9540, batch avg loss 0.3425, total avg loss: 0.3442, batch size: 38
2021-08-25 04:48:42,471 INFO [train.py:450] Epoch 2, batch 9550, batch avg loss 0.3275, total avg loss: 0.3441, batch size: 40
2021-08-25 04:48:49,295 INFO [train.py:450] Epoch 2, batch 9560, batch avg loss 0.3361, total avg loss: 0.3443, batch size: 40
2021-08-25 04:48:56,868 INFO [train.py:450] Epoch 2, batch 9570, batch avg loss 0.3197, total avg loss: 0.3435, batch size: 41
2021-08-25 04:49:03,522 INFO [train.py:450] Epoch 2, batch 9580, batch avg loss 0.3067, total avg loss: 0.3430, batch size: 40
2021-08-25 04:49:10,747 INFO [train.py:450] Epoch 2, batch 9590, batch avg loss 0.3398, total avg loss: 0.3424, batch size: 41
2021-08-25 04:49:18,185 INFO [train.py:450] Epoch 2, batch 9600, batch avg loss 0.3018, total avg loss: 0.3421, batch size: 43
2021-08-25 04:49:26,484 INFO [train.py:450] Epoch 2, batch 9610, batch avg loss 0.4088, total avg loss: 0.3424, batch size: 39
2021-08-25 04:49:34,785 INFO [train.py:450] Epoch 2, batch 9620, batch avg loss 0.3548, total avg loss: 0.3368, batch size: 41
2021-08-25 04:49:42,551 INFO [train.py:450] Epoch 2, batch 9630, batch avg loss 0.3315, total avg loss: 0.3341, batch size: 43
2021-08-25 04:49:49,483 INFO [train.py:450] Epoch 2, batch 9640, batch avg loss 0.3845, total avg loss: 0.3401, batch size: 40
2021-08-25 04:49:56,055 INFO [train.py:450] Epoch 2, batch 9650, batch avg loss 0.3044, total avg loss: 0.3437, batch size: 35
2021-08-25 04:50:03,345 INFO [train.py:450] Epoch 2, batch 9660, batch avg loss 0.3504, total avg loss: 0.3451, batch size: 41
2021-08-25 04:50:10,252 INFO [train.py:450] Epoch 2, batch 9670, batch avg loss 0.3712, total avg loss: 0.3442, batch size: 42
2021-08-25 04:50:17,034 INFO [train.py:450] Epoch 2, batch 9680, batch avg loss 0.4370, total avg loss: 0.3449, batch size: 40
2021-08-25 04:50:23,617 INFO [train.py:450] Epoch 2, batch 9690, batch avg loss 0.3260, total avg loss: 0.3452, batch size: 39
2021-08-25 04:50:30,284 INFO [train.py:450] Epoch 2, batch 9700, batch avg loss 0.3305, total avg loss: 0.3441, batch size: 40
2021-08-25 04:50:36,897 INFO [train.py:450] Epoch 2, batch 9710, batch avg loss 0.3682, total avg loss: 0.3438, batch size: 40
2021-08-25 04:50:43,920 INFO [train.py:450] Epoch 2, batch 9720, batch avg loss 0.3386, total avg loss: 0.3427, batch size: 39
2021-08-25 04:50:50,608 INFO [train.py:450] Epoch 2, batch 9730, batch avg loss 0.4140, total avg loss: 0.3437, batch size: 38
2021-08-25 04:50:57,701 INFO [train.py:450] Epoch 2, batch 9740, batch avg loss 0.3797, total avg loss: 0.3442, batch size: 42
2021-08-25 04:51:04,400 INFO [train.py:450] Epoch 2, batch 9750, batch avg loss 0.3348, total avg loss: 0.3440, batch size: 38
2021-08-25 04:51:11,246 INFO [train.py:450] Epoch 2, batch 9760, batch avg loss 0.3837, total avg loss: 0.3443, batch size: 40
2021-08-25 04:51:18,118 INFO [train.py:450] Epoch 2, batch 9770, batch avg loss 0.2818, total avg loss: 0.3438, batch size: 41
2021-08-25 04:51:25,344 INFO [train.py:450] Epoch 2, batch 9780, batch avg loss 0.3299, total avg loss: 0.3433, batch size: 38
2021-08-25 04:51:32,014 INFO [train.py:450] Epoch 2, batch 9790, batch avg loss 0.2834, total avg loss: 0.3431, batch size: 40
2021-08-25 04:51:38,530 INFO [train.py:450] Epoch 2, batch 9800, batch avg loss 0.3670, total avg loss: 0.3427, batch size: 40
2021-08-25 04:51:45,377 INFO [train.py:450] Epoch 2, batch 9810, batch avg loss 0.3487, total avg loss: 0.3428, batch size: 42
2021-08-25 04:51:52,135 INFO [train.py:450] Epoch 2, batch 9820, batch avg loss 0.3485, total avg loss: 0.3516, batch size: 41
2021-08-25 04:51:59,183 INFO [train.py:450] Epoch 2, batch 9830, batch avg loss 0.3178, total avg loss: 0.3484, batch size: 38
2021-08-25 04:52:06,233 INFO [train.py:450] Epoch 2, batch 9840, batch avg loss 0.3057, total avg loss: 0.3463, batch size: 38
2021-08-25 04:52:13,596 INFO [train.py:450] Epoch 2, batch 9850, batch avg loss 0.2939, total avg loss: 0.3500, batch size: 39
2021-08-25 04:52:20,424 INFO [train.py:450] Epoch 2, batch 9860, batch avg loss 0.3001, total avg loss: 0.3470, batch size: 40
2021-08-25 04:52:27,226 INFO [train.py:450] Epoch 2, batch 9870, batch avg loss 0.4084, total avg loss: 0.3463, batch size: 43
2021-08-25 04:52:33,654 INFO [train.py:450] Epoch 2, batch 9880, batch avg loss 0.3676, total avg loss: 0.3446, batch size: 41
2021-08-25 04:52:40,711 INFO [train.py:450] Epoch 2, batch 9890, batch avg loss 0.3813, total avg loss: 0.3435, batch size: 41
2021-08-25 04:52:48,578 INFO [train.py:450] Epoch 2, batch 9900, batch avg loss 0.3444, total avg loss: 0.3436, batch size: 38
2021-08-25 04:52:55,755 INFO [train.py:450] Epoch 2, batch 9910, batch avg loss 0.3403, total avg loss: 0.3424, batch size: 42
2021-08-25 04:53:04,546 INFO [train.py:450] Epoch 2, batch 9920, batch avg loss 0.3078, total avg loss: 0.3429, batch size: 40
2021-08-25 04:53:13,371 INFO [train.py:450] Epoch 2, batch 9930, batch avg loss 0.3909, total avg loss: 0.3419, batch size: 40
2021-08-25 04:53:20,990 INFO [train.py:450] Epoch 2, batch 9940, batch avg loss 0.3679, total avg loss: 0.3419, batch size: 42
2021-08-25 04:53:27,929 INFO [train.py:450] Epoch 2, batch 9950, batch avg loss 0.3493, total avg loss: 0.3430, batch size: 38
2021-08-25 04:53:35,009 INFO [train.py:450] Epoch 2, batch 9960, batch avg loss 0.3447, total avg loss: 0.3418, batch size: 39
2021-08-25 04:53:42,411 INFO [train.py:450] Epoch 2, batch 9970, batch avg loss 0.3314, total avg loss: 0.3424, batch size: 41
2021-08-25 04:53:49,236 INFO [train.py:450] Epoch 2, batch 9980, batch avg loss 0.3364, total avg loss: 0.3425, batch size: 40
2021-08-25 04:53:56,594 INFO [train.py:450] Epoch 2, batch 9990, batch avg loss 0.3486, total avg loss: 0.3419, batch size: 41
2021-08-25 04:54:04,442 INFO [train.py:450] Epoch 2, batch 10000, batch avg loss 0.3753, total avg loss: 0.3423, batch size: 39
2021-08-25 04:54:42,324 INFO [train.py:482] Epoch 2, valid loss 0.2455, best valid loss: 0.2442 best valid epoch: 2
2021-08-25 04:54:48,269 INFO [train.py:450] Epoch 2, batch 10010, batch avg loss 0.3611, total avg loss: 0.3543, batch size: 40
2021-08-25 04:54:55,191 INFO [train.py:450] Epoch 2, batch 10020, batch avg loss 0.3700, total avg loss: 0.3576, batch size: 43
2021-08-25 04:55:02,079 INFO [train.py:450] Epoch 2, batch 10030, batch avg loss 0.4020, total avg loss: 0.3495, batch size: 40
2021-08-25 04:55:08,793 INFO [train.py:450] Epoch 2, batch 10040, batch avg loss 0.3257, total avg loss: 0.3467, batch size: 39
2021-08-25 04:55:15,787 INFO [train.py:450] Epoch 2, batch 10050, batch avg loss 0.4072, total avg loss: 0.3481, batch size: 39
2021-08-25 04:55:22,453 INFO [train.py:450] Epoch 2, batch 10060, batch avg loss 0.3838, total avg loss: 0.3500, batch size: 39
2021-08-25 04:55:28,953 INFO [train.py:450] Epoch 2, batch 10070, batch avg loss 0.3140, total avg loss: 0.3474, batch size: 45
2021-08-25 04:55:35,619 INFO [train.py:450] Epoch 2, batch 10080, batch avg loss 0.3524, total avg loss: 0.3467, batch size: 41
2021-08-25 04:55:42,207 INFO [train.py:450] Epoch 2, batch 10090, batch avg loss 0.3264, total avg loss: 0.3462, batch size: 40
2021-08-25 04:55:49,395 INFO [train.py:450] Epoch 2, batch 10100, batch avg loss 0.3315, total avg loss: 0.3456, batch size: 43
2021-08-25 04:55:56,277 INFO [train.py:450] Epoch 2, batch 10110, batch avg loss 0.4028, total avg loss: 0.3470, batch size: 39
2021-08-25 04:56:03,189 INFO [train.py:450] Epoch 2, batch 10120, batch avg loss 0.2816, total avg loss: 0.3456, batch size: 42
2021-08-25 04:56:10,561 INFO [train.py:450] Epoch 2, batch 10130, batch avg loss 0.3125, total avg loss: 0.3440, batch size: 37
2021-08-25 04:56:17,748 INFO [train.py:450] Epoch 2, batch 10140, batch avg loss 0.3310, total avg loss: 0.3444, batch size: 39
2021-08-25 04:56:24,203 INFO [train.py:450] Epoch 2, batch 10150, batch avg loss 0.3190, total avg loss: 0.3443, batch size: 38
2021-08-25 04:56:36,971 INFO [train.py:450] Epoch 2, batch 10160, batch avg loss 0.3348, total avg loss: 0.3438, batch size: 39
2021-08-25 04:56:43,493 INFO [train.py:450] Epoch 2, batch 10170, batch avg loss 0.3496, total avg loss: 0.3443, batch size: 38
2021-08-25 04:56:50,533 INFO [train.py:450] Epoch 2, batch 10180, batch avg loss 0.3354, total avg loss: 0.3449, batch size: 38
2021-08-25 04:56:57,590 INFO [train.py:450] Epoch 2, batch 10190, batch avg loss 0.4018, total avg loss: 0.3454, batch size: 41
2021-08-25 04:57:03,945 INFO [train.py:450] Epoch 2, batch 10200, batch avg loss 0.3140, total avg loss: 0.3449, batch size: 39
2021-08-25 04:57:10,989 INFO [train.py:450] Epoch 2, batch 10210, batch avg loss 0.3379, total avg loss: 0.3521, batch size: 41
2021-08-25 04:57:18,343 INFO [train.py:450] Epoch 2, batch 10220, batch avg loss 0.3179, total avg loss: 0.3412, batch size: 38
2021-08-25 04:57:25,834 INFO [train.py:450] Epoch 2, batch 10230, batch avg loss 0.3970, total avg loss: 0.3408, batch size: 38
2021-08-25 04:57:32,088 INFO [train.py:450] Epoch 2, batch 10240, batch avg loss 0.3091, total avg loss: 0.3376, batch size: 37
2021-08-25 04:57:38,948 INFO [train.py:450] Epoch 2, batch 10250, batch avg loss 0.3328, total avg loss: 0.3365, batch size: 38
2021-08-25 04:57:45,834 INFO [train.py:450] Epoch 2, batch 10260, batch avg loss 0.2985, total avg loss: 0.3338, batch size: 40
2021-08-25 04:57:52,523 INFO [train.py:450] Epoch 2, batch 10270, batch avg loss 0.3341, total avg loss: 0.3340, batch size: 41
2021-08-25 04:57:59,308 INFO [train.py:450] Epoch 2, batch 10280, batch avg loss 0.3484, total avg loss: 0.3348, batch size: 39
2021-08-25 04:58:06,525 INFO [train.py:450] Epoch 2, batch 10290, batch avg loss 0.3234, total avg loss: 0.3362, batch size: 37
2021-08-25 04:58:13,621 INFO [train.py:450] Epoch 2, batch 10300, batch avg loss 0.3857, total avg loss: 0.3363, batch size: 40
2021-08-25 04:58:20,217 INFO [train.py:450] Epoch 2, batch 10310, batch avg loss 0.3026, total avg loss: 0.3353, batch size: 44
2021-08-25 04:58:28,385 INFO [train.py:450] Epoch 2, batch 10320, batch avg loss 0.3706, total avg loss: 0.3369, batch size: 42
2021-08-25 04:58:35,064 INFO [train.py:450] Epoch 2, batch 10330, batch avg loss 0.4267, total avg loss: 0.3370, batch size: 40
2021-08-25 04:58:41,781 INFO [train.py:450] Epoch 2, batch 10340, batch avg loss 0.4332, total avg loss: 0.3371, batch size: 39
2021-08-25 04:58:49,116 INFO [train.py:450] Epoch 2, batch 10350, batch avg loss 0.3398, total avg loss: 0.3366, batch size: 42
2021-08-25 04:58:55,553 INFO [train.py:450] Epoch 2, batch 10360, batch avg loss 0.3442, total avg loss: 0.3366, batch size: 37
2021-08-25 04:59:02,474 INFO [train.py:450] Epoch 2, batch 10370, batch avg loss 0.3145, total avg loss: 0.3360, batch size: 40
2021-08-25 04:59:08,982 INFO [train.py:450] Epoch 2, batch 10380, batch avg loss 0.3643, total avg loss: 0.3359, batch size: 39
2021-08-25 04:59:15,966 INFO [train.py:450] Epoch 2, batch 10390, batch avg loss 0.2909, total avg loss: 0.3367, batch size: 44
2021-08-25 04:59:22,299 INFO [train.py:450] Epoch 2, batch 10400, batch avg loss 0.3729, total avg loss: 0.3374, batch size: 43
2021-08-25 04:59:28,918 INFO [train.py:450] Epoch 2, batch 10410, batch avg loss 0.3288, total avg loss: 0.3421, batch size: 38
2021-08-25 04:59:35,452 INFO [train.py:450] Epoch 2, batch 10420, batch avg loss 0.3131, total avg loss: 0.3419, batch size: 35
2021-08-25 04:59:41,929 INFO [train.py:450] Epoch 2, batch 10430, batch avg loss 0.3353, total avg loss: 0.3446, batch size: 41
2021-08-25 04:59:48,453 INFO [train.py:450] Epoch 2, batch 10440, batch avg loss 0.3388, total avg loss: 0.3442, batch size: 38
2021-08-25 04:59:56,800 INFO [train.py:450] Epoch 2, batch 10450, batch avg loss 0.3344, total avg loss: 0.3421, batch size: 38
2021-08-25 05:00:05,600 INFO [train.py:450] Epoch 2, batch 10460, batch avg loss 0.3788, total avg loss: 0.3412, batch size: 38
2021-08-25 05:00:14,869 INFO [train.py:450] Epoch 2, batch 10470, batch avg loss 0.3205, total avg loss: 0.3406, batch size: 39
2021-08-25 05:00:22,285 INFO [train.py:450] Epoch 2, batch 10480, batch avg loss 0.3291, total avg loss: 0.3425, batch size: 45
2021-08-25 05:00:29,168 INFO [train.py:450] Epoch 2, batch 10490, batch avg loss 0.3245, total avg loss: 0.3414, batch size: 39
2021-08-25 05:00:36,072 INFO [train.py:450] Epoch 2, batch 10500, batch avg loss 0.3015, total avg loss: 0.3397, batch size: 40
2021-08-25 05:00:42,588 INFO [train.py:450] Epoch 2, batch 10510, batch avg loss 0.3140, total avg loss: 0.3382, batch size: 40
2021-08-25 05:00:49,339 INFO [train.py:450] Epoch 2, batch 10520, batch avg loss 0.3738, total avg loss: 0.3382, batch size: 42
2021-08-25 05:00:55,960 INFO [train.py:450] Epoch 2, batch 10530, batch avg loss 0.3519, total avg loss: 0.3387, batch size: 39
2021-08-25 05:01:02,771 INFO [train.py:450] Epoch 2, batch 10540, batch avg loss 0.3335, total avg loss: 0.3386, batch size: 42
2021-08-25 05:01:09,649 INFO [train.py:450] Epoch 2, batch 10550, batch avg loss 0.3125, total avg loss: 0.3384, batch size: 39
2021-08-25 05:01:16,427 INFO [train.py:450] Epoch 2, batch 10560, batch avg loss 0.3240, total avg loss: 0.3397, batch size: 35
2021-08-25 05:01:23,005 INFO [train.py:450] Epoch 2, batch 10570, batch avg loss 0.3338, total avg loss: 0.3388, batch size: 39
2021-08-25 05:01:29,806 INFO [train.py:450] Epoch 2, batch 10580, batch avg loss 0.3518, total avg loss: 0.3389, batch size: 41
2021-08-25 05:01:36,330 INFO [train.py:450] Epoch 2, batch 10590, batch avg loss 0.3183, total avg loss: 0.3393, batch size: 39
2021-08-25 05:01:42,996 INFO [train.py:450] Epoch 2, batch 10600, batch avg loss 0.3275, total avg loss: 0.3392, batch size: 38
2021-08-25 05:01:49,941 INFO [train.py:450] Epoch 2, batch 10610, batch avg loss 0.3355, total avg loss: 0.3330, batch size: 43
2021-08-25 05:01:56,367 INFO [train.py:450] Epoch 2, batch 10620, batch avg loss 0.3419, total avg loss: 0.3451, batch size: 35
2021-08-25 05:02:03,334 INFO [train.py:450] Epoch 2, batch 10630, batch avg loss 0.3539, total avg loss: 0.3425, batch size: 42
2021-08-25 05:02:10,429 INFO [train.py:450] Epoch 2, batch 10640, batch avg loss 0.2977, total avg loss: 0.3428, batch size: 37
2021-08-25 05:02:17,749 INFO [train.py:450] Epoch 2, batch 10650, batch avg loss 0.4198, total avg loss: 0.3443, batch size: 38
2021-08-25 05:02:25,746 INFO [train.py:450] Epoch 2, batch 10660, batch avg loss 0.3434, total avg loss: 0.3428, batch size: 39
2021-08-25 05:02:33,468 INFO [train.py:450] Epoch 2, batch 10670, batch avg loss 0.3287, total avg loss: 0.3436, batch size: 46
2021-08-25 05:02:41,237 INFO [train.py:450] Epoch 2, batch 10680, batch avg loss 0.3212, total avg loss: 0.3426, batch size: 41
2021-08-25 05:02:48,703 INFO [train.py:450] Epoch 2, batch 10690, batch avg loss 0.3620, total avg loss: 0.3410, batch size: 37
2021-08-25 05:02:55,758 INFO [train.py:450] Epoch 2, batch 10700, batch avg loss 0.3016, total avg loss: 0.3399, batch size: 36
2021-08-25 05:03:03,450 INFO [train.py:450] Epoch 2, batch 10710, batch avg loss 0.3716, total avg loss: 0.3398, batch size: 38
2021-08-25 05:03:10,962 INFO [train.py:450] Epoch 2, batch 10720, batch avg loss 0.3746, total avg loss: 0.3408, batch size: 40
2021-08-25 05:03:18,030 INFO [train.py:450] Epoch 2, batch 10730, batch avg loss 0.2913, total avg loss: 0.3394, batch size: 39
2021-08-25 05:03:25,567 INFO [train.py:450] Epoch 2, batch 10740, batch avg loss 0.3820, total avg loss: 0.3392, batch size: 39
2021-08-25 05:03:33,056 INFO [train.py:450] Epoch 2, batch 10750, batch avg loss 0.2815, total avg loss: 0.3398, batch size: 42
2021-08-25 05:03:40,265 INFO [train.py:450] Epoch 2, batch 10760, batch avg loss 0.3431, total avg loss: 0.3395, batch size: 40
2021-08-25 05:03:47,869 INFO [train.py:450] Epoch 2, batch 10770, batch avg loss 0.3397, total avg loss: 0.3401, batch size: 44
2021-08-25 05:03:55,714 INFO [train.py:450] Epoch 2, batch 10780, batch avg loss 0.3884, total avg loss: 0.3404, batch size: 42
2021-08-25 05:04:02,420 INFO [train.py:450] Epoch 2, batch 10790, batch avg loss 0.4513, total avg loss: 0.3414, batch size: 38
2021-08-25 05:04:13,065 INFO [train.py:450] Epoch 2, batch 10800, batch avg loss 0.3906, total avg loss: 0.3414, batch size: 38
2021-08-25 05:04:19,913 INFO [train.py:450] Epoch 2, batch 10810, batch avg loss 0.3263, total avg loss: 0.3367, batch size: 39
2021-08-25 05:04:27,028 INFO [train.py:450] Epoch 2, batch 10820, batch avg loss 0.3018, total avg loss: 0.3389, batch size: 39
2021-08-25 05:04:34,166 INFO [train.py:450] Epoch 2, batch 10830, batch avg loss 0.2762, total avg loss: 0.3416, batch size: 36
2021-08-25 05:04:40,993 INFO [train.py:450] Epoch 2, batch 10840, batch avg loss 0.3277, total avg loss: 0.3409, batch size: 40
2021-08-25 05:04:47,861 INFO [train.py:450] Epoch 2, batch 10850, batch avg loss 0.3430, total avg loss: 0.3425, batch size: 38
2021-08-25 05:04:54,785 INFO [train.py:450] Epoch 2, batch 10860, batch avg loss 0.3475, total avg loss: 0.3439, batch size: 40
2021-08-25 05:05:01,475 INFO [train.py:450] Epoch 2, batch 10870, batch avg loss 0.3633, total avg loss: 0.3423, batch size: 45
2021-08-25 05:05:08,304 INFO [train.py:450] Epoch 2, batch 10880, batch avg loss 0.3865, total avg loss: 0.3413, batch size: 38
2021-08-25 05:05:15,508 INFO [train.py:450] Epoch 2, batch 10890, batch avg loss 0.3602, total avg loss: 0.3414, batch size: 38
2021-08-25 05:05:21,866 INFO [train.py:450] Epoch 2, batch 10900, batch avg loss 0.3888, total avg loss: 0.3429, batch size: 39
2021-08-25 05:05:28,361 INFO [train.py:450] Epoch 2, batch 10910, batch avg loss 0.3374, total avg loss: 0.3424, batch size: 43
2021-08-25 05:05:35,084 INFO [train.py:450] Epoch 2, batch 10920, batch avg loss 0.3318, total avg loss: 0.3433, batch size: 38
2021-08-25 05:05:40,201 WARNING [cut.py:1694] To perform mix, energy must be non-zero and non-negative (got 0.0).  MonoCut with id "4b09ba69-6215-be01-f813-b0be7e471d4a" will not be mixed in.
2021-08-25 05:05:41,881 INFO [train.py:450] Epoch 2, batch 10930, batch avg loss 0.3533, total avg loss: 0.3430, batch size: 38
2021-08-25 05:05:48,512 INFO [train.py:450] Epoch 2, batch 10940, batch avg loss 0.2909, total avg loss: 0.3415, batch size: 40
2021-08-25 05:05:55,258 INFO [train.py:450] Epoch 2, batch 10950, batch avg loss 0.3749, total avg loss: 0.3415, batch size: 41
2021-08-25 05:06:02,273 INFO [train.py:450] Epoch 2, batch 10960, batch avg loss 0.3971, total avg loss: 0.3422, batch size: 43
2021-08-25 05:06:09,885 INFO [train.py:450] Epoch 2, batch 10970, batch avg loss 0.3387, total avg loss: 0.3414, batch size: 37
2021-08-25 05:06:16,596 INFO [train.py:450] Epoch 2, batch 10980, batch avg loss 0.3173, total avg loss: 0.3408, batch size: 41
2021-08-25 05:06:22,815 INFO [train.py:450] Epoch 2, batch 10990, batch avg loss 0.3407, total avg loss: 0.3413, batch size: 37
2021-08-25 05:06:29,518 INFO [train.py:450] Epoch 2, batch 11000, batch avg loss 0.3899, total avg loss: 0.3419, batch size: 39
2021-08-25 05:07:08,954 INFO [train.py:482] Epoch 2, valid loss 0.2450, best valid loss: 0.2442 best valid epoch: 2
2021-08-25 05:07:14,853 INFO [train.py:450] Epoch 2, batch 11010, batch avg loss 0.4016, total avg loss: 0.3682, batch size: 39
2021-08-25 05:07:22,784 INFO [train.py:450] Epoch 2, batch 11020, batch avg loss 0.3161, total avg loss: 0.3455, batch size: 43
2021-08-25 05:07:29,164 INFO [train.py:450] Epoch 2, batch 11030, batch avg loss 0.3165, total avg loss: 0.3473, batch size: 42
2021-08-25 05:07:38,787 INFO [train.py:450] Epoch 2, batch 11040, batch avg loss 0.3126, total avg loss: 0.3424, batch size: 38
2021-08-25 05:07:45,707 INFO [train.py:450] Epoch 2, batch 11050, batch avg loss 0.3465, total avg loss: 0.3416, batch size: 43
2021-08-25 05:07:52,948 INFO [train.py:450] Epoch 2, batch 11060, batch avg loss 0.3943, total avg loss: 0.3425, batch size: 48
2021-08-25 05:07:59,908 INFO [train.py:450] Epoch 2, batch 11070, batch avg loss 0.3110, total avg loss: 0.3436, batch size: 39
2021-08-25 05:08:06,963 INFO [train.py:450] Epoch 2, batch 11080, batch avg loss 0.3375, total avg loss: 0.3430, batch size: 38
2021-08-25 05:08:13,600 INFO [train.py:450] Epoch 2, batch 11090, batch avg loss 0.3910, total avg loss: 0.3428, batch size: 42
2021-08-25 05:08:20,318 INFO [train.py:450] Epoch 2, batch 11100, batch avg loss 0.3385, total avg loss: 0.3416, batch size: 38
2021-08-25 05:08:26,926 INFO [train.py:450] Epoch 2, batch 11110, batch avg loss 0.4140, total avg loss: 0.3430, batch size: 38
2021-08-25 05:08:33,189 INFO [train.py:450] Epoch 2, batch 11120, batch avg loss 0.3628, total avg loss: 0.3420, batch size: 41
2021-08-25 05:08:39,918 INFO [train.py:450] Epoch 2, batch 11130, batch avg loss 0.3206, total avg loss: 0.3427, batch size: 42
2021-08-25 05:08:46,212 INFO [train.py:450] Epoch 2, batch 11140, batch avg loss 0.3253, total avg loss: 0.3424, batch size: 43
2021-08-25 05:08:53,191 INFO [train.py:450] Epoch 2, batch 11150, batch avg loss 0.3407, total avg loss: 0.3415, batch size: 41
2021-08-25 05:08:59,579 INFO [train.py:450] Epoch 2, batch 11160, batch avg loss 0.3500, total avg loss: 0.3412, batch size: 37
2021-08-25 05:09:06,636 INFO [train.py:450] Epoch 2, batch 11170, batch avg loss 0.3711, total avg loss: 0.3406, batch size: 38
2021-08-25 05:09:13,541 INFO [train.py:450] Epoch 2, batch 11180, batch avg loss 0.3306, total avg loss: 0.3399, batch size: 43
2021-08-25 05:09:20,736 INFO [train.py:450] Epoch 2, batch 11190, batch avg loss 0.3611, total avg loss: 0.3411, batch size: 42
2021-08-25 05:09:27,967 INFO [train.py:450] Epoch 2, batch 11200, batch avg loss 0.3541, total avg loss: 0.3411, batch size: 41
2021-08-25 05:09:35,080 INFO [train.py:450] Epoch 2, batch 11210, batch avg loss 0.3382, total avg loss: 0.3373, batch size: 40
2021-08-25 05:09:42,046 INFO [train.py:450] Epoch 2, batch 11220, batch avg loss 0.3820, total avg loss: 0.3377, batch size: 42
2021-08-25 05:09:48,780 INFO [train.py:450] Epoch 2, batch 11230, batch avg loss 0.3076, total avg loss: 0.3383, batch size: 41
2021-08-25 05:09:55,368 INFO [train.py:450] Epoch 2, batch 11240, batch avg loss 0.3224, total avg loss: 0.3384, batch size: 40
2021-08-25 05:10:02,188 INFO [train.py:450] Epoch 2, batch 11250, batch avg loss 0.3483, total avg loss: 0.3376, batch size: 39
2021-08-25 05:10:09,225 INFO [train.py:450] Epoch 2, batch 11260, batch avg loss 0.3459, total avg loss: 0.3357, batch size: 43
2021-08-25 05:10:16,106 INFO [train.py:450] Epoch 2, batch 11270, batch avg loss 0.3742, total avg loss: 0.3375, batch size: 37
2021-08-25 05:10:22,506 INFO [train.py:450] Epoch 2, batch 11280, batch avg loss 0.3547, total avg loss: 0.3392, batch size: 41
2021-08-25 05:10:29,411 INFO [train.py:450] Epoch 2, batch 11290, batch avg loss 0.3465, total avg loss: 0.3395, batch size: 40
2021-08-25 05:10:36,547 INFO [train.py:450] Epoch 2, batch 11300, batch avg loss 0.3640, total avg loss: 0.3408, batch size: 42
2021-08-25 05:10:43,357 INFO [train.py:450] Epoch 2, batch 11310, batch avg loss 0.3094, total avg loss: 0.3398, batch size: 41
2021-08-25 05:10:50,262 INFO [train.py:450] Epoch 2, batch 11320, batch avg loss 0.3679, total avg loss: 0.3410, batch size: 40
2021-08-25 05:10:58,470 INFO [train.py:450] Epoch 2, batch 11330, batch avg loss 0.3381, total avg loss: 0.3405, batch size: 37
2021-08-25 05:11:04,671 INFO [train.py:450] Epoch 2, batch 11340, batch avg loss 0.2991, total avg loss: 0.3399, batch size: 39
2021-08-25 05:11:15,283 INFO [train.py:450] Epoch 2, batch 11350, batch avg loss 0.3667, total avg loss: 0.3403, batch size: 43
2021-08-25 05:11:21,801 INFO [train.py:450] Epoch 2, batch 11360, batch avg loss 0.3433, total avg loss: 0.3409, batch size: 37
2021-08-25 05:11:28,347 INFO [train.py:450] Epoch 2, batch 11370, batch avg loss 0.2884, total avg loss: 0.3400, batch size: 38
2021-08-25 05:11:35,378 INFO [train.py:450] Epoch 2, batch 11380, batch avg loss 0.3202, total avg loss: 0.3399, batch size: 42
2021-08-25 05:11:42,040 INFO [train.py:450] Epoch 2, batch 11390, batch avg loss 0.4029, total avg loss: 0.3396, batch size: 36
2021-08-25 05:11:48,987 INFO [train.py:450] Epoch 2, batch 11400, batch avg loss 0.3570, total avg loss: 0.3396, batch size: 39
2021-08-25 05:11:55,476 INFO [train.py:450] Epoch 2, batch 11410, batch avg loss 0.3372, total avg loss: 0.3473, batch size: 38
2021-08-25 05:12:02,592 INFO [train.py:450] Epoch 2, batch 11420, batch avg loss 0.3436, total avg loss: 0.3525, batch size: 41
2021-08-25 05:12:09,558 INFO [train.py:450] Epoch 2, batch 11430, batch avg loss 0.3525, total avg loss: 0.3464, batch size: 39
2021-08-25 05:12:16,267 INFO [train.py:450] Epoch 2, batch 11440, batch avg loss 0.3084, total avg loss: 0.3451, batch size: 43
2021-08-25 05:12:22,538 INFO [train.py:450] Epoch 2, batch 11450, batch avg loss 0.4202, total avg loss: 0.3451, batch size: 37
2021-08-25 05:12:29,231 INFO [train.py:450] Epoch 2, batch 11460, batch avg loss 0.3505, total avg loss: 0.3445, batch size: 38
2021-08-25 05:12:35,737 INFO [train.py:450] Epoch 2, batch 11470, batch avg loss 0.3512, total avg loss: 0.3444, batch size: 42
2021-08-25 05:12:42,296 INFO [train.py:450] Epoch 2, batch 11480, batch avg loss 0.3133, total avg loss: 0.3423, batch size: 38
2021-08-25 05:12:48,941 INFO [train.py:450] Epoch 2, batch 11490, batch avg loss 0.3190, total avg loss: 0.3429, batch size: 39
2021-08-25 05:12:55,476 INFO [train.py:450] Epoch 2, batch 11500, batch avg loss 0.3039, total avg loss: 0.3439, batch size: 37
2021-08-25 05:13:03,207 INFO [train.py:450] Epoch 2, batch 11510, batch avg loss 0.3506, total avg loss: 0.3434, batch size: 41
2021-08-25 05:13:09,362 INFO [train.py:450] Epoch 2, batch 11520, batch avg loss 0.3080, total avg loss: 0.3426, batch size: 39
2021-08-25 05:13:15,708 INFO [train.py:450] Epoch 2, batch 11530, batch avg loss 0.4037, total avg loss: 0.3436, batch size: 40
2021-08-25 05:13:22,487 INFO [train.py:450] Epoch 2, batch 11540, batch avg loss 0.3113, total avg loss: 0.3437, batch size: 41
2021-08-25 05:13:29,277 INFO [train.py:450] Epoch 2, batch 11550, batch avg loss 0.3731, total avg loss: 0.3431, batch size: 38
2021-08-25 05:13:35,866 INFO [train.py:450] Epoch 2, batch 11560, batch avg loss 0.3518, total avg loss: 0.3428, batch size: 38
2021-08-25 05:13:42,316 INFO [train.py:450] Epoch 2, batch 11570, batch avg loss 0.3504, total avg loss: 0.3428, batch size: 42
2021-08-25 05:13:48,994 INFO [train.py:450] Epoch 2, batch 11580, batch avg loss 0.3137, total avg loss: 0.3439, batch size: 37
2021-08-25 05:13:55,593 INFO [train.py:450] Epoch 2, batch 11590, batch avg loss 0.3517, total avg loss: 0.3431, batch size: 41
2021-08-25 05:14:02,844 INFO [train.py:450] Epoch 2, batch 11600, batch avg loss 0.3395, total avg loss: 0.3432, batch size: 43
2021-08-25 05:14:09,931 INFO [train.py:450] Epoch 2, batch 11610, batch avg loss 0.4018, total avg loss: 0.3442, batch size: 41
2021-08-25 05:14:16,928 INFO [train.py:450] Epoch 2, batch 11620, batch avg loss 0.3893, total avg loss: 0.3449, batch size: 44
2021-08-25 05:14:23,700 INFO [train.py:450] Epoch 2, batch 11630, batch avg loss 0.2989, total avg loss: 0.3425, batch size: 40
2021-08-25 05:14:30,983 INFO [train.py:450] Epoch 2, batch 11640, batch avg loss 0.3403, total avg loss: 0.3428, batch size: 40
2021-08-25 05:14:38,097 INFO [train.py:450] Epoch 2, batch 11650, batch avg loss 0.3854, total avg loss: 0.3465, batch size: 38
2021-08-25 05:14:44,840 INFO [train.py:450] Epoch 2, batch 11660, batch avg loss 0.3271, total avg loss: 0.3446, batch size: 39
2021-08-25 05:14:53,810 INFO [train.py:450] Epoch 2, batch 11670, batch avg loss 0.3731, total avg loss: 0.3451, batch size: 39
2021-08-25 05:15:00,331 INFO [train.py:450] Epoch 2, batch 11680, batch avg loss 0.3264, total avg loss: 0.3441, batch size: 42
2021-08-25 05:15:07,088 INFO [train.py:450] Epoch 2, batch 11690, batch avg loss 0.3789, total avg loss: 0.3431, batch size: 37
2021-08-25 05:15:14,046 INFO [train.py:450] Epoch 2, batch 11700, batch avg loss 0.3734, total avg loss: 0.3436, batch size: 43
2021-08-25 05:15:20,734 INFO [train.py:450] Epoch 2, batch 11710, batch avg loss 0.3424, total avg loss: 0.3456, batch size: 43
2021-08-25 05:15:27,000 INFO [train.py:450] Epoch 2, batch 11720, batch avg loss 0.3323, total avg loss: 0.3457, batch size: 42
2021-08-25 05:15:33,840 INFO [train.py:450] Epoch 2, batch 11730, batch avg loss 0.3308, total avg loss: 0.3456, batch size: 40
2021-08-25 05:15:41,517 INFO [train.py:450] Epoch 2, batch 11740, batch avg loss 0.3441, total avg loss: 0.3452, batch size: 41
2021-08-25 05:15:48,129 INFO [train.py:450] Epoch 2, batch 11750, batch avg loss 0.3148, total avg loss: 0.3439, batch size: 42
2021-08-25 05:15:54,941 INFO [train.py:450] Epoch 2, batch 11760, batch avg loss 0.3827, total avg loss: 0.3445, batch size: 41
2021-08-25 05:16:01,399 INFO [train.py:450] Epoch 2, batch 11770, batch avg loss 0.3313, total avg loss: 0.3444, batch size: 40
2021-08-25 05:16:08,257 INFO [train.py:450] Epoch 2, batch 11780, batch avg loss 0.3587, total avg loss: 0.3450, batch size: 43
2021-08-25 05:16:15,096 INFO [train.py:450] Epoch 2, batch 11790, batch avg loss 0.3467, total avg loss: 0.3454, batch size: 40
2021-08-25 05:16:21,617 INFO [train.py:450] Epoch 2, batch 11800, batch avg loss 0.4144, total avg loss: 0.3455, batch size: 42
2021-08-25 05:16:28,417 INFO [train.py:450] Epoch 2, batch 11810, batch avg loss 0.3734, total avg loss: 0.3368, batch size: 45
2021-08-25 05:16:35,352 INFO [train.py:450] Epoch 2, batch 11820, batch avg loss 0.3101, total avg loss: 0.3403, batch size: 40
2021-08-25 05:16:42,271 INFO [train.py:450] Epoch 2, batch 11830, batch avg loss 0.3414, total avg loss: 0.3393, batch size: 37
2021-08-25 05:16:48,725 INFO [train.py:450] Epoch 2, batch 11840, batch avg loss 0.3683, total avg loss: 0.3413, batch size: 40
2021-08-25 05:16:55,910 INFO [train.py:450] Epoch 2, batch 11850, batch avg loss 0.3448, total avg loss: 0.3390, batch size: 38
2021-08-25 05:17:02,639 INFO [train.py:450] Epoch 2, batch 11860, batch avg loss 0.2955, total avg loss: 0.3349, batch size: 40
2021-08-25 05:17:09,370 INFO [train.py:450] Epoch 2, batch 11870, batch avg loss 0.3559, total avg loss: 0.3365, batch size: 43
2021-08-25 05:17:15,814 INFO [train.py:450] Epoch 2, batch 11880, batch avg loss 0.3252, total avg loss: 0.3380, batch size: 39
2021-08-25 05:17:22,642 INFO [train.py:450] Epoch 2, batch 11890, batch avg loss 0.3756, total avg loss: 0.3397, batch size: 39
2021-08-25 05:17:28,937 INFO [train.py:450] Epoch 2, batch 11900, batch avg loss 0.3229, total avg loss: 0.3386, batch size: 41
2021-08-25 05:17:35,177 INFO [train.py:450] Epoch 2, batch 11910, batch avg loss 0.3216, total avg loss: 0.3386, batch size: 40
2021-08-25 05:17:42,036 INFO [train.py:450] Epoch 2, batch 11920, batch avg loss 0.3825, total avg loss: 0.3406, batch size: 41
2021-08-25 05:17:48,354 INFO [train.py:450] Epoch 2, batch 11930, batch avg loss 0.3254, total avg loss: 0.3411, batch size: 37
2021-08-25 05:17:54,500 INFO [train.py:450] Epoch 2, batch 11940, batch avg loss 0.3549, total avg loss: 0.3419, batch size: 41
2021-08-25 05:18:03,299 INFO [train.py:450] Epoch 2, batch 11950, batch avg loss 0.3733, total avg loss: 0.3440, batch size: 41
2021-08-25 05:18:13,771 INFO [train.py:450] Epoch 2, batch 11960, batch avg loss 0.3437, total avg loss: 0.3437, batch size: 40
2021-08-25 05:18:19,997 INFO [train.py:450] Epoch 2, batch 11970, batch avg loss 0.2901, total avg loss: 0.3437, batch size: 38
2021-08-25 05:18:26,389 INFO [train.py:450] Epoch 2, batch 11980, batch avg loss 0.3455, total avg loss: 0.3428, batch size: 42
2021-08-25 05:18:32,907 INFO [train.py:450] Epoch 2, batch 11990, batch avg loss 0.3255, total avg loss: 0.3422, batch size: 40
2021-08-25 05:18:39,132 INFO [train.py:450] Epoch 2, batch 12000, batch avg loss 0.4257, total avg loss: 0.3428, batch size: 40
2021-08-25 05:19:16,132 INFO [train.py:482] Epoch 2, valid loss 0.2454, best valid loss: 0.2442 best valid epoch: 2
2021-08-25 05:19:21,922 INFO [train.py:450] Epoch 2, batch 12010, batch avg loss 0.3209, total avg loss: 0.3439, batch size: 40
2021-08-25 05:19:27,822 INFO [train.py:450] Epoch 2, batch 12020, batch avg loss 0.3388, total avg loss: 0.3483, batch size: 43
2021-08-25 05:19:33,909 INFO [train.py:450] Epoch 2, batch 12030, batch avg loss 0.3536, total avg loss: 0.3428, batch size: 42
2021-08-25 05:19:40,104 INFO [train.py:450] Epoch 2, batch 12040, batch avg loss 0.3382, total avg loss: 0.3434, batch size: 43
2021-08-25 05:19:46,518 INFO [train.py:450] Epoch 2, batch 12050, batch avg loss 0.3714, total avg loss: 0.3438, batch size: 39
2021-08-25 05:19:52,806 INFO [train.py:450] Epoch 2, batch 12060, batch avg loss 0.3632, total avg loss: 0.3410, batch size: 39
2021-08-25 05:19:59,721 INFO [train.py:450] Epoch 2, batch 12070, batch avg loss 0.3543, total avg loss: 0.3416, batch size: 42
2021-08-25 05:20:06,135 INFO [train.py:450] Epoch 2, batch 12080, batch avg loss 0.2681, total avg loss: 0.3394, batch size: 38
2021-08-25 05:20:12,802 INFO [train.py:450] Epoch 2, batch 12090, batch avg loss 0.3478, total avg loss: 0.3408, batch size: 38
2021-08-25 05:20:19,249 INFO [train.py:450] Epoch 2, batch 12100, batch avg loss 0.3699, total avg loss: 0.3412, batch size: 41
2021-08-25 05:20:25,518 INFO [train.py:450] Epoch 2, batch 12110, batch avg loss 0.3309, total avg loss: 0.3410, batch size: 39
2021-08-25 05:20:32,013 INFO [train.py:450] Epoch 2, batch 12120, batch avg loss 0.3377, total avg loss: 0.3402, batch size: 39
2021-08-25 05:20:38,635 INFO [train.py:450] Epoch 2, batch 12130, batch avg loss 0.3165, total avg loss: 0.3401, batch size: 36
2021-08-25 05:20:44,990 INFO [train.py:450] Epoch 2, batch 12140, batch avg loss 0.3579, total avg loss: 0.3398, batch size: 44
2021-08-25 05:20:51,199 INFO [train.py:450] Epoch 2, batch 12150, batch avg loss 0.4153, total avg loss: 0.3416, batch size: 38
2021-08-25 05:20:57,459 INFO [train.py:450] Epoch 2, batch 12160, batch avg loss 0.3227, total avg loss: 0.3424, batch size: 42
2021-08-25 05:21:03,857 INFO [train.py:450] Epoch 2, batch 12170, batch avg loss 0.3587, total avg loss: 0.3431, batch size: 37
2021-08-25 05:21:10,302 INFO [train.py:450] Epoch 2, batch 12180, batch avg loss 0.3382, total avg loss: 0.3427, batch size: 38
2021-08-25 05:21:16,367 INFO [train.py:450] Epoch 2, batch 12190, batch avg loss 0.3258, total avg loss: 0.3417, batch size: 39
2021-08-25 05:21:23,457 INFO [train.py:450] Epoch 2, batch 12200, batch avg loss 0.4018, total avg loss: 0.3419, batch size: 37
2021-08-25 05:21:29,419 INFO [train.py:450] Epoch 2, batch 12210, batch avg loss 0.3497, total avg loss: 0.3160, batch size: 41
2021-08-25 05:21:37,708 INFO [train.py:450] Epoch 2, batch 12220, batch avg loss 0.3042, total avg loss: 0.3215, batch size: 38
2021-08-25 05:21:43,913 INFO [train.py:450] Epoch 2, batch 12230, batch avg loss 0.3778, total avg loss: 0.3302, batch size: 42
2021-08-25 05:21:52,164 INFO [train.py:450] Epoch 2, batch 12240, batch avg loss 0.3210, total avg loss: 0.3300, batch size: 39
2021-08-25 05:22:00,522 INFO [train.py:450] Epoch 2, batch 12250, batch avg loss 0.3645, total avg loss: 0.3344, batch size: 40
2021-08-25 05:22:06,893 INFO [train.py:450] Epoch 2, batch 12260, batch avg loss 0.3265, total avg loss: 0.3368, batch size: 39
2021-08-25 05:22:13,364 INFO [train.py:450] Epoch 2, batch 12270, batch avg loss 0.3679, total avg loss: 0.3387, batch size: 43
2021-08-25 05:22:19,366 INFO [train.py:450] Epoch 2, batch 12280, batch avg loss 0.2702, total avg loss: 0.3374, batch size: 39
2021-08-25 05:22:25,465 INFO [train.py:450] Epoch 2, batch 12290, batch avg loss 0.3578, total avg loss: 0.3366, batch size: 40
2021-08-25 05:22:31,890 INFO [train.py:450] Epoch 2, batch 12300, batch avg loss 0.3101, total avg loss: 0.3361, batch size: 38
2021-08-25 05:22:37,877 INFO [train.py:450] Epoch 2, batch 12310, batch avg loss 0.3348, total avg loss: 0.3377, batch size: 41
2021-08-25 05:22:44,351 INFO [train.py:450] Epoch 2, batch 12320, batch avg loss 0.3460, total avg loss: 0.3369, batch size: 39
2021-08-25 05:22:50,844 INFO [train.py:450] Epoch 2, batch 12330, batch avg loss 0.3496, total avg loss: 0.3382, batch size: 42
2021-08-25 05:22:56,703 INFO [train.py:450] Epoch 2, batch 12340, batch avg loss 0.3688, total avg loss: 0.3387, batch size: 40
2021-08-25 05:23:03,175 INFO [train.py:450] Epoch 2, batch 12350, batch avg loss 0.3678, total avg loss: 0.3386, batch size: 36
2021-08-25 05:23:09,548 INFO [train.py:450] Epoch 2, batch 12360, batch avg loss 0.3685, total avg loss: 0.3395, batch size: 45
2021-08-25 05:23:16,107 INFO [train.py:450] Epoch 2, batch 12370, batch avg loss 0.3370, total avg loss: 0.3389, batch size: 39
2021-08-25 05:23:22,528 INFO [train.py:450] Epoch 2, batch 12380, batch avg loss 0.3806, total avg loss: 0.3389, batch size: 38
2021-08-25 05:23:28,949 INFO [train.py:450] Epoch 2, batch 12390, batch avg loss 0.3746, total avg loss: 0.3392, batch size: 40
2021-08-25 05:23:35,077 INFO [train.py:450] Epoch 2, batch 12400, batch avg loss 0.2736, total avg loss: 0.3391, batch size: 37
2021-08-25 05:23:41,453 INFO [train.py:450] Epoch 2, batch 12410, batch avg loss 0.3538, total avg loss: 0.3383, batch size: 43
2021-08-25 05:23:47,650 INFO [train.py:450] Epoch 2, batch 12420, batch avg loss 0.2977, total avg loss: 0.3348, batch size: 36
2021-08-25 05:23:53,714 INFO [train.py:450] Epoch 2, batch 12430, batch avg loss 0.3112, total avg loss: 0.3295, batch size: 42
2021-08-25 05:24:00,133 INFO [train.py:450] Epoch 2, batch 12440, batch avg loss 0.2861, total avg loss: 0.3293, batch size: 40
2021-08-25 05:24:06,212 INFO [train.py:450] Epoch 2, batch 12450, batch avg loss 0.3205, total avg loss: 0.3277, batch size: 40
2021-08-25 05:24:12,595 INFO [train.py:450] Epoch 2, batch 12460, batch avg loss 0.3680, total avg loss: 0.3302, batch size: 39
2021-08-25 05:24:19,186 INFO [train.py:450] Epoch 2, batch 12470, batch avg loss 0.3608, total avg loss: 0.3321, batch size: 42
2021-08-25 05:24:25,549 INFO [train.py:450] Epoch 2, batch 12480, batch avg loss 0.3312, total avg loss: 0.3346, batch size: 36
2021-08-25 05:24:31,760 INFO [train.py:450] Epoch 2, batch 12490, batch avg loss 0.3998, total avg loss: 0.3351, batch size: 39
2021-08-25 05:24:37,748 INFO [train.py:450] Epoch 2, batch 12500, batch avg loss 0.3236, total avg loss: 0.3343, batch size: 41
2021-08-25 05:24:44,327 INFO [train.py:450] Epoch 2, batch 12510, batch avg loss 0.3083, total avg loss: 0.3342, batch size: 40
2021-08-25 05:24:50,860 INFO [train.py:450] Epoch 2, batch 12520, batch avg loss 0.3747, total avg loss: 0.3349, batch size: 39
2021-08-25 05:24:57,220 INFO [train.py:450] Epoch 2, batch 12530, batch avg loss 0.3658, total avg loss: 0.3348, batch size: 39
2021-08-25 05:25:03,649 INFO [train.py:450] Epoch 2, batch 12540, batch avg loss 0.3529, total avg loss: 0.3337, batch size: 41
2021-08-25 05:25:09,935 INFO [train.py:450] Epoch 2, batch 12550, batch avg loss 0.3487, total avg loss: 0.3343, batch size: 41
2021-08-25 05:25:17,723 INFO [train.py:450] Epoch 2, batch 12560, batch avg loss 0.2794, total avg loss: 0.3351, batch size: 39
2021-08-25 05:25:23,695 INFO [train.py:450] Epoch 2, batch 12570, batch avg loss 0.3195, total avg loss: 0.3357, batch size: 37
2021-08-25 05:25:34,280 INFO [train.py:450] Epoch 2, batch 12580, batch avg loss 0.3858, total avg loss: 0.3352, batch size: 40
2021-08-25 05:25:40,700 INFO [train.py:450] Epoch 2, batch 12590, batch avg loss 0.3557, total avg loss: 0.3363, batch size: 46
2021-08-25 05:25:46,925 INFO [train.py:450] Epoch 2, batch 12600, batch avg loss 0.3169, total avg loss: 0.3371, batch size: 40
2021-08-25 05:25:53,011 INFO [train.py:450] Epoch 2, batch 12610, batch avg loss 0.3521, total avg loss: 0.3217, batch size: 39
2021-08-25 05:25:59,436 INFO [train.py:450] Epoch 2, batch 12620, batch avg loss 0.3587, total avg loss: 0.3390, batch size: 41
2021-08-25 05:26:05,903 INFO [train.py:450] Epoch 2, batch 12630, batch avg loss 0.3730, total avg loss: 0.3425, batch size: 38
2021-08-25 05:26:12,257 INFO [train.py:450] Epoch 2, batch 12640, batch avg loss 0.3373, total avg loss: 0.3418, batch size: 40
2021-08-25 05:26:18,246 INFO [train.py:450] Epoch 2, batch 12650, batch avg loss 0.3467, total avg loss: 0.3392, batch size: 45
2021-08-25 05:26:24,545 INFO [train.py:450] Epoch 2, batch 12660, batch avg loss 0.3619, total avg loss: 0.3378, batch size: 43
2021-08-25 05:26:30,959 INFO [train.py:450] Epoch 2, batch 12670, batch avg loss 0.3137, total avg loss: 0.3375, batch size: 39
2021-08-25 05:26:37,016 INFO [train.py:450] Epoch 2, batch 12680, batch avg loss 0.3879, total avg loss: 0.3377, batch size: 42
2021-08-25 05:26:43,305 INFO [train.py:450] Epoch 2, batch 12690, batch avg loss 0.3865, total avg loss: 0.3398, batch size: 43
2021-08-25 05:26:49,503 INFO [train.py:450] Epoch 2, batch 12700, batch avg loss 0.3448, total avg loss: 0.3405, batch size: 43
2021-08-25 05:26:56,122 INFO [train.py:450] Epoch 2, batch 12710, batch avg loss 0.3354, total avg loss: 0.3403, batch size: 44
2021-08-25 05:27:02,469 INFO [train.py:450] Epoch 2, batch 12720, batch avg loss 0.2980, total avg loss: 0.3392, batch size: 38
2021-08-25 05:27:08,659 INFO [train.py:450] Epoch 2, batch 12730, batch avg loss 0.3195, total avg loss: 0.3404, batch size: 36
2021-08-25 05:27:14,618 INFO [train.py:450] Epoch 2, batch 12740, batch avg loss 0.3533, total avg loss: 0.3405, batch size: 38
2021-08-25 05:27:20,483 INFO [train.py:450] Epoch 2, batch 12750, batch avg loss 0.3447, total avg loss: 0.3398, batch size: 42
2021-08-25 05:27:26,427 INFO [train.py:450] Epoch 2, batch 12760, batch avg loss 0.4023, total avg loss: 0.3399, batch size: 39
2021-08-25 05:27:32,756 INFO [train.py:450] Epoch 2, batch 12770, batch avg loss 0.3913, total avg loss: 0.3394, batch size: 41
2021-08-25 05:27:39,028 INFO [train.py:450] Epoch 2, batch 12780, batch avg loss 0.3430, total avg loss: 0.3395, batch size: 45
2021-08-25 05:27:45,015 INFO [train.py:450] Epoch 2, batch 12790, batch avg loss 0.3652, total avg loss: 0.3399, batch size: 43
2021-08-25 05:27:51,481 INFO [train.py:450] Epoch 2, batch 12800, batch avg loss 0.3207, total avg loss: 0.3398, batch size: 43
2021-08-25 05:27:57,972 INFO [train.py:450] Epoch 2, batch 12810, batch avg loss 0.3658, total avg loss: 0.3452, batch size: 36
2021-08-25 05:28:04,606 INFO [train.py:450] Epoch 2, batch 12820, batch avg loss 0.3222, total avg loss: 0.3490, batch size: 41
2021-08-25 05:28:11,048 INFO [train.py:450] Epoch 2, batch 12830, batch avg loss 0.3179, total avg loss: 0.3452, batch size: 44
2021-08-25 05:28:17,414 INFO [train.py:450] Epoch 2, batch 12840, batch avg loss 0.3456, total avg loss: 0.3425, batch size: 38
2021-08-25 05:28:23,518 INFO [train.py:450] Epoch 2, batch 12850, batch avg loss 0.3660, total avg loss: 0.3423, batch size: 41
2021-08-25 05:28:29,746 INFO [train.py:450] Epoch 2, batch 12860, batch avg loss 0.3583, total avg loss: 0.3435, batch size: 38
2021-08-25 05:28:36,090 INFO [train.py:450] Epoch 2, batch 12870, batch avg loss 0.3117, total avg loss: 0.3412, batch size: 39
2021-08-25 05:28:42,304 INFO [train.py:450] Epoch 2, batch 12880, batch avg loss 0.3474, total avg loss: 0.3420, batch size: 39
2021-08-25 05:28:48,615 INFO [train.py:450] Epoch 2, batch 12890, batch avg loss 0.3268, total avg loss: 0.3422, batch size: 45
2021-08-25 05:28:54,655 INFO [train.py:450] Epoch 2, batch 12900, batch avg loss 0.3404, total avg loss: 0.3421, batch size: 37
2021-08-25 05:29:00,953 INFO [train.py:450] Epoch 2, batch 12910, batch avg loss 0.3597, total avg loss: 0.3410, batch size: 40
2021-08-25 05:29:07,537 INFO [train.py:450] Epoch 2, batch 12920, batch avg loss 0.3512, total avg loss: 0.3402, batch size: 42
2021-08-25 05:29:13,704 INFO [train.py:450] Epoch 2, batch 12930, batch avg loss 0.3942, total avg loss: 0.3403, batch size: 41
2021-08-25 05:29:19,910 INFO [train.py:450] Epoch 2, batch 12940, batch avg loss 0.3365, total avg loss: 0.3398, batch size: 41
2021-08-25 05:29:27,746 INFO [train.py:450] Epoch 2, batch 12950, batch avg loss 0.3109, total avg loss: 0.3401, batch size: 40
2021-08-25 05:29:34,054 INFO [train.py:450] Epoch 2, batch 12960, batch avg loss 0.3165, total avg loss: 0.3401, batch size: 42
2021-08-25 05:29:43,527 INFO [train.py:450] Epoch 2, batch 12970, batch avg loss 0.3135, total avg loss: 0.3402, batch size: 40
2021-08-25 05:29:50,331 INFO [train.py:450] Epoch 2, batch 12980, batch avg loss 0.3766, total avg loss: 0.3394, batch size: 40
2021-08-25 05:29:57,024 INFO [train.py:450] Epoch 2, batch 12990, batch avg loss 0.3144, total avg loss: 0.3407, batch size: 42
2021-08-25 05:30:03,664 INFO [train.py:450] Epoch 2, batch 13000, batch avg loss 0.2706, total avg loss: 0.3406, batch size: 42
2021-08-25 05:30:44,263 INFO [train.py:482] Epoch 2, valid loss 0.2438, best valid loss: 0.2438 best valid epoch: 2
2021-08-25 05:30:50,244 INFO [train.py:450] Epoch 2, batch 13010, batch avg loss 0.4015, total avg loss: 0.3573, batch size: 37
2021-08-25 05:30:56,167 INFO [train.py:450] Epoch 2, batch 13020, batch avg loss 0.3418, total avg loss: 0.3538, batch size: 39
2021-08-25 05:31:03,282 INFO [train.py:450] Epoch 2, batch 13030, batch avg loss 0.3462, total avg loss: 0.3490, batch size: 37
2021-08-25 05:31:09,885 INFO [train.py:450] Epoch 2, batch 13040, batch avg loss 0.3567, total avg loss: 0.3487, batch size: 38
2021-08-25 05:31:16,621 INFO [train.py:450] Epoch 2, batch 13050, batch avg loss 0.3101, total avg loss: 0.3467, batch size: 40
2021-08-25 05:31:23,701 INFO [train.py:450] Epoch 2, batch 13060, batch avg loss 0.3393, total avg loss: 0.3478, batch size: 41
2021-08-25 05:31:30,198 INFO [train.py:450] Epoch 2, batch 13070, batch avg loss 0.3710, total avg loss: 0.3465, batch size: 44
2021-08-25 05:31:36,588 INFO [train.py:450] Epoch 2, batch 13080, batch avg loss 0.3207, total avg loss: 0.3447, batch size: 40
2021-08-25 05:31:42,738 INFO [train.py:450] Epoch 2, batch 13090, batch avg loss 0.3690, total avg loss: 0.3430, batch size: 40
2021-08-25 05:31:49,108 INFO [train.py:450] Epoch 2, batch 13100, batch avg loss 0.3324, total avg loss: 0.3433, batch size: 41
2021-08-25 05:31:55,620 INFO [train.py:450] Epoch 2, batch 13110, batch avg loss 0.3299, total avg loss: 0.3420, batch size: 41
2021-08-25 05:32:01,798 INFO [train.py:450] Epoch 2, batch 13120, batch avg loss 0.3718, total avg loss: 0.3429, batch size: 40
2021-08-25 05:32:08,262 INFO [train.py:450] Epoch 2, batch 13130, batch avg loss 0.3390, total avg loss: 0.3417, batch size: 41
2021-08-25 05:32:15,280 INFO [train.py:450] Epoch 2, batch 13140, batch avg loss 0.3765, total avg loss: 0.3414, batch size: 41
2021-08-25 05:32:21,506 INFO [train.py:450] Epoch 2, batch 13150, batch avg loss 0.3176, total avg loss: 0.3411, batch size: 40
2021-08-25 05:32:28,138 INFO [train.py:450] Epoch 2, batch 13160, batch avg loss 0.4123, total avg loss: 0.3420, batch size: 40
2021-08-25 05:32:35,534 INFO [train.py:450] Epoch 2, batch 13170, batch avg loss 0.3581, total avg loss: 0.3426, batch size: 38
2021-08-25 05:32:42,210 INFO [train.py:450] Epoch 2, batch 13180, batch avg loss 0.3665, total avg loss: 0.3419, batch size: 39
2021-08-25 05:32:48,973 INFO [train.py:450] Epoch 2, batch 13190, batch avg loss 0.3548, total avg loss: 0.3412, batch size: 39
2021-08-25 05:32:55,460 INFO [train.py:450] Epoch 2, batch 13200, batch avg loss 0.3612, total avg loss: 0.3419, batch size: 39
2021-08-25 05:33:02,281 INFO [train.py:450] Epoch 2, batch 13210, batch avg loss 0.3350, total avg loss: 0.3632, batch size: 39
2021-08-25 05:33:10,258 INFO [train.py:450] Epoch 2, batch 13220, batch avg loss 0.2724, total avg loss: 0.3488, batch size: 39
2021-08-25 05:33:18,099 INFO [train.py:450] Epoch 2, batch 13230, batch avg loss 0.3597, total avg loss: 0.3448, batch size: 39
2021-08-25 05:33:26,383 INFO [train.py:450] Epoch 2, batch 13240, batch avg loss 0.3476, total avg loss: 0.3433, batch size: 44
2021-08-25 05:33:33,050 INFO [train.py:450] Epoch 2, batch 13250, batch avg loss 0.3801, total avg loss: 0.3427, batch size: 38
2021-08-25 05:33:40,151 INFO [train.py:450] Epoch 2, batch 13260, batch avg loss 0.3227, total avg loss: 0.3431, batch size: 40
2021-08-25 05:33:47,311 INFO [train.py:450] Epoch 2, batch 13270, batch avg loss 0.3492, total avg loss: 0.3446, batch size: 41
2021-08-25 05:33:54,355 INFO [train.py:450] Epoch 2, batch 13280, batch avg loss 0.4402, total avg loss: 0.3453, batch size: 41
2021-08-25 05:34:00,869 INFO [train.py:450] Epoch 2, batch 13290, batch avg loss 0.2923, total avg loss: 0.3436, batch size: 39
2021-08-25 05:34:17,972 INFO [train.py:450] Epoch 2, batch 13300, batch avg loss 0.3428, total avg loss: 0.3433, batch size: 42
2021-08-25 05:34:23,866 INFO [train.py:450] Epoch 2, batch 13310, batch avg loss 0.3494, total avg loss: 0.3443, batch size: 37
2021-08-25 05:34:30,650 INFO [train.py:450] Epoch 2, batch 13320, batch avg loss 0.3797, total avg loss: 0.3442, batch size: 41
2021-08-25 05:34:37,146 INFO [train.py:450] Epoch 2, batch 13330, batch avg loss 0.3266, total avg loss: 0.3443, batch size: 41
2021-08-25 05:34:44,099 INFO [train.py:450] Epoch 2, batch 13340, batch avg loss 0.3953, total avg loss: 0.3456, batch size: 39
2021-08-25 05:34:51,052 INFO [train.py:450] Epoch 2, batch 13350, batch avg loss 0.2971, total avg loss: 0.3439, batch size: 40
2021-08-25 05:34:58,310 INFO [train.py:450] Epoch 2, batch 13360, batch avg loss 0.3296, total avg loss: 0.3428, batch size: 43
2021-08-25 05:35:05,162 INFO [train.py:450] Epoch 2, batch 13370, batch avg loss 0.4115, total avg loss: 0.3437, batch size: 42
2021-08-25 05:35:11,779 INFO [train.py:450] Epoch 2, batch 13380, batch avg loss 0.3209, total avg loss: 0.3435, batch size: 38
2021-08-25 05:35:18,776 INFO [train.py:450] Epoch 2, batch 13390, batch avg loss 0.3779, total avg loss: 0.3433, batch size: 41
2021-08-25 05:35:25,887 INFO [train.py:450] Epoch 2, batch 13400, batch avg loss 0.3059, total avg loss: 0.3435, batch size: 40
2021-08-25 05:35:33,075 INFO [train.py:450] Epoch 2, batch 13410, batch avg loss 0.3437, total avg loss: 0.3315, batch size: 42
2021-08-25 05:35:39,629 INFO [train.py:450] Epoch 2, batch 13420, batch avg loss 0.3822, total avg loss: 0.3417, batch size: 38
2021-08-25 05:35:46,503 INFO [train.py:450] Epoch 2, batch 13430, batch avg loss 0.3119, total avg loss: 0.3405, batch size: 43
2021-08-25 05:35:53,583 INFO [train.py:450] Epoch 2, batch 13440, batch avg loss 0.3296, total avg loss: 0.3406, batch size: 40
2021-08-25 05:36:00,690 INFO [train.py:450] Epoch 2, batch 13450, batch avg loss 0.3478, total avg loss: 0.3428, batch size: 35
2021-08-25 05:36:07,992 INFO [train.py:450] Epoch 2, batch 13460, batch avg loss 0.3334, total avg loss: 0.3405, batch size: 42
2021-08-25 05:36:15,048 INFO [train.py:450] Epoch 2, batch 13470, batch avg loss 0.4257, total avg loss: 0.3426, batch size: 40
2021-08-25 05:36:21,436 INFO [train.py:450] Epoch 2, batch 13480, batch avg loss 0.3705, total avg loss: 0.3415, batch size: 39
2021-08-25 05:36:28,664 INFO [train.py:450] Epoch 2, batch 13490, batch avg loss 0.3499, total avg loss: 0.3411, batch size: 38
2021-08-25 05:36:35,616 INFO [train.py:450] Epoch 2, batch 13500, batch avg loss 0.3394, total avg loss: 0.3409, batch size: 38
2021-08-25 05:36:42,764 INFO [train.py:450] Epoch 2, batch 13510, batch avg loss 0.3546, total avg loss: 0.3415, batch size: 41
2021-08-25 05:36:49,854 INFO [train.py:450] Epoch 2, batch 13520, batch avg loss 0.4053, total avg loss: 0.3424, batch size: 38
2021-08-25 05:36:57,030 INFO [train.py:450] Epoch 2, batch 13530, batch avg loss 0.3796, total avg loss: 0.3425, batch size: 41
2021-08-25 05:37:03,840 INFO [train.py:450] Epoch 2, batch 13540, batch avg loss 0.3531, total avg loss: 0.3417, batch size: 41
2021-08-25 05:37:10,900 INFO [train.py:450] Epoch 2, batch 13550, batch avg loss 0.3254, total avg loss: 0.3415, batch size: 44
2021-08-25 05:37:19,271 INFO [train.py:450] Epoch 2, batch 13560, batch avg loss 0.3425, total avg loss: 0.3416, batch size: 38
2021-08-25 05:37:26,171 INFO [train.py:450] Epoch 2, batch 13570, batch avg loss 0.3076, total avg loss: 0.3416, batch size: 39
2021-08-25 05:37:34,497 INFO [train.py:450] Epoch 2, batch 13580, batch avg loss 0.3251, total avg loss: 0.3409, batch size: 40
2021-08-25 05:37:42,384 INFO [train.py:450] Epoch 2, batch 13590, batch avg loss 0.3394, total avg loss: 0.3404, batch size: 40
2021-08-25 05:37:49,036 INFO [train.py:450] Epoch 2, batch 13600, batch avg loss 0.2773, total avg loss: 0.3397, batch size: 40
2021-08-25 05:37:56,173 INFO [train.py:450] Epoch 2, batch 13610, batch avg loss 0.2809, total avg loss: 0.3489, batch size: 37
2021-08-25 05:38:03,307 INFO [train.py:450] Epoch 2, batch 13620, batch avg loss 0.3036, total avg loss: 0.3386, batch size: 44
2021-08-25 05:38:10,553 INFO [train.py:450] Epoch 2, batch 13630, batch avg loss 0.3131, total avg loss: 0.3322, batch size: 40
2021-08-25 05:38:17,274 INFO [train.py:450] Epoch 2, batch 13640, batch avg loss 0.3378, total avg loss: 0.3385, batch size: 38
2021-08-25 05:38:24,085 INFO [train.py:450] Epoch 2, batch 13650, batch avg loss 0.3600, total avg loss: 0.3413, batch size: 37
2021-08-25 05:38:31,022 INFO [train.py:450] Epoch 2, batch 13660, batch avg loss 0.3107, total avg loss: 0.3418, batch size: 39
2021-08-25 05:38:38,012 INFO [train.py:450] Epoch 2, batch 13670, batch avg loss 0.3150, total avg loss: 0.3422, batch size: 37
2021-08-25 05:38:45,133 INFO [train.py:450] Epoch 2, batch 13680, batch avg loss 0.3086, total avg loss: 0.3410, batch size: 40
2021-08-25 05:38:52,450 INFO [train.py:450] Epoch 2, batch 13690, batch avg loss 0.3363, total avg loss: 0.3402, batch size: 41
2021-08-25 05:38:59,623 INFO [train.py:450] Epoch 2, batch 13700, batch avg loss 0.3297, total avg loss: 0.3417, batch size: 41
2021-08-25 05:39:07,019 INFO [train.py:450] Epoch 2, batch 13710, batch avg loss 0.3057, total avg loss: 0.3410, batch size: 42
2021-08-25 05:39:11,240 WARNING [cut.py:1694] To perform mix, energy must be non-zero and non-negative (got 0.0).  MonoCut with id "1ea72490-1dd3-fd44-3283-6e935d35999e" will not be mixed in.
2021-08-25 05:39:14,183 INFO [train.py:450] Epoch 2, batch 13720, batch avg loss 0.3694, total avg loss: 0.3419, batch size: 39
2021-08-25 05:39:21,465 INFO [train.py:450] Epoch 2, batch 13730, batch avg loss 0.3579, total avg loss: 0.3416, batch size: 38
2021-08-25 05:39:28,649 INFO [train.py:450] Epoch 2, batch 13740, batch avg loss 0.3960, total avg loss: 0.3419, batch size: 44
2021-08-25 05:39:35,350 INFO [train.py:450] Epoch 2, batch 13750, batch avg loss 0.3476, total avg loss: 0.3418, batch size: 39
2021-08-25 05:39:42,649 INFO [train.py:450] Epoch 2, batch 13760, batch avg loss 0.3965, total avg loss: 0.3423, batch size: 37
2021-08-25 05:39:49,990 INFO [train.py:450] Epoch 2, batch 13770, batch avg loss 0.2923, total avg loss: 0.3408, batch size: 37
2021-08-25 05:39:57,088 INFO [train.py:450] Epoch 2, batch 13780, batch avg loss 0.3691, total avg loss: 0.3403, batch size: 39
2021-08-25 05:40:04,013 INFO [train.py:450] Epoch 2, batch 13790, batch avg loss 0.3579, total avg loss: 0.3407, batch size: 42
2021-08-25 05:40:11,384 INFO [train.py:450] Epoch 2, batch 13800, batch avg loss 0.3092, total avg loss: 0.3404, batch size: 40
2021-08-25 05:40:18,783 INFO [train.py:450] Epoch 2, batch 13810, batch avg loss 0.4090, total avg loss: 0.3395, batch size: 43
2021-08-25 05:40:26,039 INFO [train.py:450] Epoch 2, batch 13820, batch avg loss 0.3108, total avg loss: 0.3365, batch size: 43
2021-08-25 05:40:32,969 INFO [train.py:450] Epoch 2, batch 13830, batch avg loss 0.3372, total avg loss: 0.3362, batch size: 40
2021-08-25 05:40:40,274 INFO [train.py:450] Epoch 2, batch 13840, batch avg loss 0.3415, total avg loss: 0.3315, batch size: 39
2021-08-25 05:40:47,289 INFO [train.py:450] Epoch 2, batch 13850, batch avg loss 0.3591, total avg loss: 0.3332, batch size: 39
2021-08-25 05:40:54,252 INFO [train.py:450] Epoch 2, batch 13860, batch avg loss 0.3106, total avg loss: 0.3347, batch size: 39
2021-08-25 05:41:01,426 INFO [train.py:450] Epoch 2, batch 13870, batch avg loss 0.2795, total avg loss: 0.3340, batch size: 39
2021-08-25 05:41:08,664 INFO [train.py:450] Epoch 2, batch 13880, batch avg loss 0.2926, total avg loss: 0.3325, batch size: 42
2021-08-25 05:41:16,262 INFO [train.py:450] Epoch 2, batch 13890, batch avg loss 0.3237, total avg loss: 0.3340, batch size: 39
2021-08-25 05:41:24,358 INFO [train.py:450] Epoch 2, batch 13900, batch avg loss 0.3374, total avg loss: 0.3329, batch size: 39
2021-08-25 05:41:30,671 INFO [train.py:450] Epoch 2, batch 13910, batch avg loss 0.3683, total avg loss: 0.3336, batch size: 40
2021-08-25 05:41:40,524 INFO [train.py:450] Epoch 2, batch 13920, batch avg loss 0.3611, total avg loss: 0.3352, batch size: 41
2021-08-25 05:41:47,389 INFO [train.py:450] Epoch 2, batch 13930, batch avg loss 0.3269, total avg loss: 0.3360, batch size: 39
2021-08-25 05:41:54,425 INFO [train.py:450] Epoch 2, batch 13940, batch avg loss 0.4017, total avg loss: 0.3360, batch size: 35
2021-08-25 05:42:01,698 INFO [train.py:450] Epoch 2, batch 13950, batch avg loss 0.3479, total avg loss: 0.3355, batch size: 41
2021-08-25 05:42:09,561 INFO [train.py:450] Epoch 2, batch 13960, batch avg loss 0.3418, total avg loss: 0.3352, batch size: 34
2021-08-25 05:42:16,185 INFO [train.py:450] Epoch 2, batch 13970, batch avg loss 0.3377, total avg loss: 0.3350, batch size: 43
2021-08-25 05:42:22,972 INFO [train.py:450] Epoch 2, batch 13980, batch avg loss 0.4037, total avg loss: 0.3367, batch size: 41
2021-08-25 05:42:30,322 INFO [train.py:450] Epoch 2, batch 13990, batch avg loss 0.3012, total avg loss: 0.3362, batch size: 40
2021-08-25 05:42:37,408 INFO [train.py:450] Epoch 2, batch 14000, batch avg loss 0.3011, total avg loss: 0.3365, batch size: 38
2021-08-25 05:43:18,192 INFO [train.py:482] Epoch 2, valid loss 0.2434, best valid loss: 0.2434 best valid epoch: 2
2021-08-25 05:43:24,201 INFO [train.py:450] Epoch 2, batch 14010, batch avg loss 0.3392, total avg loss: 0.3439, batch size: 41
2021-08-25 05:43:30,447 INFO [train.py:450] Epoch 2, batch 14020, batch avg loss 0.3463, total avg loss: 0.3417, batch size: 39
2021-08-25 05:43:37,358 INFO [train.py:450] Epoch 2, batch 14030, batch avg loss 0.3517, total avg loss: 0.3420, batch size: 39
2021-08-25 05:43:43,962 INFO [train.py:450] Epoch 2, batch 14040, batch avg loss 0.3525, total avg loss: 0.3421, batch size: 41
2021-08-25 05:43:50,970 INFO [train.py:450] Epoch 2, batch 14050, batch avg loss 0.3537, total avg loss: 0.3444, batch size: 38
2021-08-25 05:43:58,196 INFO [train.py:450] Epoch 2, batch 14060, batch avg loss 0.3714, total avg loss: 0.3436, batch size: 43
2021-08-25 05:44:04,954 INFO [train.py:450] Epoch 2, batch 14070, batch avg loss 0.4052, total avg loss: 0.3429, batch size: 41
2021-08-25 05:44:11,873 INFO [train.py:450] Epoch 2, batch 14080, batch avg loss 0.3363, total avg loss: 0.3446, batch size: 39
2021-08-25 05:44:18,639 INFO [train.py:450] Epoch 2, batch 14090, batch avg loss 0.3500, total avg loss: 0.3453, batch size: 40
2021-08-25 05:44:26,215 INFO [train.py:450] Epoch 2, batch 14100, batch avg loss 0.3723, total avg loss: 0.3456, batch size: 37
2021-08-25 05:44:33,148 INFO [train.py:450] Epoch 2, batch 14110, batch avg loss 0.3876, total avg loss: 0.3471, batch size: 39
2021-08-25 05:44:39,666 INFO [train.py:450] Epoch 2, batch 14120, batch avg loss 0.3451, total avg loss: 0.3478, batch size: 42
2021-08-25 05:44:47,831 INFO [train.py:450] Epoch 2, batch 14130, batch avg loss 0.3142, total avg loss: 0.3478, batch size: 40
2021-08-25 05:44:54,180 INFO [train.py:450] Epoch 2, batch 14140, batch avg loss 0.3006, total avg loss: 0.3476, batch size: 41
2021-08-25 05:45:04,040 INFO [train.py:450] Epoch 2, batch 14150, batch avg loss 0.3620, total avg loss: 0.3473, batch size: 41
2021-08-25 05:45:10,674 INFO [train.py:450] Epoch 2, batch 14160, batch avg loss 0.3404, total avg loss: 0.3477, batch size: 40
2021-08-25 05:45:17,514 INFO [train.py:450] Epoch 2, batch 14170, batch avg loss 0.2992, total avg loss: 0.3475, batch size: 40
2021-08-25 05:45:24,381 INFO [train.py:450] Epoch 2, batch 14180, batch avg loss 0.3513, total avg loss: 0.3469, batch size: 40
2021-08-25 05:45:32,117 INFO [train.py:450] Epoch 2, batch 14190, batch avg loss 0.3477, total avg loss: 0.3469, batch size: 42
2021-08-25 05:45:38,877 INFO [train.py:450] Epoch 2, batch 14200, batch avg loss 0.3755, total avg loss: 0.3467, batch size: 41
2021-08-25 05:45:45,990 INFO [train.py:450] Epoch 2, batch 14210, batch avg loss 0.3330, total avg loss: 0.3321, batch size: 41
2021-08-25 05:45:52,698 INFO [train.py:450] Epoch 2, batch 14220, batch avg loss 0.3556, total avg loss: 0.3463, batch size: 42
2021-08-25 05:45:59,300 INFO [train.py:450] Epoch 2, batch 14230, batch avg loss 0.3151, total avg loss: 0.3478, batch size: 39
2021-08-25 05:46:06,626 INFO [train.py:450] Epoch 2, batch 14240, batch avg loss 0.3351, total avg loss: 0.3468, batch size: 42
2021-08-25 05:46:13,596 INFO [train.py:450] Epoch 2, batch 14250, batch avg loss 0.3508, total avg loss: 0.3493, batch size: 39
2021-08-25 05:46:20,343 INFO [train.py:450] Epoch 2, batch 14260, batch avg loss 0.3210, total avg loss: 0.3462, batch size: 40
2021-08-25 05:46:27,493 INFO [train.py:450] Epoch 2, batch 14270, batch avg loss 0.3692, total avg loss: 0.3446, batch size: 40
2021-08-25 05:46:34,402 INFO [train.py:450] Epoch 2, batch 14280, batch avg loss 0.3285, total avg loss: 0.3447, batch size: 39
2021-08-25 05:46:41,252 INFO [train.py:450] Epoch 2, batch 14290, batch avg loss 0.3500, total avg loss: 0.3450, batch size: 37
2021-08-25 05:46:47,669 INFO [train.py:450] Epoch 2, batch 14300, batch avg loss 0.2875, total avg loss: 0.3446, batch size: 39
2021-08-25 05:46:54,227 INFO [train.py:450] Epoch 2, batch 14310, batch avg loss 0.3369, total avg loss: 0.3443, batch size: 40
2021-08-25 05:47:00,318 INFO [train.py:450] Epoch 2, batch 14320, batch avg loss 0.3286, total avg loss: 0.3438, batch size: 39
2021-08-25 05:47:07,277 INFO [train.py:450] Epoch 2, batch 14330, batch avg loss 0.3890, total avg loss: 0.3428, batch size: 41
2021-08-25 05:47:13,554 INFO [train.py:450] Epoch 2, batch 14340, batch avg loss 0.2933, total avg loss: 0.3421, batch size: 37
2021-08-25 05:47:20,509 INFO [train.py:450] Epoch 2, batch 14350, batch avg loss 0.3597, total avg loss: 0.3428, batch size: 42
2021-08-25 05:47:26,787 INFO [train.py:450] Epoch 2, batch 14360, batch avg loss 0.3223, total avg loss: 0.3430, batch size: 43
2021-08-25 05:47:33,346 INFO [train.py:450] Epoch 2, batch 14370, batch avg loss 0.3346, total avg loss: 0.3425, batch size: 39
2021-08-25 05:47:39,942 INFO [train.py:450] Epoch 2, batch 14380, batch avg loss 0.3464, total avg loss: 0.3423, batch size: 39
2021-08-25 05:47:46,240 INFO [train.py:450] Epoch 2, batch 14390, batch avg loss 0.3234, total avg loss: 0.3418, batch size: 40
2021-08-25 05:47:52,765 INFO [train.py:450] Epoch 2, batch 14400, batch avg loss 0.4183, total avg loss: 0.3434, batch size: 37
2021-08-25 05:47:59,649 INFO [train.py:450] Epoch 2, batch 14410, batch avg loss 0.3743, total avg loss: 0.3816, batch size: 42
2021-08-25 05:48:06,982 INFO [train.py:450] Epoch 2, batch 14420, batch avg loss 0.3136, total avg loss: 0.3676, batch size: 38
2021-08-25 05:48:13,518 INFO [train.py:450] Epoch 2, batch 14430, batch avg loss 0.3430, total avg loss: 0.3674, batch size: 39
2021-08-25 05:48:20,242 INFO [train.py:450] Epoch 2, batch 14440, batch avg loss 0.3195, total avg loss: 0.3654, batch size: 39
2021-08-25 05:48:26,979 INFO [train.py:450] Epoch 2, batch 14450, batch avg loss 0.3602, total avg loss: 0.3619, batch size: 42
2021-08-25 05:48:33,339 INFO [train.py:450] Epoch 2, batch 14460, batch avg loss 0.3363, total avg loss: 0.3599, batch size: 41
2021-08-25 05:48:41,055 INFO [train.py:450] Epoch 2, batch 14470, batch avg loss 0.3647, total avg loss: 0.3592, batch size: 41
2021-08-25 05:48:47,597 INFO [train.py:450] Epoch 2, batch 14480, batch avg loss 0.4048, total avg loss: 0.3562, batch size: 40
2021-08-25 05:48:58,224 INFO [train.py:450] Epoch 2, batch 14490, batch avg loss 0.3312, total avg loss: 0.3536, batch size: 40
2021-08-25 05:49:04,474 INFO [train.py:450] Epoch 2, batch 14500, batch avg loss 0.3519, total avg loss: 0.3544, batch size: 41
2021-08-25 05:49:10,934 INFO [train.py:450] Epoch 2, batch 14510, batch avg loss 0.3304, total avg loss: 0.3528, batch size: 40
2021-08-25 05:49:17,403 INFO [train.py:450] Epoch 2, batch 14520, batch avg loss 0.3393, total avg loss: 0.3506, batch size: 37
2021-08-25 05:49:23,502 INFO [train.py:450] Epoch 2, batch 14530, batch avg loss 0.3289, total avg loss: 0.3500, batch size: 40
2021-08-25 05:49:30,143 INFO [train.py:450] Epoch 2, batch 14540, batch avg loss 0.3641, total avg loss: 0.3502, batch size: 38
2021-08-25 05:49:37,247 INFO [train.py:450] Epoch 2, batch 14550, batch avg loss 0.3164, total avg loss: 0.3504, batch size: 39
2021-08-25 05:49:43,440 INFO [train.py:450] Epoch 2, batch 14560, batch avg loss 0.4068, total avg loss: 0.3509, batch size: 38
2021-08-25 05:49:50,413 INFO [train.py:450] Epoch 2, batch 14570, batch avg loss 0.3648, total avg loss: 0.3507, batch size: 44
2021-08-25 05:49:57,039 INFO [train.py:450] Epoch 2, batch 14580, batch avg loss 0.3332, total avg loss: 0.3506, batch size: 41
2021-08-25 05:50:03,031 INFO [train.py:450] Epoch 2, batch 14590, batch avg loss 0.3355, total avg loss: 0.3496, batch size: 40
2021-08-25 05:50:09,384 INFO [train.py:450] Epoch 2, batch 14600, batch avg loss 0.2941, total avg loss: 0.3485, batch size: 41
2021-08-25 05:50:15,830 INFO [train.py:450] Epoch 2, batch 14610, batch avg loss 0.3576, total avg loss: 0.3614, batch size: 40
2021-08-25 05:50:22,114 INFO [train.py:450] Epoch 2, batch 14620, batch avg loss 0.3571, total avg loss: 0.3506, batch size: 42
2021-08-25 05:50:28,354 INFO [train.py:450] Epoch 2, batch 14630, batch avg loss 0.2669, total avg loss: 0.3420, batch size: 44
2021-08-25 05:50:33,824 WARNING [cut.py:1694] To perform mix, energy must be non-zero and non-negative (got 0.0).  MonoCut with id "365c322b-f7cb-124f-e962-36e5ccdbc5e8" will not be mixed in.
2021-08-25 05:50:34,348 INFO [train.py:450] Epoch 2, batch 14640, batch avg loss 0.3779, total avg loss: 0.3391, batch size: 37
2021-08-25 05:50:40,821 INFO [train.py:450] Epoch 2, batch 14650, batch avg loss 0.2917, total avg loss: 0.3407, batch size: 39
2021-08-25 05:50:46,966 INFO [train.py:450] Epoch 2, batch 14660, batch avg loss 0.2992, total avg loss: 0.3367, batch size: 42
2021-08-25 05:50:54,165 INFO [train.py:450] Epoch 2, batch 14670, batch avg loss 0.3202, total avg loss: 0.3379, batch size: 39
2021-08-25 05:51:00,723 INFO [train.py:450] Epoch 2, batch 14680, batch avg loss 0.3362, total avg loss: 0.3385, batch size: 42
2021-08-25 05:51:07,272 INFO [train.py:450] Epoch 2, batch 14690, batch avg loss 0.3408, total avg loss: 0.3403, batch size: 40
2021-08-25 05:51:13,905 INFO [train.py:450] Epoch 2, batch 14700, batch avg loss 0.3401, total avg loss: 0.3411, batch size: 38
2021-08-25 05:51:20,021 INFO [train.py:450] Epoch 2, batch 14710, batch avg loss 0.3412, total avg loss: 0.3426, batch size: 39
2021-08-25 05:51:25,994 INFO [train.py:450] Epoch 2, batch 14720, batch avg loss 0.3495, total avg loss: 0.3432, batch size: 41
2021-08-25 05:51:32,210 INFO [train.py:450] Epoch 2, batch 14730, batch avg loss 0.3405, total avg loss: 0.3436, batch size: 41
2021-08-25 05:51:38,552 INFO [train.py:450] Epoch 2, batch 14740, batch avg loss 0.3870, total avg loss: 0.3444, batch size: 40
2021-08-25 05:51:45,312 INFO [train.py:450] Epoch 2, batch 14750, batch avg loss 0.3265, total avg loss: 0.3450, batch size: 38
2021-08-25 05:51:52,600 INFO [train.py:450] Epoch 2, batch 14760, batch avg loss 0.3375, total avg loss: 0.3452, batch size: 35
2021-08-25 05:52:00,028 INFO [train.py:450] Epoch 2, batch 14770, batch avg loss 0.4198, total avg loss: 0.3454, batch size: 41
2021-08-25 05:52:07,200 INFO [train.py:450] Epoch 2, batch 14780, batch avg loss 0.3776, total avg loss: 0.3459, batch size: 41
2021-08-25 05:52:16,065 INFO [train.py:450] Epoch 2, batch 14790, batch avg loss 0.3708, total avg loss: 0.3464, batch size: 45
2021-08-25 05:52:22,593 INFO [train.py:450] Epoch 2, batch 14800, batch avg loss 0.3839, total avg loss: 0.3470, batch size: 39
2021-08-25 05:52:29,637 INFO [train.py:450] Epoch 2, batch 14810, batch avg loss 0.3503, total avg loss: 0.3363, batch size: 43
2021-08-25 05:52:36,072 INFO [train.py:450] Epoch 2, batch 14820, batch avg loss 0.3478, total avg loss: 0.3364, batch size: 40
2021-08-25 05:52:42,411 INFO [train.py:450] Epoch 2, batch 14830, batch avg loss 0.3235, total avg loss: 0.3369, batch size: 41
2021-08-25 05:52:49,292 INFO [train.py:450] Epoch 2, batch 14840, batch avg loss 0.3427, total avg loss: 0.3494, batch size: 41
2021-08-25 05:52:55,606 INFO [train.py:450] Epoch 2, batch 14850, batch avg loss 0.3233, total avg loss: 0.3568, batch size: 40
2021-08-25 05:53:02,483 INFO [train.py:450] Epoch 2, batch 14860, batch avg loss 0.3549, total avg loss: 0.3593, batch size: 38
2021-08-25 05:53:09,089 INFO [train.py:450] Epoch 2, batch 14870, batch avg loss 0.3722, total avg loss: 0.3571, batch size: 40
2021-08-25 05:53:15,470 INFO [train.py:450] Epoch 2, batch 14880, batch avg loss 0.2968, total avg loss: 0.3542, batch size: 38
2021-08-25 05:53:21,922 INFO [train.py:450] Epoch 2, batch 14890, batch avg loss 0.3782, total avg loss: 0.3546, batch size: 40
2021-08-25 05:53:28,777 INFO [train.py:450] Epoch 2, batch 14900, batch avg loss 0.3282, total avg loss: 0.3550, batch size: 39
2021-08-25 05:53:35,128 INFO [train.py:450] Epoch 2, batch 14910, batch avg loss 0.3209, total avg loss: 0.3542, batch size: 41
2021-08-25 05:53:41,291 INFO [train.py:450] Epoch 2, batch 14920, batch avg loss 0.4134, total avg loss: 0.3547, batch size: 40
2021-08-25 05:53:48,238 INFO [train.py:450] Epoch 2, batch 14930, batch avg loss 0.3403, total avg loss: 0.3554, batch size: 38
2021-08-25 05:53:54,870 INFO [train.py:450] Epoch 2, batch 14940, batch avg loss 0.3702, total avg loss: 0.3546, batch size: 37
2021-08-25 05:54:01,745 INFO [train.py:450] Epoch 2, batch 14950, batch avg loss 0.3025, total avg loss: 0.3530, batch size: 41
2021-08-25 05:54:07,689 INFO [train.py:450] Epoch 2, batch 14960, batch avg loss 0.3166, total avg loss: 0.3515, batch size: 37
2021-08-25 05:54:14,369 INFO [train.py:450] Epoch 2, batch 14970, batch avg loss 0.3062, total avg loss: 0.3514, batch size: 40
2021-08-25 05:54:20,606 INFO [train.py:450] Epoch 2, batch 14980, batch avg loss 0.2652, total avg loss: 0.3517, batch size: 37
2021-08-25 05:54:27,137 INFO [train.py:450] Epoch 2, batch 14990, batch avg loss 0.3137, total avg loss: 0.3508, batch size: 37
2021-08-25 05:54:34,011 INFO [train.py:450] Epoch 2, batch 15000, batch avg loss 0.3391, total avg loss: 0.3513, batch size: 37
2021-08-25 05:55:14,413 INFO [train.py:482] Epoch 2, valid loss 0.2458, best valid loss: 0.2434 best valid epoch: 2
2021-08-25 05:55:20,565 INFO [train.py:450] Epoch 2, batch 15010, batch avg loss 0.2934, total avg loss: 0.3316, batch size: 37
2021-08-25 05:55:26,481 INFO [train.py:450] Epoch 2, batch 15020, batch avg loss 0.3434, total avg loss: 0.3307, batch size: 39
2021-08-25 05:55:32,356 INFO [train.py:450] Epoch 2, batch 15030, batch avg loss 0.2986, total avg loss: 0.3307, batch size: 38
2021-08-25 05:55:39,097 INFO [train.py:450] Epoch 2, batch 15040, batch avg loss 0.3926, total avg loss: 0.3363, batch size: 40
2021-08-25 05:55:45,953 INFO [train.py:450] Epoch 2, batch 15050, batch avg loss 0.3208, total avg loss: 0.3383, batch size: 41
2021-08-25 05:55:53,325 INFO [train.py:450] Epoch 2, batch 15060, batch avg loss 0.3681, total avg loss: 0.3419, batch size: 39
2021-08-25 05:55:59,673 INFO [train.py:450] Epoch 2, batch 15070, batch avg loss 0.4049, total avg loss: 0.3410, batch size: 37
2021-08-25 05:56:07,584 INFO [train.py:450] Epoch 2, batch 15080, batch avg loss 0.3621, total avg loss: 0.3437, batch size: 39
2021-08-25 05:56:16,032 INFO [train.py:450] Epoch 2, batch 15090, batch avg loss 0.3933, total avg loss: 0.3443, batch size: 40
2021-08-25 05:56:21,964 INFO [train.py:450] Epoch 2, batch 15100, batch avg loss 0.3129, total avg loss: 0.3433, batch size: 36
2021-08-25 05:56:28,110 INFO [train.py:450] Epoch 2, batch 15110, batch avg loss 0.3976, total avg loss: 0.3447, batch size: 40
2021-08-25 05:56:34,411 INFO [train.py:450] Epoch 2, batch 15120, batch avg loss 0.3600, total avg loss: 0.3453, batch size: 41
2021-08-25 05:56:40,523 INFO [train.py:450] Epoch 2, batch 15130, batch avg loss 0.3513, total avg loss: 0.3459, batch size: 38
2021-08-25 05:56:46,796 INFO [train.py:450] Epoch 2, batch 15140, batch avg loss 0.3442, total avg loss: 0.3445, batch size: 40
2021-08-25 05:56:53,469 INFO [train.py:450] Epoch 2, batch 15150, batch avg loss 0.3315, total avg loss: 0.3437, batch size: 42
2021-08-25 05:56:59,456 INFO [train.py:450] Epoch 2, batch 15160, batch avg loss 0.3340, total avg loss: 0.3437, batch size: 44
2021-08-25 05:57:05,840 INFO [train.py:450] Epoch 2, batch 15170, batch avg loss 0.3498, total avg loss: 0.3434, batch size: 44
2021-08-25 05:57:11,821 INFO [train.py:450] Epoch 2, batch 15180, batch avg loss 0.3970, total avg loss: 0.3440, batch size: 41
2021-08-25 05:57:18,368 INFO [train.py:450] Epoch 2, batch 15190, batch avg loss 0.3311, total avg loss: 0.3449, batch size: 38
2021-08-25 05:57:24,914 INFO [train.py:450] Epoch 2, batch 15200, batch avg loss 0.3815, total avg loss: 0.3455, batch size: 43
2021-08-25 05:57:31,634 INFO [train.py:450] Epoch 2, batch 15210, batch avg loss 0.4149, total avg loss: 0.3345, batch size: 41
2021-08-25 05:57:37,978 INFO [train.py:450] Epoch 2, batch 15220, batch avg loss 0.3173, total avg loss: 0.3393, batch size: 39
2021-08-25 05:57:44,507 INFO [train.py:450] Epoch 2, batch 15230, batch avg loss 0.3566, total avg loss: 0.3436, batch size: 39
2021-08-25 05:57:50,774 INFO [train.py:450] Epoch 2, batch 15240, batch avg loss 0.3383, total avg loss: 0.3424, batch size: 41
2021-08-25 05:57:57,226 INFO [train.py:450] Epoch 2, batch 15250, batch avg loss 0.3480, total avg loss: 0.3443, batch size: 40
2021-08-25 05:58:03,658 INFO [train.py:450] Epoch 2, batch 15260, batch avg loss 0.3823, total avg loss: 0.3458, batch size: 37
2021-08-25 05:58:09,771 INFO [train.py:450] Epoch 2, batch 15270, batch avg loss 0.3473, total avg loss: 0.3447, batch size: 39
2021-08-25 05:58:15,723 INFO [train.py:450] Epoch 2, batch 15280, batch avg loss 0.3478, total avg loss: 0.3446, batch size: 38
2021-08-25 05:58:22,342 INFO [train.py:450] Epoch 2, batch 15290, batch avg loss 0.4402, total avg loss: 0.3433, batch size: 43
2021-08-25 05:58:28,818 INFO [train.py:450] Epoch 2, batch 15300, batch avg loss 0.2989, total avg loss: 0.3437, batch size: 35
2021-08-25 05:58:35,528 INFO [train.py:450] Epoch 2, batch 15310, batch avg loss 0.3589, total avg loss: 0.3444, batch size: 37
2021-08-25 05:58:42,164 INFO [train.py:450] Epoch 2, batch 15320, batch avg loss 0.3243, total avg loss: 0.3434, batch size: 44
2021-08-25 05:58:48,422 INFO [train.py:450] Epoch 2, batch 15330, batch avg loss 0.3605, total avg loss: 0.3439, batch size: 41
2021-08-25 05:58:55,174 INFO [train.py:450] Epoch 2, batch 15340, batch avg loss 0.3161, total avg loss: 0.3452, batch size: 40
2021-08-25 05:59:01,439 INFO [train.py:450] Epoch 2, batch 15350, batch avg loss 0.3301, total avg loss: 0.3455, batch size: 39
2021-08-25 05:59:07,725 INFO [train.py:450] Epoch 2, batch 15360, batch avg loss 0.2982, total avg loss: 0.3447, batch size: 39
2021-08-25 05:59:14,538 INFO [train.py:450] Epoch 2, batch 15370, batch avg loss 0.2804, total avg loss: 0.3447, batch size: 41
2021-08-25 05:59:20,729 INFO [train.py:450] Epoch 2, batch 15380, batch avg loss 0.4030, total avg loss: 0.3455, batch size: 36
2021-08-25 05:59:26,750 INFO [train.py:450] Epoch 2, batch 15390, batch avg loss 0.3409, total avg loss: 0.3457, batch size: 40
2021-08-25 05:59:32,987 INFO [train.py:450] Epoch 2, batch 15400, batch avg loss 0.2974, total avg loss: 0.3455, batch size: 43
2021-08-25 05:59:39,587 INFO [train.py:450] Epoch 2, batch 15410, batch avg loss 0.3970, total avg loss: 0.3433, batch size: 39
2021-08-25 05:59:47,800 INFO [train.py:450] Epoch 2, batch 15420, batch avg loss 0.3911, total avg loss: 0.3448, batch size: 41
2021-08-25 05:59:53,647 INFO [train.py:450] Epoch 2, batch 15430, batch avg loss 0.2895, total avg loss: 0.3406, batch size: 40
2021-08-25 06:00:01,597 INFO [train.py:450] Epoch 2, batch 15440, batch avg loss 0.3973, total avg loss: 0.3455, batch size: 38
2021-08-25 06:00:09,921 INFO [train.py:450] Epoch 2, batch 15450, batch avg loss 0.2885, total avg loss: 0.3428, batch size: 38
2021-08-25 06:00:17,087 INFO [train.py:450] Epoch 2, batch 15460, batch avg loss 0.3598, total avg loss: 0.3422, batch size: 43
2021-08-25 06:00:23,536 INFO [train.py:450] Epoch 2, batch 15470, batch avg loss 0.3490, total avg loss: 0.3399, batch size: 41
2021-08-25 06:00:30,138 INFO [train.py:450] Epoch 2, batch 15480, batch avg loss 0.3746, total avg loss: 0.3390, batch size: 38
2021-08-25 06:00:36,496 INFO [train.py:450] Epoch 2, batch 15490, batch avg loss 0.3349, total avg loss: 0.3409, batch size: 42
2021-08-25 06:00:42,918 INFO [train.py:450] Epoch 2, batch 15500, batch avg loss 0.3990, total avg loss: 0.3412, batch size: 42
2021-08-25 06:00:49,570 INFO [train.py:450] Epoch 2, batch 15510, batch avg loss 0.3236, total avg loss: 0.3431, batch size: 38
2021-08-25 06:00:55,829 INFO [train.py:450] Epoch 2, batch 15520, batch avg loss 0.3683, total avg loss: 0.3438, batch size: 40
2021-08-25 06:01:01,735 INFO [train.py:450] Epoch 2, batch 15530, batch avg loss 0.3696, total avg loss: 0.3433, batch size: 39
2021-08-25 06:01:07,650 INFO [train.py:450] Epoch 2, batch 15540, batch avg loss 0.3322, total avg loss: 0.3431, batch size: 36
2021-08-25 06:01:13,567 INFO [train.py:450] Epoch 2, batch 15550, batch avg loss 0.3484, total avg loss: 0.3449, batch size: 41
2021-08-25 06:01:20,166 INFO [train.py:450] Epoch 2, batch 15560, batch avg loss 0.3594, total avg loss: 0.3453, batch size: 40
2021-08-25 06:01:26,423 INFO [train.py:450] Epoch 2, batch 15570, batch avg loss 0.3659, total avg loss: 0.3453, batch size: 38
2021-08-25 06:01:32,670 INFO [train.py:450] Epoch 2, batch 15580, batch avg loss 0.3707, total avg loss: 0.3461, batch size: 39
2021-08-25 06:01:38,817 INFO [train.py:450] Epoch 2, batch 15590, batch avg loss 0.3185, total avg loss: 0.3458, batch size: 38
2021-08-25 06:01:45,039 INFO [train.py:450] Epoch 2, batch 15600, batch avg loss 0.3703, total avg loss: 0.3459, batch size: 37
2021-08-25 06:01:51,324 INFO [train.py:450] Epoch 2, batch 15610, batch avg loss 0.3771, total avg loss: 0.3533, batch size: 38
2021-08-25 06:01:57,266 INFO [train.py:450] Epoch 2, batch 15620, batch avg loss 0.3857, total avg loss: 0.3470, batch size: 41
2021-08-25 06:02:03,690 INFO [train.py:450] Epoch 2, batch 15630, batch avg loss 0.3115, total avg loss: 0.3503, batch size: 39
2021-08-25 06:02:09,958 INFO [train.py:450] Epoch 2, batch 15640, batch avg loss 0.3270, total avg loss: 0.3484, batch size: 36
2021-08-25 06:02:16,168 INFO [train.py:450] Epoch 2, batch 15650, batch avg loss 0.3687, total avg loss: 0.3491, batch size: 41
2021-08-25 06:02:22,269 INFO [train.py:450] Epoch 2, batch 15660, batch avg loss 0.3662, total avg loss: 0.3495, batch size: 37
2021-08-25 06:02:28,758 INFO [train.py:450] Epoch 2, batch 15670, batch avg loss 0.3258, total avg loss: 0.3499, batch size: 45
2021-08-25 06:02:35,330 INFO [train.py:450] Epoch 2, batch 15680, batch avg loss 0.3485, total avg loss: 0.3484, batch size: 40
2021-08-25 06:02:42,420 INFO [train.py:450] Epoch 2, batch 15690, batch avg loss 0.3088, total avg loss: 0.3491, batch size: 40
2021-08-25 06:02:48,979 INFO [train.py:450] Epoch 2, batch 15700, batch avg loss 0.3689, total avg loss: 0.3500, batch size: 38
2021-08-25 06:02:54,932 INFO [train.py:450] Epoch 2, batch 15710, batch avg loss 0.3166, total avg loss: 0.3494, batch size: 42
2021-08-25 06:03:01,149 INFO [train.py:450] Epoch 2, batch 15720, batch avg loss 0.3460, total avg loss: 0.3497, batch size: 41
2021-08-25 06:03:07,460 INFO [train.py:450] Epoch 2, batch 15730, batch avg loss 0.3396, total avg loss: 0.3486, batch size: 36
2021-08-25 06:03:13,529 INFO [train.py:450] Epoch 2, batch 15740, batch avg loss 0.3792, total avg loss: 0.3482, batch size: 39
2021-08-25 06:03:20,623 INFO [train.py:450] Epoch 2, batch 15750, batch avg loss 0.3138, total avg loss: 0.3488, batch size: 38
2021-08-25 06:03:26,980 INFO [train.py:450] Epoch 2, batch 15760, batch avg loss 0.3373, total avg loss: 0.3489, batch size: 39
2021-08-25 06:03:33,381 INFO [train.py:450] Epoch 2, batch 15770, batch avg loss 0.3369, total avg loss: 0.3483, batch size: 37
2021-08-25 06:03:40,298 INFO [train.py:450] Epoch 2, batch 15780, batch avg loss 0.3805, total avg loss: 0.3487, batch size: 44
2021-08-25 06:03:46,645 INFO [train.py:450] Epoch 2, batch 15790, batch avg loss 0.3144, total avg loss: 0.3476, batch size: 40
2021-08-25 06:03:52,873 INFO [train.py:450] Epoch 2, batch 15800, batch avg loss 0.3001, total avg loss: 0.3474, batch size: 40
2021-08-25 06:03:58,961 INFO [train.py:450] Epoch 2, batch 15810, batch avg loss 0.3760, total avg loss: 0.3377, batch size: 41
2021-08-25 06:04:04,938 INFO [train.py:450] Epoch 2, batch 15820, batch avg loss 0.3687, total avg loss: 0.3413, batch size: 38
2021-08-25 06:04:11,062 INFO [train.py:450] Epoch 2, batch 15830, batch avg loss 0.3429, total avg loss: 0.3408, batch size: 39
2021-08-25 06:04:19,076 INFO [train.py:450] Epoch 2, batch 15840, batch avg loss 0.3545, total avg loss: 0.3459, batch size: 40
2021-08-25 06:04:25,114 INFO [train.py:450] Epoch 2, batch 15850, batch avg loss 0.3351, total avg loss: 0.3467, batch size: 40
2021-08-25 06:04:34,405 INFO [train.py:450] Epoch 2, batch 15860, batch avg loss 0.3199, total avg loss: 0.3452, batch size: 43
2021-08-25 06:04:40,852 INFO [train.py:450] Epoch 2, batch 15870, batch avg loss 0.4303, total avg loss: 0.3486, batch size: 43
2021-08-25 06:04:47,610 INFO [train.py:450] Epoch 2, batch 15880, batch avg loss 0.2911, total avg loss: 0.3467, batch size: 42
2021-08-25 06:04:53,804 INFO [train.py:450] Epoch 2, batch 15890, batch avg loss 0.3347, total avg loss: 0.3464, batch size: 43
2021-08-25 06:05:00,429 INFO [train.py:450] Epoch 2, batch 15900, batch avg loss 0.3722, total avg loss: 0.3469, batch size: 37
2021-08-25 06:05:06,867 INFO [train.py:450] Epoch 2, batch 15910, batch avg loss 0.3325, total avg loss: 0.3451, batch size: 38
2021-08-25 06:05:13,206 INFO [train.py:450] Epoch 2, batch 15920, batch avg loss 0.3855, total avg loss: 0.3459, batch size: 40
2021-08-25 06:05:20,023 INFO [train.py:450] Epoch 2, batch 15930, batch avg loss 0.3740, total avg loss: 0.3473, batch size: 38
2021-08-25 06:05:26,266 INFO [train.py:450] Epoch 2, batch 15940, batch avg loss 0.3099, total avg loss: 0.3467, batch size: 41
2021-08-25 06:05:32,494 INFO [train.py:450] Epoch 2, batch 15950, batch avg loss 0.3208, total avg loss: 0.3477, batch size: 39
2021-08-25 06:05:38,943 INFO [train.py:450] Epoch 2, batch 15960, batch avg loss 0.3433, total avg loss: 0.3467, batch size: 41
2021-08-25 06:05:45,548 INFO [train.py:450] Epoch 2, batch 15970, batch avg loss 0.3463, total avg loss: 0.3472, batch size: 41
2021-08-25 06:05:51,645 INFO [train.py:450] Epoch 2, batch 15980, batch avg loss 0.3647, total avg loss: 0.3471, batch size: 43
2021-08-25 06:05:58,193 INFO [train.py:450] Epoch 2, batch 15990, batch avg loss 0.3706, total avg loss: 0.3475, batch size: 40
2021-08-25 06:06:04,434 INFO [train.py:450] Epoch 2, batch 16000, batch avg loss 0.3632, total avg loss: 0.3469, batch size: 39
2021-08-25 06:06:44,044 INFO [train.py:482] Epoch 2, valid loss 0.2443, best valid loss: 0.2434 best valid epoch: 2
2021-08-25 06:06:49,875 INFO [train.py:450] Epoch 2, batch 16010, batch avg loss 0.3546, total avg loss: 0.3459, batch size: 39
2021-08-25 06:06:56,153 INFO [train.py:450] Epoch 2, batch 16020, batch avg loss 0.3463, total avg loss: 0.3538, batch size: 40
2021-08-25 06:07:02,230 INFO [train.py:450] Epoch 2, batch 16030, batch avg loss 0.3292, total avg loss: 0.3468, batch size: 37
2021-08-25 06:07:08,935 INFO [train.py:450] Epoch 2, batch 16040, batch avg loss 0.2731, total avg loss: 0.3418, batch size: 37
2021-08-25 06:07:15,017 INFO [train.py:450] Epoch 2, batch 16050, batch avg loss 0.3444, total avg loss: 0.3443, batch size: 39
2021-08-25 06:07:21,029 INFO [train.py:450] Epoch 2, batch 16060, batch avg loss 0.4015, total avg loss: 0.3467, batch size: 44
2021-08-25 06:07:27,927 INFO [train.py:450] Epoch 2, batch 16070, batch avg loss 0.3517, total avg loss: 0.3480, batch size: 40
2021-08-25 06:07:33,945 INFO [train.py:450] Epoch 2, batch 16080, batch avg loss 0.3243, total avg loss: 0.3473, batch size: 36
2021-08-25 06:07:40,198 INFO [train.py:450] Epoch 2, batch 16090, batch avg loss 0.4033, total avg loss: 0.3470, batch size: 40
2021-08-25 06:07:46,340 INFO [train.py:450] Epoch 2, batch 16100, batch avg loss 0.3650, total avg loss: 0.3492, batch size: 43
2021-08-25 06:07:52,252 INFO [train.py:450] Epoch 2, batch 16110, batch avg loss 0.3438, total avg loss: 0.3477, batch size: 38
2021-08-25 06:07:58,766 INFO [train.py:450] Epoch 2, batch 16120, batch avg loss 0.3363, total avg loss: 0.3476, batch size: 38
2021-08-25 06:08:06,742 INFO [train.py:450] Epoch 2, batch 16130, batch avg loss 0.3417, total avg loss: 0.3488, batch size: 39
2021-08-25 06:08:12,639 INFO [train.py:450] Epoch 2, batch 16140, batch avg loss 0.3029, total avg loss: 0.3486, batch size: 38
2021-08-25 06:08:19,853 INFO [train.py:450] Epoch 2, batch 16150, batch avg loss 0.3667, total avg loss: 0.3479, batch size: 40
2021-08-25 06:08:28,916 INFO [train.py:450] Epoch 2, batch 16160, batch avg loss 0.3169, total avg loss: 0.3478, batch size: 38
2021-08-25 06:08:35,007 INFO [train.py:450] Epoch 2, batch 16170, batch avg loss 0.3180, total avg loss: 0.3467, batch size: 35
2021-08-25 06:08:41,332 INFO [train.py:450] Epoch 2, batch 16180, batch avg loss 0.3375, total avg loss: 0.3467, batch size: 39
2021-08-25 06:08:48,363 INFO [train.py:450] Epoch 2, batch 16190, batch avg loss 0.3120, total avg loss: 0.3456, batch size: 39
2021-08-25 06:08:54,424 INFO [train.py:450] Epoch 2, batch 16200, batch avg loss 0.3245, total avg loss: 0.3454, batch size: 40
2021-08-25 06:09:01,061 INFO [train.py:450] Epoch 2, batch 16210, batch avg loss 0.3430, total avg loss: 0.3563, batch size: 37
2021-08-25 06:09:07,632 INFO [train.py:450] Epoch 2, batch 16220, batch avg loss 0.3175, total avg loss: 0.3497, batch size: 38
2021-08-25 06:09:13,970 INFO [train.py:450] Epoch 2, batch 16230, batch avg loss 0.3388, total avg loss: 0.3471, batch size: 40
2021-08-25 06:09:19,844 INFO [train.py:450] Epoch 2, batch 16240, batch avg loss 0.3250, total avg loss: 0.3446, batch size: 37
2021-08-25 06:09:26,311 INFO [train.py:450] Epoch 2, batch 16250, batch avg loss 0.3455, total avg loss: 0.3426, batch size: 39
2021-08-25 06:09:32,333 INFO [train.py:450] Epoch 2, batch 16260, batch avg loss 0.3092, total avg loss: 0.3443, batch size: 38
2021-08-25 06:09:38,433 INFO [train.py:450] Epoch 2, batch 16270, batch avg loss 0.4171, total avg loss: 0.3446, batch size: 39
2021-08-25 06:09:44,905 INFO [train.py:450] Epoch 2, batch 16280, batch avg loss 0.2945, total avg loss: 0.3483, batch size: 39
2021-08-25 06:09:51,402 INFO [train.py:450] Epoch 2, batch 16290, batch avg loss 0.4118, total avg loss: 0.3495, batch size: 40
2021-08-25 06:09:57,489 INFO [train.py:450] Epoch 2, batch 16300, batch avg loss 0.3670, total avg loss: 0.3482, batch size: 43
2021-08-25 06:10:03,675 INFO [train.py:450] Epoch 2, batch 16310, batch avg loss 0.2976, total avg loss: 0.3474, batch size: 43
2021-08-25 06:10:10,311 INFO [train.py:450] Epoch 2, batch 16320, batch avg loss 0.4047, total avg loss: 0.3486, batch size: 39
2021-08-25 06:10:16,374 INFO [train.py:450] Epoch 2, batch 16330, batch avg loss 0.3740, total avg loss: 0.3491, batch size: 39
2021-08-25 06:10:22,140 INFO [train.py:450] Epoch 2, batch 16340, batch avg loss 0.3156, total avg loss: 0.3492, batch size: 41
2021-08-25 06:10:28,211 INFO [train.py:450] Epoch 2, batch 16350, batch avg loss 0.3646, total avg loss: 0.3502, batch size: 39
2021-08-25 06:10:34,195 INFO [train.py:450] Epoch 2, batch 16360, batch avg loss 0.4441, total avg loss: 0.3502, batch size: 41
2021-08-25 06:10:40,050 INFO [train.py:450] Epoch 2, batch 16370, batch avg loss 0.3587, total avg loss: 0.3508, batch size: 39
2021-08-25 06:10:46,910 INFO [train.py:450] Epoch 2, batch 16380, batch avg loss 0.3168, total avg loss: 0.3503, batch size: 39
2021-08-25 06:10:53,272 INFO [train.py:450] Epoch 2, batch 16390, batch avg loss 0.3151, total avg loss: 0.3487, batch size: 36
2021-08-25 06:11:00,072 INFO [train.py:450] Epoch 2, batch 16400, batch avg loss 0.3491, total avg loss: 0.3486, batch size: 42
2021-08-25 06:11:06,069 INFO [train.py:450] Epoch 2, batch 16410, batch avg loss 0.3227, total avg loss: 0.3419, batch size: 39
2021-08-25 06:11:12,018 INFO [train.py:450] Epoch 2, batch 16420, batch avg loss 0.3432, total avg loss: 0.3512, batch size: 40
2021-08-25 06:11:17,917 INFO [train.py:450] Epoch 2, batch 16430, batch avg loss 0.3884, total avg loss: 0.3487, batch size: 43
2021-08-25 06:11:23,847 INFO [train.py:450] Epoch 2, batch 16440, batch avg loss 0.3751, total avg loss: 0.3498, batch size: 39
2021-08-25 06:11:29,818 INFO [train.py:450] Epoch 2, batch 16450, batch avg loss 0.3139, total avg loss: 0.3494, batch size: 37
2021-08-25 06:11:36,226 INFO [train.py:450] Epoch 2, batch 16460, batch avg loss 0.3247, total avg loss: 0.3453, batch size: 38
2021-08-25 06:11:42,095 INFO [train.py:450] Epoch 2, batch 16470, batch avg loss 0.3848, total avg loss: 0.3467, batch size: 37
2021-08-25 06:11:48,049 INFO [train.py:450] Epoch 2, batch 16480, batch avg loss 0.3924, total avg loss: 0.3464, batch size: 39
2021-08-25 06:11:54,075 INFO [train.py:450] Epoch 2, batch 16490, batch avg loss 0.3736, total avg loss: 0.3455, batch size: 38
2021-08-25 06:12:02,018 INFO [train.py:450] Epoch 2, batch 16500, batch avg loss 0.3075, total avg loss: 0.3456, batch size: 42
2021-08-25 06:12:08,100 INFO [train.py:450] Epoch 2, batch 16510, batch avg loss 0.3371, total avg loss: 0.3458, batch size: 39
2021-08-25 06:12:17,669 INFO [train.py:450] Epoch 2, batch 16520, batch avg loss 0.3782, total avg loss: 0.3456, batch size: 39
2021-08-25 06:12:23,838 INFO [train.py:450] Epoch 2, batch 16530, batch avg loss 0.3498, total avg loss: 0.3461, batch size: 41
2021-08-25 06:12:29,907 INFO [train.py:450] Epoch 2, batch 16540, batch avg loss 0.3436, total avg loss: 0.3457, batch size: 44
2021-08-25 06:12:36,010 INFO [train.py:450] Epoch 2, batch 16550, batch avg loss 0.3335, total avg loss: 0.3462, batch size: 39
2021-08-25 06:12:42,160 INFO [train.py:450] Epoch 2, batch 16560, batch avg loss 0.4072, total avg loss: 0.3465, batch size: 38
2021-08-25 06:12:49,084 INFO [train.py:450] Epoch 2, batch 16570, batch avg loss 0.3457, total avg loss: 0.3471, batch size: 38
2021-08-25 06:12:55,788 INFO [train.py:450] Epoch 2, batch 16580, batch avg loss 0.3489, total avg loss: 0.3474, batch size: 38
2021-08-25 06:13:01,857 INFO [train.py:450] Epoch 2, batch 16590, batch avg loss 0.3824, total avg loss: 0.3470, batch size: 42
2021-08-25 06:13:08,419 INFO [train.py:450] Epoch 2, batch 16600, batch avg loss 0.3300, total avg loss: 0.3461, batch size: 39
2021-08-25 06:13:14,465 INFO [train.py:450] Epoch 2, batch 16610, batch avg loss 0.3507, total avg loss: 0.3429, batch size: 38
2021-08-25 06:13:21,285 INFO [train.py:450] Epoch 2, batch 16620, batch avg loss 0.4104, total avg loss: 0.3507, batch size: 41
2021-08-25 06:13:27,531 INFO [train.py:450] Epoch 2, batch 16630, batch avg loss 0.3472, total avg loss: 0.3477, batch size: 38
2021-08-25 06:13:33,594 INFO [train.py:450] Epoch 2, batch 16640, batch avg loss 0.3603, total avg loss: 0.3473, batch size: 36
2021-08-25 06:13:39,821 INFO [train.py:450] Epoch 2, batch 16650, batch avg loss 0.3394, total avg loss: 0.3489, batch size: 36
2021-08-25 06:13:46,335 INFO [train.py:450] Epoch 2, batch 16660, batch avg loss 0.3160, total avg loss: 0.3474, batch size: 42
2021-08-25 06:13:52,536 INFO [train.py:450] Epoch 2, batch 16670, batch avg loss 0.3514, total avg loss: 0.3470, batch size: 44
2021-08-25 06:13:58,479 INFO [train.py:450] Epoch 2, batch 16680, batch avg loss 0.4091, total avg loss: 0.3472, batch size: 40
2021-08-25 06:14:04,625 INFO [train.py:450] Epoch 2, batch 16690, batch avg loss 0.3535, total avg loss: 0.3469, batch size: 44
2021-08-25 06:14:11,021 INFO [train.py:450] Epoch 2, batch 16700, batch avg loss 0.3135, total avg loss: 0.3478, batch size: 41
2021-08-25 06:14:18,559 INFO [train.py:450] Epoch 2, batch 16710, batch avg loss 0.3404, total avg loss: 0.3470, batch size: 39
2021-08-25 06:14:24,779 INFO [train.py:450] Epoch 2, batch 16720, batch avg loss 0.3186, total avg loss: 0.3469, batch size: 41
2021-08-25 06:14:33,899 INFO [train.py:450] Epoch 2, batch 16730, batch avg loss 0.3118, total avg loss: 0.3469, batch size: 37
2021-08-25 06:14:39,928 INFO [train.py:450] Epoch 2, batch 16740, batch avg loss 0.4004, total avg loss: 0.3484, batch size: 39
2021-08-25 06:14:45,836 INFO [train.py:450] Epoch 2, batch 16750, batch avg loss 0.3340, total avg loss: 0.3485, batch size: 40
2021-08-25 06:14:52,077 INFO [train.py:450] Epoch 2, batch 16760, batch avg loss 0.3308, total avg loss: 0.3486, batch size: 36
2021-08-25 06:14:58,675 INFO [train.py:450] Epoch 2, batch 16770, batch avg loss 0.3079, total avg loss: 0.3476, batch size: 44
2021-08-25 06:15:04,873 INFO [train.py:450] Epoch 2, batch 16780, batch avg loss 0.3422, total avg loss: 0.3481, batch size: 38
2021-08-25 06:15:11,033 INFO [train.py:450] Epoch 2, batch 16790, batch avg loss 0.3363, total avg loss: 0.3482, batch size: 40
2021-08-25 06:15:17,648 INFO [train.py:450] Epoch 2, batch 16800, batch avg loss 0.3883, total avg loss: 0.3477, batch size: 41
2021-08-25 06:15:23,549 INFO [train.py:450] Epoch 2, batch 16810, batch avg loss 0.3779, total avg loss: 0.3523, batch size: 38
2021-08-25 06:15:29,647 INFO [train.py:450] Epoch 2, batch 16820, batch avg loss 0.3497, total avg loss: 0.3422, batch size: 37
2021-08-25 06:15:35,740 INFO [train.py:450] Epoch 2, batch 16830, batch avg loss 0.3367, total avg loss: 0.3422, batch size: 39
2021-08-25 06:15:42,013 INFO [train.py:450] Epoch 2, batch 16840, batch avg loss 0.3711, total avg loss: 0.3364, batch size: 42
2021-08-25 06:15:47,995 INFO [train.py:450] Epoch 2, batch 16850, batch avg loss 0.4074, total avg loss: 0.3381, batch size: 42
2021-08-25 06:15:54,046 INFO [train.py:450] Epoch 2, batch 16860, batch avg loss 0.3738, total avg loss: 0.3388, batch size: 40
2021-08-25 06:16:00,800 INFO [train.py:450] Epoch 2, batch 16870, batch avg loss 0.3435, total avg loss: 0.3401, batch size: 39
2021-08-25 06:16:06,818 INFO [train.py:450] Epoch 2, batch 16880, batch avg loss 0.2533, total avg loss: 0.3390, batch size: 38
2021-08-25 06:16:12,871 INFO [train.py:450] Epoch 2, batch 16890, batch avg loss 0.3372, total avg loss: 0.3424, batch size: 39
2021-08-25 06:16:18,959 INFO [train.py:450] Epoch 2, batch 16900, batch avg loss 0.3186, total avg loss: 0.3427, batch size: 41
2021-08-25 06:16:24,989 INFO [train.py:450] Epoch 2, batch 16910, batch avg loss 0.3414, total avg loss: 0.3426, batch size: 36
2021-08-25 06:16:31,459 INFO [train.py:450] Epoch 2, batch 16920, batch avg loss 0.3611, total avg loss: 0.3437, batch size: 38
2021-08-25 06:16:38,008 INFO [train.py:450] Epoch 2, batch 16930, batch avg loss 0.3066, total avg loss: 0.3440, batch size: 40
2021-08-25 06:16:43,993 INFO [train.py:450] Epoch 2, batch 16940, batch avg loss 0.3419, total avg loss: 0.3437, batch size: 41
2021-08-25 06:16:49,916 INFO [train.py:450] Epoch 2, batch 16950, batch avg loss 0.3047, total avg loss: 0.3423, batch size: 40
2021-08-25 06:16:56,108 INFO [train.py:450] Epoch 2, batch 16960, batch avg loss 0.3305, total avg loss: 0.3429, batch size: 45
2021-08-25 06:17:02,482 INFO [train.py:450] Epoch 2, batch 16970, batch avg loss 0.3185, total avg loss: 0.3446, batch size: 40
2021-08-25 06:17:08,465 INFO [train.py:450] Epoch 2, batch 16980, batch avg loss 0.3530, total avg loss: 0.3448, batch size: 38
2021-08-25 06:17:14,584 INFO [train.py:450] Epoch 2, batch 16990, batch avg loss 0.3423, total avg loss: 0.3454, batch size: 39
2021-08-25 06:17:20,973 INFO [train.py:450] Epoch 2, batch 17000, batch avg loss 0.3925, total avg loss: 0.3451, batch size: 39
2021-08-25 06:17:59,680 INFO [train.py:482] Epoch 2, valid loss 0.2456, best valid loss: 0.2434 best valid epoch: 2
2021-08-25 06:18:06,035 INFO [train.py:450] Epoch 2, batch 17010, batch avg loss 0.3079, total avg loss: 0.3242, batch size: 40
2021-08-25 06:18:12,514 INFO [train.py:450] Epoch 2, batch 17020, batch avg loss 0.3544, total avg loss: 0.3410, batch size: 41
2021-08-25 06:18:21,514 INFO [train.py:450] Epoch 2, batch 17030, batch avg loss 0.3562, total avg loss: 0.3426, batch size: 44
2021-08-25 06:18:27,871 INFO [train.py:450] Epoch 2, batch 17040, batch avg loss 0.3262, total avg loss: 0.3396, batch size: 41
2021-08-25 06:18:34,092 INFO [train.py:450] Epoch 2, batch 17050, batch avg loss 0.3212, total avg loss: 0.3411, batch size: 40
2021-08-25 06:18:40,132 INFO [train.py:450] Epoch 2, batch 17060, batch avg loss 0.3556, total avg loss: 0.3430, batch size: 41
2021-08-25 06:18:46,073 INFO [train.py:450] Epoch 2, batch 17070, batch avg loss 0.3597, total avg loss: 0.3444, batch size: 39
2021-08-25 06:18:52,336 INFO [train.py:450] Epoch 2, batch 17080, batch avg loss 0.3393, total avg loss: 0.3458, batch size: 39
2021-08-25 06:18:58,234 INFO [train.py:450] Epoch 2, batch 17090, batch avg loss 0.3360, total avg loss: 0.3464, batch size: 37
2021-08-25 06:19:04,587 INFO [train.py:450] Epoch 2, batch 17100, batch avg loss 0.3457, total avg loss: 0.3461, batch size: 40
2021-08-25 06:19:11,126 INFO [train.py:450] Epoch 2, batch 17110, batch avg loss 0.3259, total avg loss: 0.3476, batch size: 39
2021-08-25 06:19:17,045 INFO [train.py:450] Epoch 2, batch 17120, batch avg loss 0.2985, total avg loss: 0.3472, batch size: 42
2021-08-25 06:19:23,286 INFO [train.py:450] Epoch 2, batch 17130, batch avg loss 0.3177, total avg loss: 0.3483, batch size: 42
2021-08-25 06:19:29,224 INFO [train.py:450] Epoch 2, batch 17140, batch avg loss 0.3497, total avg loss: 0.3486, batch size: 37
2021-08-25 06:19:35,285 INFO [train.py:450] Epoch 2, batch 17150, batch avg loss 0.4012, total avg loss: 0.3488, batch size: 38
2021-08-25 06:19:41,394 INFO [train.py:450] Epoch 2, batch 17160, batch avg loss 0.3182, total avg loss: 0.3488, batch size: 40
2021-08-25 06:19:47,811 INFO [train.py:450] Epoch 2, batch 17170, batch avg loss 0.3493, total avg loss: 0.3485, batch size: 42
2021-08-25 06:19:54,055 INFO [train.py:450] Epoch 2, batch 17180, batch avg loss 0.4064, total avg loss: 0.3485, batch size: 42
2021-08-25 06:20:00,136 INFO [train.py:450] Epoch 2, batch 17190, batch avg loss 0.3389, total avg loss: 0.3483, batch size: 42
2021-08-25 06:20:06,332 INFO [train.py:450] Epoch 2, batch 17200, batch avg loss 0.3907, total avg loss: 0.3485, batch size: 41
2021-08-25 06:20:12,180 INFO [train.py:450] Epoch 2, batch 17210, batch avg loss 0.3172, total avg loss: 0.3424, batch size: 39
2021-08-25 06:20:18,368 INFO [train.py:450] Epoch 2, batch 17220, batch avg loss 0.3558, total avg loss: 0.3454, batch size: 47
2021-08-25 06:20:24,398 INFO [train.py:450] Epoch 2, batch 17230, batch avg loss 0.3374, total avg loss: 0.3441, batch size: 43
2021-08-25 06:20:30,860 INFO [train.py:450] Epoch 2, batch 17240, batch avg loss 0.3202, total avg loss: 0.3462, batch size: 43
2021-08-25 06:20:37,115 INFO [train.py:450] Epoch 2, batch 17250, batch avg loss 0.3445, total avg loss: 0.3451, batch size: 40
2021-08-25 06:20:43,339 INFO [train.py:450] Epoch 2, batch 17260, batch avg loss 0.3771, total avg loss: 0.3453, batch size: 39
2021-08-25 06:20:49,369 INFO [train.py:450] Epoch 2, batch 17270, batch avg loss 0.3242, total avg loss: 0.3449, batch size: 40
2021-08-25 06:20:55,874 INFO [train.py:450] Epoch 2, batch 17280, batch avg loss 0.2919, total avg loss: 0.3439, batch size: 36
2021-08-25 06:21:02,263 INFO [train.py:450] Epoch 2, batch 17290, batch avg loss 0.3449, total avg loss: 0.3442, batch size: 42
2021-08-25 06:21:08,380 INFO [train.py:450] Epoch 2, batch 17300, batch avg loss 0.3433, total avg loss: 0.3439, batch size: 44
2021-08-25 06:21:14,603 INFO [train.py:450] Epoch 2, batch 17310, batch avg loss 0.3504, total avg loss: 0.3428, batch size: 39
2021-08-25 06:21:20,817 INFO [train.py:450] Epoch 2, batch 17320, batch avg loss 0.3517, total avg loss: 0.3444, batch size: 40
2021-08-25 06:21:26,885 INFO [train.py:450] Epoch 2, batch 17330, batch avg loss 0.3230, total avg loss: 0.3452, batch size: 41
2021-08-25 06:21:32,951 INFO [train.py:450] Epoch 2, batch 17340, batch avg loss 0.4297, total avg loss: 0.3471, batch size: 41
2021-08-25 06:21:39,145 INFO [train.py:450] Epoch 2, batch 17350, batch avg loss 0.3398, total avg loss: 0.3465, batch size: 39
2021-08-25 06:21:45,418 INFO [train.py:450] Epoch 2, batch 17360, batch avg loss 0.3490, total avg loss: 0.3462, batch size: 41
2021-08-25 06:21:51,764 INFO [train.py:450] Epoch 2, batch 17370, batch avg loss 0.3040, total avg loss: 0.3466, batch size: 40
2021-08-25 06:21:58,317 INFO [train.py:450] Epoch 2, batch 17380, batch avg loss 0.3449, total avg loss: 0.3468, batch size: 46
2021-08-25 06:22:04,336 INFO [train.py:450] Epoch 2, batch 17390, batch avg loss 0.3603, total avg loss: 0.3466, batch size: 36
2021-08-25 06:22:10,476 INFO [train.py:450] Epoch 2, batch 17400, batch avg loss 0.3186, total avg loss: 0.3467, batch size: 39
2021-08-25 06:22:17,160 INFO [train.py:450] Epoch 2, batch 17410, batch avg loss 0.3242, total avg loss: 0.3362, batch size: 41
2021-08-25 06:22:25,709 INFO [train.py:450] Epoch 2, batch 17420, batch avg loss 0.3980, total avg loss: 0.3422, batch size: 36
2021-08-25 06:22:31,985 INFO [train.py:450] Epoch 2, batch 17430, batch avg loss 0.3424, total avg loss: 0.3437, batch size: 40
2021-08-25 06:22:40,307 INFO [train.py:450] Epoch 2, batch 17440, batch avg loss 0.3642, total avg loss: 0.3436, batch size: 40
2021-08-25 06:22:46,365 INFO [train.py:450] Epoch 2, batch 17450, batch avg loss 0.3226, total avg loss: 0.3458, batch size: 37
2021-08-25 06:22:52,460 INFO [train.py:450] Epoch 2, batch 17460, batch avg loss 0.3528, total avg loss: 0.3451, batch size: 39
2021-08-25 06:22:58,434 INFO [train.py:450] Epoch 2, batch 17470, batch avg loss 0.3410, total avg loss: 0.3480, batch size: 41
2021-08-25 06:23:04,896 INFO [train.py:450] Epoch 2, batch 17480, batch avg loss 0.3374, total avg loss: 0.3481, batch size: 44
2021-08-25 06:23:11,447 INFO [train.py:450] Epoch 2, batch 17490, batch avg loss 0.3511, total avg loss: 0.3475, batch size: 40
2021-08-25 06:23:18,027 INFO [train.py:450] Epoch 2, batch 17500, batch avg loss 0.2721, total avg loss: 0.3462, batch size: 38
2021-08-25 06:23:24,417 INFO [train.py:450] Epoch 2, batch 17510, batch avg loss 0.3522, total avg loss: 0.3460, batch size: 43
2021-08-25 06:23:30,803 INFO [train.py:450] Epoch 2, batch 17520, batch avg loss 0.3270, total avg loss: 0.3459, batch size: 42
2021-08-25 06:23:36,754 INFO [train.py:450] Epoch 2, batch 17530, batch avg loss 0.3588, total avg loss: 0.3455, batch size: 42
2021-08-25 06:23:42,754 INFO [train.py:450] Epoch 2, batch 17540, batch avg loss 0.3521, total avg loss: 0.3457, batch size: 39
2021-08-25 06:23:48,850 INFO [train.py:450] Epoch 2, batch 17550, batch avg loss 0.3233, total avg loss: 0.3456, batch size: 39
2021-08-25 06:23:56,119 INFO [train.py:450] Epoch 2, batch 17560, batch avg loss 0.3198, total avg loss: 0.3457, batch size: 39
2021-08-25 06:24:02,668 INFO [train.py:450] Epoch 2, batch 17570, batch avg loss 0.3382, total avg loss: 0.3466, batch size: 39
2021-08-25 06:24:09,191 INFO [train.py:450] Epoch 2, batch 17580, batch avg loss 0.3177, total avg loss: 0.3466, batch size: 41
2021-08-25 06:24:15,647 INFO [train.py:450] Epoch 2, batch 17590, batch avg loss 0.3005, total avg loss: 0.3463, batch size: 37
2021-08-25 06:24:21,723 INFO [train.py:450] Epoch 2, batch 17600, batch avg loss 0.4047, total avg loss: 0.3462, batch size: 37
2021-08-25 06:24:28,458 INFO [train.py:450] Epoch 2, batch 17610, batch avg loss 0.3211, total avg loss: 0.3350, batch size: 36
2021-08-25 06:24:34,365 INFO [train.py:450] Epoch 2, batch 17620, batch avg loss 0.3584, total avg loss: 0.3394, batch size: 41
2021-08-25 06:24:40,350 INFO [train.py:450] Epoch 2, batch 17630, batch avg loss 0.3672, total avg loss: 0.3425, batch size: 38
2021-08-25 06:24:46,598 INFO [train.py:450] Epoch 2, batch 17640, batch avg loss 0.3656, total avg loss: 0.3407, batch size: 42
2021-08-25 06:24:52,550 INFO [train.py:450] Epoch 2, batch 17650, batch avg loss 0.3427, total avg loss: 0.3403, batch size: 41
2021-08-25 06:24:59,435 INFO [train.py:450] Epoch 2, batch 17660, batch avg loss 0.3544, total avg loss: 0.3385, batch size: 38
2021-08-25 06:25:05,792 INFO [train.py:450] Epoch 2, batch 17670, batch avg loss 0.3022, total avg loss: 0.3386, batch size: 40
2021-08-25 06:25:11,606 INFO [train.py:450] Epoch 2, batch 17680, batch avg loss 0.3444, total avg loss: 0.3379, batch size: 40
2021-08-25 06:25:17,533 INFO [train.py:450] Epoch 2, batch 17690, batch avg loss 0.4291, total avg loss: 0.3413, batch size: 43
2021-08-25 06:25:23,498 INFO [train.py:450] Epoch 2, batch 17700, batch avg loss 0.3351, total avg loss: 0.3427, batch size: 37
2021-08-25 06:25:29,674 INFO [train.py:450] Epoch 2, batch 17710, batch avg loss 0.2802, total avg loss: 0.3421, batch size: 37
2021-08-25 06:25:35,795 INFO [train.py:450] Epoch 2, batch 17720, batch avg loss 0.3282, total avg loss: 0.3414, batch size: 41
2021-08-25 06:25:42,030 INFO [train.py:450] Epoch 2, batch 17730, batch avg loss 0.3448, total avg loss: 0.3409, batch size: 40
2021-08-25 06:25:47,923 INFO [train.py:450] Epoch 2, batch 17740, batch avg loss 0.3290, total avg loss: 0.3420, batch size: 42
2021-08-25 06:25:53,951 INFO [train.py:450] Epoch 2, batch 17750, batch avg loss 0.3782, total avg loss: 0.3431, batch size: 42
2021-08-25 06:26:00,061 INFO [train.py:450] Epoch 2, batch 17760, batch avg loss 0.3477, total avg loss: 0.3436, batch size: 40
2021-08-25 06:26:06,035 INFO [train.py:450] Epoch 2, batch 17770, batch avg loss 0.3232, total avg loss: 0.3435, batch size: 38
2021-08-25 06:26:13,164 INFO [train.py:450] Epoch 2, batch 17780, batch avg loss 0.3391, total avg loss: 0.3430, batch size: 43
2021-08-25 06:26:20,348 INFO [train.py:450] Epoch 2, batch 17790, batch avg loss 0.3484, total avg loss: 0.3435, batch size: 43
2021-08-25 06:26:26,398 INFO [train.py:450] Epoch 2, batch 17800, batch avg loss 0.3282, total avg loss: 0.3433, batch size: 38
2021-08-25 06:26:35,596 INFO [train.py:450] Epoch 2, batch 17810, batch avg loss 0.3196, total avg loss: 0.3366, batch size: 39
2021-08-25 06:26:41,526 INFO [train.py:450] Epoch 2, batch 17820, batch avg loss 0.3430, total avg loss: 0.3431, batch size: 38
2021-08-25 06:26:47,671 INFO [train.py:450] Epoch 2, batch 17830, batch avg loss 0.4106, total avg loss: 0.3386, batch size: 37
2021-08-25 06:26:54,088 INFO [train.py:450] Epoch 2, batch 17840, batch avg loss 0.3675, total avg loss: 0.3441, batch size: 43
2021-08-25 06:27:00,441 INFO [train.py:450] Epoch 2, batch 17850, batch avg loss 0.2991, total avg loss: 0.3413, batch size: 39
2021-08-25 06:27:07,086 INFO [train.py:450] Epoch 2, batch 17860, batch avg loss 0.3168, total avg loss: 0.3398, batch size: 39
2021-08-25 06:27:13,103 INFO [train.py:450] Epoch 2, batch 17870, batch avg loss 0.3623, total avg loss: 0.3382, batch size: 40
2021-08-25 06:27:19,370 INFO [train.py:450] Epoch 2, batch 17880, batch avg loss 0.3685, total avg loss: 0.3387, batch size: 38
2021-08-25 06:27:25,848 INFO [train.py:450] Epoch 2, batch 17890, batch avg loss 0.4100, total avg loss: 0.3435, batch size: 40
2021-08-25 06:27:32,044 INFO [train.py:450] Epoch 2, batch 17900, batch avg loss 0.3915, total avg loss: 0.3437, batch size: 40
2021-08-25 06:27:38,358 INFO [train.py:450] Epoch 2, batch 17910, batch avg loss 0.3073, total avg loss: 0.3423, batch size: 38
2021-08-25 06:27:44,690 INFO [train.py:450] Epoch 2, batch 17920, batch avg loss 0.2977, total avg loss: 0.3411, batch size: 39
2021-08-25 06:27:50,701 INFO [train.py:450] Epoch 2, batch 17930, batch avg loss 0.3078, total avg loss: 0.3403, batch size: 45
2021-08-25 06:27:56,718 INFO [train.py:450] Epoch 2, batch 17940, batch avg loss 0.3189, total avg loss: 0.3406, batch size: 38
2021-08-25 06:28:02,807 INFO [train.py:450] Epoch 2, batch 17950, batch avg loss 0.4091, total avg loss: 0.3413, batch size: 37
2021-08-25 06:28:08,956 INFO [train.py:450] Epoch 2, batch 17960, batch avg loss 0.3136, total avg loss: 0.3413, batch size: 36
2021-08-25 06:28:15,264 INFO [train.py:450] Epoch 2, batch 17970, batch avg loss 0.3410, total avg loss: 0.3419, batch size: 42
2021-08-25 06:28:21,525 INFO [train.py:450] Epoch 2, batch 17980, batch avg loss 0.3377, total avg loss: 0.3420, batch size: 43
2021-08-25 06:28:27,696 INFO [train.py:450] Epoch 2, batch 17990, batch avg loss 0.3967, total avg loss: 0.3422, batch size: 40
2021-08-25 06:28:34,109 INFO [train.py:450] Epoch 2, batch 18000, batch avg loss 0.3467, total avg loss: 0.3423, batch size: 41
2021-08-25 06:29:15,065 INFO [train.py:482] Epoch 2, valid loss 0.2450, best valid loss: 0.2434 best valid epoch: 2
2021-08-25 06:29:21,342 INFO [train.py:450] Epoch 2, batch 18010, batch avg loss 0.3165, total avg loss: 0.3380, batch size: 39
2021-08-25 06:29:27,247 INFO [train.py:450] Epoch 2, batch 18020, batch avg loss 0.3564, total avg loss: 0.3411, batch size: 40
2021-08-25 06:29:33,456 INFO [train.py:450] Epoch 2, batch 18030, batch avg loss 0.3167, total avg loss: 0.3427, batch size: 42
2021-08-25 06:29:42,185 INFO [train.py:450] Epoch 2, batch 18040, batch avg loss 0.3236, total avg loss: 0.3430, batch size: 42
2021-08-25 06:29:48,415 INFO [train.py:450] Epoch 2, batch 18050, batch avg loss 0.3126, total avg loss: 0.3410, batch size: 42
2021-08-25 06:29:56,795 INFO [train.py:450] Epoch 2, batch 18060, batch avg loss 0.2814, total avg loss: 0.3405, batch size: 39
2021-08-25 06:30:04,593 INFO [train.py:450] Epoch 2, batch 18070, batch avg loss 0.3278, total avg loss: 0.3401, batch size: 37
2021-08-25 06:30:11,432 INFO [train.py:450] Epoch 2, batch 18080, batch avg loss 0.3257, total avg loss: 0.3399, batch size: 40
2021-08-25 06:30:17,696 INFO [train.py:450] Epoch 2, batch 18090, batch avg loss 0.3167, total avg loss: 0.3393, batch size: 37
2021-08-25 06:30:24,092 INFO [train.py:450] Epoch 2, batch 18100, batch avg loss 0.3634, total avg loss: 0.3398, batch size: 39
2021-08-25 06:30:30,220 INFO [train.py:450] Epoch 2, batch 18110, batch avg loss 0.3219, total avg loss: 0.3417, batch size: 36
2021-08-25 06:30:36,533 INFO [train.py:450] Epoch 2, batch 18120, batch avg loss 0.3842, total avg loss: 0.3406, batch size: 41
2021-08-25 06:30:42,996 INFO [train.py:450] Epoch 2, batch 18130, batch avg loss 0.3023, total avg loss: 0.3398, batch size: 40
2021-08-25 06:30:49,318 INFO [train.py:450] Epoch 2, batch 18140, batch avg loss 0.3950, total avg loss: 0.3394, batch size: 41
2021-08-25 06:30:55,245 INFO [train.py:450] Epoch 2, batch 18150, batch avg loss 0.3613, total avg loss: 0.3397, batch size: 39
2021-08-25 06:31:01,849 INFO [train.py:450] Epoch 2, batch 18160, batch avg loss 0.3156, total avg loss: 0.3402, batch size: 37
2021-08-25 06:31:08,401 INFO [train.py:450] Epoch 2, batch 18170, batch avg loss 0.3450, total avg loss: 0.3406, batch size: 39
2021-08-25 06:31:14,584 INFO [train.py:450] Epoch 2, batch 18180, batch avg loss 0.3763, total avg loss: 0.3412, batch size: 43
2021-08-25 06:31:20,619 INFO [train.py:450] Epoch 2, batch 18190, batch avg loss 0.3176, total avg loss: 0.3413, batch size: 40
2021-08-25 06:31:26,777 INFO [train.py:450] Epoch 2, batch 18200, batch avg loss 0.3180, total avg loss: 0.3414, batch size: 40
2021-08-25 06:31:33,018 INFO [train.py:450] Epoch 2, batch 18210, batch avg loss 0.3526, total avg loss: 0.3431, batch size: 38
2021-08-25 06:31:39,267 INFO [train.py:450] Epoch 2, batch 18220, batch avg loss 0.3822, total avg loss: 0.3441, batch size: 39
2021-08-25 06:31:45,453 INFO [train.py:450] Epoch 2, batch 18230, batch avg loss 0.2819, total avg loss: 0.3422, batch size: 41
2021-08-25 06:31:51,490 INFO [train.py:450] Epoch 2, batch 18240, batch avg loss 0.3253, total avg loss: 0.3441, batch size: 44
2021-08-25 06:31:57,766 INFO [train.py:450] Epoch 2, batch 18250, batch avg loss 0.3018, total avg loss: 0.3465, batch size: 40
2021-08-25 06:32:04,108 INFO [train.py:450] Epoch 2, batch 18260, batch avg loss 0.3883, total avg loss: 0.3468, batch size: 40
2021-08-25 06:32:09,966 INFO [train.py:450] Epoch 2, batch 18270, batch avg loss 0.3392, total avg loss: 0.3471, batch size: 41
2021-08-25 06:32:15,962 INFO [train.py:450] Epoch 2, batch 18280, batch avg loss 0.2951, total avg loss: 0.3440, batch size: 39
2021-08-25 06:32:22,113 INFO [train.py:450] Epoch 2, batch 18290, batch avg loss 0.3098, total avg loss: 0.3431, batch size: 41
2021-08-25 06:32:28,155 INFO [train.py:450] Epoch 2, batch 18300, batch avg loss 0.3331, total avg loss: 0.3431, batch size: 37
2021-08-25 06:32:34,238 INFO [train.py:450] Epoch 2, batch 18310, batch avg loss 0.3296, total avg loss: 0.3430, batch size: 38
2021-08-25 06:32:40,199 INFO [train.py:450] Epoch 2, batch 18320, batch avg loss 0.3640, total avg loss: 0.3426, batch size: 38
2021-08-25 06:32:46,457 INFO [train.py:450] Epoch 2, batch 18330, batch avg loss 0.3358, total avg loss: 0.3430, batch size: 39
2021-08-25 06:32:53,273 INFO [train.py:450] Epoch 2, batch 18340, batch avg loss 0.3186, total avg loss: 0.3425, batch size: 41
2021-08-25 06:32:59,374 INFO [train.py:450] Epoch 2, batch 18350, batch avg loss 0.3528, total avg loss: 0.3432, batch size: 41
2021-08-25 06:33:05,439 INFO [train.py:450] Epoch 2, batch 18360, batch avg loss 0.3719, total avg loss: 0.3428, batch size: 38
2021-08-25 06:33:12,202 INFO [train.py:450] Epoch 2, batch 18370, batch avg loss 0.3296, total avg loss: 0.3432, batch size: 40
2021-08-25 06:33:18,950 INFO [train.py:450] Epoch 2, batch 18380, batch avg loss 0.3232, total avg loss: 0.3436, batch size: 40
2021-08-25 06:33:25,814 INFO [train.py:450] Epoch 2, batch 18390, batch avg loss 0.3045, total avg loss: 0.3437, batch size: 38
2021-08-25 06:33:32,203 INFO [train.py:450] Epoch 2, batch 18400, batch avg loss 0.3322, total avg loss: 0.3435, batch size: 41
2021-08-25 06:33:38,303 INFO [train.py:450] Epoch 2, batch 18410, batch avg loss 0.3016, total avg loss: 0.3185, batch size: 45
2021-08-25 06:33:44,373 INFO [train.py:450] Epoch 2, batch 18420, batch avg loss 0.3012, total avg loss: 0.3266, batch size: 41
2021-08-25 06:33:51,356 INFO [train.py:450] Epoch 2, batch 18430, batch avg loss 0.4292, total avg loss: 0.3361, batch size: 43
2021-08-25 06:33:57,874 INFO [train.py:450] Epoch 2, batch 18440, batch avg loss 0.3390, total avg loss: 0.3354, batch size: 44
2021-08-25 06:34:05,913 INFO [train.py:450] Epoch 2, batch 18450, batch avg loss 0.3341, total avg loss: 0.3392, batch size: 43
2021-08-25 06:34:12,049 INFO [train.py:450] Epoch 2, batch 18460, batch avg loss 0.3582, total avg loss: 0.3386, batch size: 40
2021-08-25 06:34:19,591 INFO [train.py:450] Epoch 2, batch 18470, batch avg loss 0.3615, total avg loss: 0.3404, batch size: 42
2021-08-25 06:34:29,420 INFO [train.py:450] Epoch 2, batch 18480, batch avg loss 0.2954, total avg loss: 0.3419, batch size: 43
2021-08-25 06:34:36,349 INFO [train.py:450] Epoch 2, batch 18490, batch avg loss 0.3781, total avg loss: 0.3427, batch size: 38
2021-08-25 06:34:43,678 INFO [train.py:450] Epoch 2, batch 18500, batch avg loss 0.3150, total avg loss: 0.3422, batch size: 38
2021-08-25 06:34:50,193 INFO [train.py:450] Epoch 2, batch 18510, batch avg loss 0.3448, total avg loss: 0.3418, batch size: 39
2021-08-25 06:34:58,411 INFO [train.py:450] Epoch 2, batch 18520, batch avg loss 0.3252, total avg loss: 0.3400, batch size: 42
2021-08-25 06:35:05,555 INFO [train.py:450] Epoch 2, batch 18530, batch avg loss 0.3424, total avg loss: 0.3398, batch size: 42
2021-08-25 06:35:13,589 INFO [train.py:450] Epoch 2, batch 18540, batch avg loss 0.3177, total avg loss: 0.3407, batch size: 40
2021-08-25 06:35:21,081 INFO [train.py:450] Epoch 2, batch 18550, batch avg loss 0.4053, total avg loss: 0.3404, batch size: 41
2021-08-25 06:35:29,487 INFO [train.py:450] Epoch 2, batch 18560, batch avg loss 0.3632, total avg loss: 0.3410, batch size: 39
2021-08-25 06:35:36,643 INFO [train.py:450] Epoch 2, batch 18570, batch avg loss 0.3458, total avg loss: 0.3415, batch size: 41
2021-08-25 06:35:43,630 INFO [train.py:450] Epoch 2, batch 18580, batch avg loss 0.3656, total avg loss: 0.3420, batch size: 42
2021-08-25 06:35:50,187 INFO [train.py:450] Epoch 2, batch 18590, batch avg loss 0.3258, total avg loss: 0.3422, batch size: 36
2021-08-25 06:35:56,575 INFO [train.py:450] Epoch 2, batch 18600, batch avg loss 0.3469, total avg loss: 0.3432, batch size: 41
2021-08-25 06:36:03,584 INFO [train.py:450] Epoch 2, batch 18610, batch avg loss 0.3071, total avg loss: 0.3411, batch size: 37
2021-08-25 06:36:10,356 INFO [train.py:450] Epoch 2, batch 18620, batch avg loss 0.3538, total avg loss: 0.3364, batch size: 41
2021-08-25 06:36:17,594 INFO [train.py:450] Epoch 2, batch 18630, batch avg loss 0.4048, total avg loss: 0.3452, batch size: 38
2021-08-25 06:36:24,219 INFO [train.py:450] Epoch 2, batch 18640, batch avg loss 0.2877, total avg loss: 0.3436, batch size: 40
2021-08-25 06:36:31,594 INFO [train.py:450] Epoch 2, batch 18650, batch avg loss 0.3157, total avg loss: 0.3420, batch size: 38
2021-08-25 06:36:38,562 INFO [train.py:450] Epoch 2, batch 18660, batch avg loss 0.3674, total avg loss: 0.3404, batch size: 41
2021-08-25 06:36:45,445 INFO [train.py:450] Epoch 2, batch 18670, batch avg loss 0.3227, total avg loss: 0.3401, batch size: 45
2021-08-25 06:36:52,041 INFO [train.py:450] Epoch 2, batch 18680, batch avg loss 0.3381, total avg loss: 0.3384, batch size: 41
2021-08-25 06:36:58,792 INFO [train.py:450] Epoch 2, batch 18690, batch avg loss 0.3366, total avg loss: 0.3379, batch size: 44
2021-08-25 06:37:05,882 INFO [train.py:450] Epoch 2, batch 18700, batch avg loss 0.3314, total avg loss: 0.3375, batch size: 41
2021-08-25 06:37:12,064 INFO [train.py:450] Epoch 2, batch 18710, batch avg loss 0.3253, total avg loss: 0.3377, batch size: 38
2021-08-25 06:37:18,919 INFO [train.py:450] Epoch 2, batch 18720, batch avg loss 0.3243, total avg loss: 0.3371, batch size: 41
2021-08-25 06:37:25,186 INFO [train.py:450] Epoch 2, batch 18730, batch avg loss 0.3018, total avg loss: 0.3372, batch size: 39
2021-08-25 06:37:31,496 INFO [train.py:450] Epoch 2, batch 18740, batch avg loss 0.2921, total avg loss: 0.3364, batch size: 38
2021-08-25 06:37:38,414 INFO [train.py:450] Epoch 2, batch 18750, batch avg loss 0.3095, total avg loss: 0.3362, batch size: 36
2021-08-25 06:37:46,952 INFO [train.py:450] Epoch 2, batch 18760, batch avg loss 0.3138, total avg loss: 0.3363, batch size: 38
2021-08-25 06:37:53,257 INFO [train.py:450] Epoch 2, batch 18770, batch avg loss 0.3779, total avg loss: 0.3358, batch size: 39
2021-08-25 06:38:01,865 INFO [train.py:450] Epoch 2, batch 18780, batch avg loss 0.3669, total avg loss: 0.3371, batch size: 43
2021-08-25 06:38:10,506 INFO [train.py:450] Epoch 2, batch 18790, batch avg loss 0.2870, total avg loss: 0.3371, batch size: 39
2021-08-25 06:38:16,688 INFO [train.py:450] Epoch 2, batch 18800, batch avg loss 0.3681, total avg loss: 0.3374, batch size: 38
2021-08-25 06:38:23,195 INFO [train.py:450] Epoch 2, batch 18810, batch avg loss 0.3311, total avg loss: 0.3374, batch size: 44
2021-08-25 06:38:29,549 INFO [train.py:450] Epoch 2, batch 18820, batch avg loss 0.2868, total avg loss: 0.3388, batch size: 41
2021-08-25 06:38:35,636 INFO [train.py:450] Epoch 2, batch 18830, batch avg loss 0.3697, total avg loss: 0.3349, batch size: 43
2021-08-25 06:38:42,234 INFO [train.py:450] Epoch 2, batch 18840, batch avg loss 0.3299, total avg loss: 0.3343, batch size: 38
2021-08-25 06:38:48,897 INFO [train.py:450] Epoch 2, batch 18850, batch avg loss 0.2950, total avg loss: 0.3333, batch size: 40
2021-08-25 06:38:55,334 INFO [train.py:450] Epoch 2, batch 18860, batch avg loss 0.3110, total avg loss: 0.3338, batch size: 40
2021-08-25 06:39:01,757 INFO [train.py:450] Epoch 2, batch 18870, batch avg loss 0.3976, total avg loss: 0.3405, batch size: 38
2021-08-25 06:39:07,878 INFO [train.py:450] Epoch 2, batch 18880, batch avg loss 0.3813, total avg loss: 0.3420, batch size: 42
2021-08-25 06:39:14,463 INFO [train.py:450] Epoch 2, batch 18890, batch avg loss 0.3681, total avg loss: 0.3411, batch size: 39
2021-08-25 06:39:21,122 INFO [train.py:450] Epoch 2, batch 18900, batch avg loss 0.3716, total avg loss: 0.3432, batch size: 40
2021-08-25 06:39:27,456 INFO [train.py:450] Epoch 2, batch 18910, batch avg loss 0.3289, total avg loss: 0.3430, batch size: 40
2021-08-25 06:39:33,990 INFO [train.py:450] Epoch 2, batch 18920, batch avg loss 0.3593, total avg loss: 0.3437, batch size: 37
2021-08-25 06:39:40,532 INFO [train.py:450] Epoch 2, batch 18930, batch avg loss 0.2754, total avg loss: 0.3430, batch size: 41
2021-08-25 06:39:47,181 INFO [train.py:450] Epoch 2, batch 18940, batch avg loss 0.3974, total avg loss: 0.3446, batch size: 38
2021-08-25 06:39:53,992 INFO [train.py:450] Epoch 2, batch 18950, batch avg loss 0.3417, total avg loss: 0.3446, batch size: 39
2021-08-25 06:40:00,420 INFO [train.py:450] Epoch 2, batch 18960, batch avg loss 0.3189, total avg loss: 0.3457, batch size: 40
2021-08-25 06:40:07,623 INFO [train.py:450] Epoch 2, batch 18970, batch avg loss 0.3664, total avg loss: 0.3463, batch size: 40
2021-08-25 06:40:14,988 INFO [train.py:450] Epoch 2, batch 18980, batch avg loss 0.3043, total avg loss: 0.3471, batch size: 41
2021-08-25 06:40:21,677 INFO [train.py:450] Epoch 2, batch 18990, batch avg loss 0.3040, total avg loss: 0.3468, batch size: 39
2021-08-25 06:40:28,209 INFO [train.py:450] Epoch 2, batch 19000, batch avg loss 0.3628, total avg loss: 0.3469, batch size: 39
2021-08-25 06:41:06,669 INFO [train.py:482] Epoch 2, valid loss 0.2484, best valid loss: 0.2434 best valid epoch: 2
2021-08-25 06:41:12,643 INFO [train.py:450] Epoch 2, batch 19010, batch avg loss 0.3033, total avg loss: 0.3428, batch size: 40
2021-08-25 06:41:18,944 INFO [train.py:450] Epoch 2, batch 19020, batch avg loss 0.3304, total avg loss: 0.3545, batch size: 37
2021-08-25 06:41:25,638 INFO [train.py:450] Epoch 2, batch 19030, batch avg loss 0.3206, total avg loss: 0.3564, batch size: 40
2021-08-25 06:41:32,328 INFO [train.py:450] Epoch 2, batch 19040, batch avg loss 0.3171, total avg loss: 0.3604, batch size: 39
2021-08-25 06:41:39,079 INFO [train.py:450] Epoch 2, batch 19050, batch avg loss 0.3305, total avg loss: 0.3581, batch size: 41
2021-08-25 06:41:45,715 INFO [train.py:450] Epoch 2, batch 19060, batch avg loss 0.3539, total avg loss: 0.3584, batch size: 41
2021-08-25 06:41:53,551 INFO [train.py:450] Epoch 2, batch 19070, batch avg loss 0.3519, total avg loss: 0.3569, batch size: 40
2021-08-25 06:42:00,111 INFO [train.py:450] Epoch 2, batch 19080, batch avg loss 0.3504, total avg loss: 0.3559, batch size: 43
2021-08-25 06:42:09,896 INFO [train.py:450] Epoch 2, batch 19090, batch avg loss 0.3736, total avg loss: 0.3552, batch size: 39
2021-08-25 06:42:16,092 INFO [train.py:450] Epoch 2, batch 19100, batch avg loss 0.3335, total avg loss: 0.3536, batch size: 38
2021-08-25 06:42:22,709 INFO [train.py:450] Epoch 2, batch 19110, batch avg loss 0.3115, total avg loss: 0.3506, batch size: 40
2021-08-25 06:42:29,318 INFO [train.py:450] Epoch 2, batch 19120, batch avg loss 0.3559, total avg loss: 0.3498, batch size: 38
2021-08-25 06:42:36,410 INFO [train.py:450] Epoch 2, batch 19130, batch avg loss 0.3689, total avg loss: 0.3501, batch size: 43
2021-08-25 06:42:42,949 INFO [train.py:450] Epoch 2, batch 19140, batch avg loss 0.3864, total avg loss: 0.3493, batch size: 39
2021-08-25 06:42:49,336 INFO [train.py:450] Epoch 2, batch 19150, batch avg loss 0.3640, total avg loss: 0.3498, batch size: 45
2021-08-25 06:42:56,280 INFO [train.py:450] Epoch 2, batch 19160, batch avg loss 0.3145, total avg loss: 0.3487, batch size: 42
2021-08-25 06:43:02,767 INFO [train.py:450] Epoch 2, batch 19170, batch avg loss 0.3413, total avg loss: 0.3486, batch size: 42
2021-08-25 06:43:08,603 INFO [train.py:450] Epoch 2, batch 19180, batch avg loss 0.3905, total avg loss: 0.3494, batch size: 37
2021-08-25 06:43:15,016 INFO [train.py:450] Epoch 2, batch 19190, batch avg loss 0.3384, total avg loss: 0.3492, batch size: 41
2021-08-25 06:43:21,404 INFO [train.py:450] Epoch 2, batch 19200, batch avg loss 0.3633, total avg loss: 0.3497, batch size: 40
2021-08-25 06:43:27,511 INFO [train.py:450] Epoch 2, batch 19210, batch avg loss 0.3548, total avg loss: 0.3457, batch size: 40
2021-08-25 06:43:34,192 INFO [train.py:450] Epoch 2, batch 19220, batch avg loss 0.3569, total avg loss: 0.3465, batch size: 39
2021-08-25 06:43:40,368 INFO [train.py:450] Epoch 2, batch 19230, batch avg loss 0.3609, total avg loss: 0.3435, batch size: 40
2021-08-25 06:43:47,710 INFO [train.py:450] Epoch 2, batch 19240, batch avg loss 0.3470, total avg loss: 0.3471, batch size: 38
2021-08-25 06:43:54,053 INFO [train.py:450] Epoch 2, batch 19250, batch avg loss 0.3786, total avg loss: 0.3469, batch size: 40
2021-08-25 06:44:00,249 INFO [train.py:450] Epoch 2, batch 19260, batch avg loss 0.3349, total avg loss: 0.3490, batch size: 40
2021-08-25 06:44:06,634 INFO [train.py:450] Epoch 2, batch 19270, batch avg loss 0.3977, total avg loss: 0.3486, batch size: 43
2021-08-25 06:44:12,925 INFO [train.py:450] Epoch 2, batch 19280, batch avg loss 0.2957, total avg loss: 0.3465, batch size: 38
2021-08-25 06:44:19,630 INFO [train.py:450] Epoch 2, batch 19290, batch avg loss 0.3295, total avg loss: 0.3495, batch size: 37
2021-08-25 06:44:26,004 INFO [train.py:450] Epoch 2, batch 19300, batch avg loss 0.3143, total avg loss: 0.3511, batch size: 41
2021-08-25 06:44:31,779 INFO [train.py:450] Epoch 2, batch 19310, batch avg loss 0.3241, total avg loss: 0.3494, batch size: 40
2021-08-25 06:44:37,852 INFO [train.py:450] Epoch 2, batch 19320, batch avg loss 0.3358, total avg loss: 0.3479, batch size: 39
2021-08-25 06:44:44,506 INFO [train.py:450] Epoch 2, batch 19330, batch avg loss 0.3248, total avg loss: 0.3469, batch size: 38
2021-08-25 06:44:50,532 INFO [train.py:450] Epoch 2, batch 19340, batch avg loss 0.3362, total avg loss: 0.3468, batch size: 37
2021-08-25 06:44:56,862 INFO [train.py:450] Epoch 2, batch 19350, batch avg loss 0.3708, total avg loss: 0.3475, batch size: 39
2021-08-25 06:45:03,335 INFO [train.py:450] Epoch 2, batch 19360, batch avg loss 0.3467, total avg loss: 0.3480, batch size: 40
2021-08-25 06:45:09,737 INFO [train.py:450] Epoch 2, batch 19370, batch avg loss 0.3646, total avg loss: 0.3478, batch size: 40
2021-08-25 06:45:16,768 INFO [train.py:450] Epoch 2, batch 19380, batch avg loss 0.3090, total avg loss: 0.3470, batch size: 39
2021-08-25 06:45:23,193 INFO [train.py:450] Epoch 2, batch 19390, batch avg loss 0.3757, total avg loss: 0.3470, batch size: 39
2021-08-25 06:45:30,052 INFO [train.py:450] Epoch 2, batch 19400, batch avg loss 0.3394, total avg loss: 0.3464, batch size: 42
2021-08-25 06:45:36,881 INFO [train.py:450] Epoch 2, batch 19410, batch avg loss 0.3496, total avg loss: 0.3650, batch size: 38
2021-08-25 06:45:44,951 INFO [train.py:450] Epoch 2, batch 19420, batch avg loss 0.3439, total avg loss: 0.3582, batch size: 41
2021-08-25 06:45:52,857 INFO [train.py:450] Epoch 2, batch 19430, batch avg loss 0.3438, total avg loss: 0.3562, batch size: 41
2021-08-25 06:46:00,644 INFO [train.py:450] Epoch 2, batch 19440, batch avg loss 0.3168, total avg loss: 0.3549, batch size: 39
2021-08-25 06:46:07,278 INFO [train.py:450] Epoch 2, batch 19450, batch avg loss 0.3349, total avg loss: 0.3528, batch size: 40
2021-08-25 06:46:13,583 INFO [train.py:450] Epoch 2, batch 19460, batch avg loss 0.3205, total avg loss: 0.3530, batch size: 39
2021-08-25 06:46:20,107 INFO [train.py:450] Epoch 2, batch 19470, batch avg loss 0.3515, total avg loss: 0.3509, batch size: 39
2021-08-25 06:46:27,295 INFO [train.py:450] Epoch 2, batch 19480, batch avg loss 0.3538, total avg loss: 0.3508, batch size: 42
2021-08-25 06:46:33,721 INFO [train.py:450] Epoch 2, batch 19490, batch avg loss 0.3620, total avg loss: 0.3531, batch size: 42
2021-08-25 06:46:40,399 INFO [train.py:450] Epoch 2, batch 19500, batch avg loss 0.3350, total avg loss: 0.3518, batch size: 39
2021-08-25 06:46:47,068 INFO [train.py:450] Epoch 2, batch 19510, batch avg loss 0.3966, total avg loss: 0.3499, batch size: 37
2021-08-25 06:46:49,655 WARNING [cut.py:1694] To perform mix, energy must be non-zero and non-negative (got 0.0).  MonoCut with id "28ebab65-a4b9-871b-b89f-cd35a698120b" will not be mixed in.
2021-08-25 06:46:53,484 INFO [train.py:450] Epoch 2, batch 19520, batch avg loss 0.3491, total avg loss: 0.3499, batch size: 40
2021-08-25 06:47:00,011 INFO [train.py:450] Epoch 2, batch 19530, batch avg loss 0.3921, total avg loss: 0.3506, batch size: 41
2021-08-25 06:47:06,124 INFO [train.py:450] Epoch 2, batch 19540, batch avg loss 0.4254, total avg loss: 0.3516, batch size: 40
2021-08-25 06:47:12,427 INFO [train.py:450] Epoch 2, batch 19550, batch avg loss 0.3412, total avg loss: 0.3502, batch size: 41
2021-08-25 06:47:19,090 INFO [train.py:450] Epoch 2, batch 19560, batch avg loss 0.3189, total avg loss: 0.3500, batch size: 38
2021-08-25 06:47:25,609 INFO [train.py:450] Epoch 2, batch 19570, batch avg loss 0.3425, total avg loss: 0.3498, batch size: 41
2021-08-25 06:47:31,887 INFO [train.py:450] Epoch 2, batch 19580, batch avg loss 0.3793, total avg loss: 0.3508, batch size: 41
2021-08-25 06:47:38,264 INFO [train.py:450] Epoch 2, batch 19590, batch avg loss 0.2672, total avg loss: 0.3506, batch size: 39
2021-08-25 06:47:44,688 INFO [train.py:450] Epoch 2, batch 19600, batch avg loss 0.2888, total avg loss: 0.3490, batch size: 42
2021-08-25 06:47:51,185 INFO [train.py:450] Epoch 2, batch 19610, batch avg loss 0.3673, total avg loss: 0.3417, batch size: 40
2021-08-25 06:47:57,423 INFO [train.py:450] Epoch 2, batch 19620, batch avg loss 0.3338, total avg loss: 0.3491, batch size: 38
2021-08-25 06:48:03,500 INFO [train.py:450] Epoch 2, batch 19630, batch avg loss 0.2596, total avg loss: 0.3517, batch size: 37
2021-08-25 06:48:10,417 INFO [train.py:450] Epoch 2, batch 19640, batch avg loss 0.3946, total avg loss: 0.3568, batch size: 42
2021-08-25 06:48:16,416 INFO [train.py:450] Epoch 2, batch 19650, batch avg loss 0.3421, total avg loss: 0.3569, batch size: 45
2021-08-25 06:48:22,943 INFO [train.py:450] Epoch 2, batch 19660, batch avg loss 0.3111, total avg loss: 0.3567, batch size: 39
2021-08-25 06:48:28,872 INFO [train.py:450] Epoch 2, batch 19670, batch avg loss 0.3404, total avg loss: 0.3538, batch size: 41
2021-08-25 06:48:35,091 INFO [train.py:450] Epoch 2, batch 19680, batch avg loss 0.3106, total avg loss: 0.3515, batch size: 40
2021-08-25 06:48:41,090 INFO [train.py:450] Epoch 2, batch 19690, batch avg loss 0.3133, total avg loss: 0.3499, batch size: 39
2021-08-25 06:48:47,584 INFO [train.py:450] Epoch 2, batch 19700, batch avg loss 0.3795, total avg loss: 0.3498, batch size: 36
2021-08-25 06:48:54,001 INFO [train.py:450] Epoch 2, batch 19710, batch avg loss 0.3930, total avg loss: 0.3511, batch size: 36
2021-08-25 06:49:00,532 INFO [train.py:450] Epoch 2, batch 19720, batch avg loss 0.3362, total avg loss: 0.3523, batch size: 38
2021-08-25 06:49:06,509 INFO [train.py:450] Epoch 2, batch 19730, batch avg loss 0.3248, total avg loss: 0.3524, batch size: 39
2021-08-25 06:49:13,168 INFO [train.py:450] Epoch 2, batch 19740, batch avg loss 0.3391, total avg loss: 0.3511, batch size: 36
2021-08-25 06:49:19,486 INFO [train.py:450] Epoch 2, batch 19750, batch avg loss 0.3616, total avg loss: 0.3503, batch size: 41
2021-08-25 06:49:27,515 INFO [train.py:450] Epoch 2, batch 19760, batch avg loss 0.4200, total avg loss: 0.3508, batch size: 37
2021-08-25 06:49:35,280 INFO [train.py:450] Epoch 2, batch 19770, batch avg loss 0.3294, total avg loss: 0.3504, batch size: 39
2021-08-25 06:49:41,566 INFO [train.py:450] Epoch 2, batch 19780, batch avg loss 0.4028, total avg loss: 0.3509, batch size: 40
2021-08-25 06:49:47,878 INFO [train.py:450] Epoch 2, batch 19790, batch avg loss 0.3332, total avg loss: 0.3507, batch size: 41
2021-08-25 06:49:54,704 INFO [train.py:450] Epoch 2, batch 19800, batch avg loss 0.3474, total avg loss: 0.3510, batch size: 44
2021-08-25 06:50:01,221 INFO [train.py:450] Epoch 2, batch 19810, batch avg loss 0.3194, total avg loss: 0.3356, batch size: 39
2021-08-25 06:50:07,685 INFO [train.py:450] Epoch 2, batch 19820, batch avg loss 0.3677, total avg loss: 0.3427, batch size: 43
2021-08-25 06:50:13,942 INFO [train.py:450] Epoch 2, batch 19830, batch avg loss 0.3454, total avg loss: 0.3429, batch size: 38
2021-08-25 06:50:20,322 INFO [train.py:450] Epoch 2, batch 19840, batch avg loss 0.3152, total avg loss: 0.3454, batch size: 38
2021-08-25 06:50:27,031 INFO [train.py:450] Epoch 2, batch 19850, batch avg loss 0.3256, total avg loss: 0.3459, batch size: 38
2021-08-25 06:50:33,479 INFO [train.py:450] Epoch 2, batch 19860, batch avg loss 0.3890, total avg loss: 0.3450, batch size: 39
2021-08-25 06:50:40,218 INFO [train.py:450] Epoch 2, batch 19870, batch avg loss 0.3680, total avg loss: 0.3447, batch size: 43
2021-08-25 06:50:46,563 INFO [train.py:450] Epoch 2, batch 19880, batch avg loss 0.4164, total avg loss: 0.3450, batch size: 37
2021-08-25 06:51:00,248 INFO [train.py:450] Epoch 2, batch 19890, batch avg loss 0.3728, total avg loss: 0.3478, batch size: 42
2021-08-25 06:51:06,172 INFO [train.py:450] Epoch 2, batch 19900, batch avg loss 0.3264, total avg loss: 0.3483, batch size: 38
2021-08-25 06:51:12,275 INFO [train.py:450] Epoch 2, batch 19910, batch avg loss 0.3811, total avg loss: 0.3496, batch size: 42
2021-08-25 06:51:18,469 INFO [train.py:450] Epoch 2, batch 19920, batch avg loss 0.3812, total avg loss: 0.3496, batch size: 38
2021-08-25 06:51:24,665 INFO [train.py:450] Epoch 2, batch 19930, batch avg loss 0.3932, total avg loss: 0.3503, batch size: 39
2021-08-25 06:51:30,940 INFO [train.py:450] Epoch 2, batch 19940, batch avg loss 0.3334, total avg loss: 0.3499, batch size: 44
2021-08-25 06:51:37,162 INFO [train.py:450] Epoch 2, batch 19950, batch avg loss 0.3432, total avg loss: 0.3498, batch size: 39
2021-08-25 06:51:43,749 INFO [train.py:450] Epoch 2, batch 19960, batch avg loss 0.3965, total avg loss: 0.3509, batch size: 36
2021-08-25 06:51:50,854 INFO [train.py:450] Epoch 2, batch 19970, batch avg loss 0.2795, total avg loss: 0.3497, batch size: 38
2021-08-25 06:51:57,422 INFO [train.py:450] Epoch 2, batch 19980, batch avg loss 0.3477, total avg loss: 0.3495, batch size: 40
2021-08-25 06:52:03,716 INFO [train.py:450] Epoch 2, batch 19990, batch avg loss 0.3285, total avg loss: 0.3497, batch size: 39
2021-08-25 06:52:09,748 INFO [train.py:450] Epoch 2, batch 20000, batch avg loss 0.4388, total avg loss: 0.3502, batch size: 43
2021-08-25 06:52:47,978 INFO [train.py:482] Epoch 2, valid loss 0.2449, best valid loss: 0.2434 best valid epoch: 2
2021-08-25 06:52:53,825 INFO [train.py:450] Epoch 2, batch 20010, batch avg loss 0.3543, total avg loss: 0.3435, batch size: 41
2021-08-25 06:52:59,909 INFO [train.py:450] Epoch 2, batch 20020, batch avg loss 0.3429, total avg loss: 0.3437, batch size: 36
2021-08-25 06:53:06,411 INFO [train.py:450] Epoch 2, batch 20030, batch avg loss 0.3431, total avg loss: 0.3497, batch size: 38
2021-08-25 06:53:14,390 INFO [train.py:450] Epoch 2, batch 20040, batch avg loss 0.2989, total avg loss: 0.3500, batch size: 41
2021-08-25 06:53:23,240 INFO [train.py:450] Epoch 2, batch 20050, batch avg loss 0.3281, total avg loss: 0.3490, batch size: 40
2021-08-25 06:53:32,206 INFO [train.py:450] Epoch 2, batch 20060, batch avg loss 0.3395, total avg loss: 0.3498, batch size: 41
2021-08-25 06:53:38,969 INFO [train.py:450] Epoch 2, batch 20070, batch avg loss 0.3236, total avg loss: 0.3462, batch size: 40
2021-08-25 06:53:45,598 INFO [train.py:450] Epoch 2, batch 20080, batch avg loss 0.4086, total avg loss: 0.3453, batch size: 37
2021-08-25 06:53:52,692 INFO [train.py:450] Epoch 2, batch 20090, batch avg loss 0.3350, total avg loss: 0.3446, batch size: 42
2021-08-25 06:53:59,230 INFO [train.py:450] Epoch 2, batch 20100, batch avg loss 0.3486, total avg loss: 0.3434, batch size: 39
2021-08-25 06:54:05,786 INFO [train.py:450] Epoch 2, batch 20110, batch avg loss 0.3370, total avg loss: 0.3430, batch size: 37
2021-08-25 06:54:12,974 INFO [train.py:450] Epoch 2, batch 20120, batch avg loss 0.3603, total avg loss: 0.3444, batch size: 39
2021-08-25 06:54:19,244 INFO [train.py:450] Epoch 2, batch 20130, batch avg loss 0.3211, total avg loss: 0.3438, batch size: 41
2021-08-25 06:54:25,403 INFO [train.py:450] Epoch 2, batch 20140, batch avg loss 0.3312, total avg loss: 0.3450, batch size: 40
2021-08-25 06:54:31,616 INFO [train.py:450] Epoch 2, batch 20150, batch avg loss 0.3349, total avg loss: 0.3446, batch size: 44
2021-08-25 06:54:37,801 INFO [train.py:450] Epoch 2, batch 20160, batch avg loss 0.3800, total avg loss: 0.3448, batch size: 40
2021-08-25 06:54:44,569 INFO [train.py:450] Epoch 2, batch 20170, batch avg loss 0.3369, total avg loss: 0.3438, batch size: 37
2021-08-25 06:54:51,133 INFO [train.py:450] Epoch 2, batch 20180, batch avg loss 0.3421, total avg loss: 0.3443, batch size: 39
2021-08-25 06:54:57,637 INFO [train.py:450] Epoch 2, batch 20190, batch avg loss 0.3934, total avg loss: 0.3449, batch size: 39
2021-08-25 06:55:03,728 INFO [train.py:450] Epoch 2, batch 20200, batch avg loss 0.3104, total avg loss: 0.3445, batch size: 40
2021-08-25 06:55:10,198 INFO [train.py:450] Epoch 2, batch 20210, batch avg loss 0.3483, total avg loss: 0.3391, batch size: 39
2021-08-25 06:55:16,865 INFO [train.py:450] Epoch 2, batch 20220, batch avg loss 0.3542, total avg loss: 0.3454, batch size: 41
2021-08-25 06:55:23,080 INFO [train.py:450] Epoch 2, batch 20230, batch avg loss 0.3608, total avg loss: 0.3464, batch size: 40
2021-08-25 06:55:29,226 INFO [train.py:450] Epoch 2, batch 20240, batch avg loss 0.4171, total avg loss: 0.3486, batch size: 44
2021-08-25 06:55:35,695 INFO [train.py:450] Epoch 2, batch 20250, batch avg loss 0.3210, total avg loss: 0.3513, batch size: 41
2021-08-25 06:55:41,691 INFO [train.py:450] Epoch 2, batch 20260, batch avg loss 0.4883, total avg loss: 0.3542, batch size: 39
2021-08-25 06:55:48,153 INFO [train.py:450] Epoch 2, batch 20270, batch avg loss 0.3490, total avg loss: 0.3519, batch size: 39
2021-08-25 06:55:54,605 INFO [train.py:450] Epoch 2, batch 20280, batch avg loss 0.3617, total avg loss: 0.3512, batch size: 44
2021-08-25 06:56:01,167 INFO [train.py:450] Epoch 2, batch 20290, batch avg loss 0.4069, total avg loss: 0.3497, batch size: 40
2021-08-25 06:56:07,718 INFO [train.py:450] Epoch 2, batch 20300, batch avg loss 0.3973, total avg loss: 0.3500, batch size: 40
2021-08-25 06:56:13,972 INFO [train.py:450] Epoch 2, batch 20310, batch avg loss 0.2876, total avg loss: 0.3502, batch size: 41
2021-08-25 06:56:20,328 INFO [train.py:450] Epoch 2, batch 20320, batch avg loss 0.3259, total avg loss: 0.3497, batch size: 43
2021-08-25 06:56:26,714 INFO [train.py:450] Epoch 2, batch 20330, batch avg loss 0.3467, total avg loss: 0.3505, batch size: 42
2021-08-25 06:56:32,866 INFO [train.py:450] Epoch 2, batch 20340, batch avg loss 0.3836, total avg loss: 0.3500, batch size: 42
2021-08-25 06:56:39,168 INFO [train.py:450] Epoch 2, batch 20350, batch avg loss 0.3180, total avg loss: 0.3493, batch size: 40
2021-08-25 06:56:46,017 INFO [train.py:450] Epoch 2, batch 20360, batch avg loss 0.3444, total avg loss: 0.3499, batch size: 39
2021-08-25 06:56:52,582 INFO [train.py:450] Epoch 2, batch 20370, batch avg loss 0.3377, total avg loss: 0.3498, batch size: 39
2021-08-25 06:56:58,857 INFO [train.py:450] Epoch 2, batch 20380, batch avg loss 0.3074, total avg loss: 0.3505, batch size: 38
2021-08-25 06:57:07,276 INFO [train.py:450] Epoch 2, batch 20390, batch avg loss 0.3090, total avg loss: 0.3496, batch size: 39
2021-08-25 06:57:13,819 INFO [train.py:450] Epoch 2, batch 20400, batch avg loss 0.3227, total avg loss: 0.3492, batch size: 38
2021-08-25 06:57:23,670 INFO [train.py:450] Epoch 2, batch 20410, batch avg loss 0.3125, total avg loss: 0.3592, batch size: 41
2021-08-25 06:57:29,922 INFO [train.py:450] Epoch 2, batch 20420, batch avg loss 0.4722, total avg loss: 0.3602, batch size: 38
2021-08-25 06:57:36,591 INFO [train.py:450] Epoch 2, batch 20430, batch avg loss 0.3445, total avg loss: 0.3573, batch size: 40
2021-08-25 06:57:42,649 INFO [train.py:450] Epoch 2, batch 20440, batch avg loss 0.3832, total avg loss: 0.3538, batch size: 40
2021-08-25 06:57:49,297 INFO [train.py:450] Epoch 2, batch 20450, batch avg loss 0.3273, total avg loss: 0.3519, batch size: 39
2021-08-25 06:57:55,529 INFO [train.py:450] Epoch 2, batch 20460, batch avg loss 0.3453, total avg loss: 0.3495, batch size: 38
2021-08-25 06:58:01,968 INFO [train.py:450] Epoch 2, batch 20470, batch avg loss 0.3789, total avg loss: 0.3512, batch size: 37
2021-08-25 06:58:08,016 INFO [train.py:450] Epoch 2, batch 20480, batch avg loss 0.3539, total avg loss: 0.3486, batch size: 40
2021-08-25 06:58:14,832 INFO [train.py:450] Epoch 2, batch 20490, batch avg loss 0.3612, total avg loss: 0.3497, batch size: 41
2021-08-25 06:58:21,338 INFO [train.py:450] Epoch 2, batch 20500, batch avg loss 0.3243, total avg loss: 0.3489, batch size: 37
2021-08-25 06:58:27,898 INFO [train.py:450] Epoch 2, batch 20510, batch avg loss 0.3340, total avg loss: 0.3499, batch size: 40
2021-08-25 06:58:34,510 INFO [train.py:450] Epoch 2, batch 20520, batch avg loss 0.3290, total avg loss: 0.3512, batch size: 38
2021-08-25 06:58:41,076 INFO [train.py:450] Epoch 2, batch 20530, batch avg loss 0.3154, total avg loss: 0.3506, batch size: 43
2021-08-25 06:58:47,292 INFO [train.py:450] Epoch 2, batch 20540, batch avg loss 0.3781, total avg loss: 0.3509, batch size: 42
2021-08-25 06:58:53,490 INFO [train.py:450] Epoch 2, batch 20550, batch avg loss 0.3515, total avg loss: 0.3507, batch size: 43
2021-08-25 06:59:00,076 INFO [train.py:450] Epoch 2, batch 20560, batch avg loss 0.3413, total avg loss: 0.3518, batch size: 39
2021-08-25 06:59:06,283 INFO [train.py:450] Epoch 2, batch 20570, batch avg loss 0.3870, total avg loss: 0.3522, batch size: 39
2021-08-25 06:59:12,318 INFO [train.py:450] Epoch 2, batch 20580, batch avg loss 0.3852, total avg loss: 0.3524, batch size: 38
2021-08-25 06:59:18,188 INFO [train.py:450] Epoch 2, batch 20590, batch avg loss 0.3352, total avg loss: 0.3527, batch size: 42
2021-08-25 06:59:24,724 INFO [train.py:450] Epoch 2, batch 20600, batch avg loss 0.4277, total avg loss: 0.3529, batch size: 42
2021-08-25 06:59:30,872 INFO [train.py:450] Epoch 2, batch 20610, batch avg loss 0.3458, total avg loss: 0.3633, batch size: 40
2021-08-25 06:59:37,479 INFO [train.py:450] Epoch 2, batch 20620, batch avg loss 0.3632, total avg loss: 0.3509, batch size: 38
2021-08-25 06:59:44,823 INFO [train.py:450] Epoch 2, batch 20630, batch avg loss 0.3200, total avg loss: 0.3536, batch size: 39
2021-08-25 06:59:51,239 INFO [train.py:450] Epoch 2, batch 20640, batch avg loss 0.3139, total avg loss: 0.3499, batch size: 39
2021-08-25 06:59:57,527 INFO [train.py:450] Epoch 2, batch 20650, batch avg loss 0.3299, total avg loss: 0.3474, batch size: 37
2021-08-25 07:00:03,928 INFO [train.py:450] Epoch 2, batch 20660, batch avg loss 0.3898, total avg loss: 0.3465, batch size: 38
2021-08-25 07:00:10,170 INFO [train.py:450] Epoch 2, batch 20670, batch avg loss 0.3297, total avg loss: 0.3467, batch size: 35
2021-08-25 07:00:16,474 INFO [train.py:450] Epoch 2, batch 20680, batch avg loss 0.3255, total avg loss: 0.3469, batch size: 40
2021-08-25 07:00:22,450 INFO [train.py:450] Epoch 2, batch 20690, batch avg loss 0.3304, total avg loss: 0.3454, batch size: 39
2021-08-25 07:00:28,797 INFO [train.py:450] Epoch 2, batch 20700, batch avg loss 0.3461, total avg loss: 0.3471, batch size: 36
2021-08-25 07:00:35,676 INFO [train.py:450] Epoch 2, batch 20710, batch avg loss 0.3336, total avg loss: 0.3464, batch size: 38
2021-08-25 07:00:42,223 INFO [train.py:450] Epoch 2, batch 20720, batch avg loss 0.3328, total avg loss: 0.3472, batch size: 37
2021-08-25 07:00:48,987 INFO [train.py:450] Epoch 2, batch 20730, batch avg loss 0.3475, total avg loss: 0.3476, batch size: 40
2021-08-25 07:00:55,196 INFO [train.py:450] Epoch 2, batch 20740, batch avg loss 0.3725, total avg loss: 0.3470, batch size: 42
2021-08-25 07:01:01,693 INFO [train.py:450] Epoch 2, batch 20750, batch avg loss 0.3496, total avg loss: 0.3460, batch size: 39
2021-08-25 07:01:08,411 INFO [train.py:450] Epoch 2, batch 20760, batch avg loss 0.3685, total avg loss: 0.3470, batch size: 44
2021-08-25 07:01:15,874 INFO [train.py:450] Epoch 2, batch 20770, batch avg loss 0.3194, total avg loss: 0.3469, batch size: 37
2021-08-25 07:01:22,217 INFO [train.py:450] Epoch 2, batch 20780, batch avg loss 0.3619, total avg loss: 0.3465, batch size: 37
2021-08-25 07:01:33,483 INFO [train.py:450] Epoch 2, batch 20790, batch avg loss 0.2900, total avg loss: 0.3451, batch size: 42
2021-08-25 07:01:39,530 INFO [train.py:450] Epoch 2, batch 20800, batch avg loss 0.3700, total avg loss: 0.3449, batch size: 40
2021-08-25 07:01:45,725 INFO [train.py:450] Epoch 2, batch 20810, batch avg loss 0.4393, total avg loss: 0.3520, batch size: 37
2021-08-25 07:01:52,051 INFO [train.py:450] Epoch 2, batch 20820, batch avg loss 0.3352, total avg loss: 0.3502, batch size: 42
2021-08-25 07:01:58,405 INFO [train.py:450] Epoch 2, batch 20830, batch avg loss 0.3164, total avg loss: 0.3489, batch size: 41
2021-08-25 07:02:04,549 INFO [train.py:450] Epoch 2, batch 20840, batch avg loss 0.3408, total avg loss: 0.3495, batch size: 39
2021-08-25 07:02:11,050 INFO [train.py:450] Epoch 2, batch 20850, batch avg loss 0.3501, total avg loss: 0.3470, batch size: 39
2021-08-25 07:02:17,774 INFO [train.py:450] Epoch 2, batch 20860, batch avg loss 0.3128, total avg loss: 0.3468, batch size: 40
2021-08-25 07:02:24,513 INFO [train.py:450] Epoch 2, batch 20870, batch avg loss 0.3164, total avg loss: 0.3475, batch size: 41
2021-08-25 07:02:30,888 INFO [train.py:450] Epoch 2, batch 20880, batch avg loss 0.3499, total avg loss: 0.3461, batch size: 40
2021-08-25 07:02:36,815 INFO [train.py:450] Epoch 2, batch 20890, batch avg loss 0.3591, total avg loss: 0.3467, batch size: 41
2021-08-25 07:02:42,858 INFO [train.py:450] Epoch 2, batch 20900, batch avg loss 0.2988, total avg loss: 0.3450, batch size: 40
2021-08-25 07:02:48,683 INFO [train.py:450] Epoch 2, batch 20910, batch avg loss 0.3547, total avg loss: 0.3442, batch size: 40
2021-08-25 07:02:54,763 INFO [train.py:450] Epoch 2, batch 20920, batch avg loss 0.3755, total avg loss: 0.3438, batch size: 46
2021-08-25 07:03:01,217 INFO [train.py:450] Epoch 2, batch 20930, batch avg loss 0.4140, total avg loss: 0.3447, batch size: 40
2021-08-25 07:03:07,464 INFO [train.py:450] Epoch 2, batch 20940, batch avg loss 0.3531, total avg loss: 0.3436, batch size: 39
2021-08-25 07:03:13,479 INFO [train.py:450] Epoch 2, batch 20950, batch avg loss 0.3151, total avg loss: 0.3424, batch size: 38
2021-08-25 07:03:20,187 INFO [train.py:450] Epoch 2, batch 20960, batch avg loss 0.3611, total avg loss: 0.3417, batch size: 43
2021-08-25 07:03:26,588 INFO [train.py:450] Epoch 2, batch 20970, batch avg loss 0.2964, total avg loss: 0.3415, batch size: 38
2021-08-25 07:03:32,899 INFO [train.py:450] Epoch 2, batch 20980, batch avg loss 0.3221, total avg loss: 0.3408, batch size: 41
2021-08-25 07:03:39,045 INFO [train.py:450] Epoch 2, batch 20990, batch avg loss 0.3104, total avg loss: 0.3399, batch size: 36
2021-08-25 07:03:45,474 INFO [train.py:450] Epoch 2, batch 21000, batch avg loss 0.3181, total avg loss: 0.3404, batch size: 39
2021-08-25 07:04:24,266 INFO [train.py:482] Epoch 2, valid loss 0.2466, best valid loss: 0.2434 best valid epoch: 2
2021-08-25 07:04:30,051 INFO [train.py:450] Epoch 2, batch 21010, batch avg loss 0.3623, total avg loss: 0.3392, batch size: 40
2021-08-25 07:04:35,970 INFO [train.py:450] Epoch 2, batch 21020, batch avg loss 0.3418, total avg loss: 0.3363, batch size: 39
2021-08-25 07:04:41,931 INFO [train.py:450] Epoch 2, batch 21030, batch avg loss 0.4283, total avg loss: 0.3412, batch size: 42
2021-08-25 07:04:48,105 INFO [train.py:450] Epoch 2, batch 21040, batch avg loss 0.3099, total avg loss: 0.3369, batch size: 38
2021-08-25 07:04:54,921 INFO [train.py:450] Epoch 2, batch 21050, batch avg loss 0.3530, total avg loss: 0.3394, batch size: 39
2021-08-25 07:05:01,254 INFO [train.py:450] Epoch 2, batch 21060, batch avg loss 0.3895, total avg loss: 0.3363, batch size: 45
2021-08-25 07:05:08,945 INFO [train.py:450] Epoch 2, batch 21070, batch avg loss 0.3179, total avg loss: 0.3353, batch size: 40
2021-08-25 07:05:15,085 INFO [train.py:450] Epoch 2, batch 21080, batch avg loss 0.3166, total avg loss: 0.3357, batch size: 39
2021-08-25 07:05:25,923 INFO [train.py:450] Epoch 2, batch 21090, batch avg loss 0.3526, total avg loss: 0.3359, batch size: 42
2021-08-25 07:05:32,668 INFO [train.py:450] Epoch 2, batch 21100, batch avg loss 0.3329, total avg loss: 0.3367, batch size: 41
2021-08-25 07:05:39,322 INFO [train.py:450] Epoch 2, batch 21110, batch avg loss 0.3533, total avg loss: 0.3377, batch size: 41
2021-08-25 07:05:46,010 INFO [train.py:450] Epoch 2, batch 21120, batch avg loss 0.3246, total avg loss: 0.3380, batch size: 37
2021-08-25 07:05:51,946 INFO [train.py:450] Epoch 2, batch 21130, batch avg loss 0.3237, total avg loss: 0.3386, batch size: 39
2021-08-25 07:05:58,662 INFO [train.py:450] Epoch 2, batch 21140, batch avg loss 0.3098, total avg loss: 0.3385, batch size: 38
2021-08-25 07:06:05,173 INFO [train.py:450] Epoch 2, batch 21150, batch avg loss 0.3442, total avg loss: 0.3379, batch size: 42
2021-08-25 07:06:11,881 INFO [train.py:450] Epoch 2, batch 21160, batch avg loss 0.3694, total avg loss: 0.3392, batch size: 43
2021-08-25 07:06:18,674 INFO [train.py:450] Epoch 2, batch 21170, batch avg loss 0.2957, total avg loss: 0.3389, batch size: 37
2021-08-25 07:06:24,874 INFO [train.py:450] Epoch 2, batch 21180, batch avg loss 0.3381, total avg loss: 0.3395, batch size: 40
2021-08-25 07:06:30,946 INFO [checkpoint.py:62] Saving checkpoint to tdnn_lstm_ctc/exp/epoch-2.pt
2021-08-25 07:06:32,419 INFO [train.py:563] epoch 3, lr: 0.001
2021-08-25 07:06:47,345 INFO [train.py:450] Epoch 3, batch 0, batch avg loss 0.3487, total avg loss: 0.3487, batch size: 44
2021-08-25 07:07:06,228 INFO [train.py:450] Epoch 3, batch 10, batch avg loss 0.3107, total avg loss: 0.3461, batch size: 38
2021-08-25 07:07:24,554 INFO [train.py:450] Epoch 3, batch 20, batch avg loss 0.3048, total avg loss: 0.3440, batch size: 34
2021-08-25 07:07:42,281 INFO [train.py:450] Epoch 3, batch 30, batch avg loss 0.3708, total avg loss: 0.3453, batch size: 37
2021-08-25 07:08:00,203 INFO [train.py:450] Epoch 3, batch 40, batch avg loss 0.3481, total avg loss: 0.3407, batch size: 45
2021-08-25 07:08:17,033 INFO [train.py:450] Epoch 3, batch 50, batch avg loss 0.3482, total avg loss: 0.3382, batch size: 39
2021-08-25 07:08:33,950 INFO [train.py:450] Epoch 3, batch 60, batch avg loss 0.3855, total avg loss: 0.3384, batch size: 39
2021-08-25 07:08:51,083 INFO [train.py:450] Epoch 3, batch 70, batch avg loss 0.3292, total avg loss: 0.3393, batch size: 37
2021-08-25 07:09:12,383 INFO [train.py:450] Epoch 3, batch 80, batch avg loss 0.3645, total avg loss: 0.3403, batch size: 37
2021-08-25 07:09:28,742 INFO [train.py:450] Epoch 3, batch 90, batch avg loss 0.3787, total avg loss: 0.3418, batch size: 39
2021-08-25 07:09:43,756 INFO [train.py:450] Epoch 3, batch 100, batch avg loss 0.4077, total avg loss: 0.3437, batch size: 43
2021-08-25 07:09:58,189 INFO [train.py:450] Epoch 3, batch 110, batch avg loss 0.3930, total avg loss: 0.3452, batch size: 36
2021-08-25 07:10:12,661 INFO [train.py:450] Epoch 3, batch 120, batch avg loss 0.2929, total avg loss: 0.3448, batch size: 39
2021-08-25 07:10:26,137 INFO [train.py:450] Epoch 3, batch 130, batch avg loss 0.3340, total avg loss: 0.3445, batch size: 37
2021-08-25 07:10:39,418 INFO [train.py:450] Epoch 3, batch 140, batch avg loss 0.3681, total avg loss: 0.3445, batch size: 37
2021-08-25 07:10:53,024 INFO [train.py:450] Epoch 3, batch 150, batch avg loss 0.3298, total avg loss: 0.3439, batch size: 41
2021-08-25 07:11:06,380 INFO [train.py:450] Epoch 3, batch 160, batch avg loss 0.3629, total avg loss: 0.3446, batch size: 40
2021-08-25 07:11:19,590 INFO [train.py:450] Epoch 3, batch 170, batch avg loss 0.3539, total avg loss: 0.3454, batch size: 42
2021-08-25 07:11:32,459 INFO [train.py:450] Epoch 3, batch 180, batch avg loss 0.3081, total avg loss: 0.3448, batch size: 38
2021-08-25 07:11:45,201 INFO [train.py:450] Epoch 3, batch 190, batch avg loss 0.3148, total avg loss: 0.3443, batch size: 40
2021-08-25 07:12:00,187 INFO [train.py:450] Epoch 3, batch 200, batch avg loss 0.3258, total avg loss: 0.3446, batch size: 38
2021-08-25 07:12:15,862 INFO [train.py:450] Epoch 3, batch 210, batch avg loss 0.3161, total avg loss: 0.3423, batch size: 38
2021-08-25 07:12:28,148 INFO [train.py:450] Epoch 3, batch 220, batch avg loss 0.3012, total avg loss: 0.3436, batch size: 36
2021-08-25 07:12:41,155 INFO [train.py:450] Epoch 3, batch 230, batch avg loss 0.3320, total avg loss: 0.3452, batch size: 41
2021-08-25 07:12:52,993 INFO [train.py:450] Epoch 3, batch 240, batch avg loss 0.2979, total avg loss: 0.3416, batch size: 41
2021-08-25 07:13:05,558 INFO [train.py:450] Epoch 3, batch 250, batch avg loss 0.3430, total avg loss: 0.3415, batch size: 39
2021-08-25 07:13:16,909 INFO [train.py:450] Epoch 3, batch 260, batch avg loss 0.3282, total avg loss: 0.3395, batch size: 39
2021-08-25 07:13:28,927 INFO [train.py:450] Epoch 3, batch 270, batch avg loss 0.3312, total avg loss: 0.3388, batch size: 41
2021-08-25 07:13:39,725 INFO [train.py:450] Epoch 3, batch 280, batch avg loss 0.3603, total avg loss: 0.3384, batch size: 40
2021-08-25 07:13:51,208 INFO [train.py:450] Epoch 3, batch 290, batch avg loss 0.2622, total avg loss: 0.3399, batch size: 38
2021-08-25 07:14:02,422 INFO [train.py:450] Epoch 3, batch 300, batch avg loss 0.3373, total avg loss: 0.3397, batch size: 43
2021-08-25 07:14:13,626 INFO [train.py:450] Epoch 3, batch 310, batch avg loss 0.3692, total avg loss: 0.3397, batch size: 42
2021-08-25 07:14:24,088 INFO [train.py:450] Epoch 3, batch 320, batch avg loss 0.3191, total avg loss: 0.3393, batch size: 40
2021-08-25 07:14:35,098 INFO [train.py:450] Epoch 3, batch 330, batch avg loss 0.3519, total avg loss: 0.3404, batch size: 42
2021-08-25 07:14:45,899 INFO [train.py:450] Epoch 3, batch 340, batch avg loss 0.3334, total avg loss: 0.3408, batch size: 40
2021-08-25 07:14:56,407 INFO [train.py:450] Epoch 3, batch 350, batch avg loss 0.3017, total avg loss: 0.3394, batch size: 40
2021-08-25 07:15:07,571 INFO [train.py:450] Epoch 3, batch 360, batch avg loss 0.3424, total avg loss: 0.3393, batch size: 40
2021-08-25 07:15:19,342 INFO [train.py:450] Epoch 3, batch 370, batch avg loss 0.3423, total avg loss: 0.3393, batch size: 41
2021-08-25 07:15:33,866 INFO [train.py:450] Epoch 3, batch 380, batch avg loss 0.2895, total avg loss: 0.3396, batch size: 37
2021-08-25 07:15:44,721 INFO [train.py:450] Epoch 3, batch 390, batch avg loss 0.3644, total avg loss: 0.3398, batch size: 43
2021-08-25 07:15:55,989 INFO [train.py:450] Epoch 3, batch 400, batch avg loss 0.3514, total avg loss: 0.3407, batch size: 41
2021-08-25 07:16:06,346 INFO [train.py:450] Epoch 3, batch 410, batch avg loss 0.3331, total avg loss: 0.3462, batch size: 40
2021-08-25 07:16:16,764 INFO [train.py:450] Epoch 3, batch 420, batch avg loss 0.3470, total avg loss: 0.3489, batch size: 39
2021-08-25 07:16:27,368 INFO [train.py:450] Epoch 3, batch 430, batch avg loss 0.3571, total avg loss: 0.3430, batch size: 37
2021-08-25 07:16:37,790 INFO [train.py:450] Epoch 3, batch 440, batch avg loss 0.3101, total avg loss: 0.3458, batch size: 38
2021-08-25 07:16:47,970 INFO [train.py:450] Epoch 3, batch 450, batch avg loss 0.3087, total avg loss: 0.3424, batch size: 43
2021-08-25 07:16:58,398 INFO [train.py:450] Epoch 3, batch 460, batch avg loss 0.3399, total avg loss: 0.3446, batch size: 40
2021-08-25 07:17:08,623 INFO [train.py:450] Epoch 3, batch 470, batch avg loss 0.3299, total avg loss: 0.3440, batch size: 37
2021-08-25 07:17:18,504 INFO [train.py:450] Epoch 3, batch 480, batch avg loss 0.3572, total avg loss: 0.3455, batch size: 39
2021-08-25 07:17:28,488 INFO [train.py:450] Epoch 3, batch 490, batch avg loss 0.3615, total avg loss: 0.3456, batch size: 39
2021-08-25 07:17:39,200 INFO [train.py:450] Epoch 3, batch 500, batch avg loss 0.3744, total avg loss: 0.3470, batch size: 42
2021-08-25 07:17:49,906 INFO [train.py:450] Epoch 3, batch 510, batch avg loss 0.3314, total avg loss: 0.3479, batch size: 41
2021-08-25 07:18:00,106 INFO [train.py:450] Epoch 3, batch 520, batch avg loss 0.3413, total avg loss: 0.3474, batch size: 41
2021-08-25 07:18:09,645 INFO [train.py:450] Epoch 3, batch 530, batch avg loss 0.3289, total avg loss: 0.3470, batch size: 35
2021-08-25 07:18:18,901 INFO [train.py:450] Epoch 3, batch 540, batch avg loss 0.3463, total avg loss: 0.3484, batch size: 38
2021-08-25 07:18:28,598 INFO [train.py:450] Epoch 3, batch 550, batch avg loss 0.3495, total avg loss: 0.3481, batch size: 40
2021-08-25 07:18:39,774 INFO [train.py:450] Epoch 3, batch 560, batch avg loss 0.3527, total avg loss: 0.3481, batch size: 40
2021-08-25 07:18:48,758 INFO [train.py:450] Epoch 3, batch 570, batch avg loss 0.3786, total avg loss: 0.3480, batch size: 37
2021-08-25 07:19:01,256 INFO [train.py:450] Epoch 3, batch 580, batch avg loss 0.3955, total avg loss: 0.3479, batch size: 40
2021-08-25 07:19:10,813 INFO [train.py:450] Epoch 3, batch 590, batch avg loss 0.3236, total avg loss: 0.3476, batch size: 40
2021-08-25 07:19:20,387 INFO [train.py:450] Epoch 3, batch 600, batch avg loss 0.3255, total avg loss: 0.3471, batch size: 39
2021-08-25 07:19:29,999 INFO [train.py:450] Epoch 3, batch 610, batch avg loss 0.3102, total avg loss: 0.3631, batch size: 44
2021-08-25 07:19:39,001 INFO [train.py:450] Epoch 3, batch 620, batch avg loss 0.4059, total avg loss: 0.3532, batch size: 39
2021-08-25 07:19:48,406 INFO [train.py:450] Epoch 3, batch 630, batch avg loss 0.3101, total avg loss: 0.3450, batch size: 37
2021-08-25 07:19:57,507 INFO [train.py:450] Epoch 3, batch 640, batch avg loss 0.3220, total avg loss: 0.3438, batch size: 40
2021-08-25 07:20:07,069 INFO [train.py:450] Epoch 3, batch 650, batch avg loss 0.3701, total avg loss: 0.3404, batch size: 37
2021-08-25 07:20:16,519 INFO [train.py:450] Epoch 3, batch 660, batch avg loss 0.3314, total avg loss: 0.3391, batch size: 40
2021-08-25 07:20:26,223 INFO [train.py:450] Epoch 3, batch 670, batch avg loss 0.3022, total avg loss: 0.3384, batch size: 37
2021-08-25 07:20:36,239 INFO [train.py:450] Epoch 3, batch 680, batch avg loss 0.3719, total avg loss: 0.3384, batch size: 40
2021-08-25 07:20:45,664 INFO [train.py:450] Epoch 3, batch 690, batch avg loss 0.3010, total avg loss: 0.3401, batch size: 40
2021-08-25 07:20:55,491 INFO [train.py:450] Epoch 3, batch 700, batch avg loss 0.3531, total avg loss: 0.3404, batch size: 38
2021-08-25 07:21:04,837 INFO [train.py:450] Epoch 3, batch 710, batch avg loss 0.2985, total avg loss: 0.3413, batch size: 38
2021-08-25 07:21:14,534 INFO [train.py:450] Epoch 3, batch 720, batch avg loss 0.3503, total avg loss: 0.3410, batch size: 38
2021-08-25 07:21:23,765 INFO [train.py:450] Epoch 3, batch 730, batch avg loss 0.3295, total avg loss: 0.3411, batch size: 41
2021-08-25 07:21:32,925 INFO [train.py:450] Epoch 3, batch 740, batch avg loss 0.3262, total avg loss: 0.3409, batch size: 40
2021-08-25 07:21:41,281 INFO [train.py:450] Epoch 3, batch 750, batch avg loss 0.3619, total avg loss: 0.3411, batch size: 41
2021-08-25 07:21:50,293 INFO [train.py:450] Epoch 3, batch 760, batch avg loss 0.4130, total avg loss: 0.3415, batch size: 38
2021-08-25 07:21:59,554 INFO [train.py:450] Epoch 3, batch 770, batch avg loss 0.4044, total avg loss: 0.3425, batch size: 38
2021-08-25 07:22:08,966 INFO [train.py:450] Epoch 3, batch 780, batch avg loss 0.3463, total avg loss: 0.3430, batch size: 40
2021-08-25 07:22:17,588 INFO [train.py:450] Epoch 3, batch 790, batch avg loss 0.3444, total avg loss: 0.3422, batch size: 36
2021-08-25 07:22:26,567 INFO [train.py:450] Epoch 3, batch 800, batch avg loss 0.3381, total avg loss: 0.3424, batch size: 39
2021-08-25 07:22:36,675 INFO [train.py:450] Epoch 3, batch 810, batch avg loss 0.3503, total avg loss: 0.3414, batch size: 41
2021-08-25 07:22:48,346 INFO [train.py:450] Epoch 3, batch 820, batch avg loss 0.3456, total avg loss: 0.3422, batch size: 42
2021-08-25 07:22:57,665 INFO [train.py:450] Epoch 3, batch 830, batch avg loss 0.3354, total avg loss: 0.3436, batch size: 39
2021-08-25 07:23:05,832 INFO [train.py:450] Epoch 3, batch 840, batch avg loss 0.3231, total avg loss: 0.3416, batch size: 40
2021-08-25 07:23:15,384 INFO [train.py:450] Epoch 3, batch 850, batch avg loss 0.3370, total avg loss: 0.3405, batch size: 38
2021-08-25 07:23:24,560 INFO [train.py:450] Epoch 3, batch 860, batch avg loss 0.3467, total avg loss: 0.3407, batch size: 39
2021-08-25 07:23:33,955 INFO [train.py:450] Epoch 3, batch 870, batch avg loss 0.3588, total avg loss: 0.3419, batch size: 39
2021-08-25 07:23:43,671 INFO [train.py:450] Epoch 3, batch 880, batch avg loss 0.3177, total avg loss: 0.3424, batch size: 38
2021-08-25 07:23:52,744 INFO [train.py:450] Epoch 3, batch 890, batch avg loss 0.3445, total avg loss: 0.3421, batch size: 38
2021-08-25 07:24:01,461 INFO [train.py:450] Epoch 3, batch 900, batch avg loss 0.3675, total avg loss: 0.3425, batch size: 43
2021-08-25 07:24:10,926 INFO [train.py:450] Epoch 3, batch 910, batch avg loss 0.3923, total avg loss: 0.3447, batch size: 44
2021-08-25 07:24:19,787 INFO [train.py:450] Epoch 3, batch 920, batch avg loss 0.4194, total avg loss: 0.3475, batch size: 41
2021-08-25 07:24:28,567 INFO [train.py:450] Epoch 3, batch 930, batch avg loss 0.3713, total avg loss: 0.3476, batch size: 37
2021-08-25 07:24:38,432 INFO [train.py:450] Epoch 3, batch 940, batch avg loss 0.3268, total avg loss: 0.3469, batch size: 40
2021-08-25 07:24:47,574 INFO [train.py:450] Epoch 3, batch 950, batch avg loss 0.3528, total avg loss: 0.3471, batch size: 37
2021-08-25 07:24:56,814 INFO [train.py:450] Epoch 3, batch 960, batch avg loss 0.3395, total avg loss: 0.3467, batch size: 37
2021-08-25 07:25:06,124 INFO [train.py:450] Epoch 3, batch 970, batch avg loss 0.3381, total avg loss: 0.3459, batch size: 39
2021-08-25 07:25:15,728 INFO [train.py:450] Epoch 3, batch 980, batch avg loss 0.3094, total avg loss: 0.3443, batch size: 41
2021-08-25 07:25:25,820 INFO [train.py:450] Epoch 3, batch 990, batch avg loss 0.3905, total avg loss: 0.3452, batch size: 42
2021-08-25 07:25:36,013 INFO [train.py:450] Epoch 3, batch 1000, batch avg loss 0.3343, total avg loss: 0.3457, batch size: 39
2021-08-25 07:26:15,503 INFO [train.py:482] Epoch 3, valid loss 0.2473, best valid loss: 0.2434 best valid epoch: 2
2021-08-25 07:26:23,630 INFO [train.py:450] Epoch 3, batch 1010, batch avg loss 0.3859, total avg loss: 0.3416, batch size: 37
2021-08-25 07:26:33,788 INFO [train.py:450] Epoch 3, batch 1020, batch avg loss 0.3404, total avg loss: 0.3432, batch size: 38
2021-08-25 07:26:41,937 WARNING [cut.py:1694] To perform mix, energy must be non-zero and non-negative (got 0.0).  MonoCut with id "423a36be-dd1c-13c5-0651-ecd7e8f0b26e" will not be mixed in.
2021-08-25 07:26:47,714 INFO [train.py:450] Epoch 3, batch 1030, batch avg loss 0.3373, total avg loss: 0.3449, batch size: 41
2021-08-25 07:26:57,021 INFO [train.py:450] Epoch 3, batch 1040, batch avg loss 0.3416, total avg loss: 0.3475, batch size: 38
2021-08-25 07:27:06,520 INFO [train.py:450] Epoch 3, batch 1050, batch avg loss 0.3415, total avg loss: 0.3498, batch size: 37
2021-08-25 07:27:15,827 INFO [train.py:450] Epoch 3, batch 1060, batch avg loss 0.4024, total avg loss: 0.3516, batch size: 41
2021-08-25 07:27:25,257 INFO [train.py:450] Epoch 3, batch 1070, batch avg loss 0.3449, total avg loss: 0.3522, batch size: 38
2021-08-25 07:27:34,904 INFO [train.py:450] Epoch 3, batch 1080, batch avg loss 0.3807, total avg loss: 0.3518, batch size: 38
2021-08-25 07:27:43,826 INFO [train.py:450] Epoch 3, batch 1090, batch avg loss 0.3018, total avg loss: 0.3509, batch size: 43
2021-08-25 07:27:53,012 INFO [train.py:450] Epoch 3, batch 1100, batch avg loss 0.3759, total avg loss: 0.3516, batch size: 37
2021-08-25 07:28:02,439 INFO [train.py:450] Epoch 3, batch 1110, batch avg loss 0.3382, total avg loss: 0.3528, batch size: 40
2021-08-25 07:28:11,951 INFO [train.py:450] Epoch 3, batch 1120, batch avg loss 0.3343, total avg loss: 0.3527, batch size: 38
2021-08-25 07:28:21,639 INFO [train.py:450] Epoch 3, batch 1130, batch avg loss 0.3447, total avg loss: 0.3521, batch size: 39
2021-08-25 07:28:30,996 INFO [train.py:450] Epoch 3, batch 1140, batch avg loss 0.3564, total avg loss: 0.3513, batch size: 40
2021-08-25 07:28:40,606 INFO [train.py:450] Epoch 3, batch 1150, batch avg loss 0.3481, total avg loss: 0.3508, batch size: 43
2021-08-25 07:28:49,319 INFO [train.py:450] Epoch 3, batch 1160, batch avg loss 0.3145, total avg loss: 0.3506, batch size: 39
2021-08-25 07:28:58,436 INFO [train.py:450] Epoch 3, batch 1170, batch avg loss 0.4028, total avg loss: 0.3509, batch size: 37
2021-08-25 07:29:07,474 INFO [train.py:450] Epoch 3, batch 1180, batch avg loss 0.3636, total avg loss: 0.3502, batch size: 38
2021-08-25 07:29:16,990 INFO [train.py:450] Epoch 3, batch 1190, batch avg loss 0.3579, total avg loss: 0.3492, batch size: 41
2021-08-25 07:29:26,132 INFO [train.py:450] Epoch 3, batch 1200, batch avg loss 0.3689, total avg loss: 0.3487, batch size: 39
2021-08-25 07:29:35,944 INFO [train.py:450] Epoch 3, batch 1210, batch avg loss 0.3198, total avg loss: 0.3434, batch size: 41
2021-08-25 07:29:45,037 INFO [train.py:450] Epoch 3, batch 1220, batch avg loss 0.3408, total avg loss: 0.3426, batch size: 39
2021-08-25 07:29:55,684 INFO [train.py:450] Epoch 3, batch 1230, batch avg loss 0.3500, total avg loss: 0.3383, batch size: 39
2021-08-25 07:30:07,860 INFO [train.py:450] Epoch 3, batch 1240, batch avg loss 0.2976, total avg loss: 0.3346, batch size: 40
2021-08-25 07:30:18,288 INFO [train.py:450] Epoch 3, batch 1250, batch avg loss 0.2895, total avg loss: 0.3324, batch size: 42
2021-08-25 07:30:27,547 INFO [train.py:450] Epoch 3, batch 1260, batch avg loss 0.3392, total avg loss: 0.3321, batch size: 41
2021-08-25 07:30:36,711 INFO [train.py:450] Epoch 3, batch 1270, batch avg loss 0.3155, total avg loss: 0.3339, batch size: 39
2021-08-25 07:30:45,557 INFO [train.py:450] Epoch 3, batch 1280, batch avg loss 0.2893, total avg loss: 0.3333, batch size: 37
2021-08-25 07:30:54,975 INFO [train.py:450] Epoch 3, batch 1290, batch avg loss 0.4092, total avg loss: 0.3354, batch size: 40
2021-08-25 07:31:04,164 INFO [train.py:450] Epoch 3, batch 1300, batch avg loss 0.3162, total avg loss: 0.3360, batch size: 42
2021-08-25 07:31:13,396 INFO [train.py:450] Epoch 3, batch 1310, batch avg loss 0.3870, total avg loss: 0.3376, batch size: 43
2021-08-25 07:31:22,398 INFO [train.py:450] Epoch 3, batch 1320, batch avg loss 0.2994, total avg loss: 0.3383, batch size: 38
2021-08-25 07:31:31,513 INFO [train.py:450] Epoch 3, batch 1330, batch avg loss 0.3382, total avg loss: 0.3376, batch size: 38
2021-08-25 07:31:40,496 INFO [train.py:450] Epoch 3, batch 1340, batch avg loss 0.3149, total avg loss: 0.3390, batch size: 38
2021-08-25 07:31:49,256 INFO [train.py:450] Epoch 3, batch 1350, batch avg loss 0.3288, total avg loss: 0.3403, batch size: 38
2021-08-25 07:31:58,556 INFO [train.py:450] Epoch 3, batch 1360, batch avg loss 0.3972, total avg loss: 0.3416, batch size: 38
2021-08-25 07:32:07,306 INFO [train.py:450] Epoch 3, batch 1370, batch avg loss 0.3506, total avg loss: 0.3417, batch size: 38
2021-08-25 07:32:16,219 INFO [train.py:450] Epoch 3, batch 1380, batch avg loss 0.3395, total avg loss: 0.3426, batch size: 41
2021-08-25 07:32:24,999 INFO [train.py:450] Epoch 3, batch 1390, batch avg loss 0.3500, total avg loss: 0.3432, batch size: 35
2021-08-25 07:32:34,304 INFO [train.py:450] Epoch 3, batch 1400, batch avg loss 0.3716, total avg loss: 0.3438, batch size: 37
2021-08-25 07:32:42,933 INFO [train.py:450] Epoch 3, batch 1410, batch avg loss 0.3581, total avg loss: 0.3469, batch size: 46
2021-08-25 07:32:52,196 INFO [train.py:450] Epoch 3, batch 1420, batch avg loss 0.4053, total avg loss: 0.3399, batch size: 42
2021-08-25 07:33:01,016 INFO [train.py:450] Epoch 3, batch 1430, batch avg loss 0.3145, total avg loss: 0.3410, batch size: 39
2021-08-25 07:33:10,290 INFO [train.py:450] Epoch 3, batch 1440, batch avg loss 0.3578, total avg loss: 0.3401, batch size: 38
2021-08-25 07:33:18,926 INFO [train.py:450] Epoch 3, batch 1450, batch avg loss 0.2971, total avg loss: 0.3415, batch size: 39
2021-08-25 07:33:28,200 INFO [train.py:450] Epoch 3, batch 1460, batch avg loss 0.3367, total avg loss: 0.3418, batch size: 42
2021-08-25 07:33:38,307 INFO [train.py:450] Epoch 3, batch 1470, batch avg loss 0.3502, total avg loss: 0.3438, batch size: 39
2021-08-25 07:33:46,490 INFO [train.py:450] Epoch 3, batch 1480, batch avg loss 0.3317, total avg loss: 0.3437, batch size: 40
2021-08-25 07:33:58,489 INFO [train.py:450] Epoch 3, batch 1490, batch avg loss 0.2993, total avg loss: 0.3431, batch size: 41
2021-08-25 07:34:07,444 INFO [train.py:450] Epoch 3, batch 1500, batch avg loss 0.3106, total avg loss: 0.3431, batch size: 38
2021-08-25 07:34:16,060 INFO [train.py:450] Epoch 3, batch 1510, batch avg loss 0.4382, total avg loss: 0.3440, batch size: 39
2021-08-25 07:34:25,214 INFO [train.py:450] Epoch 3, batch 1520, batch avg loss 0.3412, total avg loss: 0.3436, batch size: 40
2021-08-25 07:34:33,758 INFO [train.py:450] Epoch 3, batch 1530, batch avg loss 0.2998, total avg loss: 0.3428, batch size: 38
2021-08-25 07:34:42,838 INFO [train.py:450] Epoch 3, batch 1540, batch avg loss 0.3753, total avg loss: 0.3424, batch size: 41
2021-08-25 07:34:51,484 INFO [train.py:450] Epoch 3, batch 1550, batch avg loss 0.4011, total avg loss: 0.3420, batch size: 38
2021-08-25 07:35:00,776 INFO [train.py:450] Epoch 3, batch 1560, batch avg loss 0.4015, total avg loss: 0.3424, batch size: 43
2021-08-25 07:35:09,876 INFO [train.py:450] Epoch 3, batch 1570, batch avg loss 0.3324, total avg loss: 0.3421, batch size: 44
2021-08-25 07:35:18,360 INFO [train.py:450] Epoch 3, batch 1580, batch avg loss 0.3903, total avg loss: 0.3421, batch size: 38
2021-08-25 07:35:27,184 INFO [train.py:450] Epoch 3, batch 1590, batch avg loss 0.3547, total avg loss: 0.3429, batch size: 40
2021-08-25 07:35:36,002 INFO [train.py:450] Epoch 3, batch 1600, batch avg loss 0.3583, total avg loss: 0.3426, batch size: 40
2021-08-25 07:35:44,865 INFO [train.py:450] Epoch 3, batch 1610, batch avg loss 0.3475, total avg loss: 0.3308, batch size: 40
2021-08-25 07:35:53,135 INFO [train.py:450] Epoch 3, batch 1620, batch avg loss 0.3398, total avg loss: 0.3310, batch size: 39
2021-08-25 07:36:02,007 INFO [train.py:450] Epoch 3, batch 1630, batch avg loss 0.3432, total avg loss: 0.3401, batch size: 42
2021-08-25 07:36:10,973 INFO [train.py:450] Epoch 3, batch 1640, batch avg loss 0.3824, total avg loss: 0.3454, batch size: 41
2021-08-25 07:36:19,182 INFO [train.py:450] Epoch 3, batch 1650, batch avg loss 0.3305, total avg loss: 0.3468, batch size: 40
2021-08-25 07:36:28,538 INFO [train.py:450] Epoch 3, batch 1660, batch avg loss 0.3111, total avg loss: 0.3443, batch size: 44
2021-08-25 07:36:36,383 INFO [train.py:450] Epoch 3, batch 1670, batch avg loss 0.3722, total avg loss: 0.3449, batch size: 36
2021-08-25 07:36:45,551 INFO [train.py:450] Epoch 3, batch 1680, batch avg loss 0.4039, total avg loss: 0.3460, batch size: 39
2021-08-25 07:36:54,077 INFO [train.py:450] Epoch 3, batch 1690, batch avg loss 0.3187, total avg loss: 0.3454, batch size: 38
2021-08-25 07:37:02,661 INFO [train.py:450] Epoch 3, batch 1700, batch avg loss 0.3509, total avg loss: 0.3447, batch size: 42
2021-08-25 07:37:12,542 INFO [train.py:450] Epoch 3, batch 1710, batch avg loss 0.3451, total avg loss: 0.3444, batch size: 40
2021-08-25 07:37:24,210 INFO [train.py:450] Epoch 3, batch 1720, batch avg loss 0.2905, total avg loss: 0.3430, batch size: 42
2021-08-25 07:37:32,264 INFO [train.py:450] Epoch 3, batch 1730, batch avg loss 0.3313, total avg loss: 0.3426, batch size: 39
2021-08-25 07:37:41,323 INFO [train.py:450] Epoch 3, batch 1740, batch avg loss 0.3228, total avg loss: 0.3419, batch size: 38
2021-08-25 07:37:49,659 INFO [train.py:450] Epoch 3, batch 1750, batch avg loss 0.2979, total avg loss: 0.3418, batch size: 41
2021-08-25 07:37:58,270 INFO [train.py:450] Epoch 3, batch 1760, batch avg loss 0.3607, total avg loss: 0.3423, batch size: 37
2021-08-25 07:38:06,607 INFO [train.py:450] Epoch 3, batch 1770, batch avg loss 0.3565, total avg loss: 0.3423, batch size: 39
2021-08-25 07:38:14,717 INFO [train.py:450] Epoch 3, batch 1780, batch avg loss 0.3677, total avg loss: 0.3423, batch size: 36
2021-08-25 07:38:22,739 INFO [train.py:450] Epoch 3, batch 1790, batch avg loss 0.3534, total avg loss: 0.3424, batch size: 42
2021-08-25 07:38:31,261 INFO [train.py:450] Epoch 3, batch 1800, batch avg loss 0.3688, total avg loss: 0.3429, batch size: 43
2021-08-25 07:38:39,262 INFO [train.py:450] Epoch 3, batch 1810, batch avg loss 0.3966, total avg loss: 0.3464, batch size: 41
2021-08-25 07:38:47,154 INFO [train.py:450] Epoch 3, batch 1820, batch avg loss 0.3506, total avg loss: 0.3490, batch size: 37
2021-08-25 07:38:56,085 INFO [train.py:450] Epoch 3, batch 1830, batch avg loss 0.3856, total avg loss: 0.3485, batch size: 36
2021-08-25 07:39:04,445 INFO [train.py:450] Epoch 3, batch 1840, batch avg loss 0.3061, total avg loss: 0.3448, batch size: 40
2021-08-25 07:39:13,433 INFO [train.py:450] Epoch 3, batch 1850, batch avg loss 0.3160, total avg loss: 0.3413, batch size: 38
2021-08-25 07:39:21,601 INFO [train.py:450] Epoch 3, batch 1860, batch avg loss 0.3799, total avg loss: 0.3420, batch size: 35
2021-08-25 07:39:22,187 WARNING [cut.py:1694] To perform mix, energy must be non-zero and non-negative (got 0.0).  MonoCut with id "99866446-7b8d-9ed7-55a4-4a6acb5641f9" will not be mixed in.
2021-08-25 07:39:29,950 INFO [train.py:450] Epoch 3, batch 1870, batch avg loss 0.3610, total avg loss: 0.3422, batch size: 43
2021-08-25 07:39:38,269 INFO [train.py:450] Epoch 3, batch 1880, batch avg loss 0.4032, total avg loss: 0.3431, batch size: 38
2021-08-25 07:39:46,539 INFO [train.py:450] Epoch 3, batch 1890, batch avg loss 0.3594, total avg loss: 0.3425, batch size: 42
2021-08-25 07:39:54,552 INFO [train.py:450] Epoch 3, batch 1900, batch avg loss 0.3115, total avg loss: 0.3425, batch size: 39
2021-08-25 07:40:03,238 INFO [train.py:450] Epoch 3, batch 1910, batch avg loss 0.3732, total avg loss: 0.3413, batch size: 39
2021-08-25 07:40:11,182 INFO [train.py:450] Epoch 3, batch 1920, batch avg loss 0.3205, total avg loss: 0.3402, batch size: 38
2021-08-25 07:40:19,369 INFO [train.py:450] Epoch 3, batch 1930, batch avg loss 0.3610, total avg loss: 0.3394, batch size: 39
2021-08-25 07:40:27,324 INFO [train.py:450] Epoch 3, batch 1940, batch avg loss 0.3476, total avg loss: 0.3402, batch size: 37
2021-08-25 07:40:35,435 INFO [train.py:450] Epoch 3, batch 1950, batch avg loss 0.3423, total avg loss: 0.3409, batch size: 41
2021-08-25 07:40:43,198 INFO [train.py:450] Epoch 3, batch 1960, batch avg loss 0.3651, total avg loss: 0.3408, batch size: 37
2021-08-25 07:40:52,477 INFO [train.py:450] Epoch 3, batch 1970, batch avg loss 0.3709, total avg loss: 0.3415, batch size: 42
2021-08-25 07:41:06,239 INFO [train.py:450] Epoch 3, batch 1980, batch avg loss 0.3621, total avg loss: 0.3416, batch size: 36
2021-08-25 07:41:14,196 INFO [train.py:450] Epoch 3, batch 1990, batch avg loss 0.3754, total avg loss: 0.3410, batch size: 44
2021-08-25 07:41:22,209 INFO [train.py:450] Epoch 3, batch 2000, batch avg loss 0.2788, total avg loss: 0.3409, batch size: 42
2021-08-25 07:42:01,811 INFO [train.py:482] Epoch 3, valid loss 0.2453, best valid loss: 0.2434 best valid epoch: 2
2021-08-25 07:42:09,001 INFO [train.py:450] Epoch 3, batch 2010, batch avg loss 0.4322, total avg loss: 0.3462, batch size: 40
2021-08-25 07:42:16,876 INFO [train.py:450] Epoch 3, batch 2020, batch avg loss 0.3795, total avg loss: 0.3530, batch size: 39
2021-08-25 07:42:25,084 INFO [train.py:450] Epoch 3, batch 2030, batch avg loss 0.3978, total avg loss: 0.3537, batch size: 38
2021-08-25 07:42:33,492 INFO [train.py:450] Epoch 3, batch 2040, batch avg loss 0.3525, total avg loss: 0.3567, batch size: 40
2021-08-25 07:42:42,316 INFO [train.py:450] Epoch 3, batch 2050, batch avg loss 0.3537, total avg loss: 0.3541, batch size: 42
2021-08-25 07:42:50,238 INFO [train.py:450] Epoch 3, batch 2060, batch avg loss 0.3978, total avg loss: 0.3555, batch size: 42
2021-08-25 07:42:58,587 INFO [train.py:450] Epoch 3, batch 2070, batch avg loss 0.3507, total avg loss: 0.3535, batch size: 41
2021-08-25 07:43:06,858 INFO [train.py:450] Epoch 3, batch 2080, batch avg loss 0.3421, total avg loss: 0.3543, batch size: 38
2021-08-25 07:43:14,748 INFO [train.py:450] Epoch 3, batch 2090, batch avg loss 0.3623, total avg loss: 0.3530, batch size: 42
2021-08-25 07:43:22,898 INFO [train.py:450] Epoch 3, batch 2100, batch avg loss 0.3359, total avg loss: 0.3515, batch size: 42
2021-08-25 07:43:30,598 INFO [train.py:450] Epoch 3, batch 2110, batch avg loss 0.2990, total avg loss: 0.3508, batch size: 36
2021-08-25 07:43:38,809 INFO [train.py:450] Epoch 3, batch 2120, batch avg loss 0.3319, total avg loss: 0.3506, batch size: 43
2021-08-25 07:43:47,228 INFO [train.py:450] Epoch 3, batch 2130, batch avg loss 0.3646, total avg loss: 0.3504, batch size: 37
2021-08-25 07:43:55,258 INFO [train.py:450] Epoch 3, batch 2140, batch avg loss 0.2957, total avg loss: 0.3497, batch size: 40
2021-08-25 07:44:03,850 INFO [train.py:450] Epoch 3, batch 2150, batch avg loss 0.3832, total avg loss: 0.3494, batch size: 40
2021-08-25 07:44:12,417 INFO [train.py:450] Epoch 3, batch 2160, batch avg loss 0.4231, total avg loss: 0.3498, batch size: 38
2021-08-25 07:44:20,691 INFO [train.py:450] Epoch 3, batch 2170, batch avg loss 0.3299, total avg loss: 0.3494, batch size: 40
2021-08-25 07:44:28,982 INFO [train.py:450] Epoch 3, batch 2180, batch avg loss 0.3591, total avg loss: 0.3492, batch size: 39
2021-08-25 07:44:38,785 INFO [train.py:450] Epoch 3, batch 2190, batch avg loss 0.3832, total avg loss: 0.3484, batch size: 41
2021-08-25 07:44:46,637 INFO [train.py:450] Epoch 3, batch 2200, batch avg loss 0.3862, total avg loss: 0.3479, batch size: 40
2021-08-25 07:44:58,465 INFO [train.py:450] Epoch 3, batch 2210, batch avg loss 0.3079, total avg loss: 0.3292, batch size: 40
2021-08-25 07:45:06,076 INFO [train.py:450] Epoch 3, batch 2220, batch avg loss 0.3060, total avg loss: 0.3287, batch size: 36
2021-08-25 07:45:14,581 INFO [train.py:450] Epoch 3, batch 2230, batch avg loss 0.3136, total avg loss: 0.3320, batch size: 41
2021-08-25 07:45:23,244 INFO [train.py:450] Epoch 3, batch 2240, batch avg loss 0.3454, total avg loss: 0.3372, batch size: 39
2021-08-25 07:45:31,662 INFO [train.py:450] Epoch 3, batch 2250, batch avg loss 0.3119, total avg loss: 0.3343, batch size: 40
2021-08-25 07:45:40,050 INFO [train.py:450] Epoch 3, batch 2260, batch avg loss 0.2976, total avg loss: 0.3320, batch size: 42
2021-08-25 07:45:47,871 INFO [train.py:450] Epoch 3, batch 2270, batch avg loss 0.3126, total avg loss: 0.3337, batch size: 39
2021-08-25 07:45:55,856 INFO [train.py:450] Epoch 3, batch 2280, batch avg loss 0.3359, total avg loss: 0.3331, batch size: 37
2021-08-25 07:46:04,345 INFO [train.py:450] Epoch 3, batch 2290, batch avg loss 0.3230, total avg loss: 0.3342, batch size: 39
2021-08-25 07:46:12,344 INFO [train.py:450] Epoch 3, batch 2300, batch avg loss 0.3695, total avg loss: 0.3362, batch size: 39
2021-08-25 07:46:20,483 INFO [train.py:450] Epoch 3, batch 2310, batch avg loss 0.3213, total avg loss: 0.3354, batch size: 39
2021-08-25 07:46:30,039 INFO [train.py:450] Epoch 3, batch 2320, batch avg loss 0.3777, total avg loss: 0.3382, batch size: 39
2021-08-25 07:46:38,464 INFO [train.py:450] Epoch 3, batch 2330, batch avg loss 0.3270, total avg loss: 0.3394, batch size: 39
2021-08-25 07:46:46,804 INFO [train.py:450] Epoch 3, batch 2340, batch avg loss 0.3334, total avg loss: 0.3399, batch size: 39
2021-08-25 07:46:55,122 INFO [train.py:450] Epoch 3, batch 2350, batch avg loss 0.3353, total avg loss: 0.3406, batch size: 40
2021-08-25 07:47:03,313 INFO [train.py:450] Epoch 3, batch 2360, batch avg loss 0.3336, total avg loss: 0.3410, batch size: 41
2021-08-25 07:47:11,752 INFO [train.py:450] Epoch 3, batch 2370, batch avg loss 0.3753, total avg loss: 0.3413, batch size: 45
2021-08-25 07:47:20,247 INFO [train.py:450] Epoch 3, batch 2380, batch avg loss 0.3261, total avg loss: 0.3410, batch size: 38
2021-08-25 07:47:28,721 INFO [train.py:450] Epoch 3, batch 2390, batch avg loss 0.2913, total avg loss: 0.3404, batch size: 38
2021-08-25 07:47:36,860 INFO [train.py:450] Epoch 3, batch 2400, batch avg loss 0.3978, total avg loss: 0.3411, batch size: 38
2021-08-25 07:47:45,439 INFO [train.py:450] Epoch 3, batch 2410, batch avg loss 0.3584, total avg loss: 0.3268, batch size: 42
2021-08-25 07:47:53,799 INFO [train.py:450] Epoch 3, batch 2420, batch avg loss 0.3826, total avg loss: 0.3369, batch size: 40
2021-08-25 07:48:02,155 INFO [train.py:450] Epoch 3, batch 2430, batch avg loss 0.3622, total avg loss: 0.3389, batch size: 39
2021-08-25 07:48:11,272 INFO [train.py:450] Epoch 3, batch 2440, batch avg loss 0.2920, total avg loss: 0.3369, batch size: 39
2021-08-25 07:48:18,735 INFO [train.py:450] Epoch 3, batch 2450, batch avg loss 0.4162, total avg loss: 0.3384, batch size: 40
2021-08-25 07:48:29,972 INFO [train.py:450] Epoch 3, batch 2460, batch avg loss 0.3449, total avg loss: 0.3392, batch size: 40
2021-08-25 07:48:38,209 INFO [train.py:450] Epoch 3, batch 2470, batch avg loss 0.3892, total avg loss: 0.3392, batch size: 41
2021-08-25 07:48:46,771 INFO [train.py:450] Epoch 3, batch 2480, batch avg loss 0.3290, total avg loss: 0.3389, batch size: 40
2021-08-25 07:48:54,714 INFO [train.py:450] Epoch 3, batch 2490, batch avg loss 0.3341, total avg loss: 0.3377, batch size: 40
2021-08-25 07:49:03,166 INFO [train.py:450] Epoch 3, batch 2500, batch avg loss 0.3478, total avg loss: 0.3385, batch size: 38
2021-08-25 07:49:11,396 INFO [train.py:450] Epoch 3, batch 2510, batch avg loss 0.3434, total avg loss: 0.3396, batch size: 42
2021-08-25 07:49:19,493 INFO [train.py:450] Epoch 3, batch 2520, batch avg loss 0.3452, total avg loss: 0.3390, batch size: 41
2021-08-25 07:49:27,236 INFO [train.py:450] Epoch 3, batch 2530, batch avg loss 0.3547, total avg loss: 0.3385, batch size: 38
2021-08-25 07:49:35,245 INFO [train.py:450] Epoch 3, batch 2540, batch avg loss 0.3457, total avg loss: 0.3389, batch size: 37
2021-08-25 07:49:43,638 INFO [train.py:450] Epoch 3, batch 2550, batch avg loss 0.3326, total avg loss: 0.3387, batch size: 38
2021-08-25 07:49:52,270 INFO [train.py:450] Epoch 3, batch 2560, batch avg loss 0.3487, total avg loss: 0.3382, batch size: 45
2021-08-25 07:50:00,464 INFO [train.py:450] Epoch 3, batch 2570, batch avg loss 0.3255, total avg loss: 0.3384, batch size: 37
2021-08-25 07:50:08,768 INFO [train.py:450] Epoch 3, batch 2580, batch avg loss 0.3456, total avg loss: 0.3391, batch size: 40
2021-08-25 07:50:16,777 INFO [train.py:450] Epoch 3, batch 2590, batch avg loss 0.3250, total avg loss: 0.3400, batch size: 43
2021-08-25 07:50:25,089 INFO [train.py:450] Epoch 3, batch 2600, batch avg loss 0.3471, total avg loss: 0.3402, batch size: 39
2021-08-25 07:50:33,619 INFO [train.py:450] Epoch 3, batch 2610, batch avg loss 0.3865, total avg loss: 0.3361, batch size: 37
2021-08-25 07:50:42,000 INFO [train.py:450] Epoch 3, batch 2620, batch avg loss 0.3623, total avg loss: 0.3394, batch size: 43
2021-08-25 07:50:50,138 INFO [train.py:450] Epoch 3, batch 2630, batch avg loss 0.3256, total avg loss: 0.3391, batch size: 42
2021-08-25 07:50:58,446 INFO [train.py:450] Epoch 3, batch 2640, batch avg loss 0.3233, total avg loss: 0.3419, batch size: 36
2021-08-25 07:51:06,736 INFO [train.py:450] Epoch 3, batch 2650, batch avg loss 0.2641, total avg loss: 0.3384, batch size: 39
2021-08-25 07:51:15,253 INFO [train.py:450] Epoch 3, batch 2660, batch avg loss 0.3763, total avg loss: 0.3408, batch size: 40
2021-08-25 07:51:23,398 INFO [train.py:450] Epoch 3, batch 2670, batch avg loss 0.3722, total avg loss: 0.3409, batch size: 36
2021-08-25 07:51:31,907 INFO [train.py:450] Epoch 3, batch 2680, batch avg loss 0.2929, total avg loss: 0.3411, batch size: 40
2021-08-25 07:51:41,472 INFO [train.py:450] Epoch 3, batch 2690, batch avg loss 0.3558, total avg loss: 0.3423, batch size: 37
2021-08-25 07:51:48,895 INFO [train.py:450] Epoch 3, batch 2700, batch avg loss 0.3848, total avg loss: 0.3419, batch size: 39
2021-08-25 07:51:59,634 INFO [train.py:450] Epoch 3, batch 2710, batch avg loss 0.3716, total avg loss: 0.3405, batch size: 39
2021-08-25 07:52:07,518 INFO [train.py:450] Epoch 3, batch 2720, batch avg loss 0.3204, total avg loss: 0.3396, batch size: 42
2021-08-25 07:52:16,611 INFO [train.py:450] Epoch 3, batch 2730, batch avg loss 0.3216, total avg loss: 0.3404, batch size: 41
2021-08-25 07:52:24,455 INFO [train.py:450] Epoch 3, batch 2740, batch avg loss 0.3275, total avg loss: 0.3409, batch size: 36
2021-08-25 07:52:33,011 INFO [train.py:450] Epoch 3, batch 2750, batch avg loss 0.3461, total avg loss: 0.3424, batch size: 38
2021-08-25 07:52:40,978 INFO [train.py:450] Epoch 3, batch 2760, batch avg loss 0.3745, total avg loss: 0.3429, batch size: 39
2021-08-25 07:52:49,033 INFO [train.py:450] Epoch 3, batch 2770, batch avg loss 0.3347, total avg loss: 0.3432, batch size: 40
2021-08-25 07:52:56,998 INFO [train.py:450] Epoch 3, batch 2780, batch avg loss 0.3068, total avg loss: 0.3421, batch size: 35
2021-08-25 07:53:05,434 INFO [train.py:450] Epoch 3, batch 2790, batch avg loss 0.3313, total avg loss: 0.3418, batch size: 41
2021-08-25 07:53:14,000 INFO [train.py:450] Epoch 3, batch 2800, batch avg loss 0.3767, total avg loss: 0.3422, batch size: 38
2021-08-25 07:53:22,795 INFO [train.py:450] Epoch 3, batch 2810, batch avg loss 0.3559, total avg loss: 0.3344, batch size: 41
2021-08-25 07:53:30,876 INFO [train.py:450] Epoch 3, batch 2820, batch avg loss 0.2876, total avg loss: 0.3347, batch size: 40
2021-08-25 07:53:38,345 INFO [train.py:450] Epoch 3, batch 2830, batch avg loss 0.3201, total avg loss: 0.3329, batch size: 41
2021-08-25 07:53:46,578 INFO [train.py:450] Epoch 3, batch 2840, batch avg loss 0.3511, total avg loss: 0.3367, batch size: 36
2021-08-25 07:53:54,900 INFO [train.py:450] Epoch 3, batch 2850, batch avg loss 0.3809, total avg loss: 0.3379, batch size: 40
2021-08-25 07:54:03,382 INFO [train.py:450] Epoch 3, batch 2860, batch avg loss 0.3359, total avg loss: 0.3379, batch size: 43
2021-08-25 07:54:11,552 INFO [train.py:450] Epoch 3, batch 2870, batch avg loss 0.3137, total avg loss: 0.3364, batch size: 39
2021-08-25 07:54:19,936 INFO [train.py:450] Epoch 3, batch 2880, batch avg loss 0.3249, total avg loss: 0.3358, batch size: 42
2021-08-25 07:54:28,465 INFO [train.py:450] Epoch 3, batch 2890, batch avg loss 0.3715, total avg loss: 0.3355, batch size: 41
2021-08-25 07:54:36,736 INFO [train.py:450] Epoch 3, batch 2900, batch avg loss 0.4189, total avg loss: 0.3368, batch size: 36
2021-08-25 07:54:45,002 INFO [train.py:450] Epoch 3, batch 2910, batch avg loss 0.3652, total avg loss: 0.3361, batch size: 38
2021-08-25 07:54:53,536 INFO [train.py:450] Epoch 3, batch 2920, batch avg loss 0.3260, total avg loss: 0.3367, batch size: 36
2021-08-25 07:54:53,980 WARNING [cut.py:1694] To perform mix, energy must be non-zero and non-negative (got 0.0).  MonoCut with id "356678ae-e36d-2dbf-3aa1-8d28d3d42410" will not be mixed in.
2021-08-25 07:55:01,408 INFO [train.py:450] Epoch 3, batch 2930, batch avg loss 0.3747, total avg loss: 0.3382, batch size: 40
2021-08-25 07:55:09,936 INFO [train.py:450] Epoch 3, batch 2940, batch avg loss 0.3509, total avg loss: 0.3385, batch size: 43
2021-08-25 07:55:19,386 INFO [train.py:450] Epoch 3, batch 2950, batch avg loss 0.3234, total avg loss: 0.3400, batch size: 41
2021-08-25 07:55:29,268 INFO [train.py:450] Epoch 3, batch 2960, batch avg loss 0.2810, total avg loss: 0.3406, batch size: 39
2021-08-25 07:55:37,647 INFO [train.py:450] Epoch 3, batch 2970, batch avg loss 0.3766, total avg loss: 0.3401, batch size: 40
2021-08-25 07:55:46,216 INFO [train.py:450] Epoch 3, batch 2980, batch avg loss 0.4007, total avg loss: 0.3400, batch size: 38
2021-08-25 07:55:54,352 INFO [train.py:450] Epoch 3, batch 2990, batch avg loss 0.3733, total avg loss: 0.3411, batch size: 42
2021-08-25 07:56:02,761 INFO [train.py:450] Epoch 3, batch 3000, batch avg loss 0.3588, total avg loss: 0.3417, batch size: 37
2021-08-25 07:56:41,843 INFO [train.py:482] Epoch 3, valid loss 0.2474, best valid loss: 0.2434 best valid epoch: 2
2021-08-25 07:56:48,456 INFO [train.py:450] Epoch 3, batch 3010, batch avg loss 0.3347, total avg loss: 0.3319, batch size: 41
2021-08-25 07:56:56,671 INFO [train.py:450] Epoch 3, batch 3020, batch avg loss 0.3181, total avg loss: 0.3301, batch size: 38
2021-08-25 07:57:04,858 INFO [train.py:450] Epoch 3, batch 3030, batch avg loss 0.3639, total avg loss: 0.3349, batch size: 41
2021-08-25 07:57:13,123 INFO [train.py:450] Epoch 3, batch 3040, batch avg loss 0.3207, total avg loss: 0.3371, batch size: 42
2021-08-25 07:57:21,450 INFO [train.py:450] Epoch 3, batch 3050, batch avg loss 0.3238, total avg loss: 0.3377, batch size: 41
2021-08-25 07:57:29,333 INFO [train.py:450] Epoch 3, batch 3060, batch avg loss 0.2965, total avg loss: 0.3388, batch size: 34
2021-08-25 07:57:37,668 INFO [train.py:450] Epoch 3, batch 3070, batch avg loss 0.3222, total avg loss: 0.3389, batch size: 42
2021-08-25 07:57:45,936 INFO [train.py:450] Epoch 3, batch 3080, batch avg loss 0.3071, total avg loss: 0.3417, batch size: 42
2021-08-25 07:57:54,676 INFO [train.py:450] Epoch 3, batch 3090, batch avg loss 0.3367, total avg loss: 0.3426, batch size: 39
2021-08-25 07:58:03,522 INFO [train.py:450] Epoch 3, batch 3100, batch avg loss 0.3462, total avg loss: 0.3437, batch size: 44
2021-08-25 07:58:11,977 INFO [train.py:450] Epoch 3, batch 3110, batch avg loss 0.3554, total avg loss: 0.3457, batch size: 40
2021-08-25 07:58:19,896 INFO [train.py:450] Epoch 3, batch 3120, batch avg loss 0.3159, total avg loss: 0.3466, batch size: 40
2021-08-25 07:58:28,386 INFO [train.py:450] Epoch 3, batch 3130, batch avg loss 0.3281, total avg loss: 0.3471, batch size: 40
2021-08-25 07:58:36,766 INFO [train.py:450] Epoch 3, batch 3140, batch avg loss 0.3796, total avg loss: 0.3482, batch size: 40
2021-08-25 07:58:46,262 INFO [train.py:450] Epoch 3, batch 3150, batch avg loss 0.3216, total avg loss: 0.3475, batch size: 37
2021-08-25 07:58:57,953 INFO [train.py:450] Epoch 3, batch 3160, batch avg loss 0.3857, total avg loss: 0.3473, batch size: 42
2021-08-25 07:59:05,848 INFO [train.py:450] Epoch 3, batch 3170, batch avg loss 0.3582, total avg loss: 0.3471, batch size: 42
2021-08-25 07:59:13,858 INFO [train.py:450] Epoch 3, batch 3180, batch avg loss 0.3263, total avg loss: 0.3472, batch size: 40
2021-08-25 07:59:22,547 INFO [train.py:450] Epoch 3, batch 3190, batch avg loss 0.3404, total avg loss: 0.3458, batch size: 38
2021-08-25 07:59:29,685 WARNING [cut.py:1694] To perform mix, energy must be non-zero and non-negative (got 0.0).  MonoCut with id "0e866be6-da1d-7203-1296-2e37fbaf1536" will not be mixed in.
2021-08-25 07:59:31,204 INFO [train.py:450] Epoch 3, batch 3200, batch avg loss 0.2999, total avg loss: 0.3458, batch size: 36
2021-08-25 07:59:39,046 INFO [train.py:450] Epoch 3, batch 3210, batch avg loss 0.3229, total avg loss: 0.3304, batch size: 41
2021-08-25 07:59:47,219 INFO [train.py:450] Epoch 3, batch 3220, batch avg loss 0.3236, total avg loss: 0.3358, batch size: 43
2021-08-25 07:59:55,520 INFO [train.py:450] Epoch 3, batch 3230, batch avg loss 0.3638, total avg loss: 0.3424, batch size: 38
2021-08-25 08:00:03,861 INFO [train.py:450] Epoch 3, batch 3240, batch avg loss 0.3222, total avg loss: 0.3437, batch size: 42
2021-08-25 08:00:11,529 INFO [train.py:450] Epoch 3, batch 3250, batch avg loss 0.3460, total avg loss: 0.3426, batch size: 41
2021-08-25 08:00:19,965 INFO [train.py:450] Epoch 3, batch 3260, batch avg loss 0.3644, total avg loss: 0.3433, batch size: 43
2021-08-25 08:00:28,029 INFO [train.py:450] Epoch 3, batch 3270, batch avg loss 0.3299, total avg loss: 0.3429, batch size: 37
2021-08-25 08:00:35,946 INFO [train.py:450] Epoch 3, batch 3280, batch avg loss 0.3391, total avg loss: 0.3427, batch size: 42
2021-08-25 08:00:44,489 INFO [train.py:450] Epoch 3, batch 3290, batch avg loss 0.3954, total avg loss: 0.3442, batch size: 41
2021-08-25 08:00:52,722 INFO [train.py:450] Epoch 3, batch 3300, batch avg loss 0.3391, total avg loss: 0.3438, batch size: 39
2021-08-25 08:01:00,374 INFO [train.py:450] Epoch 3, batch 3310, batch avg loss 0.3462, total avg loss: 0.3461, batch size: 41
2021-08-25 08:01:08,727 INFO [train.py:450] Epoch 3, batch 3320, batch avg loss 0.3631, total avg loss: 0.3468, batch size: 40
2021-08-25 08:01:17,123 INFO [train.py:450] Epoch 3, batch 3330, batch avg loss 0.3651, total avg loss: 0.3475, batch size: 41
2021-08-25 08:01:25,606 INFO [train.py:450] Epoch 3, batch 3340, batch avg loss 0.3199, total avg loss: 0.3471, batch size: 41
2021-08-25 08:01:33,871 INFO [train.py:450] Epoch 3, batch 3350, batch avg loss 0.4157, total avg loss: 0.3472, batch size: 38
2021-08-25 08:01:43,949 INFO [train.py:450] Epoch 3, batch 3360, batch avg loss 0.2996, total avg loss: 0.3470, batch size: 41
2021-08-25 08:01:52,068 INFO [train.py:450] Epoch 3, batch 3370, batch avg loss 0.2989, total avg loss: 0.3465, batch size: 40
2021-08-25 08:02:03,884 INFO [train.py:450] Epoch 3, batch 3380, batch avg loss 0.3248, total avg loss: 0.3462, batch size: 40
2021-08-25 08:02:12,573 INFO [train.py:450] Epoch 3, batch 3390, batch avg loss 0.3549, total avg loss: 0.3464, batch size: 41
2021-08-25 08:02:21,364 INFO [train.py:450] Epoch 3, batch 3400, batch avg loss 0.3043, total avg loss: 0.3452, batch size: 41
2021-08-25 08:02:29,144 INFO [train.py:450] Epoch 3, batch 3410, batch avg loss 0.3449, total avg loss: 0.3575, batch size: 38
2021-08-25 08:02:37,326 INFO [train.py:450] Epoch 3, batch 3420, batch avg loss 0.3488, total avg loss: 0.3480, batch size: 40
2021-08-25 08:02:45,322 INFO [train.py:450] Epoch 3, batch 3430, batch avg loss 0.3733, total avg loss: 0.3557, batch size: 40
2021-08-25 08:02:53,864 INFO [train.py:450] Epoch 3, batch 3440, batch avg loss 0.3611, total avg loss: 0.3524, batch size: 41
2021-08-25 08:03:04,288 INFO [train.py:450] Epoch 3, batch 3450, batch avg loss 0.3291, total avg loss: 0.3506, batch size: 38
2021-08-25 08:03:12,489 INFO [train.py:450] Epoch 3, batch 3460, batch avg loss 0.3815, total avg loss: 0.3504, batch size: 41
2021-08-25 08:03:20,699 INFO [train.py:450] Epoch 3, batch 3470, batch avg loss 0.3032, total avg loss: 0.3476, batch size: 40
2021-08-25 08:03:28,914 INFO [train.py:450] Epoch 3, batch 3480, batch avg loss 0.3252, total avg loss: 0.3469, batch size: 37
2021-08-25 08:03:37,217 INFO [train.py:450] Epoch 3, batch 3490, batch avg loss 0.3404, total avg loss: 0.3462, batch size: 38
2021-08-25 08:03:45,773 INFO [train.py:450] Epoch 3, batch 3500, batch avg loss 0.3254, total avg loss: 0.3468, batch size: 39
2021-08-25 08:03:53,543 INFO [train.py:450] Epoch 3, batch 3510, batch avg loss 0.3286, total avg loss: 0.3465, batch size: 41
2021-08-25 08:04:01,886 INFO [train.py:450] Epoch 3, batch 3520, batch avg loss 0.2932, total avg loss: 0.3465, batch size: 40
2021-08-25 08:04:09,642 INFO [train.py:450] Epoch 3, batch 3530, batch avg loss 0.3456, total avg loss: 0.3463, batch size: 41
2021-08-25 08:04:17,479 INFO [train.py:450] Epoch 3, batch 3540, batch avg loss 0.3289, total avg loss: 0.3467, batch size: 45
2021-08-25 08:04:25,640 INFO [train.py:450] Epoch 3, batch 3550, batch avg loss 0.3600, total avg loss: 0.3464, batch size: 42
2021-08-25 08:04:34,188 INFO [train.py:450] Epoch 3, batch 3560, batch avg loss 0.3663, total avg loss: 0.3476, batch size: 42
2021-08-25 08:04:42,549 INFO [train.py:450] Epoch 3, batch 3570, batch avg loss 0.3287, total avg loss: 0.3482, batch size: 41
2021-08-25 08:04:50,387 WARNING [cut.py:1694] To perform mix, energy must be non-zero and non-negative (got 0.0).  MonoCut with id "5c3e2297-054f-480e-9773-9c3e51fa0a0d" will not be mixed in.
2021-08-25 08:04:50,851 INFO [train.py:450] Epoch 3, batch 3580, batch avg loss 0.3638, total avg loss: 0.3483, batch size: 38
2021-08-25 08:04:59,466 INFO [train.py:450] Epoch 3, batch 3590, batch avg loss 0.3476, total avg loss: 0.3475, batch size: 40
2021-08-25 08:05:07,568 INFO [train.py:450] Epoch 3, batch 3600, batch avg loss 0.2978, total avg loss: 0.3471, batch size: 40
2021-08-25 08:05:17,316 INFO [train.py:450] Epoch 3, batch 3610, batch avg loss 0.3384, total avg loss: 0.3394, batch size: 40
2021-08-25 08:05:25,006 INFO [train.py:450] Epoch 3, batch 3620, batch avg loss 0.3805, total avg loss: 0.3437, batch size: 38
2021-08-25 08:05:37,381 INFO [train.py:450] Epoch 3, batch 3630, batch avg loss 0.3944, total avg loss: 0.3471, batch size: 48
2021-08-25 08:05:45,698 INFO [train.py:450] Epoch 3, batch 3640, batch avg loss 0.3154, total avg loss: 0.3478, batch size: 40
2021-08-25 08:05:53,654 INFO [train.py:450] Epoch 3, batch 3650, batch avg loss 0.3257, total avg loss: 0.3448, batch size: 36
2021-08-25 08:05:59,302 WARNING [cut.py:1694] To perform mix, energy must be non-zero and non-negative (got 0.0).  MonoCut with id "be5fed7c-ff0f-7fbe-f294-29786e7b060d" will not be mixed in.
2021-08-25 08:06:01,543 INFO [train.py:450] Epoch 3, batch 3660, batch avg loss 0.2881, total avg loss: 0.3426, batch size: 38
2021-08-25 08:06:08,814 INFO [train.py:450] Epoch 3, batch 3670, batch avg loss 0.3076, total avg loss: 0.3412, batch size: 37
2021-08-25 08:06:16,626 INFO [train.py:450] Epoch 3, batch 3680, batch avg loss 0.3493, total avg loss: 0.3404, batch size: 38
2021-08-25 08:06:24,391 INFO [train.py:450] Epoch 3, batch 3690, batch avg loss 0.3070, total avg loss: 0.3408, batch size: 36
2021-08-25 08:06:32,079 INFO [train.py:450] Epoch 3, batch 3700, batch avg loss 0.4037, total avg loss: 0.3412, batch size: 37
2021-08-25 08:06:39,949 INFO [train.py:450] Epoch 3, batch 3710, batch avg loss 0.3754, total avg loss: 0.3419, batch size: 39
2021-08-25 08:06:48,444 INFO [train.py:450] Epoch 3, batch 3720, batch avg loss 0.3477, total avg loss: 0.3425, batch size: 43
2021-08-25 08:06:56,514 INFO [train.py:450] Epoch 3, batch 3730, batch avg loss 0.3720, total avg loss: 0.3430, batch size: 41
2021-08-25 08:07:05,636 INFO [train.py:450] Epoch 3, batch 3740, batch avg loss 0.3509, total avg loss: 0.3433, batch size: 39
2021-08-25 08:07:13,586 INFO [train.py:450] Epoch 3, batch 3750, batch avg loss 0.4488, total avg loss: 0.3447, batch size: 36
2021-08-25 08:07:21,081 INFO [train.py:450] Epoch 3, batch 3760, batch avg loss 0.3660, total avg loss: 0.3457, batch size: 39
2021-08-25 08:07:28,449 INFO [train.py:450] Epoch 3, batch 3770, batch avg loss 0.3302, total avg loss: 0.3459, batch size: 40
2021-08-25 08:07:36,323 INFO [train.py:450] Epoch 3, batch 3780, batch avg loss 0.3872, total avg loss: 0.3464, batch size: 39
2021-08-25 08:07:43,813 INFO [train.py:450] Epoch 3, batch 3790, batch avg loss 0.3435, total avg loss: 0.3462, batch size: 37
2021-08-25 08:07:52,240 INFO [train.py:450] Epoch 3, batch 3800, batch avg loss 0.3240, total avg loss: 0.3457, batch size: 39
2021-08-25 08:08:00,050 INFO [train.py:450] Epoch 3, batch 3810, batch avg loss 0.3495, total avg loss: 0.3460, batch size: 40
2021-08-25 08:08:07,605 INFO [train.py:450] Epoch 3, batch 3820, batch avg loss 0.3325, total avg loss: 0.3451, batch size: 42
2021-08-25 08:08:15,032 INFO [train.py:450] Epoch 3, batch 3830, batch avg loss 0.3083, total avg loss: 0.3414, batch size: 41
2021-08-25 08:08:22,945 INFO [train.py:450] Epoch 3, batch 3840, batch avg loss 0.3323, total avg loss: 0.3397, batch size: 38
2021-08-25 08:08:30,360 INFO [train.py:450] Epoch 3, batch 3850, batch avg loss 0.3342, total avg loss: 0.3426, batch size: 46
2021-08-25 08:08:38,244 INFO [train.py:450] Epoch 3, batch 3860, batch avg loss 0.3728, total avg loss: 0.3417, batch size: 38
2021-08-25 08:08:46,070 INFO [train.py:450] Epoch 3, batch 3870, batch avg loss 0.3119, total avg loss: 0.3437, batch size: 39
2021-08-25 08:08:54,096 INFO [train.py:450] Epoch 3, batch 3880, batch avg loss 0.3472, total avg loss: 0.3440, batch size: 41
2021-08-25 08:09:02,589 INFO [train.py:450] Epoch 3, batch 3890, batch avg loss 0.3885, total avg loss: 0.3443, batch size: 38
2021-08-25 08:09:12,703 INFO [train.py:450] Epoch 3, batch 3900, batch avg loss 0.4044, total avg loss: 0.3440, batch size: 42
2021-08-25 08:09:21,726 INFO [train.py:450] Epoch 3, batch 3910, batch avg loss 0.3402, total avg loss: 0.3428, batch size: 42
2021-08-25 08:09:29,721 INFO [train.py:450] Epoch 3, batch 3920, batch avg loss 0.3044, total avg loss: 0.3424, batch size: 38
2021-08-25 08:09:37,425 INFO [train.py:450] Epoch 3, batch 3930, batch avg loss 0.3487, total avg loss: 0.3420, batch size: 39
2021-08-25 08:09:45,046 INFO [train.py:450] Epoch 3, batch 3940, batch avg loss 0.3208, total avg loss: 0.3430, batch size: 38
2021-08-25 08:09:52,565 INFO [train.py:450] Epoch 3, batch 3950, batch avg loss 0.3088, total avg loss: 0.3431, batch size: 43
2021-08-25 08:10:00,044 INFO [train.py:450] Epoch 3, batch 3960, batch avg loss 0.3570, total avg loss: 0.3437, batch size: 40
2021-08-25 08:10:07,732 INFO [train.py:450] Epoch 3, batch 3970, batch avg loss 0.4083, total avg loss: 0.3453, batch size: 39
2021-08-25 08:10:15,471 INFO [train.py:450] Epoch 3, batch 3980, batch avg loss 0.3742, total avg loss: 0.3462, batch size: 40
2021-08-25 08:10:23,119 INFO [train.py:450] Epoch 3, batch 3990, batch avg loss 0.3115, total avg loss: 0.3460, batch size: 39
2021-08-25 08:10:30,918 INFO [train.py:450] Epoch 3, batch 4000, batch avg loss 0.3296, total avg loss: 0.3457, batch size: 37
2021-08-25 08:11:08,606 INFO [train.py:482] Epoch 3, valid loss 0.2455, best valid loss: 0.2434 best valid epoch: 2
2021-08-25 08:11:14,734 INFO [train.py:450] Epoch 3, batch 4010, batch avg loss 0.3638, total avg loss: 0.3510, batch size: 41
2021-08-25 08:11:22,104 INFO [train.py:450] Epoch 3, batch 4020, batch avg loss 0.3134, total avg loss: 0.3492, batch size: 41
2021-08-25 08:11:30,179 INFO [train.py:450] Epoch 3, batch 4030, batch avg loss 0.2983, total avg loss: 0.3446, batch size: 36
2021-08-25 08:11:37,742 INFO [train.py:450] Epoch 3, batch 4040, batch avg loss 0.3243, total avg loss: 0.3414, batch size: 42
2021-08-25 08:11:46,005 INFO [train.py:450] Epoch 3, batch 4050, batch avg loss 0.3018, total avg loss: 0.3427, batch size: 40
2021-08-25 08:11:52,925 INFO [train.py:450] Epoch 3, batch 4060, batch avg loss 0.3393, total avg loss: 0.3435, batch size: 37
2021-08-25 08:12:00,671 INFO [train.py:450] Epoch 3, batch 4070, batch avg loss 0.3604, total avg loss: 0.3458, batch size: 41
2021-08-25 08:12:08,427 INFO [train.py:450] Epoch 3, batch 4080, batch avg loss 0.3201, total avg loss: 0.3444, batch size: 44
2021-08-25 08:12:16,095 INFO [train.py:450] Epoch 3, batch 4090, batch avg loss 0.3810, total avg loss: 0.3446, batch size: 39
2021-08-25 08:12:23,879 INFO [train.py:450] Epoch 3, batch 4100, batch avg loss 0.3769, total avg loss: 0.3450, batch size: 39
2021-08-25 08:12:31,647 INFO [train.py:450] Epoch 3, batch 4110, batch avg loss 0.3481, total avg loss: 0.3454, batch size: 45
2021-08-25 08:12:39,790 INFO [train.py:450] Epoch 3, batch 4120, batch avg loss 0.3206, total avg loss: 0.3457, batch size: 36
2021-08-25 08:12:46,519 INFO [train.py:450] Epoch 3, batch 4130, batch avg loss 0.3939, total avg loss: 0.3460, batch size: 41
2021-08-25 08:12:56,983 INFO [train.py:450] Epoch 3, batch 4140, batch avg loss 0.3665, total avg loss: 0.3458, batch size: 39
2021-08-25 08:13:04,432 INFO [train.py:450] Epoch 3, batch 4150, batch avg loss 0.3569, total avg loss: 0.3457, batch size: 39
2021-08-25 08:13:12,611 INFO [train.py:450] Epoch 3, batch 4160, batch avg loss 0.3966, total avg loss: 0.3462, batch size: 37
2021-08-25 08:13:19,932 INFO [train.py:450] Epoch 3, batch 4170, batch avg loss 0.3644, total avg loss: 0.3451, batch size: 38
2021-08-25 08:13:27,631 INFO [train.py:450] Epoch 3, batch 4180, batch avg loss 0.3118, total avg loss: 0.3449, batch size: 42
2021-08-25 08:13:35,122 INFO [train.py:450] Epoch 3, batch 4190, batch avg loss 0.3549, total avg loss: 0.3451, batch size: 36
2021-08-25 08:13:42,825 INFO [train.py:450] Epoch 3, batch 4200, batch avg loss 0.3471, total avg loss: 0.3445, batch size: 42
2021-08-25 08:13:50,018 INFO [train.py:450] Epoch 3, batch 4210, batch avg loss 0.3293, total avg loss: 0.3386, batch size: 41
2021-08-25 08:13:57,769 INFO [train.py:450] Epoch 3, batch 4220, batch avg loss 0.3220, total avg loss: 0.3518, batch size: 41
2021-08-25 08:14:04,950 INFO [train.py:450] Epoch 3, batch 4230, batch avg loss 0.3684, total avg loss: 0.3516, batch size: 42
2021-08-25 08:14:12,295 INFO [train.py:450] Epoch 3, batch 4240, batch avg loss 0.3373, total avg loss: 0.3512, batch size: 37
2021-08-25 08:14:19,757 INFO [train.py:450] Epoch 3, batch 4250, batch avg loss 0.3345, total avg loss: 0.3505, batch size: 43
2021-08-25 08:14:27,036 INFO [train.py:450] Epoch 3, batch 4260, batch avg loss 0.3547, total avg loss: 0.3489, batch size: 40
2021-08-25 08:14:34,265 INFO [train.py:450] Epoch 3, batch 4270, batch avg loss 0.3474, total avg loss: 0.3487, batch size: 39
2021-08-25 08:14:42,494 INFO [train.py:450] Epoch 3, batch 4280, batch avg loss 0.4030, total avg loss: 0.3505, batch size: 39
2021-08-25 08:14:49,649 INFO [train.py:450] Epoch 3, batch 4290, batch avg loss 0.3473, total avg loss: 0.3505, batch size: 39
2021-08-25 08:14:56,699 INFO [train.py:450] Epoch 3, batch 4300, batch avg loss 0.3562, total avg loss: 0.3506, batch size: 38
2021-08-25 08:15:04,291 INFO [train.py:450] Epoch 3, batch 4310, batch avg loss 0.3606, total avg loss: 0.3518, batch size: 39
2021-08-25 08:15:11,761 INFO [train.py:450] Epoch 3, batch 4320, batch avg loss 0.3151, total avg loss: 0.3516, batch size: 41
2021-08-25 08:15:19,317 INFO [train.py:450] Epoch 3, batch 4330, batch avg loss 0.3419, total avg loss: 0.3508, batch size: 37
2021-08-25 08:15:26,939 INFO [train.py:450] Epoch 3, batch 4340, batch avg loss 0.4572, total avg loss: 0.3535, batch size: 45
2021-08-25 08:15:33,390 INFO [train.py:450] Epoch 3, batch 4350, batch avg loss 0.3385, total avg loss: 0.3526, batch size: 43
2021-08-25 08:15:40,552 INFO [train.py:450] Epoch 3, batch 4360, batch avg loss 0.3500, total avg loss: 0.3521, batch size: 40
2021-08-25 08:15:47,859 INFO [train.py:450] Epoch 3, batch 4370, batch avg loss 0.3179, total avg loss: 0.3513, batch size: 39
2021-08-25 08:15:55,472 INFO [train.py:450] Epoch 3, batch 4380, batch avg loss 0.3494, total avg loss: 0.3507, batch size: 39
2021-08-25 08:16:02,577 INFO [train.py:450] Epoch 3, batch 4390, batch avg loss 0.3706, total avg loss: 0.3505, batch size: 42
2021-08-25 08:16:11,495 INFO [train.py:450] Epoch 3, batch 4400, batch avg loss 0.4001, total avg loss: 0.3516, batch size: 39
2021-08-25 08:16:20,107 INFO [train.py:450] Epoch 3, batch 4410, batch avg loss 0.3438, total avg loss: 0.3533, batch size: 41
2021-08-25 08:16:28,922 INFO [train.py:450] Epoch 3, batch 4420, batch avg loss 0.3740, total avg loss: 0.3693, batch size: 40
2021-08-25 08:16:35,548 INFO [train.py:450] Epoch 3, batch 4430, batch avg loss 0.3711, total avg loss: 0.3646, batch size: 42
2021-08-25 08:16:43,010 INFO [train.py:450] Epoch 3, batch 4440, batch avg loss 0.3655, total avg loss: 0.3575, batch size: 40
2021-08-25 08:16:51,158 INFO [train.py:450] Epoch 3, batch 4450, batch avg loss 0.2977, total avg loss: 0.3562, batch size: 40
2021-08-25 08:16:58,137 INFO [train.py:450] Epoch 3, batch 4460, batch avg loss 0.3739, total avg loss: 0.3562, batch size: 38
2021-08-25 08:17:05,568 INFO [train.py:450] Epoch 3, batch 4470, batch avg loss 0.3404, total avg loss: 0.3559, batch size: 38
2021-08-25 08:17:14,122 INFO [train.py:450] Epoch 3, batch 4480, batch avg loss 0.3630, total avg loss: 0.3546, batch size: 43
2021-08-25 08:17:21,409 INFO [train.py:450] Epoch 3, batch 4490, batch avg loss 0.3356, total avg loss: 0.3563, batch size: 38
2021-08-25 08:17:28,741 INFO [train.py:450] Epoch 3, batch 4500, batch avg loss 0.3534, total avg loss: 0.3542, batch size: 40
2021-08-25 08:17:36,190 INFO [train.py:450] Epoch 3, batch 4510, batch avg loss 0.3622, total avg loss: 0.3552, batch size: 40
2021-08-25 08:17:43,432 INFO [train.py:450] Epoch 3, batch 4520, batch avg loss 0.2821, total avg loss: 0.3551, batch size: 41
2021-08-25 08:17:50,806 INFO [train.py:450] Epoch 3, batch 4530, batch avg loss 0.3742, total avg loss: 0.3539, batch size: 41
2021-08-25 08:17:58,271 INFO [train.py:450] Epoch 3, batch 4540, batch avg loss 0.3389, total avg loss: 0.3522, batch size: 44
2021-08-25 08:18:05,371 INFO [train.py:450] Epoch 3, batch 4550, batch avg loss 0.4073, total avg loss: 0.3524, batch size: 37
2021-08-25 08:18:12,406 INFO [train.py:450] Epoch 3, batch 4560, batch avg loss 0.3476, total avg loss: 0.3525, batch size: 36
2021-08-25 08:18:19,647 INFO [train.py:450] Epoch 3, batch 4570, batch avg loss 0.3336, total avg loss: 0.3512, batch size: 39
2021-08-25 08:18:26,843 INFO [train.py:450] Epoch 3, batch 4580, batch avg loss 0.3129, total avg loss: 0.3516, batch size: 39
2021-08-25 08:18:34,668 INFO [train.py:450] Epoch 3, batch 4590, batch avg loss 0.3511, total avg loss: 0.3519, batch size: 42
2021-08-25 08:18:42,156 INFO [train.py:450] Epoch 3, batch 4600, batch avg loss 0.3285, total avg loss: 0.3517, batch size: 41
2021-08-25 08:18:49,432 INFO [train.py:450] Epoch 3, batch 4610, batch avg loss 0.3005, total avg loss: 0.3338, batch size: 38
2021-08-25 08:18:56,625 INFO [train.py:450] Epoch 3, batch 4620, batch avg loss 0.3079, total avg loss: 0.3391, batch size: 42
2021-08-25 08:19:03,620 INFO [train.py:450] Epoch 3, batch 4630, batch avg loss 0.3070, total avg loss: 0.3399, batch size: 38
2021-08-25 08:19:11,159 INFO [train.py:450] Epoch 3, batch 4640, batch avg loss 0.3708, total avg loss: 0.3440, batch size: 43
2021-08-25 08:19:18,658 INFO [train.py:450] Epoch 3, batch 4650, batch avg loss 0.3781, total avg loss: 0.3465, batch size: 42
2021-08-25 08:19:26,305 INFO [train.py:450] Epoch 3, batch 4660, batch avg loss 0.3505, total avg loss: 0.3470, batch size: 39
2021-08-25 08:19:33,794 INFO [train.py:450] Epoch 3, batch 4670, batch avg loss 0.3845, total avg loss: 0.3472, batch size: 41
2021-08-25 08:19:42,147 INFO [train.py:450] Epoch 3, batch 4680, batch avg loss 0.3345, total avg loss: 0.3460, batch size: 42
2021-08-25 08:19:49,098 INFO [train.py:450] Epoch 3, batch 4690, batch avg loss 0.3044, total avg loss: 0.3457, batch size: 38
2021-08-25 08:19:58,456 INFO [train.py:450] Epoch 3, batch 4700, batch avg loss 0.3823, total avg loss: 0.3446, batch size: 41
2021-08-25 08:20:05,928 INFO [train.py:450] Epoch 3, batch 4710, batch avg loss 0.3394, total avg loss: 0.3458, batch size: 44
2021-08-25 08:20:12,485 INFO [train.py:450] Epoch 3, batch 4720, batch avg loss 0.3566, total avg loss: 0.3456, batch size: 39
2021-08-25 08:20:19,072 INFO [train.py:450] Epoch 3, batch 4730, batch avg loss 0.4456, total avg loss: 0.3472, batch size: 37
2021-08-25 08:20:26,567 INFO [train.py:450] Epoch 3, batch 4740, batch avg loss 0.4236, total avg loss: 0.3475, batch size: 40
2021-08-25 08:20:33,934 INFO [train.py:450] Epoch 3, batch 4750, batch avg loss 0.3319, total avg loss: 0.3474, batch size: 42
2021-08-25 08:20:40,840 INFO [train.py:450] Epoch 3, batch 4760, batch avg loss 0.4067, total avg loss: 0.3475, batch size: 39
2021-08-25 08:20:48,391 INFO [train.py:450] Epoch 3, batch 4770, batch avg loss 0.2881, total avg loss: 0.3476, batch size: 41
2021-08-25 08:20:55,433 INFO [train.py:450] Epoch 3, batch 4780, batch avg loss 0.3776, total avg loss: 0.3474, batch size: 37
2021-08-25 08:21:02,368 INFO [train.py:450] Epoch 3, batch 4790, batch avg loss 0.3412, total avg loss: 0.3476, batch size: 39
2021-08-25 08:21:09,041 INFO [train.py:450] Epoch 3, batch 4800, batch avg loss 0.3832, total avg loss: 0.3480, batch size: 41
2021-08-25 08:21:15,823 INFO [train.py:450] Epoch 3, batch 4810, batch avg loss 0.3546, total avg loss: 0.3441, batch size: 37
2021-08-25 08:21:23,188 INFO [train.py:450] Epoch 3, batch 4820, batch avg loss 0.2825, total avg loss: 0.3401, batch size: 38
2021-08-25 08:21:29,799 INFO [train.py:450] Epoch 3, batch 4830, batch avg loss 0.3186, total avg loss: 0.3454, batch size: 39
2021-08-25 08:21:36,513 INFO [train.py:450] Epoch 3, batch 4840, batch avg loss 0.3385, total avg loss: 0.3484, batch size: 39
2021-08-25 08:21:43,717 INFO [train.py:450] Epoch 3, batch 4850, batch avg loss 0.3086, total avg loss: 0.3473, batch size: 39
2021-08-25 08:21:51,125 INFO [train.py:450] Epoch 3, batch 4860, batch avg loss 0.3086, total avg loss: 0.3474, batch size: 38
2021-08-25 08:21:57,981 INFO [train.py:450] Epoch 3, batch 4870, batch avg loss 0.3598, total avg loss: 0.3455, batch size: 42
2021-08-25 08:22:04,799 INFO [train.py:450] Epoch 3, batch 4880, batch avg loss 0.3332, total avg loss: 0.3437, batch size: 42
2021-08-25 08:22:11,778 INFO [train.py:450] Epoch 3, batch 4890, batch avg loss 0.2919, total avg loss: 0.3442, batch size: 45
2021-08-25 08:22:18,522 INFO [train.py:450] Epoch 3, batch 4900, batch avg loss 0.3039, total avg loss: 0.3441, batch size: 37
2021-08-25 08:22:25,128 INFO [train.py:450] Epoch 3, batch 4910, batch avg loss 0.3148, total avg loss: 0.3457, batch size: 39
2021-08-25 08:22:32,295 INFO [train.py:450] Epoch 3, batch 4920, batch avg loss 0.3577, total avg loss: 0.3454, batch size: 42
2021-08-25 08:22:39,733 INFO [train.py:450] Epoch 3, batch 4930, batch avg loss 0.3357, total avg loss: 0.3452, batch size: 44
2021-08-25 08:22:46,723 INFO [train.py:450] Epoch 3, batch 4940, batch avg loss 0.3956, total avg loss: 0.3458, batch size: 42
2021-08-25 08:22:54,965 INFO [train.py:450] Epoch 3, batch 4950, batch avg loss 0.2825, total avg loss: 0.3453, batch size: 39
2021-08-25 08:23:01,582 INFO [train.py:450] Epoch 3, batch 4960, batch avg loss 0.3185, total avg loss: 0.3458, batch size: 38
2021-08-25 08:23:12,200 INFO [train.py:450] Epoch 3, batch 4970, batch avg loss 0.3708, total avg loss: 0.3455, batch size: 42
2021-08-25 08:23:19,011 INFO [train.py:450] Epoch 3, batch 4980, batch avg loss 0.3292, total avg loss: 0.3459, batch size: 36
2021-08-25 08:23:25,848 INFO [train.py:450] Epoch 3, batch 4990, batch avg loss 0.3465, total avg loss: 0.3455, batch size: 38
2021-08-25 08:23:32,283 INFO [train.py:450] Epoch 3, batch 5000, batch avg loss 0.3130, total avg loss: 0.3462, batch size: 38
2021-08-25 08:24:11,756 INFO [train.py:482] Epoch 3, valid loss 0.2464, best valid loss: 0.2434 best valid epoch: 2
2021-08-25 08:24:17,562 INFO [train.py:450] Epoch 3, batch 5010, batch avg loss 0.3211, total avg loss: 0.3539, batch size: 40
2021-08-25 08:24:24,101 INFO [train.py:450] Epoch 3, batch 5020, batch avg loss 0.3978, total avg loss: 0.3532, batch size: 37
2021-08-25 08:24:31,090 INFO [train.py:450] Epoch 3, batch 5030, batch avg loss 0.3535, total avg loss: 0.3511, batch size: 38
2021-08-25 08:24:37,602 INFO [train.py:450] Epoch 3, batch 5040, batch avg loss 0.3603, total avg loss: 0.3480, batch size: 39
2021-08-25 08:24:44,580 INFO [train.py:450] Epoch 3, batch 5050, batch avg loss 0.3484, total avg loss: 0.3502, batch size: 42
2021-08-25 08:24:51,372 INFO [train.py:450] Epoch 3, batch 5060, batch avg loss 0.3418, total avg loss: 0.3492, batch size: 40
2021-08-25 08:24:58,432 INFO [train.py:450] Epoch 3, batch 5070, batch avg loss 0.3392, total avg loss: 0.3466, batch size: 40
2021-08-25 08:25:05,409 INFO [train.py:450] Epoch 3, batch 5080, batch avg loss 0.3033, total avg loss: 0.3467, batch size: 40
2021-08-25 08:25:11,978 INFO [train.py:450] Epoch 3, batch 5090, batch avg loss 0.3362, total avg loss: 0.3463, batch size: 37
2021-08-25 08:25:18,367 INFO [train.py:450] Epoch 3, batch 5100, batch avg loss 0.3063, total avg loss: 0.3467, batch size: 40
2021-08-25 08:25:25,653 INFO [train.py:450] Epoch 3, batch 5110, batch avg loss 0.3624, total avg loss: 0.3492, batch size: 44
2021-08-25 08:25:32,319 INFO [train.py:450] Epoch 3, batch 5120, batch avg loss 0.3334, total avg loss: 0.3499, batch size: 39
2021-08-25 08:25:39,350 INFO [train.py:450] Epoch 3, batch 5130, batch avg loss 0.3865, total avg loss: 0.3506, batch size: 39
2021-08-25 08:25:46,223 INFO [train.py:450] Epoch 3, batch 5140, batch avg loss 0.4095, total avg loss: 0.3507, batch size: 41
2021-08-25 08:25:52,416 INFO [train.py:450] Epoch 3, batch 5150, batch avg loss 0.3252, total avg loss: 0.3495, batch size: 38
2021-08-25 08:26:00,280 INFO [train.py:450] Epoch 3, batch 5160, batch avg loss 0.3805, total avg loss: 0.3508, batch size: 38
2021-08-25 08:26:07,432 INFO [train.py:450] Epoch 3, batch 5170, batch avg loss 0.3010, total avg loss: 0.3494, batch size: 40
2021-08-25 08:26:14,939 INFO [train.py:450] Epoch 3, batch 5180, batch avg loss 0.3896, total avg loss: 0.3501, batch size: 41
2021-08-25 08:26:23,169 INFO [train.py:450] Epoch 3, batch 5190, batch avg loss 0.3394, total avg loss: 0.3498, batch size: 40
2021-08-25 08:26:29,779 INFO [train.py:450] Epoch 3, batch 5200, batch avg loss 0.3809, total avg loss: 0.3500, batch size: 39
2021-08-25 08:26:36,454 INFO [train.py:450] Epoch 3, batch 5210, batch avg loss 0.3189, total avg loss: 0.3393, batch size: 39
2021-08-25 08:26:42,921 INFO [train.py:450] Epoch 3, batch 5220, batch avg loss 0.3374, total avg loss: 0.3534, batch size: 37
2021-08-25 08:26:49,124 INFO [train.py:450] Epoch 3, batch 5230, batch avg loss 0.3649, total avg loss: 0.3460, batch size: 38
2021-08-25 08:26:55,979 INFO [train.py:450] Epoch 3, batch 5240, batch avg loss 0.3469, total avg loss: 0.3472, batch size: 37
2021-08-25 08:27:03,040 INFO [train.py:450] Epoch 3, batch 5250, batch avg loss 0.3433, total avg loss: 0.3481, batch size: 41
2021-08-25 08:27:10,412 INFO [train.py:450] Epoch 3, batch 5260, batch avg loss 0.3676, total avg loss: 0.3508, batch size: 39
2021-08-25 08:27:16,720 INFO [train.py:450] Epoch 3, batch 5270, batch avg loss 0.3538, total avg loss: 0.3532, batch size: 36
2021-08-25 08:27:23,657 INFO [train.py:450] Epoch 3, batch 5280, batch avg loss 0.4711, total avg loss: 0.3527, batch size: 38
2021-08-25 08:27:29,933 INFO [train.py:450] Epoch 3, batch 5290, batch avg loss 0.3272, total avg loss: 0.3524, batch size: 37
2021-08-25 08:27:36,595 INFO [train.py:450] Epoch 3, batch 5300, batch avg loss 0.3418, total avg loss: 0.3524, batch size: 40
2021-08-25 08:27:43,485 INFO [train.py:450] Epoch 3, batch 5310, batch avg loss 0.3257, total avg loss: 0.3523, batch size: 39
2021-08-25 08:27:50,197 INFO [train.py:450] Epoch 3, batch 5320, batch avg loss 0.3329, total avg loss: 0.3508, batch size: 39
2021-08-25 08:27:56,490 INFO [train.py:450] Epoch 3, batch 5330, batch avg loss 0.3908, total avg loss: 0.3522, batch size: 40
2021-08-25 08:28:02,965 INFO [train.py:450] Epoch 3, batch 5340, batch avg loss 0.2998, total avg loss: 0.3517, batch size: 42
2021-08-25 08:28:09,019 INFO [train.py:450] Epoch 3, batch 5350, batch avg loss 0.3329, total avg loss: 0.3527, batch size: 40
2021-08-25 08:28:15,174 INFO [train.py:450] Epoch 3, batch 5360, batch avg loss 0.3298, total avg loss: 0.3527, batch size: 38
2021-08-25 08:28:21,658 INFO [train.py:450] Epoch 3, batch 5370, batch avg loss 0.3471, total avg loss: 0.3532, batch size: 41
2021-08-25 08:28:27,881 INFO [train.py:450] Epoch 3, batch 5380, batch avg loss 0.3334, total avg loss: 0.3526, batch size: 39
2021-08-25 08:28:33,979 INFO [train.py:450] Epoch 3, batch 5390, batch avg loss 0.3503, total avg loss: 0.3519, batch size: 42
2021-08-25 08:28:40,511 INFO [train.py:450] Epoch 3, batch 5400, batch avg loss 0.3678, total avg loss: 0.3513, batch size: 38
2021-08-25 08:28:46,513 INFO [train.py:450] Epoch 3, batch 5410, batch avg loss 0.3742, total avg loss: 0.3451, batch size: 39
2021-08-25 08:28:52,546 INFO [train.py:450] Epoch 3, batch 5420, batch avg loss 0.4377, total avg loss: 0.3547, batch size: 42
2021-08-25 08:28:58,781 INFO [train.py:450] Epoch 3, batch 5430, batch avg loss 0.3434, total avg loss: 0.3498, batch size: 37
2021-08-25 08:29:05,109 INFO [train.py:450] Epoch 3, batch 5440, batch avg loss 0.3075, total avg loss: 0.3500, batch size: 36
2021-08-25 08:29:11,514 INFO [train.py:450] Epoch 3, batch 5450, batch avg loss 0.3245, total avg loss: 0.3506, batch size: 40
2021-08-25 08:29:18,059 INFO [train.py:450] Epoch 3, batch 5460, batch avg loss 0.3523, total avg loss: 0.3527, batch size: 40
2021-08-25 08:29:25,195 INFO [train.py:450] Epoch 3, batch 5470, batch avg loss 0.3435, total avg loss: 0.3546, batch size: 37
2021-08-25 08:29:31,900 INFO [train.py:450] Epoch 3, batch 5480, batch avg loss 0.3359, total avg loss: 0.3523, batch size: 42
2021-08-25 08:29:42,217 INFO [train.py:450] Epoch 3, batch 5490, batch avg loss 0.3284, total avg loss: 0.3521, batch size: 41
2021-08-25 08:29:49,131 INFO [train.py:450] Epoch 3, batch 5500, batch avg loss 0.3161, total avg loss: 0.3507, batch size: 39
2021-08-25 08:29:56,191 INFO [train.py:450] Epoch 3, batch 5510, batch avg loss 0.3224, total avg loss: 0.3489, batch size: 39
2021-08-25 08:30:02,288 INFO [train.py:450] Epoch 3, batch 5520, batch avg loss 0.4035, total avg loss: 0.3475, batch size: 37
2021-08-25 08:30:08,600 INFO [train.py:450] Epoch 3, batch 5530, batch avg loss 0.3119, total avg loss: 0.3472, batch size: 37
2021-08-25 08:30:22,362 INFO [train.py:450] Epoch 3, batch 5540, batch avg loss 0.3453, total avg loss: 0.3468, batch size: 42
2021-08-25 08:30:28,140 INFO [train.py:450] Epoch 3, batch 5550, batch avg loss 0.3158, total avg loss: 0.3481, batch size: 40
2021-08-25 08:30:33,976 INFO [train.py:450] Epoch 3, batch 5560, batch avg loss 0.3412, total avg loss: 0.3480, batch size: 37
2021-08-25 08:30:40,101 INFO [train.py:450] Epoch 3, batch 5570, batch avg loss 0.3709, total avg loss: 0.3481, batch size: 42
2021-08-25 08:30:46,292 INFO [train.py:450] Epoch 3, batch 5580, batch avg loss 0.3463, total avg loss: 0.3488, batch size: 40
2021-08-25 08:30:52,114 INFO [train.py:450] Epoch 3, batch 5590, batch avg loss 0.3139, total avg loss: 0.3487, batch size: 36
2021-08-25 08:30:58,552 INFO [train.py:450] Epoch 3, batch 5600, batch avg loss 0.3356, total avg loss: 0.3482, batch size: 37
2021-08-25 08:31:04,943 INFO [train.py:450] Epoch 3, batch 5610, batch avg loss 0.3488, total avg loss: 0.3322, batch size: 43
2021-08-25 08:31:11,268 INFO [train.py:450] Epoch 3, batch 5620, batch avg loss 0.3458, total avg loss: 0.3389, batch size: 41
2021-08-25 08:31:17,192 INFO [train.py:450] Epoch 3, batch 5630, batch avg loss 0.2816, total avg loss: 0.3393, batch size: 37
2021-08-25 08:31:23,102 INFO [train.py:450] Epoch 3, batch 5640, batch avg loss 0.3449, total avg loss: 0.3409, batch size: 41
2021-08-25 08:31:29,459 INFO [train.py:450] Epoch 3, batch 5650, batch avg loss 0.3859, total avg loss: 0.3429, batch size: 37
2021-08-25 08:31:35,827 INFO [train.py:450] Epoch 3, batch 5660, batch avg loss 0.3384, total avg loss: 0.3524, batch size: 36
2021-08-25 08:31:41,940 INFO [train.py:450] Epoch 3, batch 5670, batch avg loss 0.3190, total avg loss: 0.3514, batch size: 41
2021-08-25 08:31:48,308 INFO [train.py:450] Epoch 3, batch 5680, batch avg loss 0.3830, total avg loss: 0.3541, batch size: 41
2021-08-25 08:31:54,231 INFO [train.py:450] Epoch 3, batch 5690, batch avg loss 0.3418, total avg loss: 0.3533, batch size: 42
2021-08-25 08:32:00,518 INFO [train.py:450] Epoch 3, batch 5700, batch avg loss 0.3779, total avg loss: 0.3563, batch size: 42
2021-08-25 08:32:06,585 INFO [train.py:450] Epoch 3, batch 5710, batch avg loss 0.3304, total avg loss: 0.3554, batch size: 42
2021-08-25 08:32:12,667 INFO [train.py:450] Epoch 3, batch 5720, batch avg loss 0.4033, total avg loss: 0.3559, batch size: 39
2021-08-25 08:32:18,579 INFO [train.py:450] Epoch 3, batch 5730, batch avg loss 0.3050, total avg loss: 0.3543, batch size: 42
2021-08-25 08:32:24,606 INFO [train.py:450] Epoch 3, batch 5740, batch avg loss 0.3892, total avg loss: 0.3542, batch size: 41
2021-08-25 08:32:30,674 INFO [train.py:450] Epoch 3, batch 5750, batch avg loss 0.3796, total avg loss: 0.3529, batch size: 36
2021-08-25 08:32:36,979 INFO [train.py:450] Epoch 3, batch 5760, batch avg loss 0.4237, total avg loss: 0.3533, batch size: 45
2021-08-25 08:32:44,414 INFO [train.py:450] Epoch 3, batch 5770, batch avg loss 0.3771, total avg loss: 0.3520, batch size: 43
2021-08-25 08:32:50,358 INFO [train.py:450] Epoch 3, batch 5780, batch avg loss 0.3751, total avg loss: 0.3514, batch size: 37
2021-08-25 08:33:00,302 INFO [train.py:450] Epoch 3, batch 5790, batch avg loss 0.3072, total avg loss: 0.3509, batch size: 40
2021-08-25 08:33:06,335 INFO [train.py:450] Epoch 3, batch 5800, batch avg loss 0.3600, total avg loss: 0.3504, batch size: 39
2021-08-25 08:33:12,856 INFO [train.py:450] Epoch 3, batch 5810, batch avg loss 0.3340, total avg loss: 0.3407, batch size: 39
2021-08-25 08:33:19,275 INFO [train.py:450] Epoch 3, batch 5820, batch avg loss 0.3084, total avg loss: 0.3402, batch size: 42
2021-08-25 08:33:25,486 INFO [train.py:450] Epoch 3, batch 5830, batch avg loss 0.2988, total avg loss: 0.3464, batch size: 39
2021-08-25 08:33:31,280 INFO [train.py:450] Epoch 3, batch 5840, batch avg loss 0.2816, total avg loss: 0.3472, batch size: 37
2021-08-25 08:33:37,431 INFO [train.py:450] Epoch 3, batch 5850, batch avg loss 0.3622, total avg loss: 0.3472, batch size: 41
2021-08-25 08:33:43,391 INFO [train.py:450] Epoch 3, batch 5860, batch avg loss 0.3566, total avg loss: 0.3473, batch size: 39
2021-08-25 08:33:49,597 INFO [train.py:450] Epoch 3, batch 5870, batch avg loss 0.2749, total avg loss: 0.3457, batch size: 40
2021-08-25 08:33:56,291 INFO [train.py:450] Epoch 3, batch 5880, batch avg loss 0.3560, total avg loss: 0.3470, batch size: 37
2021-08-25 08:34:02,386 INFO [train.py:450] Epoch 3, batch 5890, batch avg loss 0.3277, total avg loss: 0.3471, batch size: 38
2021-08-25 08:34:08,757 INFO [train.py:450] Epoch 3, batch 5900, batch avg loss 0.3419, total avg loss: 0.3497, batch size: 40
2021-08-25 08:34:14,930 INFO [train.py:450] Epoch 3, batch 5910, batch avg loss 0.3847, total avg loss: 0.3524, batch size: 39
2021-08-25 08:34:21,308 INFO [train.py:450] Epoch 3, batch 5920, batch avg loss 0.3148, total avg loss: 0.3530, batch size: 42
2021-08-25 08:34:27,348 INFO [train.py:450] Epoch 3, batch 5930, batch avg loss 0.3706, total avg loss: 0.3521, batch size: 37
2021-08-25 08:34:33,612 INFO [train.py:450] Epoch 3, batch 5940, batch avg loss 0.3342, total avg loss: 0.3517, batch size: 39
2021-08-25 08:34:39,473 INFO [train.py:450] Epoch 3, batch 5950, batch avg loss 0.3535, total avg loss: 0.3512, batch size: 39
2021-08-25 08:34:45,425 INFO [train.py:450] Epoch 3, batch 5960, batch avg loss 0.2984, total avg loss: 0.3502, batch size: 38
2021-08-25 08:34:52,069 INFO [train.py:450] Epoch 3, batch 5970, batch avg loss 0.3496, total avg loss: 0.3512, batch size: 40
2021-08-25 08:34:57,891 INFO [train.py:450] Epoch 3, batch 5980, batch avg loss 0.4106, total avg loss: 0.3516, batch size: 38
2021-08-25 08:35:03,720 INFO [train.py:450] Epoch 3, batch 5990, batch avg loss 0.3869, total avg loss: 0.3516, batch size: 36
2021-08-25 08:35:09,732 INFO [train.py:450] Epoch 3, batch 6000, batch avg loss 0.3650, total avg loss: 0.3515, batch size: 39
2021-08-25 08:35:49,506 INFO [train.py:482] Epoch 3, valid loss 0.2487, best valid loss: 0.2434 best valid epoch: 2
2021-08-25 08:35:55,243 INFO [train.py:450] Epoch 3, batch 6010, batch avg loss 0.3683, total avg loss: 0.3595, batch size: 41
2021-08-25 08:36:01,062 INFO [train.py:450] Epoch 3, batch 6020, batch avg loss 0.3404, total avg loss: 0.3528, batch size: 43
2021-08-25 08:36:07,008 INFO [train.py:450] Epoch 3, batch 6030, batch avg loss 0.4044, total avg loss: 0.3545, batch size: 43
2021-08-25 08:36:13,129 INFO [train.py:450] Epoch 3, batch 6040, batch avg loss 0.3818, total avg loss: 0.3539, batch size: 39
2021-08-25 08:36:19,028 INFO [train.py:450] Epoch 3, batch 6050, batch avg loss 0.3109, total avg loss: 0.3544, batch size: 38
2021-08-25 08:36:24,915 INFO [train.py:450] Epoch 3, batch 6060, batch avg loss 0.3236, total avg loss: 0.3530, batch size: 42
2021-08-25 08:36:30,892 INFO [train.py:450] Epoch 3, batch 6070, batch avg loss 0.3709, total avg loss: 0.3527, batch size: 40
2021-08-25 08:36:37,497 INFO [train.py:450] Epoch 3, batch 6080, batch avg loss 0.3187, total avg loss: 0.3506, batch size: 37
2021-08-25 08:36:44,804 INFO [train.py:450] Epoch 3, batch 6090, batch avg loss 0.2967, total avg loss: 0.3497, batch size: 41
2021-08-25 08:36:50,976 INFO [train.py:450] Epoch 3, batch 6100, batch avg loss 0.3825, total avg loss: 0.3489, batch size: 41
2021-08-25 08:36:56,776 INFO [train.py:450] Epoch 3, batch 6110, batch avg loss 0.3348, total avg loss: 0.3485, batch size: 40
2021-08-25 08:37:06,138 INFO [train.py:450] Epoch 3, batch 6120, batch avg loss 0.3355, total avg loss: 0.3475, batch size: 39
2021-08-25 08:37:12,046 INFO [train.py:450] Epoch 3, batch 6130, batch avg loss 0.3317, total avg loss: 0.3494, batch size: 39
2021-08-25 08:37:17,954 INFO [train.py:450] Epoch 3, batch 6140, batch avg loss 0.3450, total avg loss: 0.3485, batch size: 41
2021-08-25 08:37:23,834 INFO [train.py:450] Epoch 3, batch 6150, batch avg loss 0.4125, total avg loss: 0.3484, batch size: 39
2021-08-25 08:37:29,769 INFO [train.py:450] Epoch 3, batch 6160, batch avg loss 0.3537, total avg loss: 0.3482, batch size: 41
2021-08-25 08:37:35,829 INFO [train.py:450] Epoch 3, batch 6170, batch avg loss 0.3492, total avg loss: 0.3478, batch size: 40
2021-08-25 08:37:41,761 INFO [train.py:450] Epoch 3, batch 6180, batch avg loss 0.3098, total avg loss: 0.3470, batch size: 41
2021-08-25 08:37:47,663 INFO [train.py:450] Epoch 3, batch 6190, batch avg loss 0.3781, total avg loss: 0.3481, batch size: 37
2021-08-25 08:37:53,510 INFO [train.py:450] Epoch 3, batch 6200, batch avg loss 0.3812, total avg loss: 0.3473, batch size: 39
2021-08-25 08:37:59,400 INFO [train.py:450] Epoch 3, batch 6210, batch avg loss 0.3623, total avg loss: 0.3491, batch size: 39
2021-08-25 08:38:05,211 INFO [train.py:450] Epoch 3, batch 6220, batch avg loss 0.3695, total avg loss: 0.3477, batch size: 40
2021-08-25 08:38:11,199 INFO [train.py:450] Epoch 3, batch 6230, batch avg loss 0.3191, total avg loss: 0.3515, batch size: 41
2021-08-25 08:38:17,172 INFO [train.py:450] Epoch 3, batch 6240, batch avg loss 0.3346, total avg loss: 0.3514, batch size: 41
2021-08-25 08:38:23,068 INFO [train.py:450] Epoch 3, batch 6250, batch avg loss 0.3314, total avg loss: 0.3522, batch size: 37
2021-08-25 08:38:28,936 INFO [train.py:450] Epoch 3, batch 6260, batch avg loss 0.3577, total avg loss: 0.3515, batch size: 37
2021-08-25 08:38:34,880 INFO [train.py:450] Epoch 3, batch 6270, batch avg loss 0.3398, total avg loss: 0.3517, batch size: 44
2021-08-25 08:38:40,895 INFO [train.py:450] Epoch 3, batch 6280, batch avg loss 0.4128, total avg loss: 0.3526, batch size: 37
2021-08-25 08:38:46,798 INFO [train.py:450] Epoch 3, batch 6290, batch avg loss 0.3708, total avg loss: 0.3519, batch size: 43
2021-08-25 08:38:47,365 WARNING [cut.py:1694] To perform mix, energy must be non-zero and non-negative (got 0.0).  MonoCut with id "13edeebf-5d33-4d5f-3cbc-7f0bba6d190a" will not be mixed in.
2021-08-25 08:38:52,708 INFO [train.py:450] Epoch 3, batch 6300, batch avg loss 0.3628, total avg loss: 0.3524, batch size: 38
2021-08-25 08:38:58,808 INFO [train.py:450] Epoch 3, batch 6310, batch avg loss 0.3415, total avg loss: 0.3529, batch size: 39
2021-08-25 08:39:04,815 INFO [train.py:450] Epoch 3, batch 6320, batch avg loss 0.3348, total avg loss: 0.3531, batch size: 37
2021-08-25 08:39:10,783 INFO [train.py:450] Epoch 3, batch 6330, batch avg loss 0.3199, total avg loss: 0.3527, batch size: 43
2021-08-25 08:39:16,674 INFO [train.py:450] Epoch 3, batch 6340, batch avg loss 0.3365, total avg loss: 0.3533, batch size: 40
2021-08-25 08:39:22,944 INFO [train.py:450] Epoch 3, batch 6350, batch avg loss 0.3766, total avg loss: 0.3534, batch size: 39
2021-08-25 08:39:28,758 INFO [train.py:450] Epoch 3, batch 6360, batch avg loss 0.3551, total avg loss: 0.3524, batch size: 38
2021-08-25 08:39:34,481 INFO [train.py:450] Epoch 3, batch 6370, batch avg loss 0.4114, total avg loss: 0.3526, batch size: 43
2021-08-25 08:39:40,430 INFO [train.py:450] Epoch 3, batch 6380, batch avg loss 0.3491, total avg loss: 0.3529, batch size: 39
2021-08-25 08:39:46,345 INFO [train.py:450] Epoch 3, batch 6390, batch avg loss 0.3236, total avg loss: 0.3526, batch size: 39
2021-08-25 08:39:52,295 INFO [train.py:450] Epoch 3, batch 6400, batch avg loss 0.3374, total avg loss: 0.3521, batch size: 36
2021-08-25 08:39:58,788 INFO [train.py:450] Epoch 3, batch 6410, batch avg loss 0.3598, total avg loss: 0.3477, batch size: 42
2021-08-25 08:40:06,493 INFO [train.py:450] Epoch 3, batch 6420, batch avg loss 0.3592, total avg loss: 0.3541, batch size: 38
2021-08-25 08:40:12,432 INFO [train.py:450] Epoch 3, batch 6430, batch avg loss 0.3908, total avg loss: 0.3508, batch size: 39
2021-08-25 08:40:18,265 INFO [train.py:450] Epoch 3, batch 6440, batch avg loss 0.3242, total avg loss: 0.3491, batch size: 37
2021-08-25 08:40:24,142 INFO [train.py:450] Epoch 3, batch 6450, batch avg loss 0.3563, total avg loss: 0.3474, batch size: 39
2021-08-25 08:40:30,160 INFO [train.py:450] Epoch 3, batch 6460, batch avg loss 0.3744, total avg loss: 0.3493, batch size: 38
2021-08-25 08:40:36,032 INFO [train.py:450] Epoch 3, batch 6470, batch avg loss 0.3174, total avg loss: 0.3481, batch size: 40
2021-08-25 08:40:41,962 INFO [train.py:450] Epoch 3, batch 6480, batch avg loss 0.3548, total avg loss: 0.3485, batch size: 41
2021-08-25 08:40:47,818 INFO [train.py:450] Epoch 3, batch 6490, batch avg loss 0.4123, total avg loss: 0.3493, batch size: 41
2021-08-25 08:40:49,517 WARNING [cut.py:1694] To perform mix, energy must be non-zero and non-negative (got 0.0).  MonoCut with id "a01ea57f-4eea-b5f3-21bb-9f49f0392025" will not be mixed in.
2021-08-25 08:40:53,751 INFO [train.py:450] Epoch 3, batch 6500, batch avg loss 0.3347, total avg loss: 0.3497, batch size: 41
2021-08-25 08:40:59,654 INFO [train.py:450] Epoch 3, batch 6510, batch avg loss 0.3350, total avg loss: 0.3496, batch size: 40
2021-08-25 08:41:05,484 INFO [train.py:450] Epoch 3, batch 6520, batch avg loss 0.3569, total avg loss: 0.3492, batch size: 39
2021-08-25 08:41:11,486 INFO [train.py:450] Epoch 3, batch 6530, batch avg loss 0.3269, total avg loss: 0.3485, batch size: 36
2021-08-25 08:41:17,328 INFO [train.py:450] Epoch 3, batch 6540, batch avg loss 0.3678, total avg loss: 0.3486, batch size: 45
2021-08-25 08:41:23,266 INFO [train.py:450] Epoch 3, batch 6550, batch avg loss 0.3529, total avg loss: 0.3492, batch size: 41
2021-08-25 08:41:29,102 INFO [train.py:450] Epoch 3, batch 6560, batch avg loss 0.2965, total avg loss: 0.3480, batch size: 37
2021-08-25 08:41:34,908 INFO [train.py:450] Epoch 3, batch 6570, batch avg loss 0.4385, total avg loss: 0.3488, batch size: 44
2021-08-25 08:41:40,771 INFO [train.py:450] Epoch 3, batch 6580, batch avg loss 0.3667, total avg loss: 0.3497, batch size: 39
2021-08-25 08:41:46,676 INFO [train.py:450] Epoch 3, batch 6590, batch avg loss 0.2972, total avg loss: 0.3491, batch size: 37
2021-08-25 08:41:52,561 INFO [train.py:450] Epoch 3, batch 6600, batch avg loss 0.3158, total avg loss: 0.3489, batch size: 38
2021-08-25 08:41:58,375 INFO [train.py:450] Epoch 3, batch 6610, batch avg loss 0.3624, total avg loss: 0.3666, batch size: 39
2021-08-25 08:42:04,200 INFO [train.py:450] Epoch 3, batch 6620, batch avg loss 0.3451, total avg loss: 0.3599, batch size: 42
2021-08-25 08:42:10,083 INFO [train.py:450] Epoch 3, batch 6630, batch avg loss 0.3399, total avg loss: 0.3586, batch size: 42
2021-08-25 08:42:15,910 INFO [train.py:450] Epoch 3, batch 6640, batch avg loss 0.3242, total avg loss: 0.3569, batch size: 44
2021-08-25 08:42:21,715 INFO [train.py:450] Epoch 3, batch 6650, batch avg loss 0.3221, total avg loss: 0.3540, batch size: 41
2021-08-25 08:42:27,607 INFO [train.py:450] Epoch 3, batch 6660, batch avg loss 0.3519, total avg loss: 0.3569, batch size: 41
2021-08-25 08:42:33,460 INFO [train.py:450] Epoch 3, batch 6670, batch avg loss 0.3567, total avg loss: 0.3551, batch size: 39
2021-08-25 08:42:39,255 INFO [train.py:450] Epoch 3, batch 6680, batch avg loss 0.4074, total avg loss: 0.3537, batch size: 39
2021-08-25 08:42:45,050 INFO [train.py:450] Epoch 3, batch 6690, batch avg loss 0.3011, total avg loss: 0.3519, batch size: 42
2021-08-25 08:42:50,914 INFO [train.py:450] Epoch 3, batch 6700, batch avg loss 0.3432, total avg loss: 0.3509, batch size: 42
2021-08-25 08:42:56,790 INFO [train.py:450] Epoch 3, batch 6710, batch avg loss 0.3799, total avg loss: 0.3512, batch size: 37
2021-08-25 08:43:02,716 INFO [train.py:450] Epoch 3, batch 6720, batch avg loss 0.3183, total avg loss: 0.3498, batch size: 41
2021-08-25 08:43:08,536 INFO [train.py:450] Epoch 3, batch 6730, batch avg loss 0.3180, total avg loss: 0.3502, batch size: 38
2021-08-25 08:43:14,522 INFO [train.py:450] Epoch 3, batch 6740, batch avg loss 0.4008, total avg loss: 0.3494, batch size: 42
2021-08-25 08:43:20,771 INFO [train.py:450] Epoch 3, batch 6750, batch avg loss 0.3500, total avg loss: 0.3506, batch size: 39
2021-08-25 08:43:26,699 INFO [train.py:450] Epoch 3, batch 6760, batch avg loss 0.3400, total avg loss: 0.3515, batch size: 41
2021-08-25 08:43:33,282 INFO [train.py:450] Epoch 3, batch 6770, batch avg loss 0.4049, total avg loss: 0.3521, batch size: 41
2021-08-25 08:43:40,003 INFO [train.py:450] Epoch 3, batch 6780, batch avg loss 0.3315, total avg loss: 0.3520, batch size: 37
2021-08-25 08:43:45,756 INFO [train.py:450] Epoch 3, batch 6790, batch avg loss 0.3235, total avg loss: 0.3518, batch size: 40
2021-08-25 08:43:51,572 INFO [train.py:450] Epoch 3, batch 6800, batch avg loss 0.3679, total avg loss: 0.3529, batch size: 37
2021-08-25 08:43:57,371 INFO [train.py:450] Epoch 3, batch 6810, batch avg loss 0.3761, total avg loss: 0.3440, batch size: 42
2021-08-25 08:44:03,294 INFO [train.py:450] Epoch 3, batch 6820, batch avg loss 0.3637, total avg loss: 0.3492, batch size: 40
2021-08-25 08:44:09,203 INFO [train.py:450] Epoch 3, batch 6830, batch avg loss 0.4309, total avg loss: 0.3500, batch size: 43
2021-08-25 08:44:15,994 INFO [train.py:450] Epoch 3, batch 6840, batch avg loss 0.4155, total avg loss: 0.3508, batch size: 38
2021-08-25 08:44:23,192 INFO [train.py:450] Epoch 3, batch 6850, batch avg loss 0.3594, total avg loss: 0.3484, batch size: 44
2021-08-25 08:44:29,968 INFO [train.py:450] Epoch 3, batch 6860, batch avg loss 0.3851, total avg loss: 0.3503, batch size: 42
2021-08-25 08:44:36,499 INFO [train.py:450] Epoch 3, batch 6870, batch avg loss 0.3194, total avg loss: 0.3487, batch size: 38
2021-08-25 08:44:42,984 INFO [train.py:450] Epoch 3, batch 6880, batch avg loss 0.3802, total avg loss: 0.3464, batch size: 38
2021-08-25 08:44:50,032 INFO [train.py:450] Epoch 3, batch 6890, batch avg loss 0.3515, total avg loss: 0.3447, batch size: 44
2021-08-25 08:44:57,086 INFO [train.py:450] Epoch 3, batch 6900, batch avg loss 0.3510, total avg loss: 0.3451, batch size: 39
2021-08-25 08:45:04,344 INFO [train.py:450] Epoch 3, batch 6910, batch avg loss 0.3353, total avg loss: 0.3463, batch size: 41
2021-08-25 08:45:11,529 INFO [train.py:450] Epoch 3, batch 6920, batch avg loss 0.3509, total avg loss: 0.3465, batch size: 41
2021-08-25 08:45:17,920 INFO [train.py:450] Epoch 3, batch 6930, batch avg loss 0.3088, total avg loss: 0.3449, batch size: 40
2021-08-25 08:45:25,054 INFO [train.py:450] Epoch 3, batch 6940, batch avg loss 0.3451, total avg loss: 0.3447, batch size: 38
2021-08-25 08:45:32,059 INFO [train.py:450] Epoch 3, batch 6950, batch avg loss 0.3508, total avg loss: 0.3447, batch size: 39
2021-08-25 08:45:38,139 INFO [train.py:450] Epoch 3, batch 6960, batch avg loss 0.3753, total avg loss: 0.3433, batch size: 38
2021-08-25 08:45:44,555 INFO [train.py:450] Epoch 3, batch 6970, batch avg loss 0.4407, total avg loss: 0.3441, batch size: 41
2021-08-25 08:45:51,327 INFO [train.py:450] Epoch 3, batch 6980, batch avg loss 0.3641, total avg loss: 0.3450, batch size: 40
2021-08-25 08:45:57,823 INFO [train.py:450] Epoch 3, batch 6990, batch avg loss 0.3634, total avg loss: 0.3450, batch size: 40
2021-08-25 08:46:04,498 INFO [train.py:450] Epoch 3, batch 7000, batch avg loss 0.3434, total avg loss: 0.3452, batch size: 36
2021-08-25 08:46:42,482 INFO [train.py:482] Epoch 3, valid loss 0.2491, best valid loss: 0.2434 best valid epoch: 2
2021-08-25 08:46:48,314 INFO [train.py:450] Epoch 3, batch 7010, batch avg loss 0.3150, total avg loss: 0.3448, batch size: 42
2021-08-25 08:46:54,367 INFO [train.py:450] Epoch 3, batch 7020, batch avg loss 0.3552, total avg loss: 0.3470, batch size: 42
2021-08-25 08:47:01,687 INFO [train.py:450] Epoch 3, batch 7030, batch avg loss 0.3371, total avg loss: 0.3484, batch size: 42
2021-08-25 08:47:08,186 INFO [train.py:450] Epoch 3, batch 7040, batch avg loss 0.3263, total avg loss: 0.3493, batch size: 41
2021-08-25 08:47:14,386 INFO [train.py:450] Epoch 3, batch 7050, batch avg loss 0.3122, total avg loss: 0.3471, batch size: 39
2021-08-25 08:47:20,703 INFO [train.py:450] Epoch 3, batch 7060, batch avg loss 0.3786, total avg loss: 0.3489, batch size: 42
2021-08-25 08:47:26,388 INFO [train.py:450] Epoch 3, batch 7070, batch avg loss 0.3533, total avg loss: 0.3510, batch size: 39
2021-08-25 08:47:32,380 INFO [train.py:450] Epoch 3, batch 7080, batch avg loss 0.3629, total avg loss: 0.3495, batch size: 41
2021-08-25 08:47:38,394 INFO [train.py:450] Epoch 3, batch 7090, batch avg loss 0.3516, total avg loss: 0.3486, batch size: 38
2021-08-25 08:47:44,686 INFO [train.py:450] Epoch 3, batch 7100, batch avg loss 0.3306, total avg loss: 0.3487, batch size: 39
2021-08-25 08:47:51,328 INFO [train.py:450] Epoch 3, batch 7110, batch avg loss 0.3207, total avg loss: 0.3470, batch size: 40
2021-08-25 08:47:57,417 INFO [train.py:450] Epoch 3, batch 7120, batch avg loss 0.3095, total avg loss: 0.3461, batch size: 37
2021-08-25 08:48:04,540 INFO [train.py:450] Epoch 3, batch 7130, batch avg loss 0.3450, total avg loss: 0.3454, batch size: 37
2021-08-25 08:48:10,894 INFO [train.py:450] Epoch 3, batch 7140, batch avg loss 0.3501, total avg loss: 0.3448, batch size: 40
2021-08-25 08:48:17,192 INFO [train.py:450] Epoch 3, batch 7150, batch avg loss 0.3706, total avg loss: 0.3444, batch size: 44
2021-08-25 08:48:23,367 INFO [train.py:450] Epoch 3, batch 7160, batch avg loss 0.3578, total avg loss: 0.3443, batch size: 43
2021-08-25 08:48:29,846 INFO [train.py:450] Epoch 3, batch 7170, batch avg loss 0.3458, total avg loss: 0.3448, batch size: 40
2021-08-25 08:48:36,323 INFO [train.py:450] Epoch 3, batch 7180, batch avg loss 0.2819, total avg loss: 0.3448, batch size: 36
2021-08-25 08:48:42,605 INFO [train.py:450] Epoch 3, batch 7190, batch avg loss 0.2961, total avg loss: 0.3447, batch size: 43
2021-08-25 08:48:48,826 INFO [train.py:450] Epoch 3, batch 7200, batch avg loss 0.3217, total avg loss: 0.3447, batch size: 44
2021-08-25 08:48:55,645 INFO [train.py:450] Epoch 3, batch 7210, batch avg loss 0.3415, total avg loss: 0.3633, batch size: 38
2021-08-25 08:49:01,816 INFO [train.py:450] Epoch 3, batch 7220, batch avg loss 0.3376, total avg loss: 0.3615, batch size: 39
2021-08-25 08:49:08,812 INFO [train.py:450] Epoch 3, batch 7230, batch avg loss 0.3526, total avg loss: 0.3636, batch size: 39
2021-08-25 08:49:15,167 INFO [train.py:450] Epoch 3, batch 7240, batch avg loss 0.3423, total avg loss: 0.3595, batch size: 38
2021-08-25 08:49:21,323 INFO [train.py:450] Epoch 3, batch 7250, batch avg loss 0.3125, total avg loss: 0.3565, batch size: 39
2021-08-25 08:49:27,750 INFO [train.py:450] Epoch 3, batch 7260, batch avg loss 0.3394, total avg loss: 0.3547, batch size: 41
2021-08-25 08:49:29,678 WARNING [cut.py:1694] To perform mix, energy must be non-zero and non-negative (got 0.0).  MonoCut with id "8f992b60-799c-910c-6deb-a0e3368df957" will not be mixed in.
2021-08-25 08:49:34,209 INFO [train.py:450] Epoch 3, batch 7270, batch avg loss 0.3673, total avg loss: 0.3562, batch size: 38
2021-08-25 08:49:40,995 INFO [train.py:450] Epoch 3, batch 7280, batch avg loss 0.3406, total avg loss: 0.3537, batch size: 39
2021-08-25 08:49:47,969 INFO [train.py:450] Epoch 3, batch 7290, batch avg loss 0.3424, total avg loss: 0.3526, batch size: 43
2021-08-25 08:49:55,498 INFO [train.py:450] Epoch 3, batch 7300, batch avg loss 0.3094, total avg loss: 0.3506, batch size: 42
2021-08-25 08:50:02,058 INFO [train.py:450] Epoch 3, batch 7310, batch avg loss 0.3014, total avg loss: 0.3497, batch size: 39
2021-08-25 08:50:08,447 INFO [train.py:450] Epoch 3, batch 7320, batch avg loss 0.3756, total avg loss: 0.3513, batch size: 39
2021-08-25 08:50:16,125 INFO [train.py:450] Epoch 3, batch 7330, batch avg loss 0.3327, total avg loss: 0.3523, batch size: 36
2021-08-25 08:50:24,031 INFO [train.py:450] Epoch 3, batch 7340, batch avg loss 0.3959, total avg loss: 0.3523, batch size: 39
2021-08-25 08:50:30,801 INFO [train.py:450] Epoch 3, batch 7350, batch avg loss 0.3327, total avg loss: 0.3521, batch size: 41
2021-08-25 08:50:37,719 INFO [train.py:450] Epoch 3, batch 7360, batch avg loss 0.4006, total avg loss: 0.3513, batch size: 40
2021-08-25 08:50:43,967 INFO [train.py:450] Epoch 3, batch 7370, batch avg loss 0.3647, total avg loss: 0.3507, batch size: 40
2021-08-25 08:50:50,203 INFO [train.py:450] Epoch 3, batch 7380, batch avg loss 0.3202, total avg loss: 0.3504, batch size: 40
2021-08-25 08:50:56,128 INFO [train.py:450] Epoch 3, batch 7390, batch avg loss 0.3176, total avg loss: 0.3503, batch size: 37
2021-08-25 08:51:02,436 INFO [train.py:450] Epoch 3, batch 7400, batch avg loss 0.3648, total avg loss: 0.3503, batch size: 39
2021-08-25 08:51:09,495 INFO [train.py:450] Epoch 3, batch 7410, batch avg loss 0.3100, total avg loss: 0.3250, batch size: 41
2021-08-25 08:51:16,582 INFO [train.py:450] Epoch 3, batch 7420, batch avg loss 0.3347, total avg loss: 0.3258, batch size: 40
2021-08-25 08:51:23,416 INFO [train.py:450] Epoch 3, batch 7430, batch avg loss 0.3824, total avg loss: 0.3355, batch size: 39
2021-08-25 08:51:30,276 INFO [train.py:450] Epoch 3, batch 7440, batch avg loss 0.3247, total avg loss: 0.3389, batch size: 41
2021-08-25 08:51:37,290 INFO [train.py:450] Epoch 3, batch 7450, batch avg loss 0.3770, total avg loss: 0.3415, batch size: 37
2021-08-25 08:51:44,178 INFO [train.py:450] Epoch 3, batch 7460, batch avg loss 0.3243, total avg loss: 0.3444, batch size: 36
2021-08-25 08:51:50,686 INFO [train.py:450] Epoch 3, batch 7470, batch avg loss 0.3793, total avg loss: 0.3461, batch size: 42
2021-08-25 08:51:56,987 INFO [train.py:450] Epoch 3, batch 7480, batch avg loss 0.3750, total avg loss: 0.3476, batch size: 38
2021-08-25 08:52:03,395 INFO [train.py:450] Epoch 3, batch 7490, batch avg loss 0.3321, total avg loss: 0.3474, batch size: 39
2021-08-25 08:52:09,633 INFO [train.py:450] Epoch 3, batch 7500, batch avg loss 0.3467, total avg loss: 0.3479, batch size: 41
2021-08-25 08:52:16,058 INFO [train.py:450] Epoch 3, batch 7510, batch avg loss 0.3540, total avg loss: 0.3478, batch size: 39
2021-08-25 08:52:22,826 INFO [train.py:450] Epoch 3, batch 7520, batch avg loss 0.3513, total avg loss: 0.3481, batch size: 40
2021-08-25 08:52:29,884 INFO [train.py:450] Epoch 3, batch 7530, batch avg loss 0.3270, total avg loss: 0.3479, batch size: 38
2021-08-25 08:52:36,672 INFO [train.py:450] Epoch 3, batch 7540, batch avg loss 0.3461, total avg loss: 0.3473, batch size: 42
2021-08-25 08:52:43,124 INFO [train.py:450] Epoch 3, batch 7550, batch avg loss 0.3632, total avg loss: 0.3487, batch size: 39
2021-08-25 08:52:49,473 INFO [train.py:450] Epoch 3, batch 7560, batch avg loss 0.2750, total avg loss: 0.3492, batch size: 36
2021-08-25 08:52:55,279 INFO [train.py:450] Epoch 3, batch 7570, batch avg loss 0.3799, total avg loss: 0.3499, batch size: 42
2021-08-25 08:53:02,149 INFO [train.py:450] Epoch 3, batch 7580, batch avg loss 0.3499, total avg loss: 0.3497, batch size: 39
2021-08-25 08:53:08,257 INFO [train.py:450] Epoch 3, batch 7590, batch avg loss 0.3320, total avg loss: 0.3502, batch size: 37
2021-08-25 08:53:14,864 INFO [train.py:450] Epoch 3, batch 7600, batch avg loss 0.3267, total avg loss: 0.3501, batch size: 40
2021-08-25 08:53:22,228 INFO [train.py:450] Epoch 3, batch 7610, batch avg loss 0.3882, total avg loss: 0.3587, batch size: 43
2021-08-25 08:53:28,182 INFO [train.py:450] Epoch 3, batch 7620, batch avg loss 0.3022, total avg loss: 0.3539, batch size: 41
2021-08-25 08:53:34,198 INFO [train.py:450] Epoch 3, batch 7630, batch avg loss 0.3753, total avg loss: 0.3527, batch size: 43
2021-08-25 08:53:40,202 INFO [train.py:450] Epoch 3, batch 7640, batch avg loss 0.3829, total avg loss: 0.3503, batch size: 42
2021-08-25 08:53:46,199 INFO [train.py:450] Epoch 3, batch 7650, batch avg loss 0.3360, total avg loss: 0.3479, batch size: 43
2021-08-25 08:53:52,024 INFO [train.py:450] Epoch 3, batch 7660, batch avg loss 0.3557, total avg loss: 0.3478, batch size: 40
2021-08-25 08:53:58,305 INFO [train.py:450] Epoch 3, batch 7670, batch avg loss 0.3211, total avg loss: 0.3480, batch size: 38
2021-08-25 08:54:05,002 INFO [train.py:450] Epoch 3, batch 7680, batch avg loss 0.3736, total avg loss: 0.3492, batch size: 39
2021-08-25 08:54:10,925 INFO [train.py:450] Epoch 3, batch 7690, batch avg loss 0.3387, total avg loss: 0.3493, batch size: 42
2021-08-25 08:54:16,692 INFO [train.py:450] Epoch 3, batch 7700, batch avg loss 0.3206, total avg loss: 0.3472, batch size: 38
2021-08-25 08:54:22,638 INFO [train.py:450] Epoch 3, batch 7710, batch avg loss 0.3130, total avg loss: 0.3460, batch size: 37
2021-08-25 08:54:28,559 INFO [train.py:450] Epoch 3, batch 7720, batch avg loss 0.3557, total avg loss: 0.3455, batch size: 40
2021-08-25 08:54:34,507 INFO [train.py:450] Epoch 3, batch 7730, batch avg loss 0.3251, total avg loss: 0.3453, batch size: 39
2021-08-25 08:54:40,442 INFO [train.py:450] Epoch 3, batch 7740, batch avg loss 0.3554, total avg loss: 0.3455, batch size: 40
2021-08-25 08:54:46,386 INFO [train.py:450] Epoch 3, batch 7750, batch avg loss 0.3398, total avg loss: 0.3459, batch size: 41
2021-08-25 08:54:52,298 INFO [train.py:450] Epoch 3, batch 7760, batch avg loss 0.2962, total avg loss: 0.3456, batch size: 37
2021-08-25 08:54:58,426 INFO [train.py:450] Epoch 3, batch 7770, batch avg loss 0.4444, total avg loss: 0.3472, batch size: 40
2021-08-25 08:55:04,389 INFO [train.py:450] Epoch 3, batch 7780, batch avg loss 0.2694, total avg loss: 0.3460, batch size: 36
2021-08-25 08:55:10,247 INFO [train.py:450] Epoch 3, batch 7790, batch avg loss 0.3625, total avg loss: 0.3463, batch size: 37
2021-08-25 08:55:16,065 INFO [train.py:450] Epoch 3, batch 7800, batch avg loss 0.3472, total avg loss: 0.3462, batch size: 41
2021-08-25 08:55:22,048 INFO [train.py:450] Epoch 3, batch 7810, batch avg loss 0.3670, total avg loss: 0.3548, batch size: 39
2021-08-25 08:55:27,899 INFO [train.py:450] Epoch 3, batch 7820, batch avg loss 0.3443, total avg loss: 0.3422, batch size: 41
2021-08-25 08:55:33,764 INFO [train.py:450] Epoch 3, batch 7830, batch avg loss 0.2757, total avg loss: 0.3390, batch size: 43
2021-08-25 08:55:39,612 INFO [train.py:450] Epoch 3, batch 7840, batch avg loss 0.3735, total avg loss: 0.3397, batch size: 40
2021-08-25 08:55:45,617 INFO [train.py:450] Epoch 3, batch 7850, batch avg loss 0.3547, total avg loss: 0.3427, batch size: 43
2021-08-25 08:55:51,650 INFO [train.py:450] Epoch 3, batch 7860, batch avg loss 0.3568, total avg loss: 0.3444, batch size: 39
2021-08-25 08:55:57,681 INFO [train.py:450] Epoch 3, batch 7870, batch avg loss 0.3205, total avg loss: 0.3436, batch size: 38
2021-08-25 08:56:03,679 INFO [train.py:450] Epoch 3, batch 7880, batch avg loss 0.3166, total avg loss: 0.3441, batch size: 39
2021-08-25 08:56:09,557 INFO [train.py:450] Epoch 3, batch 7890, batch avg loss 0.3316, total avg loss: 0.3445, batch size: 42
2021-08-25 08:56:15,559 INFO [train.py:450] Epoch 3, batch 7900, batch avg loss 0.3213, total avg loss: 0.3450, batch size: 41
2021-08-25 08:56:21,459 INFO [train.py:450] Epoch 3, batch 7910, batch avg loss 0.3136, total avg loss: 0.3467, batch size: 38
2021-08-25 08:56:27,220 INFO [train.py:450] Epoch 3, batch 7920, batch avg loss 0.4054, total avg loss: 0.3478, batch size: 40
2021-08-25 08:56:33,025 INFO [train.py:450] Epoch 3, batch 7930, batch avg loss 0.3454, total avg loss: 0.3482, batch size: 38
2021-08-25 08:56:38,784 INFO [train.py:450] Epoch 3, batch 7940, batch avg loss 0.3927, total avg loss: 0.3509, batch size: 39
2021-08-25 08:56:44,609 INFO [train.py:450] Epoch 3, batch 7950, batch avg loss 0.4362, total avg loss: 0.3510, batch size: 39
2021-08-25 08:56:50,504 INFO [train.py:450] Epoch 3, batch 7960, batch avg loss 0.3436, total avg loss: 0.3514, batch size: 42
2021-08-25 08:56:56,738 INFO [train.py:450] Epoch 3, batch 7970, batch avg loss 0.3367, total avg loss: 0.3511, batch size: 43
2021-08-25 08:57:02,742 INFO [train.py:450] Epoch 3, batch 7980, batch avg loss 0.3364, total avg loss: 0.3519, batch size: 38
2021-08-25 08:57:08,572 INFO [train.py:450] Epoch 3, batch 7990, batch avg loss 0.3508, total avg loss: 0.3516, batch size: 38
2021-08-25 08:57:15,466 INFO [train.py:450] Epoch 3, batch 8000, batch avg loss 0.3655, total avg loss: 0.3509, batch size: 40
2021-08-25 08:57:54,950 INFO [train.py:482] Epoch 3, valid loss 0.2469, best valid loss: 0.2434 best valid epoch: 2
2021-08-25 08:58:00,805 INFO [train.py:450] Epoch 3, batch 8010, batch avg loss 0.3172, total avg loss: 0.3491, batch size: 39
2021-08-25 08:58:06,656 INFO [train.py:450] Epoch 3, batch 8020, batch avg loss 0.2740, total avg loss: 0.3347, batch size: 40
2021-08-25 08:58:12,556 INFO [train.py:450] Epoch 3, batch 8030, batch avg loss 0.3479, total avg loss: 0.3407, batch size: 38
2021-08-25 08:58:18,418 INFO [train.py:450] Epoch 3, batch 8040, batch avg loss 0.4044, total avg loss: 0.3408, batch size: 44
2021-08-25 08:58:24,286 INFO [train.py:450] Epoch 3, batch 8050, batch avg loss 0.3499, total avg loss: 0.3407, batch size: 39
2021-08-25 08:58:30,127 INFO [train.py:450] Epoch 3, batch 8060, batch avg loss 0.3495, total avg loss: 0.3404, batch size: 45
2021-08-25 08:58:35,963 INFO [train.py:450] Epoch 3, batch 8070, batch avg loss 0.3253, total avg loss: 0.3417, batch size: 41
2021-08-25 08:58:41,844 INFO [train.py:450] Epoch 3, batch 8080, batch avg loss 0.4120, total avg loss: 0.3434, batch size: 41
2021-08-25 08:58:47,824 INFO [train.py:450] Epoch 3, batch 8090, batch avg loss 0.3740, total avg loss: 0.3437, batch size: 40
2021-08-25 08:58:53,681 INFO [train.py:450] Epoch 3, batch 8100, batch avg loss 0.3738, total avg loss: 0.3437, batch size: 40
2021-08-25 08:58:59,548 INFO [train.py:450] Epoch 3, batch 8110, batch avg loss 0.3615, total avg loss: 0.3435, batch size: 43
2021-08-25 08:59:05,502 INFO [train.py:450] Epoch 3, batch 8120, batch avg loss 0.3769, total avg loss: 0.3422, batch size: 45
2021-08-25 08:59:11,349 INFO [train.py:450] Epoch 3, batch 8130, batch avg loss 0.3334, total avg loss: 0.3415, batch size: 42
2021-08-25 08:59:17,176 INFO [train.py:450] Epoch 3, batch 8140, batch avg loss 0.3566, total avg loss: 0.3426, batch size: 36
2021-08-25 08:59:22,938 INFO [train.py:450] Epoch 3, batch 8150, batch avg loss 0.3417, total avg loss: 0.3424, batch size: 39
2021-08-25 08:59:28,813 INFO [train.py:450] Epoch 3, batch 8160, batch avg loss 0.3814, total avg loss: 0.3431, batch size: 41
2021-08-25 08:59:34,630 INFO [train.py:450] Epoch 3, batch 8170, batch avg loss 0.3222, total avg loss: 0.3435, batch size: 40
2021-08-25 08:59:40,563 INFO [train.py:450] Epoch 3, batch 8180, batch avg loss 0.3242, total avg loss: 0.3444, batch size: 37
2021-08-25 08:59:46,306 INFO [train.py:450] Epoch 3, batch 8190, batch avg loss 0.2949, total avg loss: 0.3446, batch size: 36
2021-08-25 08:59:52,068 INFO [train.py:450] Epoch 3, batch 8200, batch avg loss 0.3423, total avg loss: 0.3447, batch size: 39
2021-08-25 08:59:57,771 INFO [train.py:450] Epoch 3, batch 8210, batch avg loss 0.3434, total avg loss: 0.3480, batch size: 37
2021-08-25 09:00:03,565 INFO [train.py:450] Epoch 3, batch 8220, batch avg loss 0.3356, total avg loss: 0.3514, batch size: 41
2021-08-25 09:00:09,311 INFO [train.py:450] Epoch 3, batch 8230, batch avg loss 0.3658, total avg loss: 0.3502, batch size: 37
2021-08-25 09:00:15,195 INFO [train.py:450] Epoch 3, batch 8240, batch avg loss 0.3519, total avg loss: 0.3474, batch size: 38
2021-08-25 09:00:21,052 INFO [train.py:450] Epoch 3, batch 8250, batch avg loss 0.4563, total avg loss: 0.3494, batch size: 40
2021-08-25 09:00:27,211 INFO [train.py:450] Epoch 3, batch 8260, batch avg loss 0.3733, total avg loss: 0.3510, batch size: 40
2021-08-25 09:00:33,093 INFO [train.py:450] Epoch 3, batch 8270, batch avg loss 0.4029, total avg loss: 0.3500, batch size: 43
2021-08-25 09:00:39,104 INFO [train.py:450] Epoch 3, batch 8280, batch avg loss 0.3008, total avg loss: 0.3508, batch size: 38
2021-08-25 09:00:46,959 INFO [train.py:450] Epoch 3, batch 8290, batch avg loss 0.3581, total avg loss: 0.3514, batch size: 43
2021-08-25 09:00:52,747 INFO [train.py:450] Epoch 3, batch 8300, batch avg loss 0.3520, total avg loss: 0.3505, batch size: 39
2021-08-25 09:00:58,661 INFO [train.py:450] Epoch 3, batch 8310, batch avg loss 0.3144, total avg loss: 0.3496, batch size: 42
2021-08-25 09:01:04,514 INFO [train.py:450] Epoch 3, batch 8320, batch avg loss 0.3101, total avg loss: 0.3500, batch size: 39
2021-08-25 09:01:10,411 INFO [train.py:450] Epoch 3, batch 8330, batch avg loss 0.3358, total avg loss: 0.3496, batch size: 38
2021-08-25 09:01:16,161 INFO [train.py:450] Epoch 3, batch 8340, batch avg loss 0.3442, total avg loss: 0.3505, batch size: 36
2021-08-25 09:01:22,018 INFO [train.py:450] Epoch 3, batch 8350, batch avg loss 0.3565, total avg loss: 0.3507, batch size: 38
2021-08-25 09:01:27,794 INFO [train.py:450] Epoch 3, batch 8360, batch avg loss 0.3279, total avg loss: 0.3509, batch size: 45
2021-08-25 09:01:33,734 INFO [train.py:450] Epoch 3, batch 8370, batch avg loss 0.3191, total avg loss: 0.3511, batch size: 39
2021-08-25 09:01:39,561 INFO [train.py:450] Epoch 3, batch 8380, batch avg loss 0.4138, total avg loss: 0.3512, batch size: 38
2021-08-25 09:01:45,494 INFO [train.py:450] Epoch 3, batch 8390, batch avg loss 0.3459, total avg loss: 0.3519, batch size: 37
2021-08-25 09:01:51,134 INFO [train.py:450] Epoch 3, batch 8400, batch avg loss 0.3563, total avg loss: 0.3519, batch size: 40
2021-08-25 09:01:54,148 WARNING [cut.py:1694] To perform mix, energy must be non-zero and non-negative (got 0.0).  MonoCut with id "d4a4470c-eb50-77e1-bcf7-dd1b621048a5" will not be mixed in.
2021-08-25 09:01:57,059 INFO [train.py:450] Epoch 3, batch 8410, batch avg loss 0.3273, total avg loss: 0.3534, batch size: 41
2021-08-25 09:02:02,818 INFO [train.py:450] Epoch 3, batch 8420, batch avg loss 0.3673, total avg loss: 0.3557, batch size: 40
2021-08-25 09:02:08,704 INFO [train.py:450] Epoch 3, batch 8430, batch avg loss 0.2659, total avg loss: 0.3486, batch size: 42
2021-08-25 09:02:14,677 INFO [train.py:450] Epoch 3, batch 8440, batch avg loss 0.3290, total avg loss: 0.3480, batch size: 38
2021-08-25 09:02:20,441 INFO [train.py:450] Epoch 3, batch 8450, batch avg loss 0.3292, total avg loss: 0.3473, batch size: 40
2021-08-25 09:02:26,219 INFO [train.py:450] Epoch 3, batch 8460, batch avg loss 0.3170, total avg loss: 0.3419, batch size: 42
2021-08-25 09:02:31,980 INFO [train.py:450] Epoch 3, batch 8470, batch avg loss 0.3455, total avg loss: 0.3432, batch size: 38
2021-08-25 09:02:37,815 INFO [train.py:450] Epoch 3, batch 8480, batch avg loss 0.4106, total avg loss: 0.3460, batch size: 38
2021-08-25 09:02:43,713 INFO [train.py:450] Epoch 3, batch 8490, batch avg loss 0.3200, total avg loss: 0.3449, batch size: 43
2021-08-25 09:02:49,658 INFO [train.py:450] Epoch 3, batch 8500, batch avg loss 0.3541, total avg loss: 0.3443, batch size: 39
2021-08-25 09:02:55,606 INFO [train.py:450] Epoch 3, batch 8510, batch avg loss 0.3425, total avg loss: 0.3457, batch size: 43
2021-08-25 09:03:01,542 INFO [train.py:450] Epoch 3, batch 8520, batch avg loss 0.4367, total avg loss: 0.3468, batch size: 37
2021-08-25 09:03:07,467 INFO [train.py:450] Epoch 3, batch 8530, batch avg loss 0.3489, total avg loss: 0.3462, batch size: 40
2021-08-25 09:03:13,386 INFO [train.py:450] Epoch 3, batch 8540, batch avg loss 0.3296, total avg loss: 0.3472, batch size: 42
2021-08-25 09:03:19,247 INFO [train.py:450] Epoch 3, batch 8550, batch avg loss 0.3484, total avg loss: 0.3471, batch size: 37
2021-08-25 09:03:24,999 INFO [train.py:450] Epoch 3, batch 8560, batch avg loss 0.3446, total avg loss: 0.3479, batch size: 38
2021-08-25 09:03:30,758 INFO [train.py:450] Epoch 3, batch 8570, batch avg loss 0.4243, total avg loss: 0.3488, batch size: 41
2021-08-25 09:03:36,539 INFO [train.py:450] Epoch 3, batch 8580, batch avg loss 0.3905, total avg loss: 0.3497, batch size: 41
2021-08-25 09:03:42,377 INFO [train.py:450] Epoch 3, batch 8590, batch avg loss 0.3326, total avg loss: 0.3491, batch size: 38
2021-08-25 09:03:48,375 INFO [train.py:450] Epoch 3, batch 8600, batch avg loss 0.3592, total avg loss: 0.3485, batch size: 39
2021-08-25 09:03:54,248 INFO [train.py:450] Epoch 3, batch 8610, batch avg loss 0.3658, total avg loss: 0.3693, batch size: 41
2021-08-25 09:04:00,095 INFO [train.py:450] Epoch 3, batch 8620, batch avg loss 0.3232, total avg loss: 0.3526, batch size: 38
2021-08-25 09:04:06,801 INFO [train.py:450] Epoch 3, batch 8630, batch avg loss 0.3689, total avg loss: 0.3470, batch size: 38
2021-08-25 09:04:12,649 INFO [train.py:450] Epoch 3, batch 8640, batch avg loss 0.3857, total avg loss: 0.3480, batch size: 46
2021-08-25 09:04:18,656 INFO [train.py:450] Epoch 3, batch 8650, batch avg loss 0.3777, total avg loss: 0.3465, batch size: 48
2021-08-25 09:04:24,541 INFO [train.py:450] Epoch 3, batch 8660, batch avg loss 0.3091, total avg loss: 0.3438, batch size: 40
2021-08-25 09:04:30,419 INFO [train.py:450] Epoch 3, batch 8670, batch avg loss 0.3229, total avg loss: 0.3429, batch size: 40
2021-08-25 09:04:36,252 INFO [train.py:450] Epoch 3, batch 8680, batch avg loss 0.3522, total avg loss: 0.3427, batch size: 45
2021-08-25 09:04:42,152 INFO [train.py:450] Epoch 3, batch 8690, batch avg loss 0.3186, total avg loss: 0.3424, batch size: 40
2021-08-25 09:04:48,027 INFO [train.py:450] Epoch 3, batch 8700, batch avg loss 0.3898, total avg loss: 0.3439, batch size: 38
2021-08-25 09:04:53,917 INFO [train.py:450] Epoch 3, batch 8710, batch avg loss 0.3288, total avg loss: 0.3443, batch size: 40
2021-08-25 09:04:59,939 INFO [train.py:450] Epoch 3, batch 8720, batch avg loss 0.3414, total avg loss: 0.3456, batch size: 39
2021-08-25 09:05:05,773 INFO [train.py:450] Epoch 3, batch 8730, batch avg loss 0.3647, total avg loss: 0.3461, batch size: 39
2021-08-25 09:05:11,620 INFO [train.py:450] Epoch 3, batch 8740, batch avg loss 0.3578, total avg loss: 0.3459, batch size: 41
2021-08-25 09:05:17,507 INFO [train.py:450] Epoch 3, batch 8750, batch avg loss 0.3098, total avg loss: 0.3462, batch size: 37
2021-08-25 09:05:23,380 INFO [train.py:450] Epoch 3, batch 8760, batch avg loss 0.3056, total avg loss: 0.3464, batch size: 38
2021-08-25 09:05:29,364 INFO [train.py:450] Epoch 3, batch 8770, batch avg loss 0.3843, total avg loss: 0.3472, batch size: 43
2021-08-25 09:05:35,154 INFO [train.py:450] Epoch 3, batch 8780, batch avg loss 0.3307, total avg loss: 0.3475, batch size: 40
2021-08-25 09:05:41,025 INFO [train.py:450] Epoch 3, batch 8790, batch avg loss 0.3382, total avg loss: 0.3475, batch size: 40
2021-08-25 09:05:46,906 INFO [train.py:450] Epoch 3, batch 8800, batch avg loss 0.3365, total avg loss: 0.3470, batch size: 43
2021-08-25 09:05:52,758 INFO [train.py:450] Epoch 3, batch 8810, batch avg loss 0.3448, total avg loss: 0.3443, batch size: 41
2021-08-25 09:05:58,576 INFO [train.py:450] Epoch 3, batch 8820, batch avg loss 0.3729, total avg loss: 0.3457, batch size: 41
2021-08-25 09:06:04,758 INFO [train.py:450] Epoch 3, batch 8830, batch avg loss 0.3753, total avg loss: 0.3498, batch size: 42
2021-08-25 09:06:10,577 INFO [train.py:450] Epoch 3, batch 8840, batch avg loss 0.3606, total avg loss: 0.3518, batch size: 38
2021-08-25 09:06:16,600 INFO [train.py:450] Epoch 3, batch 8850, batch avg loss 0.4421, total avg loss: 0.3525, batch size: 36
2021-08-25 09:06:22,473 INFO [train.py:450] Epoch 3, batch 8860, batch avg loss 0.4607, total avg loss: 0.3537, batch size: 41
2021-08-25 09:06:28,315 INFO [train.py:450] Epoch 3, batch 8870, batch avg loss 0.2944, total avg loss: 0.3506, batch size: 40
2021-08-25 09:06:34,180 INFO [train.py:450] Epoch 3, batch 8880, batch avg loss 0.3332, total avg loss: 0.3512, batch size: 37
2021-08-25 09:06:40,139 INFO [train.py:450] Epoch 3, batch 8890, batch avg loss 0.3463, total avg loss: 0.3516, batch size: 40
2021-08-25 09:06:45,999 INFO [train.py:450] Epoch 3, batch 8900, batch avg loss 0.3515, total avg loss: 0.3509, batch size: 40
2021-08-25 09:06:51,785 INFO [train.py:450] Epoch 3, batch 8910, batch avg loss 0.3505, total avg loss: 0.3507, batch size: 40
2021-08-25 09:06:57,632 INFO [train.py:450] Epoch 3, batch 8920, batch avg loss 0.3697, total avg loss: 0.3499, batch size: 42
2021-08-25 09:07:03,538 INFO [train.py:450] Epoch 3, batch 8930, batch avg loss 0.3254, total avg loss: 0.3488, batch size: 42
2021-08-25 09:07:09,420 INFO [train.py:450] Epoch 3, batch 8940, batch avg loss 0.3659, total avg loss: 0.3493, batch size: 40
2021-08-25 09:07:15,301 INFO [train.py:450] Epoch 3, batch 8950, batch avg loss 0.3404, total avg loss: 0.3500, batch size: 40
2021-08-25 09:07:21,440 INFO [train.py:450] Epoch 3, batch 8960, batch avg loss 0.3467, total avg loss: 0.3501, batch size: 38
2021-08-25 09:07:27,235 INFO [train.py:450] Epoch 3, batch 8970, batch avg loss 0.3710, total avg loss: 0.3503, batch size: 39
2021-08-25 09:07:33,124 INFO [train.py:450] Epoch 3, batch 8980, batch avg loss 0.3487, total avg loss: 0.3496, batch size: 43
2021-08-25 09:07:39,545 INFO [train.py:450] Epoch 3, batch 8990, batch avg loss 0.3477, total avg loss: 0.3493, batch size: 36
2021-08-25 09:07:45,339 INFO [train.py:450] Epoch 3, batch 9000, batch avg loss 0.3062, total avg loss: 0.3501, batch size: 38
2021-08-25 09:08:22,382 INFO [train.py:482] Epoch 3, valid loss 0.2481, best valid loss: 0.2434 best valid epoch: 2
2021-08-25 09:08:28,321 INFO [train.py:450] Epoch 3, batch 9010, batch avg loss 0.3473, total avg loss: 0.3452, batch size: 39
2021-08-25 09:08:34,068 INFO [train.py:450] Epoch 3, batch 9020, batch avg loss 0.3489, total avg loss: 0.3502, batch size: 41
2021-08-25 09:08:39,951 INFO [train.py:450] Epoch 3, batch 9030, batch avg loss 0.3548, total avg loss: 0.3492, batch size: 41
2021-08-25 09:08:45,910 INFO [train.py:450] Epoch 3, batch 9040, batch avg loss 0.3034, total avg loss: 0.3485, batch size: 40
2021-08-25 09:08:51,670 INFO [train.py:450] Epoch 3, batch 9050, batch avg loss 0.3522, total avg loss: 0.3512, batch size: 42
2021-08-25 09:08:57,393 INFO [train.py:450] Epoch 3, batch 9060, batch avg loss 0.3806, total avg loss: 0.3542, batch size: 43
2021-08-25 09:09:03,183 INFO [train.py:450] Epoch 3, batch 9070, batch avg loss 0.3711, total avg loss: 0.3518, batch size: 39
2021-08-25 09:09:08,998 INFO [train.py:450] Epoch 3, batch 9080, batch avg loss 0.3410, total avg loss: 0.3531, batch size: 40
2021-08-25 09:09:15,214 INFO [train.py:450] Epoch 3, batch 9090, batch avg loss 0.3476, total avg loss: 0.3527, batch size: 41
2021-08-25 09:09:21,087 INFO [train.py:450] Epoch 3, batch 9100, batch avg loss 0.3509, total avg loss: 0.3522, batch size: 39
2021-08-25 09:09:26,949 INFO [train.py:450] Epoch 3, batch 9110, batch avg loss 0.3748, total avg loss: 0.3505, batch size: 41
2021-08-25 09:09:32,699 INFO [train.py:450] Epoch 3, batch 9120, batch avg loss 0.3815, total avg loss: 0.3505, batch size: 42
2021-08-25 09:09:38,528 INFO [train.py:450] Epoch 3, batch 9130, batch avg loss 0.2827, total avg loss: 0.3495, batch size: 40
2021-08-25 09:09:44,467 INFO [train.py:450] Epoch 3, batch 9140, batch avg loss 0.3367, total avg loss: 0.3500, batch size: 39
2021-08-25 09:09:50,282 INFO [train.py:450] Epoch 3, batch 9150, batch avg loss 0.3616, total avg loss: 0.3496, batch size: 39
2021-08-25 09:09:56,137 INFO [train.py:450] Epoch 3, batch 9160, batch avg loss 0.3373, total avg loss: 0.3487, batch size: 38
2021-08-25 09:10:01,813 INFO [train.py:450] Epoch 3, batch 9170, batch avg loss 0.3928, total avg loss: 0.3491, batch size: 37
2021-08-25 09:10:07,629 INFO [train.py:450] Epoch 3, batch 9180, batch avg loss 0.4335, total avg loss: 0.3499, batch size: 38
2021-08-25 09:10:13,477 INFO [train.py:450] Epoch 3, batch 9190, batch avg loss 0.3416, total avg loss: 0.3493, batch size: 40
2021-08-25 09:10:19,502 INFO [train.py:450] Epoch 3, batch 9200, batch avg loss 0.3426, total avg loss: 0.3497, batch size: 43
2021-08-25 09:10:25,363 INFO [train.py:450] Epoch 3, batch 9210, batch avg loss 0.3221, total avg loss: 0.3386, batch size: 40
2021-08-25 09:10:31,281 INFO [train.py:450] Epoch 3, batch 9220, batch avg loss 0.3260, total avg loss: 0.3356, batch size: 40
2021-08-25 09:10:37,125 INFO [train.py:450] Epoch 3, batch 9230, batch avg loss 0.3397, total avg loss: 0.3395, batch size: 40
2021-08-25 09:10:43,045 INFO [train.py:450] Epoch 3, batch 9240, batch avg loss 0.3392, total avg loss: 0.3447, batch size: 38
2021-08-25 09:10:49,539 INFO [train.py:450] Epoch 3, batch 9250, batch avg loss 0.3528, total avg loss: 0.3462, batch size: 40
2021-08-25 09:10:55,779 INFO [train.py:450] Epoch 3, batch 9260, batch avg loss 0.3304, total avg loss: 0.3474, batch size: 40
2021-08-25 09:11:01,584 INFO [train.py:450] Epoch 3, batch 9270, batch avg loss 0.4111, total avg loss: 0.3472, batch size: 41
2021-08-25 09:11:07,459 INFO [train.py:450] Epoch 3, batch 9280, batch avg loss 0.3441, total avg loss: 0.3460, batch size: 40
2021-08-25 09:11:13,388 INFO [train.py:450] Epoch 3, batch 9290, batch avg loss 0.3899, total avg loss: 0.3459, batch size: 41
2021-08-25 09:11:19,251 INFO [train.py:450] Epoch 3, batch 9300, batch avg loss 0.3390, total avg loss: 0.3444, batch size: 39
2021-08-25 09:11:25,031 INFO [train.py:450] Epoch 3, batch 9310, batch avg loss 0.3119, total avg loss: 0.3447, batch size: 42
2021-08-25 09:11:30,931 INFO [train.py:450] Epoch 3, batch 9320, batch avg loss 0.3236, total avg loss: 0.3437, batch size: 42
2021-08-25 09:11:36,832 INFO [train.py:450] Epoch 3, batch 9330, batch avg loss 0.3839, total avg loss: 0.3439, batch size: 39
2021-08-25 09:11:42,745 INFO [train.py:450] Epoch 3, batch 9340, batch avg loss 0.3134, total avg loss: 0.3446, batch size: 39
2021-08-25 09:11:48,712 INFO [train.py:450] Epoch 3, batch 9350, batch avg loss 0.3164, total avg loss: 0.3443, batch size: 36
2021-08-25 09:11:54,650 INFO [train.py:450] Epoch 3, batch 9360, batch avg loss 0.3770, total avg loss: 0.3446, batch size: 41
2021-08-25 09:12:00,545 INFO [train.py:450] Epoch 3, batch 9370, batch avg loss 0.3224, total avg loss: 0.3439, batch size: 41
2021-08-25 09:12:06,525 INFO [train.py:450] Epoch 3, batch 9380, batch avg loss 0.3509, total avg loss: 0.3451, batch size: 40
2021-08-25 09:12:12,415 INFO [train.py:450] Epoch 3, batch 9390, batch avg loss 0.3421, total avg loss: 0.3447, batch size: 35
2021-08-25 09:12:18,374 INFO [train.py:450] Epoch 3, batch 9400, batch avg loss 0.4070, total avg loss: 0.3454, batch size: 36
2021-08-25 09:12:24,367 INFO [train.py:450] Epoch 3, batch 9410, batch avg loss 0.3266, total avg loss: 0.3409, batch size: 42
2021-08-25 09:12:30,223 INFO [train.py:450] Epoch 3, batch 9420, batch avg loss 0.3094, total avg loss: 0.3413, batch size: 38
2021-08-25 09:12:36,110 INFO [train.py:450] Epoch 3, batch 9430, batch avg loss 0.3645, total avg loss: 0.3484, batch size: 41
2021-08-25 09:12:42,090 INFO [train.py:450] Epoch 3, batch 9440, batch avg loss 0.3441, total avg loss: 0.3506, batch size: 37
2021-08-25 09:12:47,963 INFO [train.py:450] Epoch 3, batch 9450, batch avg loss 0.4238, total avg loss: 0.3521, batch size: 40
2021-08-25 09:12:53,866 INFO [train.py:450] Epoch 3, batch 9460, batch avg loss 0.3136, total avg loss: 0.3522, batch size: 39
2021-08-25 09:12:59,771 INFO [train.py:450] Epoch 3, batch 9470, batch avg loss 0.3252, total avg loss: 0.3522, batch size: 37
2021-08-25 09:13:05,615 INFO [train.py:450] Epoch 3, batch 9480, batch avg loss 0.2973, total avg loss: 0.3495, batch size: 38
2021-08-25 09:13:11,542 INFO [train.py:450] Epoch 3, batch 9490, batch avg loss 0.3801, total avg loss: 0.3504, batch size: 43
2021-08-25 09:13:17,343 INFO [train.py:450] Epoch 3, batch 9500, batch avg loss 0.3524, total avg loss: 0.3505, batch size: 39
2021-08-25 09:13:23,494 INFO [train.py:450] Epoch 3, batch 9510, batch avg loss 0.3397, total avg loss: 0.3513, batch size: 41
2021-08-25 09:13:29,420 INFO [train.py:450] Epoch 3, batch 9520, batch avg loss 0.3496, total avg loss: 0.3507, batch size: 46
2021-08-25 09:13:35,450 INFO [train.py:450] Epoch 3, batch 9530, batch avg loss 0.3496, total avg loss: 0.3504, batch size: 39
2021-08-25 09:13:41,335 INFO [train.py:450] Epoch 3, batch 9540, batch avg loss 0.3795, total avg loss: 0.3500, batch size: 39
2021-08-25 09:13:47,232 INFO [train.py:450] Epoch 3, batch 9550, batch avg loss 0.3038, total avg loss: 0.3492, batch size: 39
2021-08-25 09:13:53,235 INFO [train.py:450] Epoch 3, batch 9560, batch avg loss 0.3874, total avg loss: 0.3489, batch size: 40
2021-08-25 09:13:59,190 INFO [train.py:450] Epoch 3, batch 9570, batch avg loss 0.3303, total avg loss: 0.3482, batch size: 39
2021-08-25 09:14:05,117 INFO [train.py:450] Epoch 3, batch 9580, batch avg loss 0.3592, total avg loss: 0.3482, batch size: 37
2021-08-25 09:14:11,072 INFO [train.py:450] Epoch 3, batch 9590, batch avg loss 0.3207, total avg loss: 0.3480, batch size: 44
2021-08-25 09:14:16,995 INFO [train.py:450] Epoch 3, batch 9600, batch avg loss 0.3917, total avg loss: 0.3484, batch size: 37
2021-08-25 09:14:22,938 INFO [train.py:450] Epoch 3, batch 9610, batch avg loss 0.3232, total avg loss: 0.3539, batch size: 41
2021-08-25 09:14:28,804 INFO [train.py:450] Epoch 3, batch 9620, batch avg loss 0.3461, total avg loss: 0.3522, batch size: 40
2021-08-25 09:14:35,032 INFO [train.py:450] Epoch 3, batch 9630, batch avg loss 0.3277, total avg loss: 0.3502, batch size: 38
2021-08-25 09:14:40,924 INFO [train.py:450] Epoch 3, batch 9640, batch avg loss 0.3216, total avg loss: 0.3470, batch size: 37
2021-08-25 09:14:46,893 INFO [train.py:450] Epoch 3, batch 9650, batch avg loss 0.3618, total avg loss: 0.3487, batch size: 42
2021-08-25 09:14:54,386 INFO [train.py:450] Epoch 3, batch 9660, batch avg loss 0.3212, total avg loss: 0.3470, batch size: 37
2021-08-25 09:15:00,223 INFO [train.py:450] Epoch 3, batch 9670, batch avg loss 0.3720, total avg loss: 0.3473, batch size: 37
2021-08-25 09:15:06,329 INFO [train.py:450] Epoch 3, batch 9680, batch avg loss 0.3379, total avg loss: 0.3488, batch size: 41
2021-08-25 09:15:12,547 INFO [train.py:450] Epoch 3, batch 9690, batch avg loss 0.3778, total avg loss: 0.3485, batch size: 35
2021-08-25 09:15:18,514 INFO [train.py:450] Epoch 3, batch 9700, batch avg loss 0.3379, total avg loss: 0.3502, batch size: 40
2021-08-25 09:15:24,404 INFO [train.py:450] Epoch 3, batch 9710, batch avg loss 0.3384, total avg loss: 0.3509, batch size: 41
2021-08-25 09:15:30,206 INFO [train.py:450] Epoch 3, batch 9720, batch avg loss 0.3006, total avg loss: 0.3505, batch size: 40
2021-08-25 09:15:36,136 INFO [train.py:450] Epoch 3, batch 9730, batch avg loss 0.3409, total avg loss: 0.3486, batch size: 45
2021-08-25 09:15:42,110 INFO [train.py:450] Epoch 3, batch 9740, batch avg loss 0.3342, total avg loss: 0.3487, batch size: 39
2021-08-25 09:15:48,277 INFO [train.py:450] Epoch 3, batch 9750, batch avg loss 0.3498, total avg loss: 0.3484, batch size: 36
2021-08-25 09:15:54,202 INFO [train.py:450] Epoch 3, batch 9760, batch avg loss 0.4358, total avg loss: 0.3491, batch size: 41
2021-08-25 09:16:00,111 INFO [train.py:450] Epoch 3, batch 9770, batch avg loss 0.3673, total avg loss: 0.3491, batch size: 43
2021-08-25 09:16:06,037 INFO [train.py:450] Epoch 3, batch 9780, batch avg loss 0.4089, total avg loss: 0.3496, batch size: 39
2021-08-25 09:16:12,344 INFO [train.py:450] Epoch 3, batch 9790, batch avg loss 0.3033, total avg loss: 0.3498, batch size: 40
2021-08-25 09:16:18,529 INFO [train.py:450] Epoch 3, batch 9800, batch avg loss 0.3123, total avg loss: 0.3497, batch size: 39
2021-08-25 09:16:24,820 INFO [train.py:450] Epoch 3, batch 9810, batch avg loss 0.3679, total avg loss: 0.3524, batch size: 39
2021-08-25 09:16:30,879 INFO [train.py:450] Epoch 3, batch 9820, batch avg loss 0.3035, total avg loss: 0.3524, batch size: 40
2021-08-25 09:16:36,807 INFO [train.py:450] Epoch 3, batch 9830, batch avg loss 0.3788, total avg loss: 0.3512, batch size: 38
2021-08-25 09:16:42,802 INFO [train.py:450] Epoch 3, batch 9840, batch avg loss 0.3153, total avg loss: 0.3490, batch size: 40
2021-08-25 09:16:48,993 INFO [train.py:450] Epoch 3, batch 9850, batch avg loss 0.3211, total avg loss: 0.3481, batch size: 40
2021-08-25 09:16:55,349 INFO [train.py:450] Epoch 3, batch 9860, batch avg loss 0.3093, total avg loss: 0.3459, batch size: 39
2021-08-25 09:17:01,887 INFO [train.py:450] Epoch 3, batch 9870, batch avg loss 0.3562, total avg loss: 0.3453, batch size: 39
2021-08-25 09:17:08,051 INFO [train.py:450] Epoch 3, batch 9880, batch avg loss 0.3280, total avg loss: 0.3469, batch size: 41
2021-08-25 09:17:14,533 INFO [train.py:450] Epoch 3, batch 9890, batch avg loss 0.3100, total avg loss: 0.3475, batch size: 41
2021-08-25 09:17:21,213 INFO [train.py:450] Epoch 3, batch 9900, batch avg loss 0.3257, total avg loss: 0.3483, batch size: 37
2021-08-25 09:17:27,411 INFO [train.py:450] Epoch 3, batch 9910, batch avg loss 0.3598, total avg loss: 0.3484, batch size: 36
2021-08-25 09:17:33,730 INFO [train.py:450] Epoch 3, batch 9920, batch avg loss 0.3360, total avg loss: 0.3478, batch size: 39
2021-08-25 09:17:40,629 INFO [train.py:450] Epoch 3, batch 9930, batch avg loss 0.3159, total avg loss: 0.3463, batch size: 37
2021-08-25 09:17:47,164 INFO [train.py:450] Epoch 3, batch 9940, batch avg loss 0.3177, total avg loss: 0.3459, batch size: 39
2021-08-25 09:17:54,290 INFO [train.py:450] Epoch 3, batch 9950, batch avg loss 0.3183, total avg loss: 0.3458, batch size: 41
2021-08-25 09:18:00,400 INFO [train.py:450] Epoch 3, batch 9960, batch avg loss 0.3378, total avg loss: 0.3468, batch size: 42
2021-08-25 09:18:08,503 INFO [train.py:450] Epoch 3, batch 9970, batch avg loss 0.3296, total avg loss: 0.3469, batch size: 43
2021-08-25 09:18:14,982 INFO [train.py:450] Epoch 3, batch 9980, batch avg loss 0.4030, total avg loss: 0.3470, batch size: 38
2021-08-25 09:18:24,904 INFO [train.py:450] Epoch 3, batch 9990, batch avg loss 0.3465, total avg loss: 0.3461, batch size: 43
2021-08-25 09:18:31,403 INFO [train.py:450] Epoch 3, batch 10000, batch avg loss 0.3015, total avg loss: 0.3471, batch size: 40
2021-08-25 09:19:10,594 INFO [train.py:482] Epoch 3, valid loss 0.2463, best valid loss: 0.2434 best valid epoch: 2
2021-08-25 09:19:16,662 INFO [train.py:450] Epoch 3, batch 10010, batch avg loss 0.3054, total avg loss: 0.3588, batch size: 43
2021-08-25 09:19:23,150 INFO [train.py:450] Epoch 3, batch 10020, batch avg loss 0.3032, total avg loss: 0.3559, batch size: 39
2021-08-25 09:19:30,101 INFO [train.py:450] Epoch 3, batch 10030, batch avg loss 0.3535, total avg loss: 0.3509, batch size: 41
2021-08-25 09:19:37,397 INFO [train.py:450] Epoch 3, batch 10040, batch avg loss 0.3141, total avg loss: 0.3486, batch size: 43
2021-08-25 09:19:44,377 INFO [train.py:450] Epoch 3, batch 10050, batch avg loss 0.2883, total avg loss: 0.3498, batch size: 40
2021-08-25 09:19:51,485 INFO [train.py:450] Epoch 3, batch 10060, batch avg loss 0.2912, total avg loss: 0.3454, batch size: 42
2021-08-25 09:19:58,284 INFO [train.py:450] Epoch 3, batch 10070, batch avg loss 0.3186, total avg loss: 0.3442, batch size: 37
2021-08-25 09:20:05,284 INFO [train.py:450] Epoch 3, batch 10080, batch avg loss 0.3103, total avg loss: 0.3445, batch size: 39
2021-08-25 09:20:12,178 INFO [train.py:450] Epoch 3, batch 10090, batch avg loss 0.3434, total avg loss: 0.3452, batch size: 37
2021-08-25 09:20:18,686 INFO [train.py:450] Epoch 3, batch 10100, batch avg loss 0.3494, total avg loss: 0.3444, batch size: 40
2021-08-25 09:20:25,332 INFO [train.py:450] Epoch 3, batch 10110, batch avg loss 0.4061, total avg loss: 0.3446, batch size: 38
2021-08-25 09:20:32,089 INFO [train.py:450] Epoch 3, batch 10120, batch avg loss 0.3835, total avg loss: 0.3441, batch size: 38
2021-08-25 09:20:39,365 INFO [train.py:450] Epoch 3, batch 10130, batch avg loss 0.3279, total avg loss: 0.3448, batch size: 40
2021-08-25 09:20:46,436 INFO [train.py:450] Epoch 3, batch 10140, batch avg loss 0.3384, total avg loss: 0.3440, batch size: 41
2021-08-25 09:20:53,475 INFO [train.py:450] Epoch 3, batch 10150, batch avg loss 0.3120, total avg loss: 0.3451, batch size: 43
2021-08-25 09:21:00,318 INFO [train.py:450] Epoch 3, batch 10160, batch avg loss 0.3123, total avg loss: 0.3446, batch size: 39
2021-08-25 09:21:07,125 INFO [train.py:450] Epoch 3, batch 10170, batch avg loss 0.3024, total avg loss: 0.3442, batch size: 40
2021-08-25 09:21:14,185 INFO [train.py:450] Epoch 3, batch 10180, batch avg loss 0.3961, total avg loss: 0.3442, batch size: 43
2021-08-25 09:21:21,427 INFO [train.py:450] Epoch 3, batch 10190, batch avg loss 0.3284, total avg loss: 0.3432, batch size: 42
2021-08-25 09:21:28,962 INFO [train.py:450] Epoch 3, batch 10200, batch avg loss 0.3455, total avg loss: 0.3430, batch size: 36
2021-08-25 09:21:37,722 INFO [train.py:450] Epoch 3, batch 10210, batch avg loss 0.3482, total avg loss: 0.3491, batch size: 42
2021-08-25 09:21:46,599 INFO [train.py:450] Epoch 3, batch 10220, batch avg loss 0.3101, total avg loss: 0.3494, batch size: 35
2021-08-25 09:21:53,201 INFO [train.py:450] Epoch 3, batch 10230, batch avg loss 0.3464, total avg loss: 0.3474, batch size: 39
2021-08-25 09:22:00,398 INFO [train.py:450] Epoch 3, batch 10240, batch avg loss 0.3120, total avg loss: 0.3428, batch size: 40
2021-08-25 09:22:07,409 INFO [train.py:450] Epoch 3, batch 10250, batch avg loss 0.3449, total avg loss: 0.3438, batch size: 42
2021-08-25 09:22:11,643 WARNING [cut.py:1694] To perform mix, energy must be non-zero and non-negative (got 0.0).  MonoCut with id "226293a9-5894-6b26-7c70-53fa18d3baf6" will not be mixed in.
2021-08-25 09:22:14,705 INFO [train.py:450] Epoch 3, batch 10260, batch avg loss 0.3326, total avg loss: 0.3446, batch size: 38
2021-08-25 09:22:21,762 INFO [train.py:450] Epoch 3, batch 10270, batch avg loss 0.2973, total avg loss: 0.3471, batch size: 39
2021-08-25 09:22:28,827 INFO [train.py:450] Epoch 3, batch 10280, batch avg loss 0.3922, total avg loss: 0.3458, batch size: 38
2021-08-25 09:22:35,577 INFO [train.py:450] Epoch 3, batch 10290, batch avg loss 0.3257, total avg loss: 0.3448, batch size: 42
2021-08-25 09:22:42,749 INFO [train.py:450] Epoch 3, batch 10300, batch avg loss 0.3209, total avg loss: 0.3444, batch size: 40
2021-08-25 09:22:49,735 INFO [train.py:450] Epoch 3, batch 10310, batch avg loss 0.3629, total avg loss: 0.3445, batch size: 39
2021-08-25 09:22:58,253 INFO [train.py:450] Epoch 3, batch 10320, batch avg loss 0.3684, total avg loss: 0.3442, batch size: 44
2021-08-25 09:23:05,555 INFO [train.py:450] Epoch 3, batch 10330, batch avg loss 0.3648, total avg loss: 0.3441, batch size: 42
2021-08-25 09:23:12,979 INFO [train.py:450] Epoch 3, batch 10340, batch avg loss 0.3391, total avg loss: 0.3432, batch size: 42
2021-08-25 09:23:20,215 INFO [train.py:450] Epoch 3, batch 10350, batch avg loss 0.3495, total avg loss: 0.3432, batch size: 40
2021-08-25 09:23:27,458 INFO [train.py:450] Epoch 3, batch 10360, batch avg loss 0.3450, total avg loss: 0.3432, batch size: 40
2021-08-25 09:23:33,845 INFO [train.py:450] Epoch 3, batch 10370, batch avg loss 0.3129, total avg loss: 0.3427, batch size: 40
2021-08-25 09:23:41,095 INFO [train.py:450] Epoch 3, batch 10380, batch avg loss 0.3377, total avg loss: 0.3426, batch size: 36
2021-08-25 09:23:48,195 INFO [train.py:450] Epoch 3, batch 10390, batch avg loss 0.3015, total avg loss: 0.3427, batch size: 43
2021-08-25 09:23:55,367 INFO [train.py:450] Epoch 3, batch 10400, batch avg loss 0.2824, total avg loss: 0.3429, batch size: 38
2021-08-25 09:24:02,121 INFO [train.py:450] Epoch 3, batch 10410, batch avg loss 0.3165, total avg loss: 0.3347, batch size: 41
2021-08-25 09:24:09,600 INFO [train.py:450] Epoch 3, batch 10420, batch avg loss 0.3309, total avg loss: 0.3419, batch size: 42
2021-08-25 09:24:17,706 INFO [train.py:450] Epoch 3, batch 10430, batch avg loss 0.3345, total avg loss: 0.3494, batch size: 41
2021-08-25 09:24:24,247 INFO [train.py:450] Epoch 3, batch 10440, batch avg loss 0.3138, total avg loss: 0.3490, batch size: 38
2021-08-25 09:24:31,112 INFO [train.py:450] Epoch 3, batch 10450, batch avg loss 0.3669, total avg loss: 0.3499, batch size: 39
2021-08-25 09:24:38,218 INFO [train.py:450] Epoch 3, batch 10460, batch avg loss 0.4045, total avg loss: 0.3492, batch size: 43
2021-08-25 09:24:45,780 INFO [train.py:450] Epoch 3, batch 10470, batch avg loss 0.3336, total avg loss: 0.3502, batch size: 38
2021-08-25 09:24:53,130 INFO [train.py:450] Epoch 3, batch 10480, batch avg loss 0.3669, total avg loss: 0.3508, batch size: 37
2021-08-25 09:25:02,099 INFO [train.py:450] Epoch 3, batch 10490, batch avg loss 0.3425, total avg loss: 0.3488, batch size: 39
2021-08-25 09:25:11,130 INFO [train.py:450] Epoch 3, batch 10500, batch avg loss 0.3665, total avg loss: 0.3484, batch size: 40
2021-08-25 09:25:18,286 INFO [train.py:450] Epoch 3, batch 10510, batch avg loss 0.3059, total avg loss: 0.3500, batch size: 37
2021-08-25 09:25:25,491 INFO [train.py:450] Epoch 3, batch 10520, batch avg loss 0.3533, total avg loss: 0.3503, batch size: 42
2021-08-25 09:25:32,597 INFO [train.py:450] Epoch 3, batch 10530, batch avg loss 0.3367, total avg loss: 0.3506, batch size: 42
2021-08-25 09:25:39,855 INFO [train.py:450] Epoch 3, batch 10540, batch avg loss 0.3063, total avg loss: 0.3493, batch size: 41
2021-08-25 09:25:47,027 INFO [train.py:450] Epoch 3, batch 10550, batch avg loss 0.3429, total avg loss: 0.3480, batch size: 37
2021-08-25 09:25:54,343 INFO [train.py:450] Epoch 3, batch 10560, batch avg loss 0.3545, total avg loss: 0.3462, batch size: 41
2021-08-25 09:26:01,858 INFO [train.py:450] Epoch 3, batch 10570, batch avg loss 0.3151, total avg loss: 0.3454, batch size: 39
2021-08-25 09:26:08,961 INFO [train.py:450] Epoch 3, batch 10580, batch avg loss 0.3819, total avg loss: 0.3457, batch size: 47
2021-08-25 09:26:16,132 INFO [train.py:450] Epoch 3, batch 10590, batch avg loss 0.3691, total avg loss: 0.3458, batch size: 41
2021-08-25 09:26:22,968 INFO [train.py:450] Epoch 3, batch 10600, batch avg loss 0.3326, total avg loss: 0.3458, batch size: 40
2021-08-25 09:26:30,376 INFO [train.py:450] Epoch 3, batch 10610, batch avg loss 0.3286, total avg loss: 0.3350, batch size: 42
2021-08-25 09:26:37,336 INFO [train.py:450] Epoch 3, batch 10620, batch avg loss 0.3185, total avg loss: 0.3444, batch size: 41
2021-08-25 09:26:44,408 INFO [train.py:450] Epoch 3, batch 10630, batch avg loss 0.3878, total avg loss: 0.3477, batch size: 43
2021-08-25 09:26:51,957 INFO [train.py:450] Epoch 3, batch 10640, batch avg loss 0.3122, total avg loss: 0.3469, batch size: 42
2021-08-25 09:26:59,055 INFO [train.py:450] Epoch 3, batch 10650, batch avg loss 0.3482, total avg loss: 0.3443, batch size: 42
2021-08-25 09:27:06,111 INFO [train.py:450] Epoch 3, batch 10660, batch avg loss 0.3266, total avg loss: 0.3438, batch size: 41
2021-08-25 09:27:13,721 INFO [train.py:450] Epoch 3, batch 10670, batch avg loss 0.3753, total avg loss: 0.3446, batch size: 40
2021-08-25 09:27:20,711 INFO [train.py:450] Epoch 3, batch 10680, batch avg loss 0.3320, total avg loss: 0.3452, batch size: 38
2021-08-25 09:27:23,977 WARNING [cut.py:1694] To perform mix, energy must be non-zero and non-negative (got 0.0).  MonoCut with id "ea669bf9-1270-10a0-4613-5207badf38b2" will not be mixed in.
2021-08-25 09:27:27,759 INFO [train.py:450] Epoch 3, batch 10690, batch avg loss 0.3471, total avg loss: 0.3476, batch size: 44
2021-08-25 09:27:35,028 INFO [train.py:450] Epoch 3, batch 10700, batch avg loss 0.3636, total avg loss: 0.3487, batch size: 38
2021-08-25 09:27:42,103 INFO [train.py:450] Epoch 3, batch 10710, batch avg loss 0.3674, total avg loss: 0.3501, batch size: 35
2021-08-25 09:27:51,266 INFO [train.py:450] Epoch 3, batch 10720, batch avg loss 0.3896, total avg loss: 0.3493, batch size: 43
2021-08-25 09:27:57,985 INFO [train.py:450] Epoch 3, batch 10730, batch avg loss 0.3463, total avg loss: 0.3496, batch size: 40
2021-08-25 09:28:06,775 INFO [train.py:450] Epoch 3, batch 10740, batch avg loss 0.3273, total avg loss: 0.3482, batch size: 41
2021-08-25 09:28:15,111 INFO [train.py:450] Epoch 3, batch 10750, batch avg loss 0.3561, total avg loss: 0.3478, batch size: 37
2021-08-25 09:28:22,423 INFO [train.py:450] Epoch 3, batch 10760, batch avg loss 0.3216, total avg loss: 0.3485, batch size: 40
2021-08-25 09:28:29,864 INFO [train.py:450] Epoch 3, batch 10770, batch avg loss 0.2931, total avg loss: 0.3486, batch size: 38
2021-08-25 09:28:36,958 INFO [train.py:450] Epoch 3, batch 10780, batch avg loss 0.3144, total avg loss: 0.3483, batch size: 38
2021-08-25 09:28:44,506 INFO [train.py:450] Epoch 3, batch 10790, batch avg loss 0.3176, total avg loss: 0.3492, batch size: 43
2021-08-25 09:28:51,678 INFO [train.py:450] Epoch 3, batch 10800, batch avg loss 0.3449, total avg loss: 0.3486, batch size: 40
2021-08-25 09:28:59,152 INFO [train.py:450] Epoch 3, batch 10810, batch avg loss 0.3424, total avg loss: 0.3392, batch size: 41
2021-08-25 09:29:06,329 INFO [train.py:450] Epoch 3, batch 10820, batch avg loss 0.3745, total avg loss: 0.3461, batch size: 43
2021-08-25 09:29:13,519 INFO [train.py:450] Epoch 3, batch 10830, batch avg loss 0.3593, total avg loss: 0.3467, batch size: 43
2021-08-25 09:29:21,448 INFO [train.py:450] Epoch 3, batch 10840, batch avg loss 0.3953, total avg loss: 0.3513, batch size: 39
2021-08-25 09:29:28,635 INFO [train.py:450] Epoch 3, batch 10850, batch avg loss 0.3039, total avg loss: 0.3492, batch size: 42
2021-08-25 09:29:36,287 INFO [train.py:450] Epoch 3, batch 10860, batch avg loss 0.3579, total avg loss: 0.3509, batch size: 39
2021-08-25 09:29:43,973 INFO [train.py:450] Epoch 3, batch 10870, batch avg loss 0.3121, total avg loss: 0.3511, batch size: 37
2021-08-25 09:29:51,229 INFO [train.py:450] Epoch 3, batch 10880, batch avg loss 0.3164, total avg loss: 0.3499, batch size: 37
2021-08-25 09:29:58,222 INFO [train.py:450] Epoch 3, batch 10890, batch avg loss 0.3636, total avg loss: 0.3494, batch size: 40
2021-08-25 09:30:05,563 INFO [train.py:450] Epoch 3, batch 10900, batch avg loss 0.3573, total avg loss: 0.3505, batch size: 42
2021-08-25 09:30:12,075 INFO [train.py:450] Epoch 3, batch 10910, batch avg loss 0.3156, total avg loss: 0.3490, batch size: 39
2021-08-25 09:30:19,361 INFO [train.py:450] Epoch 3, batch 10920, batch avg loss 0.3938, total avg loss: 0.3482, batch size: 39
2021-08-25 09:30:26,914 INFO [train.py:450] Epoch 3, batch 10930, batch avg loss 0.3687, total avg loss: 0.3473, batch size: 39
2021-08-25 09:30:34,444 INFO [train.py:450] Epoch 3, batch 10940, batch avg loss 0.3433, total avg loss: 0.3466, batch size: 41
2021-08-25 09:30:42,011 INFO [train.py:450] Epoch 3, batch 10950, batch avg loss 0.3546, total avg loss: 0.3466, batch size: 38
2021-08-25 09:30:49,810 INFO [train.py:450] Epoch 3, batch 10960, batch avg loss 0.3448, total avg loss: 0.3458, batch size: 39
2021-08-25 09:30:57,518 INFO [train.py:450] Epoch 3, batch 10970, batch avg loss 0.3810, total avg loss: 0.3451, batch size: 44
2021-08-25 09:31:05,098 INFO [train.py:450] Epoch 3, batch 10980, batch avg loss 0.3541, total avg loss: 0.3452, batch size: 38
2021-08-25 09:31:12,534 INFO [train.py:450] Epoch 3, batch 10990, batch avg loss 0.3734, total avg loss: 0.3460, batch size: 37
2021-08-25 09:31:20,687 INFO [train.py:450] Epoch 3, batch 11000, batch avg loss 0.3467, total avg loss: 0.3470, batch size: 37
2021-08-25 09:31:59,966 INFO [train.py:482] Epoch 3, valid loss 0.2469, best valid loss: 0.2434 best valid epoch: 2
2021-08-25 09:32:06,357 INFO [train.py:450] Epoch 3, batch 11010, batch avg loss 0.3605, total avg loss: 0.3319, batch size: 39
2021-08-25 09:32:14,416 INFO [train.py:450] Epoch 3, batch 11020, batch avg loss 0.3034, total avg loss: 0.3335, batch size: 37
2021-08-25 09:32:22,397 INFO [train.py:450] Epoch 3, batch 11030, batch avg loss 0.3289, total avg loss: 0.3381, batch size: 41
2021-08-25 09:32:30,825 INFO [train.py:450] Epoch 3, batch 11040, batch avg loss 0.3570, total avg loss: 0.3417, batch size: 36
2021-08-25 09:32:38,941 INFO [train.py:450] Epoch 3, batch 11050, batch avg loss 0.3624, total avg loss: 0.3431, batch size: 44
2021-08-25 09:32:46,832 INFO [train.py:450] Epoch 3, batch 11060, batch avg loss 0.3526, total avg loss: 0.3434, batch size: 39
2021-08-25 09:32:54,482 INFO [train.py:450] Epoch 3, batch 11070, batch avg loss 0.3346, total avg loss: 0.3448, batch size: 41
2021-08-25 09:33:02,871 INFO [train.py:450] Epoch 3, batch 11080, batch avg loss 0.3401, total avg loss: 0.3438, batch size: 39
2021-08-25 09:33:10,827 INFO [train.py:450] Epoch 3, batch 11090, batch avg loss 0.3752, total avg loss: 0.3437, batch size: 38
2021-08-25 09:33:18,732 INFO [train.py:450] Epoch 3, batch 11100, batch avg loss 0.3478, total avg loss: 0.3450, batch size: 42
2021-08-25 09:33:26,243 INFO [train.py:450] Epoch 3, batch 11110, batch avg loss 0.3032, total avg loss: 0.3459, batch size: 40
2021-08-25 09:33:33,662 INFO [train.py:450] Epoch 3, batch 11120, batch avg loss 0.4011, total avg loss: 0.3458, batch size: 39
2021-08-25 09:33:41,014 INFO [train.py:450] Epoch 3, batch 11130, batch avg loss 0.3484, total avg loss: 0.3455, batch size: 37
2021-08-25 09:33:49,631 INFO [train.py:450] Epoch 3, batch 11140, batch avg loss 0.3303, total avg loss: 0.3460, batch size: 39
2021-08-25 09:33:56,981 INFO [train.py:450] Epoch 3, batch 11150, batch avg loss 0.3912, total avg loss: 0.3459, batch size: 40
2021-08-25 09:34:05,039 INFO [train.py:450] Epoch 3, batch 11160, batch avg loss 0.3000, total avg loss: 0.3448, batch size: 37
2021-08-25 09:34:12,561 INFO [train.py:450] Epoch 3, batch 11170, batch avg loss 0.3217, total avg loss: 0.3447, batch size: 43
2021-08-25 09:34:19,925 INFO [train.py:450] Epoch 3, batch 11180, batch avg loss 0.3563, total avg loss: 0.3448, batch size: 39
2021-08-25 09:34:27,330 INFO [train.py:450] Epoch 3, batch 11190, batch avg loss 0.3455, total avg loss: 0.3449, batch size: 38
2021-08-25 09:34:34,711 INFO [train.py:450] Epoch 3, batch 11200, batch avg loss 0.3812, total avg loss: 0.3457, batch size: 39
2021-08-25 09:34:41,889 INFO [train.py:450] Epoch 3, batch 11210, batch avg loss 0.3597, total avg loss: 0.3461, batch size: 39
2021-08-25 09:34:50,834 INFO [train.py:450] Epoch 3, batch 11220, batch avg loss 0.3425, total avg loss: 0.3590, batch size: 39
2021-08-25 09:34:58,523 INFO [train.py:450] Epoch 3, batch 11230, batch avg loss 0.3481, total avg loss: 0.3622, batch size: 39
2021-08-25 09:35:08,610 INFO [train.py:450] Epoch 3, batch 11240, batch avg loss 0.3052, total avg loss: 0.3594, batch size: 44
2021-08-25 09:35:16,593 INFO [train.py:450] Epoch 3, batch 11250, batch avg loss 0.3550, total avg loss: 0.3593, batch size: 42
2021-08-25 09:35:23,913 INFO [train.py:450] Epoch 3, batch 11260, batch avg loss 0.3603, total avg loss: 0.3539, batch size: 42
2021-08-25 09:35:31,663 INFO [train.py:450] Epoch 3, batch 11270, batch avg loss 0.3572, total avg loss: 0.3531, batch size: 43
2021-08-25 09:35:39,135 INFO [train.py:450] Epoch 3, batch 11280, batch avg loss 0.3922, total avg loss: 0.3504, batch size: 40
2021-08-25 09:35:46,260 INFO [train.py:450] Epoch 3, batch 11290, batch avg loss 0.3622, total avg loss: 0.3489, batch size: 42
2021-08-25 09:35:53,349 INFO [train.py:450] Epoch 3, batch 11300, batch avg loss 0.3128, total avg loss: 0.3484, batch size: 42
2021-08-25 09:36:00,393 INFO [train.py:450] Epoch 3, batch 11310, batch avg loss 0.3816, total avg loss: 0.3494, batch size: 40
2021-08-25 09:36:07,837 INFO [train.py:450] Epoch 3, batch 11320, batch avg loss 0.3248, total avg loss: 0.3500, batch size: 42
2021-08-25 09:36:15,532 INFO [train.py:450] Epoch 3, batch 11330, batch avg loss 0.3828, total avg loss: 0.3506, batch size: 41
2021-08-25 09:36:24,126 INFO [train.py:450] Epoch 3, batch 11340, batch avg loss 0.3718, total avg loss: 0.3511, batch size: 40
2021-08-25 09:36:31,717 INFO [train.py:450] Epoch 3, batch 11350, batch avg loss 0.3254, total avg loss: 0.3513, batch size: 39
2021-08-25 09:36:39,007 INFO [train.py:450] Epoch 3, batch 11360, batch avg loss 0.3668, total avg loss: 0.3519, batch size: 40
2021-08-25 09:36:46,551 INFO [train.py:450] Epoch 3, batch 11370, batch avg loss 0.3508, total avg loss: 0.3510, batch size: 41
2021-08-25 09:36:54,259 INFO [train.py:450] Epoch 3, batch 11380, batch avg loss 0.4110, total avg loss: 0.3513, batch size: 44
2021-08-25 09:37:01,851 INFO [train.py:450] Epoch 3, batch 11390, batch avg loss 0.3758, total avg loss: 0.3518, batch size: 41
2021-08-25 09:37:09,154 INFO [train.py:450] Epoch 3, batch 11400, batch avg loss 0.3456, total avg loss: 0.3523, batch size: 41
2021-08-25 09:37:16,397 INFO [train.py:450] Epoch 3, batch 11410, batch avg loss 0.3306, total avg loss: 0.3514, batch size: 39
2021-08-25 09:37:23,819 INFO [train.py:450] Epoch 3, batch 11420, batch avg loss 0.3753, total avg loss: 0.3499, batch size: 43
2021-08-25 09:37:30,942 INFO [train.py:450] Epoch 3, batch 11430, batch avg loss 0.3305, total avg loss: 0.3487, batch size: 41
2021-08-25 09:37:38,524 INFO [train.py:450] Epoch 3, batch 11440, batch avg loss 0.4132, total avg loss: 0.3412, batch size: 42
2021-08-25 09:37:45,697 INFO [train.py:450] Epoch 3, batch 11450, batch avg loss 0.3205, total avg loss: 0.3416, batch size: 38
2021-08-25 09:37:52,596 INFO [train.py:450] Epoch 3, batch 11460, batch avg loss 0.3234, total avg loss: 0.3409, batch size: 43
2021-08-25 09:37:59,844 INFO [train.py:450] Epoch 3, batch 11470, batch avg loss 0.3239, total avg loss: 0.3412, batch size: 43
2021-08-25 09:38:07,217 INFO [train.py:450] Epoch 3, batch 11480, batch avg loss 0.3432, total avg loss: 0.3435, batch size: 41
2021-08-25 09:38:14,789 INFO [train.py:450] Epoch 3, batch 11490, batch avg loss 0.3623, total avg loss: 0.3453, batch size: 43
2021-08-25 09:38:23,143 INFO [train.py:450] Epoch 3, batch 11500, batch avg loss 0.3371, total avg loss: 0.3471, batch size: 38
2021-08-25 09:38:30,495 INFO [train.py:450] Epoch 3, batch 11510, batch avg loss 0.5218, total avg loss: 0.3496, batch size: 36
2021-08-25 09:38:39,549 INFO [train.py:450] Epoch 3, batch 11520, batch avg loss 0.3341, total avg loss: 0.3508, batch size: 40
2021-08-25 09:38:46,602 INFO [train.py:450] Epoch 3, batch 11530, batch avg loss 0.2962, total avg loss: 0.3513, batch size: 41
2021-08-25 09:38:54,178 INFO [train.py:450] Epoch 3, batch 11540, batch avg loss 0.3236, total avg loss: 0.3505, batch size: 42
2021-08-25 09:39:01,254 INFO [train.py:450] Epoch 3, batch 11550, batch avg loss 0.3854, total avg loss: 0.3508, batch size: 44
2021-08-25 09:39:08,305 INFO [train.py:450] Epoch 3, batch 11560, batch avg loss 0.4165, total avg loss: 0.3507, batch size: 41
2021-08-25 09:39:15,647 INFO [train.py:450] Epoch 3, batch 11570, batch avg loss 0.3428, total avg loss: 0.3497, batch size: 39
2021-08-25 09:39:23,718 INFO [train.py:450] Epoch 3, batch 11580, batch avg loss 0.3444, total avg loss: 0.3489, batch size: 40
2021-08-25 09:39:30,489 INFO [train.py:450] Epoch 3, batch 11590, batch avg loss 0.2896, total avg loss: 0.3483, batch size: 39
2021-08-25 09:39:35,428 WARNING [cut.py:1694] To perform mix, energy must be non-zero and non-negative (got 0.0).  MonoCut with id "de343993-012e-00ba-9c81-8aa1d24f14c7" will not be mixed in.
2021-08-25 09:39:37,853 INFO [train.py:450] Epoch 3, batch 11600, batch avg loss 0.3458, total avg loss: 0.3486, batch size: 43
2021-08-25 09:39:44,998 INFO [train.py:450] Epoch 3, batch 11610, batch avg loss 0.3783, total avg loss: 0.3418, batch size: 37
2021-08-25 09:39:52,059 INFO [train.py:450] Epoch 3, batch 11620, batch avg loss 0.3642, total avg loss: 0.3427, batch size: 42
2021-08-25 09:39:59,475 INFO [train.py:450] Epoch 3, batch 11630, batch avg loss 0.3086, total avg loss: 0.3354, batch size: 43
2021-08-25 09:40:06,560 INFO [train.py:450] Epoch 3, batch 11640, batch avg loss 0.3045, total avg loss: 0.3406, batch size: 40
2021-08-25 09:40:13,615 INFO [train.py:450] Epoch 3, batch 11650, batch avg loss 0.3299, total avg loss: 0.3449, batch size: 37
2021-08-25 09:40:20,398 INFO [train.py:450] Epoch 3, batch 11660, batch avg loss 0.3428, total avg loss: 0.3472, batch size: 40
2021-08-25 09:40:28,479 INFO [train.py:450] Epoch 3, batch 11670, batch avg loss 0.3449, total avg loss: 0.3509, batch size: 44
2021-08-25 09:40:35,793 INFO [train.py:450] Epoch 3, batch 11680, batch avg loss 0.3099, total avg loss: 0.3523, batch size: 39
2021-08-25 09:40:42,863 INFO [train.py:450] Epoch 3, batch 11690, batch avg loss 0.3146, total avg loss: 0.3506, batch size: 40
2021-08-25 09:40:49,727 INFO [train.py:450] Epoch 3, batch 11700, batch avg loss 0.3918, total avg loss: 0.3522, batch size: 41
2021-08-25 09:40:56,582 INFO [train.py:450] Epoch 3, batch 11710, batch avg loss 0.3461, total avg loss: 0.3524, batch size: 38
2021-08-25 09:41:03,557 INFO [train.py:450] Epoch 3, batch 11720, batch avg loss 0.3510, total avg loss: 0.3540, batch size: 38
2021-08-25 09:41:04,280 WARNING [cut.py:1694] To perform mix, energy must be non-zero and non-negative (got 0.0).  MonoCut with id "1cc62aee-7270-61b4-b796-b6b9c1854080" will not be mixed in.
2021-08-25 09:41:10,754 INFO [train.py:450] Epoch 3, batch 11730, batch avg loss 0.3709, total avg loss: 0.3557, batch size: 37
2021-08-25 09:41:18,177 INFO [train.py:450] Epoch 3, batch 11740, batch avg loss 0.3824, total avg loss: 0.3570, batch size: 40
2021-08-25 09:41:26,295 INFO [train.py:450] Epoch 3, batch 11750, batch avg loss 0.4143, total avg loss: 0.3587, batch size: 38
2021-08-25 09:41:32,872 INFO [train.py:450] Epoch 3, batch 11760, batch avg loss 0.3204, total avg loss: 0.3585, batch size: 38
2021-08-25 09:41:42,463 INFO [train.py:450] Epoch 3, batch 11770, batch avg loss 0.4050, total avg loss: 0.3573, batch size: 42
2021-08-25 09:41:48,963 INFO [train.py:450] Epoch 3, batch 11780, batch avg loss 0.3725, total avg loss: 0.3582, batch size: 38
2021-08-25 09:41:56,148 INFO [train.py:450] Epoch 3, batch 11790, batch avg loss 0.3760, total avg loss: 0.3576, batch size: 40
2021-08-25 09:42:03,085 INFO [train.py:450] Epoch 3, batch 11800, batch avg loss 0.3103, total avg loss: 0.3578, batch size: 39
2021-08-25 09:42:09,603 INFO [train.py:450] Epoch 3, batch 11810, batch avg loss 0.3532, total avg loss: 0.3671, batch size: 39
2021-08-25 09:42:16,414 INFO [train.py:450] Epoch 3, batch 11820, batch avg loss 0.3582, total avg loss: 0.3589, batch size: 42
2021-08-25 09:42:23,479 INFO [train.py:450] Epoch 3, batch 11830, batch avg loss 0.3695, total avg loss: 0.3585, batch size: 38
2021-08-25 09:42:31,663 INFO [train.py:450] Epoch 3, batch 11840, batch avg loss 0.4289, total avg loss: 0.3578, batch size: 38
2021-08-25 09:42:38,535 INFO [train.py:450] Epoch 3, batch 11850, batch avg loss 0.4236, total avg loss: 0.3609, batch size: 35
2021-08-25 09:42:45,726 INFO [train.py:450] Epoch 3, batch 11860, batch avg loss 0.3665, total avg loss: 0.3615, batch size: 38
2021-08-25 09:42:52,756 INFO [train.py:450] Epoch 3, batch 11870, batch avg loss 0.3967, total avg loss: 0.3613, batch size: 39
2021-08-25 09:42:59,546 INFO [train.py:450] Epoch 3, batch 11880, batch avg loss 0.3536, total avg loss: 0.3604, batch size: 45
2021-08-25 09:43:05,987 INFO [train.py:450] Epoch 3, batch 11890, batch avg loss 0.3244, total avg loss: 0.3612, batch size: 39
2021-08-25 09:43:12,588 INFO [train.py:450] Epoch 3, batch 11900, batch avg loss 0.3668, total avg loss: 0.3609, batch size: 38
2021-08-25 09:43:19,701 INFO [train.py:450] Epoch 3, batch 11910, batch avg loss 0.3195, total avg loss: 0.3603, batch size: 43
2021-08-25 09:43:25,971 INFO [train.py:450] Epoch 3, batch 11920, batch avg loss 0.3579, total avg loss: 0.3603, batch size: 39
2021-08-25 09:43:32,365 INFO [train.py:450] Epoch 3, batch 11930, batch avg loss 0.3415, total avg loss: 0.3592, batch size: 37
2021-08-25 09:43:38,915 INFO [train.py:450] Epoch 3, batch 11940, batch avg loss 0.3839, total avg loss: 0.3594, batch size: 42
2021-08-25 09:43:46,063 INFO [train.py:450] Epoch 3, batch 11950, batch avg loss 0.3555, total avg loss: 0.3600, batch size: 45
2021-08-25 09:43:53,132 INFO [train.py:450] Epoch 3, batch 11960, batch avg loss 0.4379, total avg loss: 0.3607, batch size: 46
2021-08-25 09:44:00,240 INFO [train.py:450] Epoch 3, batch 11970, batch avg loss 0.3587, total avg loss: 0.3605, batch size: 39
2021-08-25 09:44:06,546 INFO [train.py:450] Epoch 3, batch 11980, batch avg loss 0.3647, total avg loss: 0.3610, batch size: 39
2021-08-25 09:44:13,620 INFO [train.py:450] Epoch 3, batch 11990, batch avg loss 0.3234, total avg loss: 0.3598, batch size: 40
2021-08-25 09:44:20,428 INFO [train.py:450] Epoch 3, batch 12000, batch avg loss 0.3550, total avg loss: 0.3587, batch size: 37
2021-08-25 09:44:58,262 INFO [train.py:482] Epoch 3, valid loss 0.2630, best valid loss: 0.2434 best valid epoch: 2
2021-08-25 09:45:03,959 INFO [train.py:450] Epoch 3, batch 12010, batch avg loss 0.3299, total avg loss: 0.3457, batch size: 39
2021-08-25 09:45:10,185 INFO [train.py:450] Epoch 3, batch 12020, batch avg loss 0.2975, total avg loss: 0.3474, batch size: 39
2021-08-25 09:45:16,884 INFO [train.py:450] Epoch 3, batch 12030, batch avg loss 0.3261, total avg loss: 0.3518, batch size: 41
2021-08-25 09:45:23,566 INFO [train.py:450] Epoch 3, batch 12040, batch avg loss 0.2972, total avg loss: 0.3492, batch size: 37
2021-08-25 09:45:30,516 INFO [train.py:450] Epoch 3, batch 12050, batch avg loss 0.3597, total avg loss: 0.3531, batch size: 42
2021-08-25 09:45:36,957 INFO [train.py:450] Epoch 3, batch 12060, batch avg loss 0.3789, total avg loss: 0.3540, batch size: 40
2021-08-25 09:45:43,871 INFO [train.py:450] Epoch 3, batch 12070, batch avg loss 0.3899, total avg loss: 0.3534, batch size: 41
2021-08-25 09:45:50,992 INFO [train.py:450] Epoch 3, batch 12080, batch avg loss 0.3823, total avg loss: 0.3549, batch size: 37
2021-08-25 09:45:57,315 INFO [train.py:450] Epoch 3, batch 12090, batch avg loss 0.4021, total avg loss: 0.3547, batch size: 36
2021-08-25 09:46:04,061 INFO [train.py:450] Epoch 3, batch 12100, batch avg loss 0.3403, total avg loss: 0.3544, batch size: 38
2021-08-25 09:46:11,055 INFO [train.py:450] Epoch 3, batch 12110, batch avg loss 0.3787, total avg loss: 0.3550, batch size: 38
2021-08-25 09:46:17,269 INFO [train.py:450] Epoch 3, batch 12120, batch avg loss 0.3826, total avg loss: 0.3550, batch size: 39
2021-08-25 09:46:24,060 INFO [train.py:450] Epoch 3, batch 12130, batch avg loss 0.3630, total avg loss: 0.3558, batch size: 40
2021-08-25 09:46:31,127 INFO [train.py:450] Epoch 3, batch 12140, batch avg loss 0.3612, total avg loss: 0.3561, batch size: 42
2021-08-25 09:46:37,710 INFO [train.py:450] Epoch 3, batch 12150, batch avg loss 0.3778, total avg loss: 0.3580, batch size: 38
2021-08-25 09:46:44,348 INFO [train.py:450] Epoch 3, batch 12160, batch avg loss 0.3329, total avg loss: 0.3570, batch size: 40
2021-08-25 09:46:51,269 INFO [train.py:450] Epoch 3, batch 12170, batch avg loss 0.4193, total avg loss: 0.3577, batch size: 38
2021-08-25 09:46:57,842 INFO [train.py:450] Epoch 3, batch 12180, batch avg loss 0.3634, total avg loss: 0.3583, batch size: 38
2021-08-25 09:47:03,877 INFO [train.py:450] Epoch 3, batch 12190, batch avg loss 0.3185, total avg loss: 0.3573, batch size: 39
2021-08-25 09:47:10,551 INFO [train.py:450] Epoch 3, batch 12200, batch avg loss 0.3656, total avg loss: 0.3565, batch size: 40
2021-08-25 09:47:17,292 INFO [train.py:450] Epoch 3, batch 12210, batch avg loss 0.3526, total avg loss: 0.3472, batch size: 38
2021-08-25 09:47:23,641 INFO [train.py:450] Epoch 3, batch 12220, batch avg loss 0.3555, total avg loss: 0.3534, batch size: 39
2021-08-25 09:47:30,032 INFO [train.py:450] Epoch 3, batch 12230, batch avg loss 0.3481, total avg loss: 0.3543, batch size: 40
2021-08-25 09:47:37,844 INFO [train.py:450] Epoch 3, batch 12240, batch avg loss 0.3213, total avg loss: 0.3535, batch size: 39
2021-08-25 09:47:44,245 INFO [train.py:450] Epoch 3, batch 12250, batch avg loss 0.3531, total avg loss: 0.3563, batch size: 40
2021-08-25 09:47:52,579 INFO [train.py:450] Epoch 3, batch 12260, batch avg loss 0.3586, total avg loss: 0.3554, batch size: 43
2021-08-25 09:47:59,616 INFO [train.py:450] Epoch 3, batch 12270, batch avg loss 0.3325, total avg loss: 0.3547, batch size: 39
2021-08-25 09:48:08,028 INFO [train.py:450] Epoch 3, batch 12280, batch avg loss 0.3553, total avg loss: 0.3565, batch size: 42
2021-08-25 09:48:14,355 INFO [train.py:450] Epoch 3, batch 12290, batch avg loss 0.3555, total avg loss: 0.3579, batch size: 46
2021-08-25 09:48:22,103 INFO [train.py:450] Epoch 3, batch 12300, batch avg loss 0.3338, total avg loss: 0.3592, batch size: 40
2021-08-25 09:48:29,814 INFO [train.py:450] Epoch 3, batch 12310, batch avg loss 0.3357, total avg loss: 0.3577, batch size: 41
2021-08-25 09:48:36,032 INFO [train.py:450] Epoch 3, batch 12320, batch avg loss 0.4010, total avg loss: 0.3575, batch size: 37
2021-08-25 09:48:42,421 INFO [train.py:450] Epoch 3, batch 12330, batch avg loss 0.3769, total avg loss: 0.3583, batch size: 44
2021-08-25 09:48:49,171 INFO [train.py:450] Epoch 3, batch 12340, batch avg loss 0.3898, total avg loss: 0.3587, batch size: 41
2021-08-25 09:48:55,572 INFO [train.py:450] Epoch 3, batch 12350, batch avg loss 0.4413, total avg loss: 0.3597, batch size: 36
2021-08-25 09:49:01,854 INFO [train.py:450] Epoch 3, batch 12360, batch avg loss 0.3241, total avg loss: 0.3600, batch size: 42
2021-08-25 09:49:08,143 INFO [train.py:450] Epoch 3, batch 12370, batch avg loss 0.3599, total avg loss: 0.3607, batch size: 39
2021-08-25 09:49:14,670 INFO [train.py:450] Epoch 3, batch 12380, batch avg loss 0.3752, total avg loss: 0.3613, batch size: 38
2021-08-25 09:49:21,303 INFO [train.py:450] Epoch 3, batch 12390, batch avg loss 0.4108, total avg loss: 0.3618, batch size: 44
2021-08-25 09:49:27,668 INFO [train.py:450] Epoch 3, batch 12400, batch avg loss 0.3812, total avg loss: 0.3619, batch size: 40
2021-08-25 09:49:34,603 INFO [train.py:450] Epoch 3, batch 12410, batch avg loss 0.3276, total avg loss: 0.3626, batch size: 39
2021-08-25 09:49:40,710 INFO [train.py:450] Epoch 3, batch 12420, batch avg loss 0.3239, total avg loss: 0.3646, batch size: 40
2021-08-25 09:49:47,116 INFO [train.py:450] Epoch 3, batch 12430, batch avg loss 0.3574, total avg loss: 0.3614, batch size: 39
2021-08-25 09:49:53,486 INFO [train.py:450] Epoch 3, batch 12440, batch avg loss 0.3387, total avg loss: 0.3588, batch size: 42
2021-08-25 09:49:59,536 INFO [train.py:450] Epoch 3, batch 12450, batch avg loss 0.3242, total avg loss: 0.3562, batch size: 42
2021-08-25 09:50:05,728 INFO [train.py:450] Epoch 3, batch 12460, batch avg loss 0.3702, total avg loss: 0.3576, batch size: 39
2021-08-25 09:50:11,895 INFO [train.py:450] Epoch 3, batch 12470, batch avg loss 0.4225, total avg loss: 0.3559, batch size: 42
2021-08-25 09:50:17,780 INFO [train.py:450] Epoch 3, batch 12480, batch avg loss 0.3335, total avg loss: 0.3556, batch size: 38
2021-08-25 09:50:24,521 INFO [train.py:450] Epoch 3, batch 12490, batch avg loss 0.3941, total avg loss: 0.3546, batch size: 40
2021-08-25 09:50:31,564 INFO [train.py:450] Epoch 3, batch 12500, batch avg loss 0.3780, total avg loss: 0.3545, batch size: 41
2021-08-25 09:50:38,442 INFO [train.py:450] Epoch 3, batch 12510, batch avg loss 0.4010, total avg loss: 0.3542, batch size: 39
2021-08-25 09:50:44,717 INFO [train.py:450] Epoch 3, batch 12520, batch avg loss 0.3593, total avg loss: 0.3547, batch size: 42
2021-08-25 09:50:51,214 INFO [train.py:450] Epoch 3, batch 12530, batch avg loss 0.3364, total avg loss: 0.3553, batch size: 39
2021-08-25 09:50:57,503 INFO [train.py:450] Epoch 3, batch 12540, batch avg loss 0.3544, total avg loss: 0.3552, batch size: 43
2021-08-25 09:51:05,578 INFO [train.py:450] Epoch 3, batch 12550, batch avg loss 0.3482, total avg loss: 0.3547, batch size: 37
2021-08-25 09:51:12,001 INFO [train.py:450] Epoch 3, batch 12560, batch avg loss 0.3335, total avg loss: 0.3554, batch size: 38
2021-08-25 09:51:20,727 INFO [train.py:450] Epoch 3, batch 12570, batch avg loss 0.3740, total avg loss: 0.3553, batch size: 38
2021-08-25 09:51:27,745 INFO [train.py:450] Epoch 3, batch 12580, batch avg loss 0.3050, total avg loss: 0.3552, batch size: 39
2021-08-25 09:51:33,946 INFO [train.py:450] Epoch 3, batch 12590, batch avg loss 0.3904, total avg loss: 0.3552, batch size: 47
2021-08-25 09:51:40,661 INFO [train.py:450] Epoch 3, batch 12600, batch avg loss 0.3364, total avg loss: 0.3558, batch size: 40
2021-08-25 09:51:46,535 INFO [train.py:450] Epoch 3, batch 12610, batch avg loss 0.3552, total avg loss: 0.3493, batch size: 37
2021-08-25 09:51:53,003 INFO [train.py:450] Epoch 3, batch 12620, batch avg loss 0.3260, total avg loss: 0.3579, batch size: 37
2021-08-25 09:51:58,925 INFO [train.py:450] Epoch 3, batch 12630, batch avg loss 0.3969, total avg loss: 0.3599, batch size: 38
2021-08-25 09:52:04,882 INFO [train.py:450] Epoch 3, batch 12640, batch avg loss 0.3723, total avg loss: 0.3621, batch size: 39
2021-08-25 09:52:10,681 INFO [train.py:450] Epoch 3, batch 12650, batch avg loss 0.3764, total avg loss: 0.3592, batch size: 44
2021-08-25 09:52:17,119 INFO [train.py:450] Epoch 3, batch 12660, batch avg loss 0.3688, total avg loss: 0.3593, batch size: 41
2021-08-25 09:52:23,853 INFO [train.py:450] Epoch 3, batch 12670, batch avg loss 0.3974, total avg loss: 0.3588, batch size: 42
2021-08-25 09:52:30,269 INFO [train.py:450] Epoch 3, batch 12680, batch avg loss 0.3608, total avg loss: 0.3595, batch size: 41
2021-08-25 09:52:36,543 INFO [train.py:450] Epoch 3, batch 12690, batch avg loss 0.3683, total avg loss: 0.3610, batch size: 41
2021-08-25 09:52:43,145 INFO [train.py:450] Epoch 3, batch 12700, batch avg loss 0.3342, total avg loss: 0.3627, batch size: 39
2021-08-25 09:52:49,470 INFO [train.py:450] Epoch 3, batch 12710, batch avg loss 0.3464, total avg loss: 0.3660, batch size: 37
2021-08-25 09:52:55,771 INFO [train.py:450] Epoch 3, batch 12720, batch avg loss 0.3902, total avg loss: 0.3711, batch size: 39
2021-08-25 09:53:01,819 INFO [train.py:450] Epoch 3, batch 12730, batch avg loss 0.4464, total avg loss: 0.3750, batch size: 39
2021-08-25 09:53:07,886 INFO [train.py:450] Epoch 3, batch 12740, batch avg loss 0.3129, total avg loss: 0.3746, batch size: 45
2021-08-25 09:53:14,191 INFO [train.py:450] Epoch 3, batch 12750, batch avg loss 0.3916, total avg loss: 0.3755, batch size: 37
2021-08-25 09:53:20,265 INFO [train.py:450] Epoch 3, batch 12760, batch avg loss 0.4021, total avg loss: 0.3760, batch size: 41
2021-08-25 09:53:26,423 INFO [train.py:450] Epoch 3, batch 12770, batch avg loss 0.3298, total avg loss: 0.3765, batch size: 38
2021-08-25 09:53:32,449 INFO [train.py:450] Epoch 3, batch 12780, batch avg loss 0.3967, total avg loss: 0.3763, batch size: 41
2021-08-25 09:53:38,296 INFO [train.py:450] Epoch 3, batch 12790, batch avg loss 0.3857, total avg loss: 0.3758, batch size: 40
2021-08-25 09:53:44,220 INFO [train.py:450] Epoch 3, batch 12800, batch avg loss 0.3878, total avg loss: 0.3754, batch size: 42
2021-08-25 09:53:50,075 INFO [train.py:450] Epoch 3, batch 12810, batch avg loss 0.3488, total avg loss: 0.3770, batch size: 40
2021-08-25 09:53:55,935 INFO [train.py:450] Epoch 3, batch 12820, batch avg loss 0.4277, total avg loss: 0.3783, batch size: 40
2021-08-25 09:54:01,908 INFO [train.py:450] Epoch 3, batch 12830, batch avg loss 0.3526, total avg loss: 0.3663, batch size: 40
2021-08-25 09:54:08,190 INFO [train.py:450] Epoch 3, batch 12840, batch avg loss 0.3606, total avg loss: 0.3626, batch size: 43
2021-08-25 09:54:14,054 INFO [train.py:450] Epoch 3, batch 12850, batch avg loss 0.2931, total avg loss: 0.3604, batch size: 37
2021-08-25 09:54:20,080 INFO [train.py:450] Epoch 3, batch 12860, batch avg loss 0.3679, total avg loss: 0.3584, batch size: 37
2021-08-25 09:54:26,024 INFO [train.py:450] Epoch 3, batch 12870, batch avg loss 0.3627, total avg loss: 0.3582, batch size: 41
2021-08-25 09:54:32,862 INFO [train.py:450] Epoch 3, batch 12880, batch avg loss 0.3538, total avg loss: 0.3558, batch size: 39
2021-08-25 09:54:38,696 INFO [train.py:450] Epoch 3, batch 12890, batch avg loss 0.3107, total avg loss: 0.3568, batch size: 40
2021-08-25 09:54:47,631 INFO [train.py:450] Epoch 3, batch 12900, batch avg loss 0.3641, total avg loss: 0.3583, batch size: 39
2021-08-25 09:54:53,566 INFO [train.py:450] Epoch 3, batch 12910, batch avg loss 0.3408, total avg loss: 0.3586, batch size: 41
2021-08-25 09:55:06,443 INFO [train.py:450] Epoch 3, batch 12920, batch avg loss 0.3620, total avg loss: 0.3586, batch size: 40
2021-08-25 09:55:12,432 INFO [train.py:450] Epoch 3, batch 12930, batch avg loss 0.3236, total avg loss: 0.3565, batch size: 38
2021-08-25 09:55:18,297 INFO [train.py:450] Epoch 3, batch 12940, batch avg loss 0.3636, total avg loss: 0.3567, batch size: 38
2021-08-25 09:55:24,276 INFO [train.py:450] Epoch 3, batch 12950, batch avg loss 0.4258, total avg loss: 0.3574, batch size: 40
2021-08-25 09:55:30,296 INFO [train.py:450] Epoch 3, batch 12960, batch avg loss 0.4124, total avg loss: 0.3575, batch size: 39
2021-08-25 09:55:36,194 INFO [train.py:450] Epoch 3, batch 12970, batch avg loss 0.3876, total avg loss: 0.3575, batch size: 36
2021-08-25 09:55:42,084 INFO [train.py:450] Epoch 3, batch 12980, batch avg loss 0.3628, total avg loss: 0.3585, batch size: 42
2021-08-25 09:55:47,961 INFO [train.py:450] Epoch 3, batch 12990, batch avg loss 0.3186, total avg loss: 0.3583, batch size: 41
2021-08-25 09:55:54,046 INFO [train.py:450] Epoch 3, batch 13000, batch avg loss 0.3366, total avg loss: 0.3585, batch size: 40
2021-08-25 09:56:31,375 INFO [train.py:482] Epoch 3, valid loss 0.2516, best valid loss: 0.2434 best valid epoch: 2
2021-08-25 09:56:37,286 INFO [train.py:450] Epoch 3, batch 13010, batch avg loss 0.3250, total avg loss: 0.3417, batch size: 41
2021-08-25 09:56:43,237 INFO [train.py:450] Epoch 3, batch 13020, batch avg loss 0.3601, total avg loss: 0.3554, batch size: 36
2021-08-25 09:56:49,036 INFO [train.py:450] Epoch 3, batch 13030, batch avg loss 0.2816, total avg loss: 0.3554, batch size: 39
2021-08-25 09:56:54,887 INFO [train.py:450] Epoch 3, batch 13040, batch avg loss 0.3531, total avg loss: 0.3564, batch size: 41
2021-08-25 09:57:00,753 INFO [train.py:450] Epoch 3, batch 13050, batch avg loss 0.2854, total avg loss: 0.3544, batch size: 37
2021-08-25 09:57:06,688 INFO [train.py:450] Epoch 3, batch 13060, batch avg loss 0.3539, total avg loss: 0.3573, batch size: 42
2021-08-25 09:57:12,617 INFO [train.py:450] Epoch 3, batch 13070, batch avg loss 0.3923, total avg loss: 0.3592, batch size: 36
2021-08-25 09:57:18,578 INFO [train.py:450] Epoch 3, batch 13080, batch avg loss 0.2936, total avg loss: 0.3600, batch size: 37
2021-08-25 09:57:24,454 INFO [train.py:450] Epoch 3, batch 13090, batch avg loss 0.3016, total avg loss: 0.3596, batch size: 41
2021-08-25 09:57:31,624 INFO [train.py:450] Epoch 3, batch 13100, batch avg loss 0.3825, total avg loss: 0.3596, batch size: 43
2021-08-25 09:57:37,481 INFO [train.py:450] Epoch 3, batch 13110, batch avg loss 0.3015, total avg loss: 0.3607, batch size: 36
2021-08-25 09:57:45,974 INFO [train.py:450] Epoch 3, batch 13120, batch avg loss 0.4813, total avg loss: 0.3624, batch size: 37
2021-08-25 09:57:51,979 INFO [train.py:450] Epoch 3, batch 13130, batch avg loss 0.3345, total avg loss: 0.3619, batch size: 40
2021-08-25 09:57:57,819 INFO [train.py:450] Epoch 3, batch 13140, batch avg loss 0.3860, total avg loss: 0.3620, batch size: 42
2021-08-25 09:58:03,661 INFO [train.py:450] Epoch 3, batch 13150, batch avg loss 0.4010, total avg loss: 0.3613, batch size: 36
2021-08-25 09:58:09,465 INFO [train.py:450] Epoch 3, batch 13160, batch avg loss 0.3186, total avg loss: 0.3608, batch size: 37
2021-08-25 09:58:15,501 INFO [train.py:450] Epoch 3, batch 13170, batch avg loss 0.3817, total avg loss: 0.3610, batch size: 41
2021-08-25 09:58:21,461 INFO [train.py:450] Epoch 3, batch 13180, batch avg loss 0.3728, total avg loss: 0.3610, batch size: 39
2021-08-25 09:58:27,393 INFO [train.py:450] Epoch 3, batch 13190, batch avg loss 0.2802, total avg loss: 0.3607, batch size: 40
2021-08-25 09:58:33,263 INFO [train.py:450] Epoch 3, batch 13200, batch avg loss 0.3340, total avg loss: 0.3605, batch size: 40
2021-08-25 09:58:39,109 INFO [train.py:450] Epoch 3, batch 13210, batch avg loss 0.3510, total avg loss: 0.3642, batch size: 42
2021-08-25 09:58:44,857 INFO [train.py:450] Epoch 3, batch 13220, batch avg loss 0.4484, total avg loss: 0.3561, batch size: 41
2021-08-25 09:58:50,671 INFO [train.py:450] Epoch 3, batch 13230, batch avg loss 0.3438, total avg loss: 0.3523, batch size: 40
2021-08-25 09:58:56,553 INFO [train.py:450] Epoch 3, batch 13240, batch avg loss 0.3402, total avg loss: 0.3552, batch size: 41
2021-08-25 09:59:02,374 INFO [train.py:450] Epoch 3, batch 13250, batch avg loss 0.3590, total avg loss: 0.3579, batch size: 38
2021-08-25 09:59:08,541 INFO [train.py:450] Epoch 3, batch 13260, batch avg loss 0.3424, total avg loss: 0.3559, batch size: 41
2021-08-25 09:59:14,531 INFO [train.py:450] Epoch 3, batch 13270, batch avg loss 0.3839, total avg loss: 0.3552, batch size: 40
2021-08-25 09:59:20,421 INFO [train.py:450] Epoch 3, batch 13280, batch avg loss 0.3545, total avg loss: 0.3524, batch size: 40
2021-08-25 09:59:26,254 INFO [train.py:450] Epoch 3, batch 13290, batch avg loss 0.3740, total avg loss: 0.3524, batch size: 38
2021-08-25 09:59:32,219 INFO [train.py:450] Epoch 3, batch 13300, batch avg loss 0.4248, total avg loss: 0.3539, batch size: 39
2021-08-25 09:59:38,067 INFO [train.py:450] Epoch 3, batch 13310, batch avg loss 0.3263, total avg loss: 0.3551, batch size: 40
2021-08-25 09:59:43,979 INFO [train.py:450] Epoch 3, batch 13320, batch avg loss 0.3525, total avg loss: 0.3553, batch size: 42
2021-08-25 09:59:49,747 INFO [train.py:450] Epoch 3, batch 13330, batch avg loss 0.3868, total avg loss: 0.3552, batch size: 38
2021-08-25 09:59:55,588 INFO [train.py:450] Epoch 3, batch 13340, batch avg loss 0.3583, total avg loss: 0.3560, batch size: 40
2021-08-25 10:00:01,381 INFO [train.py:450] Epoch 3, batch 13350, batch avg loss 0.3298, total avg loss: 0.3565, batch size: 39
2021-08-25 10:00:07,216 INFO [train.py:450] Epoch 3, batch 13360, batch avg loss 0.4047, total avg loss: 0.3565, batch size: 37
2021-08-25 10:00:13,092 INFO [train.py:450] Epoch 3, batch 13370, batch avg loss 0.3777, total avg loss: 0.3560, batch size: 39
2021-08-25 10:00:19,080 INFO [train.py:450] Epoch 3, batch 13380, batch avg loss 0.4162, total avg loss: 0.3568, batch size: 42
2021-08-25 10:00:25,164 INFO [train.py:450] Epoch 3, batch 13390, batch avg loss 0.3681, total avg loss: 0.3567, batch size: 38
2021-08-25 10:00:31,020 INFO [train.py:450] Epoch 3, batch 13400, batch avg loss 0.3740, total avg loss: 0.3555, batch size: 39
2021-08-25 10:00:36,758 INFO [train.py:450] Epoch 3, batch 13410, batch avg loss 0.4114, total avg loss: 0.3670, batch size: 38
2021-08-25 10:00:42,621 INFO [train.py:450] Epoch 3, batch 13420, batch avg loss 0.3704, total avg loss: 0.3591, batch size: 36
2021-08-25 10:00:49,742 INFO [train.py:450] Epoch 3, batch 13430, batch avg loss 0.3627, total avg loss: 0.3525, batch size: 39
2021-08-25 10:00:56,573 INFO [train.py:450] Epoch 3, batch 13440, batch avg loss 0.3228, total avg loss: 0.3533, batch size: 38
2021-08-25 10:01:03,999 INFO [train.py:450] Epoch 3, batch 13450, batch avg loss 0.3394, total avg loss: 0.3530, batch size: 36
2021-08-25 10:01:09,902 INFO [train.py:450] Epoch 3, batch 13460, batch avg loss 0.2999, total avg loss: 0.3566, batch size: 38
2021-08-25 10:01:15,779 INFO [train.py:450] Epoch 3, batch 13470, batch avg loss 0.4091, total avg loss: 0.3582, batch size: 40
2021-08-25 10:01:21,534 INFO [train.py:450] Epoch 3, batch 13480, batch avg loss 0.3502, total avg loss: 0.3575, batch size: 38
2021-08-25 10:01:27,323 INFO [train.py:450] Epoch 3, batch 13490, batch avg loss 0.3790, total avg loss: 0.3572, batch size: 37
2021-08-25 10:01:33,181 INFO [train.py:450] Epoch 3, batch 13500, batch avg loss 0.3111, total avg loss: 0.3572, batch size: 39
2021-08-25 10:01:38,983 INFO [train.py:450] Epoch 3, batch 13510, batch avg loss 0.3714, total avg loss: 0.3556, batch size: 40
2021-08-25 10:01:44,859 INFO [train.py:450] Epoch 3, batch 13520, batch avg loss 0.3282, total avg loss: 0.3555, batch size: 39
2021-08-25 10:01:50,624 INFO [train.py:450] Epoch 3, batch 13530, batch avg loss 0.3565, total avg loss: 0.3560, batch size: 41
2021-08-25 10:01:56,612 INFO [train.py:450] Epoch 3, batch 13540, batch avg loss 0.3885, total avg loss: 0.3561, batch size: 39
2021-08-25 10:02:02,331 INFO [train.py:450] Epoch 3, batch 13550, batch avg loss 0.3218, total avg loss: 0.3557, batch size: 39
2021-08-25 10:02:08,256 INFO [train.py:450] Epoch 3, batch 13560, batch avg loss 0.3292, total avg loss: 0.3560, batch size: 37
2021-08-25 10:02:14,164 INFO [train.py:450] Epoch 3, batch 13570, batch avg loss 0.3832, total avg loss: 0.3564, batch size: 44
2021-08-25 10:02:20,117 INFO [train.py:450] Epoch 3, batch 13580, batch avg loss 0.3470, total avg loss: 0.3562, batch size: 39
2021-08-25 10:02:26,163 INFO [train.py:450] Epoch 3, batch 13590, batch avg loss 0.3674, total avg loss: 0.3563, batch size: 40
2021-08-25 10:02:32,111 INFO [train.py:450] Epoch 3, batch 13600, batch avg loss 0.3881, total avg loss: 0.3553, batch size: 38
2021-08-25 10:02:37,916 INFO [train.py:450] Epoch 3, batch 13610, batch avg loss 0.4122, total avg loss: 0.3501, batch size: 41
2021-08-25 10:02:43,826 INFO [train.py:450] Epoch 3, batch 13620, batch avg loss 0.4059, total avg loss: 0.3515, batch size: 42
2021-08-25 10:02:49,731 INFO [train.py:450] Epoch 3, batch 13630, batch avg loss 0.3117, total avg loss: 0.3504, batch size: 42
2021-08-25 10:02:55,650 INFO [train.py:450] Epoch 3, batch 13640, batch avg loss 0.3460, total avg loss: 0.3515, batch size: 37
2021-08-25 10:03:01,792 INFO [train.py:450] Epoch 3, batch 13650, batch avg loss 0.3673, total avg loss: 0.3472, batch size: 41
2021-08-25 10:03:07,654 INFO [train.py:450] Epoch 3, batch 13660, batch avg loss 0.3527, total avg loss: 0.3469, batch size: 39
2021-08-25 10:03:13,605 INFO [train.py:450] Epoch 3, batch 13670, batch avg loss 0.3388, total avg loss: 0.3492, batch size: 41
2021-08-25 10:03:19,364 INFO [train.py:450] Epoch 3, batch 13680, batch avg loss 0.3582, total avg loss: 0.3489, batch size: 39
2021-08-25 10:03:25,342 INFO [train.py:450] Epoch 3, batch 13690, batch avg loss 0.3570, total avg loss: 0.3487, batch size: 43
2021-08-25 10:03:31,294 INFO [train.py:450] Epoch 3, batch 13700, batch avg loss 0.3641, total avg loss: 0.3498, batch size: 38
2021-08-25 10:03:37,139 INFO [train.py:450] Epoch 3, batch 13710, batch avg loss 0.3485, total avg loss: 0.3497, batch size: 38
2021-08-25 10:03:43,054 INFO [train.py:450] Epoch 3, batch 13720, batch avg loss 0.3286, total avg loss: 0.3516, batch size: 40
2021-08-25 10:03:48,885 INFO [train.py:450] Epoch 3, batch 13730, batch avg loss 0.3650, total avg loss: 0.3536, batch size: 41
2021-08-25 10:03:55,511 INFO [train.py:450] Epoch 3, batch 13740, batch avg loss 0.3606, total avg loss: 0.3551, batch size: 40
2021-08-25 10:04:01,390 INFO [train.py:450] Epoch 3, batch 13750, batch avg loss 0.4639, total avg loss: 0.3601, batch size: 44
2021-08-25 10:04:07,429 INFO [train.py:450] Epoch 3, batch 13760, batch avg loss 0.4555, total avg loss: 0.3653, batch size: 39
2021-08-25 10:04:14,105 INFO [train.py:450] Epoch 3, batch 13770, batch avg loss 0.3749, total avg loss: 0.3672, batch size: 38
2021-08-25 10:04:19,874 INFO [train.py:450] Epoch 3, batch 13780, batch avg loss 0.3630, total avg loss: 0.3677, batch size: 37
2021-08-25 10:04:25,805 INFO [train.py:450] Epoch 3, batch 13790, batch avg loss 0.3864, total avg loss: 0.3687, batch size: 39
2021-08-25 10:04:31,621 INFO [train.py:450] Epoch 3, batch 13800, batch avg loss 0.3532, total avg loss: 0.3681, batch size: 40
2021-08-25 10:04:37,533 INFO [train.py:450] Epoch 3, batch 13810, batch avg loss 0.4113, total avg loss: 0.3798, batch size: 38
2021-08-25 10:04:43,451 INFO [train.py:450] Epoch 3, batch 13820, batch avg loss 0.3331, total avg loss: 0.3710, batch size: 39
2021-08-25 10:04:49,294 INFO [train.py:450] Epoch 3, batch 13830, batch avg loss 0.3133, total avg loss: 0.3660, batch size: 42
2021-08-25 10:04:55,189 INFO [train.py:450] Epoch 3, batch 13840, batch avg loss 0.4393, total avg loss: 0.3670, batch size: 43
2021-08-25 10:05:01,114 INFO [train.py:450] Epoch 3, batch 13850, batch avg loss 0.3561, total avg loss: 0.3695, batch size: 38
2021-08-25 10:05:06,950 INFO [train.py:450] Epoch 3, batch 13860, batch avg loss 0.4564, total avg loss: 0.3721, batch size: 40
2021-08-25 10:05:12,754 INFO [train.py:450] Epoch 3, batch 13870, batch avg loss 0.4147, total avg loss: 0.3742, batch size: 42
2021-08-25 10:05:18,554 INFO [train.py:450] Epoch 3, batch 13880, batch avg loss 0.3316, total avg loss: 0.3714, batch size: 39
2021-08-25 10:05:24,447 INFO [train.py:450] Epoch 3, batch 13890, batch avg loss 0.3527, total avg loss: 0.3724, batch size: 39
2021-08-25 10:05:30,265 INFO [train.py:450] Epoch 3, batch 13900, batch avg loss 0.4155, total avg loss: 0.3723, batch size: 38
2021-08-25 10:05:36,170 INFO [train.py:450] Epoch 3, batch 13910, batch avg loss 0.4047, total avg loss: 0.3740, batch size: 41
2021-08-25 10:05:42,019 INFO [train.py:450] Epoch 3, batch 13920, batch avg loss 0.3640, total avg loss: 0.3754, batch size: 39
2021-08-25 10:05:47,916 INFO [train.py:450] Epoch 3, batch 13930, batch avg loss 0.3647, total avg loss: 0.3784, batch size: 36
2021-08-25 10:05:53,856 INFO [train.py:450] Epoch 3, batch 13940, batch avg loss 0.3819, total avg loss: 0.3782, batch size: 39
2021-08-25 10:05:59,690 INFO [train.py:450] Epoch 3, batch 13950, batch avg loss 0.3975, total avg loss: 0.3795, batch size: 40
2021-08-25 10:06:05,579 INFO [train.py:450] Epoch 3, batch 13960, batch avg loss 0.4401, total avg loss: 0.3820, batch size: 41
2021-08-25 10:06:11,538 INFO [train.py:450] Epoch 3, batch 13970, batch avg loss 0.4072, total avg loss: 0.3850, batch size: 40
2021-08-25 10:06:17,320 INFO [train.py:450] Epoch 3, batch 13980, batch avg loss 0.4377, total avg loss: 0.3868, batch size: 41
2021-08-25 10:06:23,175 INFO [train.py:450] Epoch 3, batch 13990, batch avg loss 0.4368, total avg loss: 0.3888, batch size: 39
2021-08-25 10:06:29,044 INFO [train.py:450] Epoch 3, batch 14000, batch avg loss 0.4311, total avg loss: 0.3903, batch size: 42
2021-08-25 10:07:06,327 INFO [train.py:482] Epoch 3, valid loss 0.2707, best valid loss: 0.2434 best valid epoch: 2
2021-08-25 10:07:12,163 INFO [train.py:450] Epoch 3, batch 14010, batch avg loss 0.4247, total avg loss: 0.4034, batch size: 42
2021-08-25 10:07:18,017 INFO [train.py:450] Epoch 3, batch 14020, batch avg loss 0.4063, total avg loss: 0.4027, batch size: 38
2021-08-25 10:07:25,982 INFO [train.py:450] Epoch 3, batch 14030, batch avg loss 0.3885, total avg loss: 0.3967, batch size: 40
2021-08-25 10:07:31,880 INFO [train.py:450] Epoch 3, batch 14040, batch avg loss 0.3513, total avg loss: 0.3935, batch size: 40
2021-08-25 10:07:37,701 INFO [train.py:450] Epoch 3, batch 14050, batch avg loss 0.3609, total avg loss: 0.3908, batch size: 37
2021-08-25 10:07:43,455 INFO [train.py:450] Epoch 3, batch 14060, batch avg loss 0.3775, total avg loss: 0.3869, batch size: 39
2021-08-25 10:07:49,204 INFO [train.py:450] Epoch 3, batch 14070, batch avg loss 0.3382, total avg loss: 0.3847, batch size: 40
2021-08-25 10:07:55,138 INFO [train.py:450] Epoch 3, batch 14080, batch avg loss 0.3414, total avg loss: 0.3815, batch size: 40
2021-08-25 10:08:01,041 INFO [train.py:450] Epoch 3, batch 14090, batch avg loss 0.3398, total avg loss: 0.3817, batch size: 37
2021-08-25 10:08:06,965 INFO [train.py:450] Epoch 3, batch 14100, batch avg loss 0.4058, total avg loss: 0.3802, batch size: 41
2021-08-25 10:08:12,889 INFO [train.py:450] Epoch 3, batch 14110, batch avg loss 0.3575, total avg loss: 0.3805, batch size: 40
2021-08-25 10:08:18,660 INFO [train.py:450] Epoch 3, batch 14120, batch avg loss 0.3949, total avg loss: 0.3805, batch size: 40
2021-08-25 10:08:25,097 INFO [train.py:450] Epoch 3, batch 14130, batch avg loss 0.3059, total avg loss: 0.3782, batch size: 43
2021-08-25 10:08:31,011 INFO [train.py:450] Epoch 3, batch 14140, batch avg loss 0.3995, total avg loss: 0.3773, batch size: 41
2021-08-25 10:08:36,920 INFO [train.py:450] Epoch 3, batch 14150, batch avg loss 0.3593, total avg loss: 0.3763, batch size: 41
2021-08-25 10:08:42,824 INFO [train.py:450] Epoch 3, batch 14160, batch avg loss 0.3215, total avg loss: 0.3759, batch size: 40
2021-08-25 10:08:48,669 INFO [train.py:450] Epoch 3, batch 14170, batch avg loss 0.3191, total avg loss: 0.3749, batch size: 39
2021-08-25 10:08:54,335 INFO [train.py:450] Epoch 3, batch 14180, batch avg loss 0.3745, total avg loss: 0.3741, batch size: 36
2021-08-25 10:09:00,214 INFO [train.py:450] Epoch 3, batch 14190, batch avg loss 0.3329, total avg loss: 0.3732, batch size: 40
2021-08-25 10:09:05,941 INFO [train.py:450] Epoch 3, batch 14200, batch avg loss 0.3310, total avg loss: 0.3724, batch size: 39
2021-08-25 10:09:11,683 INFO [train.py:450] Epoch 3, batch 14210, batch avg loss 0.3570, total avg loss: 0.3617, batch size: 38
2021-08-25 10:09:17,571 INFO [train.py:450] Epoch 3, batch 14220, batch avg loss 0.3821, total avg loss: 0.3726, batch size: 41
2021-08-25 10:09:23,430 INFO [train.py:450] Epoch 3, batch 14230, batch avg loss 0.3120, total avg loss: 0.3693, batch size: 40
2021-08-25 10:09:29,267 INFO [train.py:450] Epoch 3, batch 14240, batch avg loss 0.3757, total avg loss: 0.3663, batch size: 39
2021-08-25 10:09:35,210 INFO [train.py:450] Epoch 3, batch 14250, batch avg loss 0.3758, total avg loss: 0.3631, batch size: 37
2021-08-25 10:09:41,140 INFO [train.py:450] Epoch 3, batch 14260, batch avg loss 0.4359, total avg loss: 0.3656, batch size: 43
2021-08-25 10:09:46,898 INFO [train.py:450] Epoch 3, batch 14270, batch avg loss 0.3460, total avg loss: 0.3637, batch size: 39
2021-08-25 10:09:52,800 INFO [train.py:450] Epoch 3, batch 14280, batch avg loss 0.4121, total avg loss: 0.3635, batch size: 39
2021-08-25 10:09:58,676 INFO [train.py:450] Epoch 3, batch 14290, batch avg loss 0.3325, total avg loss: 0.3626, batch size: 41
2021-08-25 10:10:04,458 INFO [train.py:450] Epoch 3, batch 14300, batch avg loss 0.2888, total avg loss: 0.3608, batch size: 41
2021-08-25 10:10:10,259 INFO [train.py:450] Epoch 3, batch 14310, batch avg loss 0.2937, total avg loss: 0.3600, batch size: 40
2021-08-25 10:10:16,206 INFO [train.py:450] Epoch 3, batch 14320, batch avg loss 0.4035, total avg loss: 0.3604, batch size: 41
2021-08-25 10:10:22,049 INFO [train.py:450] Epoch 3, batch 14330, batch avg loss 0.3911, total avg loss: 0.3620, batch size: 40
2021-08-25 10:10:27,945 INFO [train.py:450] Epoch 3, batch 14340, batch avg loss 0.3959, total avg loss: 0.3613, batch size: 41
2021-08-25 10:10:33,805 INFO [train.py:450] Epoch 3, batch 14350, batch avg loss 0.3798, total avg loss: 0.3609, batch size: 39
2021-08-25 10:10:39,674 INFO [train.py:450] Epoch 3, batch 14360, batch avg loss 0.3230, total avg loss: 0.3603, batch size: 39
2021-08-25 10:10:46,673 INFO [train.py:450] Epoch 3, batch 14370, batch avg loss 0.3405, total avg loss: 0.3599, batch size: 37
2021-08-25 10:10:52,664 INFO [train.py:450] Epoch 3, batch 14380, batch avg loss 0.3327, total avg loss: 0.3593, batch size: 37
2021-08-25 10:10:58,619 INFO [train.py:450] Epoch 3, batch 14390, batch avg loss 0.3865, total avg loss: 0.3594, batch size: 40
2021-08-25 10:11:04,570 INFO [train.py:450] Epoch 3, batch 14400, batch avg loss 0.3840, total avg loss: 0.3595, batch size: 46
2021-08-25 10:11:10,451 INFO [train.py:450] Epoch 3, batch 14410, batch avg loss 0.3687, total avg loss: 0.3598, batch size: 38
2021-08-25 10:11:16,228 INFO [train.py:450] Epoch 3, batch 14420, batch avg loss 0.3509, total avg loss: 0.3636, batch size: 40
2021-08-25 10:11:22,096 INFO [train.py:450] Epoch 3, batch 14430, batch avg loss 0.3608, total avg loss: 0.3648, batch size: 41
2021-08-25 10:11:28,105 INFO [train.py:450] Epoch 3, batch 14440, batch avg loss 0.3716, total avg loss: 0.3614, batch size: 40
2021-08-25 10:11:33,895 INFO [train.py:450] Epoch 3, batch 14450, batch avg loss 0.3653, total avg loss: 0.3616, batch size: 40
2021-08-25 10:11:39,791 INFO [train.py:450] Epoch 3, batch 14460, batch avg loss 0.3406, total avg loss: 0.3605, batch size: 43
2021-08-25 10:11:45,742 INFO [train.py:450] Epoch 3, batch 14470, batch avg loss 0.3391, total avg loss: 0.3600, batch size: 41
2021-08-25 10:11:51,552 INFO [train.py:450] Epoch 3, batch 14480, batch avg loss 0.3616, total avg loss: 0.3589, batch size: 37
2021-08-25 10:11:57,371 INFO [train.py:450] Epoch 3, batch 14490, batch avg loss 0.3879, total avg loss: 0.3596, batch size: 38
2021-08-25 10:12:03,325 INFO [train.py:450] Epoch 3, batch 14500, batch avg loss 0.3309, total avg loss: 0.3589, batch size: 42
2021-08-25 10:12:09,216 INFO [train.py:450] Epoch 3, batch 14510, batch avg loss 0.3175, total avg loss: 0.3585, batch size: 38
2021-08-25 10:12:15,334 INFO [train.py:450] Epoch 3, batch 14520, batch avg loss 0.4212, total avg loss: 0.3592, batch size: 39
2021-08-25 10:12:21,107 INFO [train.py:450] Epoch 3, batch 14530, batch avg loss 0.3717, total avg loss: 0.3582, batch size: 41
2021-08-25 10:12:26,984 INFO [train.py:450] Epoch 3, batch 14540, batch avg loss 0.4258, total avg loss: 0.3583, batch size: 41
2021-08-25 10:12:32,937 INFO [train.py:450] Epoch 3, batch 14550, batch avg loss 0.3421, total avg loss: 0.3583, batch size: 45
2021-08-25 10:12:38,700 INFO [train.py:450] Epoch 3, batch 14560, batch avg loss 0.3657, total avg loss: 0.3592, batch size: 41
2021-08-25 10:12:44,560 INFO [train.py:450] Epoch 3, batch 14570, batch avg loss 0.3434, total avg loss: 0.3588, batch size: 40
2021-08-25 10:12:50,443 INFO [train.py:450] Epoch 3, batch 14580, batch avg loss 0.3089, total avg loss: 0.3579, batch size: 40
2021-08-25 10:12:56,351 INFO [train.py:450] Epoch 3, batch 14590, batch avg loss 0.3608, total avg loss: 0.3575, batch size: 40
2021-08-25 10:13:02,082 INFO [train.py:450] Epoch 3, batch 14600, batch avg loss 0.3160, total avg loss: 0.3575, batch size: 39
2021-08-25 10:13:07,870 INFO [train.py:450] Epoch 3, batch 14610, batch avg loss 0.3510, total avg loss: 0.3512, batch size: 42
2021-08-25 10:13:13,656 INFO [train.py:450] Epoch 3, batch 14620, batch avg loss 0.3318, total avg loss: 0.3659, batch size: 42
2021-08-25 10:13:19,509 INFO [train.py:450] Epoch 3, batch 14630, batch avg loss 0.4064, total avg loss: 0.3599, batch size: 39
2021-08-25 10:13:25,508 INFO [train.py:450] Epoch 3, batch 14640, batch avg loss 0.3340, total avg loss: 0.3567, batch size: 38
2021-08-25 10:13:31,365 INFO [train.py:450] Epoch 3, batch 14650, batch avg loss 0.3828, total avg loss: 0.3586, batch size: 41
2021-08-25 10:13:37,166 INFO [train.py:450] Epoch 3, batch 14660, batch avg loss 0.3536, total avg loss: 0.3561, batch size: 44
2021-08-25 10:13:43,121 INFO [train.py:450] Epoch 3, batch 14670, batch avg loss 0.3612, total avg loss: 0.3590, batch size: 43
2021-08-25 10:13:48,920 INFO [train.py:450] Epoch 3, batch 14680, batch avg loss 0.3373, total avg loss: 0.3602, batch size: 40
2021-08-25 10:13:54,852 INFO [train.py:450] Epoch 3, batch 14690, batch avg loss 0.3775, total avg loss: 0.3601, batch size: 40
2021-08-25 10:14:00,624 INFO [train.py:450] Epoch 3, batch 14700, batch avg loss 0.3444, total avg loss: 0.3593, batch size: 40
2021-08-25 10:14:06,615 INFO [train.py:450] Epoch 3, batch 14710, batch avg loss 0.3630, total avg loss: 0.3598, batch size: 42
2021-08-25 10:14:12,429 INFO [train.py:450] Epoch 3, batch 14720, batch avg loss 0.3477, total avg loss: 0.3590, batch size: 38
2021-08-25 10:14:19,808 INFO [train.py:450] Epoch 3, batch 14730, batch avg loss 0.3783, total avg loss: 0.3587, batch size: 35
2021-08-25 10:14:25,646 INFO [train.py:450] Epoch 3, batch 14740, batch avg loss 0.3927, total avg loss: 0.3597, batch size: 41
2021-08-25 10:14:26,465 WARNING [cut.py:1694] To perform mix, energy must be non-zero and non-negative (got 0.0).  MonoCut with id "fb750f05-7c72-4e6b-756d-248c5359c5bd" will not be mixed in.
2021-08-25 10:14:31,549 INFO [train.py:450] Epoch 3, batch 14750, batch avg loss 0.3778, total avg loss: 0.3601, batch size: 39
2021-08-25 10:14:37,443 INFO [train.py:450] Epoch 3, batch 14760, batch avg loss 0.3687, total avg loss: 0.3598, batch size: 38
2021-08-25 10:14:43,314 INFO [train.py:450] Epoch 3, batch 14770, batch avg loss 0.3618, total avg loss: 0.3588, batch size: 40
2021-08-25 10:14:49,148 INFO [train.py:450] Epoch 3, batch 14780, batch avg loss 0.3443, total avg loss: 0.3581, batch size: 39
2021-08-25 10:14:54,867 INFO [train.py:450] Epoch 3, batch 14790, batch avg loss 0.3577, total avg loss: 0.3580, batch size: 38
2021-08-25 10:15:00,894 INFO [train.py:450] Epoch 3, batch 14800, batch avg loss 0.3747, total avg loss: 0.3580, batch size: 40
2021-08-25 10:15:06,781 INFO [train.py:450] Epoch 3, batch 14810, batch avg loss 0.3390, total avg loss: 0.3508, batch size: 43
2021-08-25 10:15:12,770 INFO [train.py:450] Epoch 3, batch 14820, batch avg loss 0.3502, total avg loss: 0.3488, batch size: 38
2021-08-25 10:15:18,531 INFO [train.py:450] Epoch 3, batch 14830, batch avg loss 0.3673, total avg loss: 0.3481, batch size: 38
2021-08-25 10:15:24,278 INFO [train.py:450] Epoch 3, batch 14840, batch avg loss 0.3243, total avg loss: 0.3461, batch size: 37
2021-08-25 10:15:30,203 INFO [train.py:450] Epoch 3, batch 14850, batch avg loss 0.3317, total avg loss: 0.3476, batch size: 43
2021-08-25 10:15:36,137 INFO [train.py:450] Epoch 3, batch 14860, batch avg loss 0.3707, total avg loss: 0.3521, batch size: 41
2021-08-25 10:15:41,839 INFO [train.py:450] Epoch 3, batch 14870, batch avg loss 0.4297, total avg loss: 0.3534, batch size: 40
2021-08-25 10:15:47,689 INFO [train.py:450] Epoch 3, batch 14880, batch avg loss 0.3761, total avg loss: 0.3552, batch size: 39
2021-08-25 10:15:53,472 INFO [train.py:450] Epoch 3, batch 14890, batch avg loss 0.3706, total avg loss: 0.3573, batch size: 40
2021-08-25 10:15:59,357 INFO [train.py:450] Epoch 3, batch 14900, batch avg loss 0.4482, total avg loss: 0.3594, batch size: 41
2021-08-25 10:16:05,174 INFO [train.py:450] Epoch 3, batch 14910, batch avg loss 0.3677, total avg loss: 0.3604, batch size: 41
2021-08-25 10:16:10,976 INFO [train.py:450] Epoch 3, batch 14920, batch avg loss 0.3120, total avg loss: 0.3592, batch size: 39
2021-08-25 10:16:16,766 INFO [train.py:450] Epoch 3, batch 14930, batch avg loss 0.3976, total avg loss: 0.3614, batch size: 42
2021-08-25 10:16:22,452 INFO [train.py:450] Epoch 3, batch 14940, batch avg loss 0.3779, total avg loss: 0.3613, batch size: 37
2021-08-25 10:16:28,343 INFO [train.py:450] Epoch 3, batch 14950, batch avg loss 0.3636, total avg loss: 0.3607, batch size: 40
2021-08-25 10:16:34,246 INFO [train.py:450] Epoch 3, batch 14960, batch avg loss 0.3649, total avg loss: 0.3615, batch size: 43
2021-08-25 10:16:40,064 INFO [train.py:450] Epoch 3, batch 14970, batch avg loss 0.3992, total avg loss: 0.3612, batch size: 42
2021-08-25 10:16:45,980 INFO [train.py:450] Epoch 3, batch 14980, batch avg loss 0.3893, total avg loss: 0.3606, batch size: 39
2021-08-25 10:16:51,871 INFO [train.py:450] Epoch 3, batch 14990, batch avg loss 0.3642, total avg loss: 0.3607, batch size: 39
2021-08-25 10:16:57,706 INFO [train.py:450] Epoch 3, batch 15000, batch avg loss 0.3183, total avg loss: 0.3601, batch size: 40
2021-08-25 10:17:35,139 INFO [train.py:482] Epoch 3, valid loss 0.2525, best valid loss: 0.2434 best valid epoch: 2
2021-08-25 10:17:41,321 INFO [train.py:450] Epoch 3, batch 15010, batch avg loss 0.4046, total avg loss: 0.3550, batch size: 40
2021-08-25 10:17:47,179 INFO [train.py:450] Epoch 3, batch 15020, batch avg loss 0.3761, total avg loss: 0.3659, batch size: 40
2021-08-25 10:17:53,081 INFO [train.py:450] Epoch 3, batch 15030, batch avg loss 0.3813, total avg loss: 0.3667, batch size: 40
2021-08-25 10:17:59,155 INFO [train.py:450] Epoch 3, batch 15040, batch avg loss 0.3458, total avg loss: 0.3675, batch size: 39
2021-08-25 10:18:04,990 INFO [train.py:450] Epoch 3, batch 15050, batch avg loss 0.4337, total avg loss: 0.3661, batch size: 38
2021-08-25 10:18:10,878 INFO [train.py:450] Epoch 3, batch 15060, batch avg loss 0.3364, total avg loss: 0.3611, batch size: 41
2021-08-25 10:18:16,613 INFO [train.py:450] Epoch 3, batch 15070, batch avg loss 0.3424, total avg loss: 0.3598, batch size: 41
2021-08-25 10:18:22,500 INFO [train.py:450] Epoch 3, batch 15080, batch avg loss 0.3843, total avg loss: 0.3598, batch size: 41
2021-08-25 10:18:28,293 INFO [train.py:450] Epoch 3, batch 15090, batch avg loss 0.3512, total avg loss: 0.3591, batch size: 40
2021-08-25 10:18:34,276 INFO [train.py:450] Epoch 3, batch 15100, batch avg loss 0.3317, total avg loss: 0.3580, batch size: 39
2021-08-25 10:18:40,240 INFO [train.py:450] Epoch 3, batch 15110, batch avg loss 0.2994, total avg loss: 0.3564, batch size: 42
2021-08-25 10:18:46,085 INFO [train.py:450] Epoch 3, batch 15120, batch avg loss 0.4105, total avg loss: 0.3578, batch size: 38
2021-08-25 10:18:51,950 INFO [train.py:450] Epoch 3, batch 15130, batch avg loss 0.3470, total avg loss: 0.3581, batch size: 37
2021-08-25 10:18:57,712 INFO [train.py:450] Epoch 3, batch 15140, batch avg loss 0.3918, total avg loss: 0.3583, batch size: 40
2021-08-25 10:19:03,488 INFO [train.py:450] Epoch 3, batch 15150, batch avg loss 0.3376, total avg loss: 0.3589, batch size: 39
2021-08-25 10:19:09,322 INFO [train.py:450] Epoch 3, batch 15160, batch avg loss 0.3662, total avg loss: 0.3600, batch size: 38
2021-08-25 10:19:15,237 INFO [train.py:450] Epoch 3, batch 15170, batch avg loss 0.3024, total avg loss: 0.3593, batch size: 40
2021-08-25 10:19:21,077 INFO [train.py:450] Epoch 3, batch 15180, batch avg loss 0.3661, total avg loss: 0.3598, batch size: 38
2021-08-25 10:19:26,899 INFO [train.py:450] Epoch 3, batch 15190, batch avg loss 0.3505, total avg loss: 0.3603, batch size: 40
2021-08-25 10:19:32,810 INFO [train.py:450] Epoch 3, batch 15200, batch avg loss 0.3220, total avg loss: 0.3590, batch size: 43
2021-08-25 10:19:38,695 INFO [train.py:450] Epoch 3, batch 15210, batch avg loss 0.3270, total avg loss: 0.3610, batch size: 41
2021-08-25 10:19:44,616 INFO [train.py:450] Epoch 3, batch 15220, batch avg loss 0.3347, total avg loss: 0.3583, batch size: 40
2021-08-25 10:19:50,455 INFO [train.py:450] Epoch 3, batch 15230, batch avg loss 0.4218, total avg loss: 0.3628, batch size: 43
2021-08-25 10:19:56,353 INFO [train.py:450] Epoch 3, batch 15240, batch avg loss 0.3280, total avg loss: 0.3614, batch size: 39
2021-08-25 10:20:02,235 INFO [train.py:450] Epoch 3, batch 15250, batch avg loss 0.4119, total avg loss: 0.3632, batch size: 41
2021-08-25 10:20:08,090 INFO [train.py:450] Epoch 3, batch 15260, batch avg loss 0.4447, total avg loss: 0.3640, batch size: 41
2021-08-25 10:20:14,030 INFO [train.py:450] Epoch 3, batch 15270, batch avg loss 0.3393, total avg loss: 0.3631, batch size: 39
2021-08-25 10:20:19,828 INFO [train.py:450] Epoch 3, batch 15280, batch avg loss 0.3723, total avg loss: 0.3618, batch size: 38
2021-08-25 10:20:25,687 INFO [train.py:450] Epoch 3, batch 15290, batch avg loss 0.3455, total avg loss: 0.3633, batch size: 39
2021-08-25 10:20:31,551 INFO [train.py:450] Epoch 3, batch 15300, batch avg loss 0.3456, total avg loss: 0.3655, batch size: 35
2021-08-25 10:20:37,509 INFO [train.py:450] Epoch 3, batch 15310, batch avg loss 0.3474, total avg loss: 0.3674, batch size: 43
2021-08-25 10:20:43,302 INFO [train.py:450] Epoch 3, batch 15320, batch avg loss 0.3704, total avg loss: 0.3677, batch size: 38
2021-08-25 10:20:49,381 INFO [train.py:450] Epoch 3, batch 15330, batch avg loss 0.3414, total avg loss: 0.3680, batch size: 40
2021-08-25 10:20:56,237 INFO [train.py:450] Epoch 3, batch 15340, batch avg loss 0.3838, total avg loss: 0.3681, batch size: 39
2021-08-25 10:21:02,113 INFO [train.py:450] Epoch 3, batch 15350, batch avg loss 0.3923, total avg loss: 0.3683, batch size: 41
2021-08-25 10:21:07,876 INFO [train.py:450] Epoch 3, batch 15360, batch avg loss 0.3910, total avg loss: 0.3686, batch size: 40
2021-08-25 10:21:13,790 INFO [train.py:450] Epoch 3, batch 15370, batch avg loss 0.3254, total avg loss: 0.3681, batch size: 39
2021-08-25 10:21:19,797 INFO [train.py:450] Epoch 3, batch 15380, batch avg loss 0.3312, total avg loss: 0.3670, batch size: 41
2021-08-25 10:21:25,666 INFO [train.py:450] Epoch 3, batch 15390, batch avg loss 0.2963, total avg loss: 0.3662, batch size: 42
2021-08-25 10:21:31,526 INFO [train.py:450] Epoch 3, batch 15400, batch avg loss 0.4173, total avg loss: 0.3658, batch size: 41
2021-08-25 10:21:37,383 INFO [train.py:450] Epoch 3, batch 15410, batch avg loss 0.3061, total avg loss: 0.3490, batch size: 43
2021-08-25 10:21:43,150 INFO [train.py:450] Epoch 3, batch 15420, batch avg loss 0.4410, total avg loss: 0.3620, batch size: 38
2021-08-25 10:21:48,931 INFO [train.py:450] Epoch 3, batch 15430, batch avg loss 0.3064, total avg loss: 0.3627, batch size: 35
2021-08-25 10:21:54,937 INFO [train.py:450] Epoch 3, batch 15440, batch avg loss 0.3760, total avg loss: 0.3684, batch size: 36
2021-08-25 10:22:00,935 INFO [train.py:450] Epoch 3, batch 15450, batch avg loss 0.3358, total avg loss: 0.3634, batch size: 41
2021-08-25 10:22:06,805 INFO [train.py:450] Epoch 3, batch 15460, batch avg loss 0.3556, total avg loss: 0.3633, batch size: 40
2021-08-25 10:22:12,608 INFO [train.py:450] Epoch 3, batch 15470, batch avg loss 0.3825, total avg loss: 0.3635, batch size: 40
2021-08-25 10:22:18,490 INFO [train.py:450] Epoch 3, batch 15480, batch avg loss 0.3630, total avg loss: 0.3643, batch size: 37
2021-08-25 10:22:24,427 INFO [train.py:450] Epoch 3, batch 15490, batch avg loss 0.3937, total avg loss: 0.3649, batch size: 42
2021-08-25 10:22:30,329 INFO [train.py:450] Epoch 3, batch 15500, batch avg loss 0.3246, total avg loss: 0.3647, batch size: 41
2021-08-25 10:22:36,205 INFO [train.py:450] Epoch 3, batch 15510, batch avg loss 0.4324, total avg loss: 0.3646, batch size: 39
2021-08-25 10:22:42,054 INFO [train.py:450] Epoch 3, batch 15520, batch avg loss 0.3752, total avg loss: 0.3655, batch size: 37
2021-08-25 10:22:48,066 INFO [train.py:450] Epoch 3, batch 15530, batch avg loss 0.4035, total avg loss: 0.3656, batch size: 45
2021-08-25 10:22:53,973 INFO [train.py:450] Epoch 3, batch 15540, batch avg loss 0.3333, total avg loss: 0.3652, batch size: 41
2021-08-25 10:22:59,468 WARNING [cut.py:1694] To perform mix, energy must be non-zero and non-negative (got 0.0).  MonoCut with id "f38c4641-33b5-c937-cdc1-e26f8e2c736d" will not be mixed in.
2021-08-25 10:22:59,860 INFO [train.py:450] Epoch 3, batch 15550, batch avg loss 0.4041, total avg loss: 0.3647, batch size: 42
2021-08-25 10:23:05,824 INFO [train.py:450] Epoch 3, batch 15560, batch avg loss 0.3387, total avg loss: 0.3645, batch size: 39
2021-08-25 10:23:11,624 INFO [train.py:450] Epoch 3, batch 15570, batch avg loss 0.3285, total avg loss: 0.3648, batch size: 36
2021-08-25 10:23:17,562 INFO [train.py:450] Epoch 3, batch 15580, batch avg loss 0.3441, total avg loss: 0.3651, batch size: 36
2021-08-25 10:23:23,362 INFO [train.py:450] Epoch 3, batch 15590, batch avg loss 0.3277, total avg loss: 0.3655, batch size: 38
2021-08-25 10:23:29,316 INFO [train.py:450] Epoch 3, batch 15600, batch avg loss 0.3657, total avg loss: 0.3645, batch size: 42
2021-08-25 10:23:35,105 INFO [train.py:450] Epoch 3, batch 15610, batch avg loss 0.3260, total avg loss: 0.3665, batch size: 41
2021-08-25 10:23:40,847 INFO [train.py:450] Epoch 3, batch 15620, batch avg loss 0.3521, total avg loss: 0.3594, batch size: 40
2021-08-25 10:23:46,708 INFO [train.py:450] Epoch 3, batch 15630, batch avg loss 0.3298, total avg loss: 0.3526, batch size: 40
2021-08-25 10:23:52,411 INFO [train.py:450] Epoch 3, batch 15640, batch avg loss 0.3499, total avg loss: 0.3507, batch size: 39
2021-08-25 10:23:58,239 INFO [train.py:450] Epoch 3, batch 15650, batch avg loss 0.3590, total avg loss: 0.3528, batch size: 39
2021-08-25 10:24:05,147 INFO [train.py:450] Epoch 3, batch 15660, batch avg loss 0.4322, total avg loss: 0.3610, batch size: 39
2021-08-25 10:24:11,008 INFO [train.py:450] Epoch 3, batch 15670, batch avg loss 0.6215, total avg loss: 0.3774, batch size: 40
2021-08-25 10:24:16,900 INFO [train.py:450] Epoch 3, batch 15680, batch avg loss 0.7542, total avg loss: 0.4195, batch size: 40
2021-08-25 10:24:22,744 INFO [train.py:450] Epoch 3, batch 15690, batch avg loss 0.6640, total avg loss: 0.4579, batch size: 36
2021-08-25 10:24:28,607 INFO [train.py:450] Epoch 3, batch 15700, batch avg loss 0.6562, total avg loss: 0.4806, batch size: 38
2021-08-25 10:24:34,508 INFO [train.py:450] Epoch 3, batch 15710, batch avg loss 0.5416, total avg loss: 0.4827, batch size: 39
2021-08-25 10:24:40,240 INFO [train.py:450] Epoch 3, batch 15720, batch avg loss 0.3463, total avg loss: 0.4759, batch size: 39
2021-08-25 10:24:40,463 WARNING [cut.py:1694] To perform mix, energy must be non-zero and non-negative (got 0.0).  MonoCut with id "6ec5366e-62b0-ce64-2d7a-7be3aa87130a" will not be mixed in.
2021-08-25 10:24:46,127 INFO [train.py:450] Epoch 3, batch 15730, batch avg loss 0.4264, total avg loss: 0.4699, batch size: 38
2021-08-25 10:24:52,190 INFO [train.py:450] Epoch 3, batch 15740, batch avg loss 0.4182, total avg loss: 0.4650, batch size: 37
2021-08-25 10:24:58,109 INFO [train.py:450] Epoch 3, batch 15750, batch avg loss 0.3853, total avg loss: 0.4606, batch size: 46
2021-08-25 10:25:03,958 INFO [train.py:450] Epoch 3, batch 15760, batch avg loss 0.4153, total avg loss: 0.4566, batch size: 40
2021-08-25 10:25:09,953 INFO [train.py:450] Epoch 3, batch 15770, batch avg loss 0.3621, total avg loss: 0.4527, batch size: 41
2021-08-25 10:25:15,689 INFO [train.py:450] Epoch 3, batch 15780, batch avg loss 0.3175, total avg loss: 0.4474, batch size: 38
2021-08-25 10:25:21,392 INFO [train.py:450] Epoch 3, batch 15790, batch avg loss 0.3789, total avg loss: 0.4429, batch size: 39
2021-08-25 10:25:27,303 INFO [train.py:450] Epoch 3, batch 15800, batch avg loss 0.3557, total avg loss: 0.4415, batch size: 39
2021-08-25 10:25:33,244 INFO [train.py:450] Epoch 3, batch 15810, batch avg loss 0.3553, total avg loss: 0.3676, batch size: 40
2021-08-25 10:25:39,013 INFO [train.py:450] Epoch 3, batch 15820, batch avg loss 0.4255, total avg loss: 0.3742, batch size: 39
2021-08-25 10:25:44,847 INFO [train.py:450] Epoch 3, batch 15830, batch avg loss 0.3930, total avg loss: 0.3774, batch size: 40
2021-08-25 10:25:50,618 INFO [train.py:450] Epoch 3, batch 15840, batch avg loss 0.4345, total avg loss: 0.3829, batch size: 38
2021-08-25 10:25:56,565 INFO [train.py:450] Epoch 3, batch 15850, batch avg loss 0.4140, total avg loss: 0.3838, batch size: 42
2021-08-25 10:26:02,409 INFO [train.py:450] Epoch 3, batch 15860, batch avg loss 0.3586, total avg loss: 0.3839, batch size: 39
2021-08-25 10:26:08,360 INFO [train.py:450] Epoch 3, batch 15870, batch avg loss 0.3737, total avg loss: 0.3859, batch size: 38
2021-08-25 10:26:14,055 INFO [train.py:450] Epoch 3, batch 15880, batch avg loss 0.3303, total avg loss: 0.3838, batch size: 35
2021-08-25 10:26:19,908 INFO [train.py:450] Epoch 3, batch 15890, batch avg loss 0.3596, total avg loss: 0.3809, batch size: 38
2021-08-25 10:26:25,666 INFO [train.py:450] Epoch 3, batch 15900, batch avg loss 0.3574, total avg loss: 0.3824, batch size: 37
2021-08-25 10:26:31,398 INFO [train.py:450] Epoch 3, batch 15910, batch avg loss 0.3881, total avg loss: 0.3825, batch size: 39
2021-08-25 10:26:37,129 INFO [train.py:450] Epoch 3, batch 15920, batch avg loss 0.3959, total avg loss: 0.3837, batch size: 40
2021-08-25 10:26:42,990 INFO [train.py:450] Epoch 3, batch 15930, batch avg loss 0.3519, total avg loss: 0.3843, batch size: 36
2021-08-25 10:26:48,861 INFO [train.py:450] Epoch 3, batch 15940, batch avg loss 0.3577, total avg loss: 0.3838, batch size: 35
2021-08-25 10:26:54,716 INFO [train.py:450] Epoch 3, batch 15950, batch avg loss 0.3968, total avg loss: 0.3826, batch size: 38
2021-08-25 10:27:00,525 INFO [train.py:450] Epoch 3, batch 15960, batch avg loss 0.3454, total avg loss: 0.3824, batch size: 36
2021-08-25 10:27:06,523 INFO [train.py:450] Epoch 3, batch 15970, batch avg loss 0.3814, total avg loss: 0.3813, batch size: 38
2021-08-25 10:27:12,374 INFO [train.py:450] Epoch 3, batch 15980, batch avg loss 0.4195, total avg loss: 0.3814, batch size: 38
2021-08-25 10:27:18,459 INFO [train.py:450] Epoch 3, batch 15990, batch avg loss 0.3841, total avg loss: 0.3803, batch size: 44
2021-08-25 10:27:24,844 INFO [train.py:450] Epoch 3, batch 16000, batch avg loss 0.3406, total avg loss: 0.3801, batch size: 44
2021-08-25 10:28:04,634 INFO [train.py:482] Epoch 3, valid loss 0.2584, best valid loss: 0.2434 best valid epoch: 2
2021-08-25 10:28:10,529 INFO [train.py:450] Epoch 3, batch 16010, batch avg loss 0.3402, total avg loss: 0.3837, batch size: 38
2021-08-25 10:28:16,353 INFO [train.py:450] Epoch 3, batch 16020, batch avg loss 0.4250, total avg loss: 0.3808, batch size: 45
2021-08-25 10:28:22,222 INFO [train.py:450] Epoch 3, batch 16030, batch avg loss 0.4311, total avg loss: 0.3762, batch size: 40
2021-08-25 10:28:27,932 INFO [train.py:450] Epoch 3, batch 16040, batch avg loss 0.4437, total avg loss: 0.3744, batch size: 40
2021-08-25 10:28:33,810 INFO [train.py:450] Epoch 3, batch 16050, batch avg loss 0.3673, total avg loss: 0.3715, batch size: 39
2021-08-25 10:28:39,684 INFO [train.py:450] Epoch 3, batch 16060, batch avg loss 0.3573, total avg loss: 0.3692, batch size: 43
2021-08-25 10:28:45,535 INFO [train.py:450] Epoch 3, batch 16070, batch avg loss 0.3162, total avg loss: 0.3678, batch size: 40
2021-08-25 10:28:51,339 INFO [train.py:450] Epoch 3, batch 16080, batch avg loss 0.3616, total avg loss: 0.3685, batch size: 41
2021-08-25 10:28:57,177 INFO [train.py:450] Epoch 3, batch 16090, batch avg loss 0.4280, total avg loss: 0.3695, batch size: 42
2021-08-25 10:29:03,053 INFO [train.py:450] Epoch 3, batch 16100, batch avg loss 0.3470, total avg loss: 0.3688, batch size: 44
2021-08-25 10:29:08,946 INFO [train.py:450] Epoch 3, batch 16110, batch avg loss 0.3420, total avg loss: 0.3683, batch size: 38
2021-08-25 10:29:14,756 INFO [train.py:450] Epoch 3, batch 16120, batch avg loss 0.3488, total avg loss: 0.3689, batch size: 38
2021-08-25 10:29:20,627 INFO [train.py:450] Epoch 3, batch 16130, batch avg loss 0.3636, total avg loss: 0.3710, batch size: 36
2021-08-25 10:29:26,528 INFO [train.py:450] Epoch 3, batch 16140, batch avg loss 0.3719, total avg loss: 0.3707, batch size: 39
2021-08-25 10:29:32,292 INFO [train.py:450] Epoch 3, batch 16150, batch avg loss 0.3143, total avg loss: 0.3702, batch size: 39
2021-08-25 10:29:38,089 INFO [train.py:450] Epoch 3, batch 16160, batch avg loss 0.3642, total avg loss: 0.3710, batch size: 42
2021-08-25 10:29:43,857 INFO [train.py:450] Epoch 3, batch 16170, batch avg loss 0.3565, total avg loss: 0.3701, batch size: 39
2021-08-25 10:29:49,733 INFO [train.py:450] Epoch 3, batch 16180, batch avg loss 0.3525, total avg loss: 0.3709, batch size: 38
2021-08-25 10:29:55,590 INFO [train.py:450] Epoch 3, batch 16190, batch avg loss 0.2709, total avg loss: 0.3703, batch size: 40
2021-08-25 10:30:01,591 INFO [train.py:450] Epoch 3, batch 16200, batch avg loss 0.3498, total avg loss: 0.3709, batch size: 42
2021-08-25 10:30:07,492 INFO [train.py:450] Epoch 3, batch 16210, batch avg loss 0.3223, total avg loss: 0.3489, batch size: 37
2021-08-25 10:30:13,324 INFO [train.py:450] Epoch 3, batch 16220, batch avg loss 0.3261, total avg loss: 0.3526, batch size: 37
2021-08-25 10:30:19,155 INFO [train.py:450] Epoch 3, batch 16230, batch avg loss 0.3690, total avg loss: 0.3530, batch size: 40
2021-08-25 10:30:25,035 INFO [train.py:450] Epoch 3, batch 16240, batch avg loss 0.3597, total avg loss: 0.3588, batch size: 37
2021-08-25 10:30:30,901 INFO [train.py:450] Epoch 3, batch 16250, batch avg loss 0.3964, total avg loss: 0.3589, batch size: 43
2021-08-25 10:30:36,759 INFO [train.py:450] Epoch 3, batch 16260, batch avg loss 0.3187, total avg loss: 0.3634, batch size: 40
2021-08-25 10:30:42,591 INFO [train.py:450] Epoch 3, batch 16270, batch avg loss 0.4078, total avg loss: 0.3632, batch size: 39
2021-08-25 10:30:48,564 INFO [train.py:450] Epoch 3, batch 16280, batch avg loss 0.3957, total avg loss: 0.3627, batch size: 40
2021-08-25 10:30:54,282 INFO [train.py:450] Epoch 3, batch 16290, batch avg loss 0.3422, total avg loss: 0.3630, batch size: 37
2021-08-25 10:31:00,126 INFO [train.py:450] Epoch 3, batch 16300, batch avg loss 0.3802, total avg loss: 0.3624, batch size: 47
2021-08-25 10:31:06,043 INFO [train.py:450] Epoch 3, batch 16310, batch avg loss 0.3350, total avg loss: 0.3618, batch size: 42
2021-08-25 10:31:12,015 INFO [train.py:450] Epoch 3, batch 16320, batch avg loss 0.3382, total avg loss: 0.3623, batch size: 43
2021-08-25 10:31:17,926 INFO [train.py:450] Epoch 3, batch 16330, batch avg loss 0.4004, total avg loss: 0.3635, batch size: 39
2021-08-25 10:31:24,050 INFO [train.py:450] Epoch 3, batch 16340, batch avg loss 0.4028, total avg loss: 0.3649, batch size: 39
2021-08-25 10:31:29,985 INFO [train.py:450] Epoch 3, batch 16350, batch avg loss 0.3271, total avg loss: 0.3649, batch size: 36
2021-08-25 10:31:35,866 INFO [train.py:450] Epoch 3, batch 16360, batch avg loss 0.4090, total avg loss: 0.3655, batch size: 41
2021-08-25 10:31:41,648 INFO [train.py:450] Epoch 3, batch 16370, batch avg loss 0.3531, total avg loss: 0.3660, batch size: 40
2021-08-25 10:31:44,697 WARNING [cut.py:1694] To perform mix, energy must be non-zero and non-negative (got 0.0).  MonoCut with id "6862a9ca-be56-6dda-024c-e6f03099bacb" will not be mixed in.
2021-08-25 10:31:47,611 INFO [train.py:450] Epoch 3, batch 16380, batch avg loss 0.3780, total avg loss: 0.3671, batch size: 39
2021-08-25 10:31:53,482 INFO [train.py:450] Epoch 3, batch 16390, batch avg loss 0.3855, total avg loss: 0.3674, batch size: 37
2021-08-25 10:31:59,331 INFO [train.py:450] Epoch 3, batch 16400, batch avg loss 0.3645, total avg loss: 0.3671, batch size: 42
2021-08-25 10:32:05,080 INFO [train.py:450] Epoch 3, batch 16410, batch avg loss 0.3369, total avg loss: 0.3637, batch size: 36
2021-08-25 10:32:10,919 INFO [train.py:450] Epoch 3, batch 16420, batch avg loss 0.4332, total avg loss: 0.3770, batch size: 36
2021-08-25 10:32:16,734 INFO [train.py:450] Epoch 3, batch 16430, batch avg loss 0.4380, total avg loss: 0.3811, batch size: 40
2021-08-25 10:32:22,567 INFO [train.py:450] Epoch 3, batch 16440, batch avg loss 0.3553, total avg loss: 0.3786, batch size: 40
2021-08-25 10:32:28,365 INFO [train.py:450] Epoch 3, batch 16450, batch avg loss 0.3155, total avg loss: 0.3740, batch size: 43
2021-08-25 10:32:34,231 INFO [train.py:450] Epoch 3, batch 16460, batch avg loss 0.3874, total avg loss: 0.3741, batch size: 40
2021-08-25 10:32:40,003 INFO [train.py:450] Epoch 3, batch 16470, batch avg loss 0.3964, total avg loss: 0.3709, batch size: 41
2021-08-25 10:32:45,734 INFO [train.py:450] Epoch 3, batch 16480, batch avg loss 0.3751, total avg loss: 0.3696, batch size: 40
2021-08-25 10:32:51,637 INFO [train.py:450] Epoch 3, batch 16490, batch avg loss 0.3786, total avg loss: 0.3690, batch size: 41
2021-08-25 10:32:57,441 INFO [train.py:450] Epoch 3, batch 16500, batch avg loss 0.3402, total avg loss: 0.3678, batch size: 37
2021-08-25 10:33:03,230 INFO [train.py:450] Epoch 3, batch 16510, batch avg loss 0.3424, total avg loss: 0.3682, batch size: 43
2021-08-25 10:33:09,136 INFO [train.py:450] Epoch 3, batch 16520, batch avg loss 0.3363, total avg loss: 0.3670, batch size: 37
2021-08-25 10:33:14,991 INFO [train.py:450] Epoch 3, batch 16530, batch avg loss 0.3781, total avg loss: 0.3659, batch size: 40
2021-08-25 10:33:20,737 INFO [train.py:450] Epoch 3, batch 16540, batch avg loss 0.3709, total avg loss: 0.3659, batch size: 38
2021-08-25 10:33:26,552 INFO [train.py:450] Epoch 3, batch 16550, batch avg loss 0.3545, total avg loss: 0.3663, batch size: 39
2021-08-25 10:33:32,346 INFO [train.py:450] Epoch 3, batch 16560, batch avg loss 0.3391, total avg loss: 0.3653, batch size: 38
2021-08-25 10:33:38,198 INFO [train.py:450] Epoch 3, batch 16570, batch avg loss 0.4478, total avg loss: 0.3651, batch size: 41
2021-08-25 10:33:43,903 INFO [train.py:450] Epoch 3, batch 16580, batch avg loss 0.3984, total avg loss: 0.3637, batch size: 37
2021-08-25 10:33:50,534 INFO [train.py:450] Epoch 3, batch 16590, batch avg loss 0.4382, total avg loss: 0.3637, batch size: 44
2021-08-25 10:33:56,337 INFO [train.py:450] Epoch 3, batch 16600, batch avg loss 0.3971, total avg loss: 0.3646, batch size: 41
2021-08-25 10:34:02,357 INFO [train.py:450] Epoch 3, batch 16610, batch avg loss 0.3945, total avg loss: 0.3775, batch size: 37
2021-08-25 10:34:08,216 INFO [train.py:450] Epoch 3, batch 16620, batch avg loss 0.3584, total avg loss: 0.3715, batch size: 41
2021-08-25 10:34:13,995 INFO [train.py:450] Epoch 3, batch 16630, batch avg loss 0.4258, total avg loss: 0.3728, batch size: 37
2021-08-25 10:34:19,834 INFO [train.py:450] Epoch 3, batch 16640, batch avg loss 0.3954, total avg loss: 0.3740, batch size: 37
2021-08-25 10:34:25,644 INFO [train.py:450] Epoch 3, batch 16650, batch avg loss 0.3420, total avg loss: 0.3716, batch size: 40
2021-08-25 10:34:31,454 INFO [train.py:450] Epoch 3, batch 16660, batch avg loss 0.3611, total avg loss: 0.3691, batch size: 39
2021-08-25 10:34:37,390 INFO [train.py:450] Epoch 3, batch 16670, batch avg loss 0.3445, total avg loss: 0.3684, batch size: 38
2021-08-25 10:34:43,315 INFO [train.py:450] Epoch 3, batch 16680, batch avg loss 0.4164, total avg loss: 0.3685, batch size: 41
2021-08-25 10:34:49,031 INFO [train.py:450] Epoch 3, batch 16690, batch avg loss 0.4131, total avg loss: 0.3683, batch size: 41
2021-08-25 10:34:54,890 INFO [train.py:450] Epoch 3, batch 16700, batch avg loss 0.4198, total avg loss: 0.3676, batch size: 40
2021-08-25 10:35:01,015 INFO [train.py:450] Epoch 3, batch 16710, batch avg loss 0.3901, total avg loss: 0.3659, batch size: 41
2021-08-25 10:35:06,793 INFO [train.py:450] Epoch 3, batch 16720, batch avg loss 0.4013, total avg loss: 0.3670, batch size: 40
2021-08-25 10:35:12,616 INFO [train.py:450] Epoch 3, batch 16730, batch avg loss 0.3889, total avg loss: 0.3672, batch size: 40
2021-08-25 10:35:18,430 INFO [train.py:450] Epoch 3, batch 16740, batch avg loss 0.4035, total avg loss: 0.3669, batch size: 39
2021-08-25 10:35:24,354 INFO [train.py:450] Epoch 3, batch 16750, batch avg loss 0.4114, total avg loss: 0.3673, batch size: 38
2021-08-25 10:35:30,323 INFO [train.py:450] Epoch 3, batch 16760, batch avg loss 0.3804, total avg loss: 0.3675, batch size: 39
2021-08-25 10:35:36,584 INFO [train.py:450] Epoch 3, batch 16770, batch avg loss 0.4584, total avg loss: 0.3687, batch size: 35
2021-08-25 10:35:42,546 INFO [train.py:450] Epoch 3, batch 16780, batch avg loss 0.2865, total avg loss: 0.3682, batch size: 38
2021-08-25 10:35:48,441 INFO [train.py:450] Epoch 3, batch 16790, batch avg loss 0.3870, total avg loss: 0.3674, batch size: 43
2021-08-25 10:35:54,180 INFO [train.py:450] Epoch 3, batch 16800, batch avg loss 0.2861, total avg loss: 0.3665, batch size: 39
2021-08-25 10:36:00,013 INFO [train.py:450] Epoch 3, batch 16810, batch avg loss 0.3894, total avg loss: 0.3568, batch size: 40
2021-08-25 10:36:05,912 INFO [train.py:450] Epoch 3, batch 16820, batch avg loss 0.3952, total avg loss: 0.3546, batch size: 38
2021-08-25 10:36:11,689 INFO [train.py:450] Epoch 3, batch 16830, batch avg loss 0.3661, total avg loss: 0.3594, batch size: 40
2021-08-25 10:36:17,470 INFO [train.py:450] Epoch 3, batch 16840, batch avg loss 0.3315, total avg loss: 0.3608, batch size: 35
2021-08-25 10:36:23,304 INFO [train.py:450] Epoch 3, batch 16850, batch avg loss 0.3369, total avg loss: 0.3586, batch size: 39
2021-08-25 10:36:29,274 INFO [train.py:450] Epoch 3, batch 16860, batch avg loss 0.3726, total avg loss: 0.3600, batch size: 39
2021-08-25 10:36:35,054 INFO [train.py:450] Epoch 3, batch 16870, batch avg loss 0.3592, total avg loss: 0.3616, batch size: 39
2021-08-25 10:36:40,957 INFO [train.py:450] Epoch 3, batch 16880, batch avg loss 0.3402, total avg loss: 0.3606, batch size: 35
2021-08-25 10:36:46,872 INFO [train.py:450] Epoch 3, batch 16890, batch avg loss 0.3444, total avg loss: 0.3611, batch size: 37
2021-08-25 10:36:52,754 INFO [train.py:450] Epoch 3, batch 16900, batch avg loss 0.3573, total avg loss: 0.3617, batch size: 43
2021-08-25 10:36:58,649 INFO [train.py:450] Epoch 3, batch 16910, batch avg loss 0.4030, total avg loss: 0.3606, batch size: 37
2021-08-25 10:37:04,484 INFO [train.py:450] Epoch 3, batch 16920, batch avg loss 0.3740, total avg loss: 0.3611, batch size: 40
2021-08-25 10:37:10,570 INFO [train.py:450] Epoch 3, batch 16930, batch avg loss 0.3780, total avg loss: 0.3600, batch size: 40
2021-08-25 10:37:16,370 INFO [train.py:450] Epoch 3, batch 16940, batch avg loss 0.4074, total avg loss: 0.3607, batch size: 39
2021-08-25 10:37:22,349 INFO [train.py:450] Epoch 3, batch 16950, batch avg loss 0.3811, total avg loss: 0.3614, batch size: 41
2021-08-25 10:37:28,210 INFO [train.py:450] Epoch 3, batch 16960, batch avg loss 0.3873, total avg loss: 0.3609, batch size: 39
2021-08-25 10:37:34,092 INFO [train.py:450] Epoch 3, batch 16970, batch avg loss 0.4157, total avg loss: 0.3607, batch size: 41
2021-08-25 10:37:40,065 INFO [train.py:450] Epoch 3, batch 16980, batch avg loss 0.3504, total avg loss: 0.3613, batch size: 38
2021-08-25 10:37:46,006 INFO [train.py:450] Epoch 3, batch 16990, batch avg loss 0.4052, total avg loss: 0.3625, batch size: 45
2021-08-25 10:37:52,106 INFO [train.py:450] Epoch 3, batch 17000, batch avg loss 0.3050, total avg loss: 0.3622, batch size: 41
2021-08-25 10:38:32,153 INFO [train.py:482] Epoch 3, valid loss 0.2578, best valid loss: 0.2434 best valid epoch: 2
2021-08-25 10:38:38,218 INFO [train.py:450] Epoch 3, batch 17010, batch avg loss 0.3823, total avg loss: 0.3672, batch size: 41
2021-08-25 10:38:44,051 INFO [train.py:450] Epoch 3, batch 17020, batch avg loss 0.3429, total avg loss: 0.3638, batch size: 40
2021-08-25 10:38:49,808 INFO [train.py:450] Epoch 3, batch 17030, batch avg loss 0.3858, total avg loss: 0.3653, batch size: 41
2021-08-25 10:38:55,789 INFO [train.py:450] Epoch 3, batch 17040, batch avg loss 0.3817, total avg loss: 0.3662, batch size: 41
2021-08-25 10:39:01,691 INFO [train.py:450] Epoch 3, batch 17050, batch avg loss 0.3611, total avg loss: 0.3695, batch size: 43
2021-08-25 10:39:07,413 INFO [train.py:450] Epoch 3, batch 17060, batch avg loss 0.3386, total avg loss: 0.3699, batch size: 38
2021-08-25 10:39:13,227 INFO [train.py:450] Epoch 3, batch 17070, batch avg loss 0.2814, total avg loss: 0.3679, batch size: 42
2021-08-25 10:39:19,072 INFO [train.py:450] Epoch 3, batch 17080, batch avg loss 0.3190, total avg loss: 0.3663, batch size: 41
2021-08-25 10:39:24,851 INFO [train.py:450] Epoch 3, batch 17090, batch avg loss 0.3198, total avg loss: 0.3662, batch size: 37
2021-08-25 10:39:30,766 INFO [train.py:450] Epoch 3, batch 17100, batch avg loss 0.3911, total avg loss: 0.3646, batch size: 38
2021-08-25 10:39:36,746 INFO [train.py:450] Epoch 3, batch 17110, batch avg loss 0.3513, total avg loss: 0.3649, batch size: 44
2021-08-25 10:39:42,609 INFO [train.py:450] Epoch 3, batch 17120, batch avg loss 0.3653, total avg loss: 0.3634, batch size: 40
2021-08-25 10:39:48,405 INFO [train.py:450] Epoch 3, batch 17130, batch avg loss 0.3620, total avg loss: 0.3638, batch size: 39
2021-08-25 10:39:54,238 INFO [train.py:450] Epoch 3, batch 17140, batch avg loss 0.4058, total avg loss: 0.3646, batch size: 38
2021-08-25 10:40:00,087 INFO [train.py:450] Epoch 3, batch 17150, batch avg loss 0.3669, total avg loss: 0.3644, batch size: 41
2021-08-25 10:40:05,971 INFO [train.py:450] Epoch 3, batch 17160, batch avg loss 0.3387, total avg loss: 0.3640, batch size: 41
2021-08-25 10:40:11,788 INFO [train.py:450] Epoch 3, batch 17170, batch avg loss 0.3473, total avg loss: 0.3646, batch size: 41
2021-08-25 10:40:17,691 INFO [train.py:450] Epoch 3, batch 17180, batch avg loss 0.3656, total avg loss: 0.3639, batch size: 39
2021-08-25 10:40:23,879 INFO [train.py:450] Epoch 3, batch 17190, batch avg loss 0.3879, total avg loss: 0.3629, batch size: 39
2021-08-25 10:40:29,888 INFO [train.py:450] Epoch 3, batch 17200, batch avg loss 0.3788, total avg loss: 0.3638, batch size: 40
2021-08-25 10:40:35,719 INFO [train.py:450] Epoch 3, batch 17210, batch avg loss 0.3742, total avg loss: 0.3657, batch size: 41
2021-08-25 10:40:41,592 INFO [train.py:450] Epoch 3, batch 17220, batch avg loss 0.3833, total avg loss: 0.3631, batch size: 39
2021-08-25 10:40:47,389 INFO [train.py:450] Epoch 3, batch 17230, batch avg loss 0.3698, total avg loss: 0.3639, batch size: 41
2021-08-25 10:40:53,231 INFO [train.py:450] Epoch 3, batch 17240, batch avg loss 0.3455, total avg loss: 0.3660, batch size: 38
2021-08-25 10:40:58,948 INFO [train.py:450] Epoch 3, batch 17250, batch avg loss 0.2926, total avg loss: 0.3682, batch size: 38
2021-08-25 10:41:04,693 INFO [train.py:450] Epoch 3, batch 17260, batch avg loss 0.4184, total avg loss: 0.3708, batch size: 40
2021-08-25 10:41:10,479 INFO [train.py:450] Epoch 3, batch 17270, batch avg loss 0.3759, total avg loss: 0.3715, batch size: 41
2021-08-25 10:41:16,227 INFO [train.py:450] Epoch 3, batch 17280, batch avg loss 0.3784, total avg loss: 0.3741, batch size: 40
2021-08-25 10:41:22,017 INFO [train.py:450] Epoch 3, batch 17290, batch avg loss 0.3617, total avg loss: 0.3744, batch size: 38
2021-08-25 10:41:27,889 INFO [train.py:450] Epoch 3, batch 17300, batch avg loss 0.4093, total avg loss: 0.3780, batch size: 38
2021-08-25 10:41:33,702 INFO [train.py:450] Epoch 3, batch 17310, batch avg loss 0.4213, total avg loss: 0.3769, batch size: 41
2021-08-25 10:41:39,523 INFO [train.py:450] Epoch 3, batch 17320, batch avg loss 0.4087, total avg loss: 0.3768, batch size: 40
2021-08-25 10:41:45,235 INFO [train.py:450] Epoch 3, batch 17330, batch avg loss 0.4362, total avg loss: 0.3762, batch size: 39
2021-08-25 10:41:51,064 INFO [train.py:450] Epoch 3, batch 17340, batch avg loss 0.3645, total avg loss: 0.3762, batch size: 35
2021-08-25 10:41:56,882 INFO [train.py:450] Epoch 3, batch 17350, batch avg loss 0.3830, total avg loss: 0.3768, batch size: 40
2021-08-25 10:42:02,725 INFO [train.py:450] Epoch 3, batch 17360, batch avg loss 0.3718, total avg loss: 0.3739, batch size: 44
2021-08-25 10:42:08,478 INFO [train.py:450] Epoch 3, batch 17370, batch avg loss 0.3368, total avg loss: 0.3742, batch size: 43
2021-08-25 10:42:14,276 INFO [train.py:450] Epoch 3, batch 17380, batch avg loss 0.3677, total avg loss: 0.3735, batch size: 40
2021-08-25 10:42:20,017 INFO [train.py:450] Epoch 3, batch 17390, batch avg loss 0.3498, total avg loss: 0.3720, batch size: 36
2021-08-25 10:42:25,848 INFO [train.py:450] Epoch 3, batch 17400, batch avg loss 0.4019, total avg loss: 0.3722, batch size: 39
2021-08-25 10:42:31,602 INFO [train.py:450] Epoch 3, batch 17410, batch avg loss 0.3558, total avg loss: 0.3610, batch size: 40
2021-08-25 10:42:37,574 INFO [train.py:450] Epoch 3, batch 17420, batch avg loss 0.3475, total avg loss: 0.3665, batch size: 42
2021-08-25 10:42:43,489 INFO [train.py:450] Epoch 3, batch 17430, batch avg loss 0.3478, total avg loss: 0.3694, batch size: 42
2021-08-25 10:42:49,414 INFO [train.py:450] Epoch 3, batch 17440, batch avg loss 0.3714, total avg loss: 0.3689, batch size: 40
2021-08-25 10:42:55,330 INFO [train.py:450] Epoch 3, batch 17450, batch avg loss 0.3337, total avg loss: 0.3688, batch size: 39
2021-08-25 10:43:01,296 INFO [train.py:450] Epoch 3, batch 17460, batch avg loss 0.3255, total avg loss: 0.3660, batch size: 41
2021-08-25 10:43:07,081 INFO [train.py:450] Epoch 3, batch 17470, batch avg loss 0.3670, total avg loss: 0.3654, batch size: 42
2021-08-25 10:43:12,785 INFO [train.py:450] Epoch 3, batch 17480, batch avg loss 0.4104, total avg loss: 0.3678, batch size: 38
2021-08-25 10:43:18,643 INFO [train.py:450] Epoch 3, batch 17490, batch avg loss 0.3307, total avg loss: 0.3655, batch size: 39
2021-08-25 10:43:24,443 INFO [train.py:450] Epoch 3, batch 17500, batch avg loss 0.3424, total avg loss: 0.3679, batch size: 42
2021-08-25 10:43:30,368 INFO [train.py:450] Epoch 3, batch 17510, batch avg loss 0.3756, total avg loss: 0.3683, batch size: 38
2021-08-25 10:43:36,297 INFO [train.py:450] Epoch 3, batch 17520, batch avg loss 0.3799, total avg loss: 0.3690, batch size: 42
2021-08-25 10:43:42,079 INFO [train.py:450] Epoch 3, batch 17530, batch avg loss 0.3823, total avg loss: 0.3689, batch size: 40
2021-08-25 10:43:47,867 INFO [train.py:450] Epoch 3, batch 17540, batch avg loss 0.3694, total avg loss: 0.3701, batch size: 38
2021-08-25 10:43:53,727 INFO [train.py:450] Epoch 3, batch 17550, batch avg loss 0.3612, total avg loss: 0.3702, batch size: 40
2021-08-25 10:43:59,620 INFO [train.py:450] Epoch 3, batch 17560, batch avg loss 0.3519, total avg loss: 0.3693, batch size: 42
2021-08-25 10:44:05,490 INFO [train.py:450] Epoch 3, batch 17570, batch avg loss 0.3035, total avg loss: 0.3692, batch size: 40
2021-08-25 10:44:11,326 INFO [train.py:450] Epoch 3, batch 17580, batch avg loss 0.3747, total avg loss: 0.3683, batch size: 37
2021-08-25 10:44:17,199 INFO [train.py:450] Epoch 3, batch 17590, batch avg loss 0.3703, total avg loss: 0.3685, batch size: 40
2021-08-25 10:44:23,167 INFO [train.py:450] Epoch 3, batch 17600, batch avg loss 0.3739, total avg loss: 0.3687, batch size: 41
2021-08-25 10:44:29,052 INFO [train.py:450] Epoch 3, batch 17610, batch avg loss 0.3643, total avg loss: 0.3773, batch size: 40
2021-08-25 10:44:34,818 INFO [train.py:450] Epoch 3, batch 17620, batch avg loss 0.3553, total avg loss: 0.3635, batch size: 41
2021-08-25 10:44:40,668 INFO [train.py:450] Epoch 3, batch 17630, batch avg loss 0.3699, total avg loss: 0.3617, batch size: 37
2021-08-25 10:44:46,513 INFO [train.py:450] Epoch 3, batch 17640, batch avg loss 0.3390, total avg loss: 0.3619, batch size: 40
2021-08-25 10:44:52,454 INFO [train.py:450] Epoch 3, batch 17650, batch avg loss 0.3414, total avg loss: 0.3589, batch size: 40
2021-08-25 10:44:58,405 INFO [train.py:450] Epoch 3, batch 17660, batch avg loss 0.3698, total avg loss: 0.3580, batch size: 39
2021-08-25 10:45:04,164 INFO [train.py:450] Epoch 3, batch 17670, batch avg loss 0.3716, total avg loss: 0.3600, batch size: 41
2021-08-25 10:45:09,801 WARNING [cut.py:1694] To perform mix, energy must be non-zero and non-negative (got 0.0).  MonoCut with id "2b331ba9-d649-6e49-c40b-4440c9dffb39" will not be mixed in.
2021-08-25 10:45:10,201 INFO [train.py:450] Epoch 3, batch 17680, batch avg loss 0.3899, total avg loss: 0.3615, batch size: 43
2021-08-25 10:45:16,087 INFO [train.py:450] Epoch 3, batch 17690, batch avg loss 0.3579, total avg loss: 0.3610, batch size: 37
2021-08-25 10:45:21,960 INFO [train.py:450] Epoch 3, batch 17700, batch avg loss 0.3688, total avg loss: 0.3617, batch size: 39
2021-08-25 10:45:27,849 INFO [train.py:450] Epoch 3, batch 17710, batch avg loss 0.3685, total avg loss: 0.3612, batch size: 36
2021-08-25 10:45:33,572 INFO [train.py:450] Epoch 3, batch 17720, batch avg loss 0.3530, total avg loss: 0.3602, batch size: 39
2021-08-25 10:45:39,355 INFO [train.py:450] Epoch 3, batch 17730, batch avg loss 0.3583, total avg loss: 0.3597, batch size: 41
2021-08-25 10:45:45,137 INFO [train.py:450] Epoch 3, batch 17740, batch avg loss 0.3125, total avg loss: 0.3585, batch size: 40
2021-08-25 10:45:50,976 INFO [train.py:450] Epoch 3, batch 17750, batch avg loss 0.3937, total avg loss: 0.3595, batch size: 42
2021-08-25 10:45:56,765 INFO [train.py:450] Epoch 3, batch 17760, batch avg loss 0.3951, total avg loss: 0.3602, batch size: 37
2021-08-25 10:46:02,625 INFO [train.py:450] Epoch 3, batch 17770, batch avg loss 0.4187, total avg loss: 0.3603, batch size: 40
2021-08-25 10:46:08,567 INFO [train.py:450] Epoch 3, batch 17780, batch avg loss 0.3340, total avg loss: 0.3603, batch size: 37
2021-08-25 10:46:14,386 INFO [train.py:450] Epoch 3, batch 17790, batch avg loss 0.3386, total avg loss: 0.3599, batch size: 39
2021-08-25 10:46:20,156 INFO [train.py:450] Epoch 3, batch 17800, batch avg loss 0.3586, total avg loss: 0.3603, batch size: 39
2021-08-25 10:46:26,059 INFO [train.py:450] Epoch 3, batch 17810, batch avg loss 0.3589, total avg loss: 0.3540, batch size: 40
2021-08-25 10:46:31,967 INFO [train.py:450] Epoch 3, batch 17820, batch avg loss 0.3549, total avg loss: 0.3538, batch size: 41
2021-08-25 10:46:37,871 INFO [train.py:450] Epoch 3, batch 17830, batch avg loss 0.3255, total avg loss: 0.3589, batch size: 40
2021-08-25 10:46:43,820 INFO [train.py:450] Epoch 3, batch 17840, batch avg loss 0.3710, total avg loss: 0.3562, batch size: 38
2021-08-25 10:46:49,713 INFO [train.py:450] Epoch 3, batch 17850, batch avg loss 0.3833, total avg loss: 0.3599, batch size: 38
2021-08-25 10:46:55,593 INFO [train.py:450] Epoch 3, batch 17860, batch avg loss 0.3258, total avg loss: 0.3590, batch size: 36
2021-08-25 10:47:01,463 INFO [train.py:450] Epoch 3, batch 17870, batch avg loss 0.4311, total avg loss: 0.3612, batch size: 39
2021-08-25 10:47:07,416 INFO [train.py:450] Epoch 3, batch 17880, batch avg loss 0.3848, total avg loss: 0.3600, batch size: 39
2021-08-25 10:47:13,324 INFO [train.py:450] Epoch 3, batch 17890, batch avg loss 0.3557, total avg loss: 0.3605, batch size: 40
2021-08-25 10:47:19,167 INFO [train.py:450] Epoch 3, batch 17900, batch avg loss 0.3362, total avg loss: 0.3604, batch size: 37
2021-08-25 10:47:25,226 INFO [train.py:450] Epoch 3, batch 17910, batch avg loss 0.4155, total avg loss: 0.3600, batch size: 42
2021-08-25 10:47:31,082 INFO [train.py:450] Epoch 3, batch 17920, batch avg loss 0.4000, total avg loss: 0.3606, batch size: 42
2021-08-25 10:47:36,882 INFO [train.py:450] Epoch 3, batch 17930, batch avg loss 0.3422, total avg loss: 0.3608, batch size: 39
2021-08-25 10:47:42,690 INFO [train.py:450] Epoch 3, batch 17940, batch avg loss 0.3557, total avg loss: 0.3597, batch size: 40
2021-08-25 10:47:48,583 INFO [train.py:450] Epoch 3, batch 17950, batch avg loss 0.3424, total avg loss: 0.3600, batch size: 38
2021-08-25 10:47:54,401 INFO [train.py:450] Epoch 3, batch 17960, batch avg loss 0.3618, total avg loss: 0.3597, batch size: 43
2021-08-25 10:48:00,457 INFO [train.py:450] Epoch 3, batch 17970, batch avg loss 0.3773, total avg loss: 0.3606, batch size: 40
2021-08-25 10:48:06,202 INFO [train.py:450] Epoch 3, batch 17980, batch avg loss 0.3424, total avg loss: 0.3605, batch size: 38
2021-08-25 10:48:12,100 INFO [train.py:450] Epoch 3, batch 17990, batch avg loss 0.3822, total avg loss: 0.3599, batch size: 36
2021-08-25 10:48:17,906 INFO [train.py:450] Epoch 3, batch 18000, batch avg loss 0.3263, total avg loss: 0.3598, batch size: 36
2021-08-25 10:48:55,405 INFO [train.py:482] Epoch 3, valid loss 0.2543, best valid loss: 0.2434 best valid epoch: 2
2021-08-25 10:49:01,355 INFO [train.py:450] Epoch 3, batch 18010, batch avg loss 0.3574, total avg loss: 0.3540, batch size: 40
2021-08-25 10:49:07,095 INFO [train.py:450] Epoch 3, batch 18020, batch avg loss 0.3579, total avg loss: 0.3525, batch size: 38
2021-08-25 10:49:13,032 INFO [train.py:450] Epoch 3, batch 18030, batch avg loss 0.3012, total avg loss: 0.3560, batch size: 38
2021-08-25 10:49:18,805 INFO [train.py:450] Epoch 3, batch 18040, batch avg loss 0.3084, total avg loss: 0.3605, batch size: 41
2021-08-25 10:49:24,613 INFO [train.py:450] Epoch 3, batch 18050, batch avg loss 0.3153, total avg loss: 0.3601, batch size: 40
2021-08-25 10:49:30,584 INFO [train.py:450] Epoch 3, batch 18060, batch avg loss 0.3591, total avg loss: 0.3639, batch size: 37
2021-08-25 10:49:36,371 INFO [train.py:450] Epoch 3, batch 18070, batch avg loss 0.3879, total avg loss: 0.3643, batch size: 40
2021-08-25 10:49:42,322 INFO [train.py:450] Epoch 3, batch 18080, batch avg loss 0.3239, total avg loss: 0.3651, batch size: 44
2021-08-25 10:49:48,150 INFO [train.py:450] Epoch 3, batch 18090, batch avg loss 0.3433, total avg loss: 0.3650, batch size: 41
2021-08-25 10:49:53,979 INFO [train.py:450] Epoch 3, batch 18100, batch avg loss 0.3089, total avg loss: 0.3635, batch size: 40
2021-08-25 10:49:59,839 INFO [train.py:450] Epoch 3, batch 18110, batch avg loss 0.3929, total avg loss: 0.3628, batch size: 41
2021-08-25 10:50:05,575 INFO [train.py:450] Epoch 3, batch 18120, batch avg loss 0.3613, total avg loss: 0.3652, batch size: 39
2021-08-25 10:50:11,398 INFO [train.py:450] Epoch 3, batch 18130, batch avg loss 0.3690, total avg loss: 0.3651, batch size: 43
2021-08-25 10:50:17,214 INFO [train.py:450] Epoch 3, batch 18140, batch avg loss 0.3693, total avg loss: 0.3647, batch size: 42
2021-08-25 10:50:23,060 INFO [train.py:450] Epoch 3, batch 18150, batch avg loss 0.3872, total avg loss: 0.3643, batch size: 40
2021-08-25 10:50:28,918 INFO [train.py:450] Epoch 3, batch 18160, batch avg loss 0.3650, total avg loss: 0.3648, batch size: 42
2021-08-25 10:50:34,752 INFO [train.py:450] Epoch 3, batch 18170, batch avg loss 0.3384, total avg loss: 0.3645, batch size: 40
2021-08-25 10:50:40,549 INFO [train.py:450] Epoch 3, batch 18180, batch avg loss 0.3650, total avg loss: 0.3650, batch size: 39
2021-08-25 10:50:46,300 INFO [train.py:450] Epoch 3, batch 18190, batch avg loss 0.3828, total avg loss: 0.3639, batch size: 41
2021-08-25 10:50:52,136 INFO [train.py:450] Epoch 3, batch 18200, batch avg loss 0.3586, total avg loss: 0.3639, batch size: 41
2021-08-25 10:50:58,039 INFO [train.py:450] Epoch 3, batch 18210, batch avg loss 0.3644, total avg loss: 0.3527, batch size: 39
2021-08-25 10:51:04,071 INFO [train.py:450] Epoch 3, batch 18220, batch avg loss 0.3652, total avg loss: 0.3607, batch size: 42
2021-08-25 10:51:09,861 INFO [train.py:450] Epoch 3, batch 18230, batch avg loss 0.3394, total avg loss: 0.3564, batch size: 38
2021-08-25 10:51:15,686 INFO [train.py:450] Epoch 3, batch 18240, batch avg loss 0.2950, total avg loss: 0.3533, batch size: 39
2021-08-25 10:51:21,506 INFO [train.py:450] Epoch 3, batch 18250, batch avg loss 0.3755, total avg loss: 0.3491, batch size: 39
2021-08-25 10:51:25,898 WARNING [cut.py:1694] To perform mix, energy must be non-zero and non-negative (got 0.0).  MonoCut with id "2826afca-1288-1177-d1fd-1571c5d8ff0a" will not be mixed in.
2021-08-25 10:51:27,376 INFO [train.py:450] Epoch 3, batch 18260, batch avg loss 0.3164, total avg loss: 0.3486, batch size: 43
2021-08-25 10:51:33,271 INFO [train.py:450] Epoch 3, batch 18270, batch avg loss 0.3940, total avg loss: 0.3500, batch size: 41
2021-08-25 10:51:39,129 INFO [train.py:450] Epoch 3, batch 18280, batch avg loss 0.3182, total avg loss: 0.3514, batch size: 42
2021-08-25 10:51:45,126 INFO [train.py:450] Epoch 3, batch 18290, batch avg loss 0.3194, total avg loss: 0.3519, batch size: 40
2021-08-25 10:51:50,947 INFO [train.py:450] Epoch 3, batch 18300, batch avg loss 0.3244, total avg loss: 0.3508, batch size: 38
2021-08-25 10:51:56,929 INFO [train.py:450] Epoch 3, batch 18310, batch avg loss 0.3455, total avg loss: 0.3526, batch size: 40
2021-08-25 10:52:02,869 INFO [train.py:450] Epoch 3, batch 18320, batch avg loss 0.3248, total avg loss: 0.3514, batch size: 40
2021-08-25 10:52:08,742 INFO [train.py:450] Epoch 3, batch 18330, batch avg loss 0.3236, total avg loss: 0.3508, batch size: 42
2021-08-25 10:52:14,524 INFO [train.py:450] Epoch 3, batch 18340, batch avg loss 0.3873, total avg loss: 0.3523, batch size: 40
2021-08-25 10:52:20,409 INFO [train.py:450] Epoch 3, batch 18350, batch avg loss 0.3859, total avg loss: 0.3532, batch size: 37
2021-08-25 10:52:26,465 INFO [train.py:450] Epoch 3, batch 18360, batch avg loss 0.3539, total avg loss: 0.3537, batch size: 41
2021-08-25 10:52:32,531 INFO [train.py:450] Epoch 3, batch 18370, batch avg loss 0.3457, total avg loss: 0.3555, batch size: 39
2021-08-25 10:52:38,403 INFO [train.py:450] Epoch 3, batch 18380, batch avg loss 0.3105, total avg loss: 0.3558, batch size: 41
2021-08-25 10:52:44,347 INFO [train.py:450] Epoch 3, batch 18390, batch avg loss 0.3900, total avg loss: 0.3561, batch size: 40
2021-08-25 10:52:50,432 INFO [train.py:450] Epoch 3, batch 18400, batch avg loss 0.3736, total avg loss: 0.3567, batch size: 38
2021-08-25 10:52:56,319 INFO [train.py:450] Epoch 3, batch 18410, batch avg loss 0.3398, total avg loss: 0.3618, batch size: 39
2021-08-25 10:53:02,403 INFO [train.py:450] Epoch 3, batch 18420, batch avg loss 0.3315, total avg loss: 0.3578, batch size: 43
2021-08-25 10:53:08,582 INFO [train.py:450] Epoch 3, batch 18430, batch avg loss 0.3892, total avg loss: 0.3612, batch size: 43
2021-08-25 10:53:14,521 INFO [train.py:450] Epoch 3, batch 18440, batch avg loss 0.3274, total avg loss: 0.3546, batch size: 42
2021-08-25 10:53:20,291 INFO [train.py:450] Epoch 3, batch 18450, batch avg loss 0.3065, total avg loss: 0.3514, batch size: 41
2021-08-25 10:53:26,098 INFO [train.py:450] Epoch 3, batch 18460, batch avg loss 0.4070, total avg loss: 0.3538, batch size: 44
2021-08-25 10:53:31,898 INFO [train.py:450] Epoch 3, batch 18470, batch avg loss 0.3923, total avg loss: 0.3544, batch size: 41
2021-08-25 10:53:37,834 INFO [train.py:450] Epoch 3, batch 18480, batch avg loss 0.3202, total avg loss: 0.3549, batch size: 43
2021-08-25 10:53:43,635 INFO [train.py:450] Epoch 3, batch 18490, batch avg loss 0.3417, total avg loss: 0.3542, batch size: 42
2021-08-25 10:53:49,402 INFO [train.py:450] Epoch 3, batch 18500, batch avg loss 0.3796, total avg loss: 0.3537, batch size: 40
2021-08-25 10:53:55,212 INFO [train.py:450] Epoch 3, batch 18510, batch avg loss 0.3705, total avg loss: 0.3547, batch size: 40
2021-08-25 10:54:01,040 INFO [train.py:450] Epoch 3, batch 18520, batch avg loss 0.3658, total avg loss: 0.3552, batch size: 37
2021-08-25 10:54:07,049 INFO [train.py:450] Epoch 3, batch 18530, batch avg loss 0.3143, total avg loss: 0.3556, batch size: 42
2021-08-25 10:54:12,868 INFO [train.py:450] Epoch 3, batch 18540, batch avg loss 0.3499, total avg loss: 0.3566, batch size: 37
2021-08-25 10:54:18,620 INFO [train.py:450] Epoch 3, batch 18550, batch avg loss 0.3585, total avg loss: 0.3571, batch size: 41
2021-08-25 10:54:24,438 INFO [train.py:450] Epoch 3, batch 18560, batch avg loss 0.3111, total avg loss: 0.3567, batch size: 38
2021-08-25 10:54:30,288 INFO [train.py:450] Epoch 3, batch 18570, batch avg loss 0.3323, total avg loss: 0.3566, batch size: 42
2021-08-25 10:54:36,050 INFO [train.py:450] Epoch 3, batch 18580, batch avg loss 0.3883, total avg loss: 0.3570, batch size: 40
2021-08-25 10:54:41,962 INFO [train.py:450] Epoch 3, batch 18590, batch avg loss 0.3865, total avg loss: 0.3566, batch size: 40
2021-08-25 10:54:47,849 INFO [train.py:450] Epoch 3, batch 18600, batch avg loss 0.3487, total avg loss: 0.3563, batch size: 40
2021-08-25 10:54:53,739 INFO [train.py:450] Epoch 3, batch 18610, batch avg loss 0.3792, total avg loss: 0.3623, batch size: 38
2021-08-25 10:54:59,581 INFO [train.py:450] Epoch 3, batch 18620, batch avg loss 0.3622, total avg loss: 0.3640, batch size: 40
2021-08-25 10:55:05,378 INFO [train.py:450] Epoch 3, batch 18630, batch avg loss 0.3839, total avg loss: 0.3651, batch size: 40
2021-08-25 10:55:11,424 INFO [train.py:450] Epoch 3, batch 18640, batch avg loss 0.3449, total avg loss: 0.3652, batch size: 38
2021-08-25 10:55:17,406 INFO [train.py:450] Epoch 3, batch 18650, batch avg loss 0.3346, total avg loss: 0.3618, batch size: 37
2021-08-25 10:55:23,206 INFO [train.py:450] Epoch 3, batch 18660, batch avg loss 0.2943, total avg loss: 0.3561, batch size: 39
2021-08-25 10:55:29,077 INFO [train.py:450] Epoch 3, batch 18670, batch avg loss 0.3610, total avg loss: 0.3549, batch size: 42
2021-08-25 10:55:34,840 INFO [train.py:450] Epoch 3, batch 18680, batch avg loss 0.3438, total avg loss: 0.3548, batch size: 45
2021-08-25 10:55:40,853 INFO [train.py:450] Epoch 3, batch 18690, batch avg loss 0.3553, total avg loss: 0.3543, batch size: 44
2021-08-25 10:55:46,712 INFO [train.py:450] Epoch 3, batch 18700, batch avg loss 0.3315, total avg loss: 0.3543, batch size: 40
2021-08-25 10:55:52,689 INFO [train.py:450] Epoch 3, batch 18710, batch avg loss 0.3133, total avg loss: 0.3551, batch size: 41
2021-08-25 10:55:58,592 INFO [train.py:450] Epoch 3, batch 18720, batch avg loss 0.3410, total avg loss: 0.3555, batch size: 38
2021-08-25 10:56:04,421 INFO [train.py:450] Epoch 3, batch 18730, batch avg loss 0.3592, total avg loss: 0.3542, batch size: 41
2021-08-25 10:56:10,348 INFO [train.py:450] Epoch 3, batch 18740, batch avg loss 0.3376, total avg loss: 0.3541, batch size: 38
2021-08-25 10:56:16,196 INFO [train.py:450] Epoch 3, batch 18750, batch avg loss 0.3492, total avg loss: 0.3549, batch size: 41
2021-08-25 10:56:22,182 INFO [train.py:450] Epoch 3, batch 18760, batch avg loss 0.3936, total avg loss: 0.3541, batch size: 41
2021-08-25 10:56:27,998 INFO [train.py:450] Epoch 3, batch 18770, batch avg loss 0.3898, total avg loss: 0.3552, batch size: 41
2021-08-25 10:56:33,753 INFO [train.py:450] Epoch 3, batch 18780, batch avg loss 0.3201, total avg loss: 0.3546, batch size: 38
2021-08-25 10:56:39,540 INFO [train.py:450] Epoch 3, batch 18790, batch avg loss 0.3555, total avg loss: 0.3548, batch size: 38
2021-08-25 10:56:45,433 INFO [train.py:450] Epoch 3, batch 18800, batch avg loss 0.4677, total avg loss: 0.3558, batch size: 36
2021-08-25 10:56:51,263 INFO [train.py:450] Epoch 3, batch 18810, batch avg loss 0.3148, total avg loss: 0.3559, batch size: 36
2021-08-25 10:56:57,273 INFO [train.py:450] Epoch 3, batch 18820, batch avg loss 0.4072, total avg loss: 0.3613, batch size: 42
2021-08-25 10:57:03,177 INFO [train.py:450] Epoch 3, batch 18830, batch avg loss 0.3273, total avg loss: 0.3540, batch size: 41
2021-08-25 10:57:09,364 INFO [train.py:450] Epoch 3, batch 18840, batch avg loss 0.3235, total avg loss: 0.3556, batch size: 43
2021-08-25 10:57:15,149 INFO [train.py:450] Epoch 3, batch 18850, batch avg loss 0.3488, total avg loss: 0.3576, batch size: 39
2021-08-25 10:57:20,938 INFO [train.py:450] Epoch 3, batch 18860, batch avg loss 0.3930, total avg loss: 0.3586, batch size: 37
2021-08-25 10:57:26,666 INFO [train.py:450] Epoch 3, batch 18870, batch avg loss 0.3616, total avg loss: 0.3582, batch size: 36
2021-08-25 10:57:32,572 INFO [train.py:450] Epoch 3, batch 18880, batch avg loss 0.3324, total avg loss: 0.3577, batch size: 39
2021-08-25 10:57:38,402 INFO [train.py:450] Epoch 3, batch 18890, batch avg loss 0.3093, total avg loss: 0.3577, batch size: 38
2021-08-25 10:57:44,280 INFO [train.py:450] Epoch 3, batch 18900, batch avg loss 0.3599, total avg loss: 0.3568, batch size: 40
2021-08-25 10:57:50,269 INFO [train.py:450] Epoch 3, batch 18910, batch avg loss 0.3606, total avg loss: 0.3568, batch size: 43
2021-08-25 10:57:56,270 INFO [train.py:450] Epoch 3, batch 18920, batch avg loss 0.3221, total avg loss: 0.3565, batch size: 40
2021-08-25 10:58:02,081 INFO [train.py:450] Epoch 3, batch 18930, batch avg loss 0.3970, total avg loss: 0.3569, batch size: 39
2021-08-25 10:58:07,922 INFO [train.py:450] Epoch 3, batch 18940, batch avg loss 0.3366, total avg loss: 0.3576, batch size: 43
2021-08-25 10:58:13,760 INFO [train.py:450] Epoch 3, batch 18950, batch avg loss 0.3525, total avg loss: 0.3585, batch size: 39
2021-08-25 10:58:19,700 INFO [train.py:450] Epoch 3, batch 18960, batch avg loss 0.3336, total avg loss: 0.3592, batch size: 38
2021-08-25 10:58:25,410 INFO [train.py:450] Epoch 3, batch 18970, batch avg loss 0.4210, total avg loss: 0.3594, batch size: 39
2021-08-25 10:58:31,421 INFO [train.py:450] Epoch 3, batch 18980, batch avg loss 0.4240, total avg loss: 0.3599, batch size: 39
2021-08-25 10:58:37,196 INFO [train.py:450] Epoch 3, batch 18990, batch avg loss 0.3532, total avg loss: 0.3598, batch size: 36
2021-08-25 10:58:42,994 INFO [train.py:450] Epoch 3, batch 19000, batch avg loss 0.3835, total avg loss: 0.3595, batch size: 38
2021-08-25 10:59:20,111 INFO [train.py:482] Epoch 3, valid loss 0.2658, best valid loss: 0.2434 best valid epoch: 2
2021-08-25 10:59:26,019 INFO [train.py:450] Epoch 3, batch 19010, batch avg loss 0.3548, total avg loss: 0.3603, batch size: 40
2021-08-25 10:59:31,877 INFO [train.py:450] Epoch 3, batch 19020, batch avg loss 0.3132, total avg loss: 0.3596, batch size: 38
2021-08-25 10:59:37,554 INFO [train.py:450] Epoch 3, batch 19030, batch avg loss 0.3127, total avg loss: 0.3599, batch size: 38
2021-08-25 10:59:43,226 INFO [train.py:450] Epoch 3, batch 19040, batch avg loss 0.3836, total avg loss: 0.3570, batch size: 40
2021-08-25 10:59:48,985 INFO [train.py:450] Epoch 3, batch 19050, batch avg loss 0.3444, total avg loss: 0.3586, batch size: 42
2021-08-25 10:59:54,780 INFO [train.py:450] Epoch 3, batch 19060, batch avg loss 0.3891, total avg loss: 0.3584, batch size: 35
2021-08-25 11:00:00,598 INFO [train.py:450] Epoch 3, batch 19070, batch avg loss 0.3878, total avg loss: 0.3597, batch size: 39
2021-08-25 11:00:06,450 INFO [train.py:450] Epoch 3, batch 19080, batch avg loss 0.3433, total avg loss: 0.3593, batch size: 41
2021-08-25 11:00:12,307 INFO [train.py:450] Epoch 3, batch 19090, batch avg loss 0.3692, total avg loss: 0.3615, batch size: 43
2021-08-25 11:00:18,141 INFO [train.py:450] Epoch 3, batch 19100, batch avg loss 0.3519, total avg loss: 0.3602, batch size: 39
2021-08-25 11:00:24,127 INFO [train.py:450] Epoch 3, batch 19110, batch avg loss 0.3986, total avg loss: 0.3605, batch size: 42
2021-08-25 11:00:29,981 INFO [train.py:450] Epoch 3, batch 19120, batch avg loss 0.3256, total avg loss: 0.3604, batch size: 39
2021-08-25 11:00:35,885 INFO [train.py:450] Epoch 3, batch 19130, batch avg loss 0.3473, total avg loss: 0.3600, batch size: 37
2021-08-25 11:00:41,864 INFO [train.py:450] Epoch 3, batch 19140, batch avg loss 0.3273, total avg loss: 0.3591, batch size: 41
2021-08-25 11:00:47,675 INFO [train.py:450] Epoch 3, batch 19150, batch avg loss 0.3371, total avg loss: 0.3600, batch size: 40
2021-08-25 11:00:53,507 INFO [train.py:450] Epoch 3, batch 19160, batch avg loss 0.3765, total avg loss: 0.3594, batch size: 43
2021-08-25 11:00:59,443 INFO [train.py:450] Epoch 3, batch 19170, batch avg loss 0.3504, total avg loss: 0.3595, batch size: 39
2021-08-25 11:01:05,193 INFO [train.py:450] Epoch 3, batch 19180, batch avg loss 0.4574, total avg loss: 0.3600, batch size: 41
2021-08-25 11:01:11,044 INFO [train.py:450] Epoch 3, batch 19190, batch avg loss 0.4734, total avg loss: 0.3614, batch size: 42
2021-08-25 11:01:16,881 INFO [train.py:450] Epoch 3, batch 19200, batch avg loss 0.4786, total avg loss: 0.3635, batch size: 41
2021-08-25 11:01:22,687 INFO [train.py:450] Epoch 3, batch 19210, batch avg loss 0.3267, total avg loss: 0.4265, batch size: 37
2021-08-25 11:01:28,367 INFO [train.py:450] Epoch 3, batch 19220, batch avg loss 0.4263, total avg loss: 0.4259, batch size: 39
2021-08-25 11:01:34,415 INFO [train.py:450] Epoch 3, batch 19230, batch avg loss 0.5187, total avg loss: 0.4357, batch size: 39
2021-08-25 11:01:40,305 INFO [train.py:450] Epoch 3, batch 19240, batch avg loss 0.4653, total avg loss: 0.4377, batch size: 41
2021-08-25 11:01:46,250 INFO [train.py:450] Epoch 3, batch 19250, batch avg loss 0.5123, total avg loss: 0.4360, batch size: 40
2021-08-25 11:01:52,125 INFO [train.py:450] Epoch 3, batch 19260, batch avg loss 0.3974, total avg loss: 0.4334, batch size: 44
2021-08-25 11:01:57,848 INFO [train.py:450] Epoch 3, batch 19270, batch avg loss 0.3140, total avg loss: 0.4241, batch size: 39
2021-08-25 11:02:03,765 INFO [train.py:450] Epoch 3, batch 19280, batch avg loss 0.3868, total avg loss: 0.4160, batch size: 40
2021-08-25 11:02:09,723 INFO [train.py:450] Epoch 3, batch 19290, batch avg loss 0.3223, total avg loss: 0.4138, batch size: 41
2021-08-25 11:02:15,522 INFO [train.py:450] Epoch 3, batch 19300, batch avg loss 0.3802, total avg loss: 0.4087, batch size: 42
2021-08-25 11:02:21,372 INFO [train.py:450] Epoch 3, batch 19310, batch avg loss 0.3208, total avg loss: 0.4064, batch size: 44
2021-08-25 11:02:27,272 INFO [train.py:450] Epoch 3, batch 19320, batch avg loss 0.3581, total avg loss: 0.4048, batch size: 40
2021-08-25 11:02:33,051 INFO [train.py:450] Epoch 3, batch 19330, batch avg loss 0.3790, total avg loss: 0.4038, batch size: 40
2021-08-25 11:02:38,851 INFO [train.py:450] Epoch 3, batch 19340, batch avg loss 0.3360, total avg loss: 0.4021, batch size: 39
2021-08-25 11:02:44,674 INFO [train.py:450] Epoch 3, batch 19350, batch avg loss 0.4386, total avg loss: 0.4007, batch size: 37
2021-08-25 11:02:50,472 INFO [train.py:450] Epoch 3, batch 19360, batch avg loss 0.4765, total avg loss: 0.3984, batch size: 45
2021-08-25 11:02:56,277 INFO [train.py:450] Epoch 3, batch 19370, batch avg loss 0.3530, total avg loss: 0.3966, batch size: 40
2021-08-25 11:03:01,985 INFO [train.py:450] Epoch 3, batch 19380, batch avg loss 0.3533, total avg loss: 0.3950, batch size: 38
2021-08-25 11:03:07,741 INFO [train.py:450] Epoch 3, batch 19390, batch avg loss 0.4074, total avg loss: 0.3939, batch size: 40
2021-08-25 11:03:13,590 INFO [train.py:450] Epoch 3, batch 19400, batch avg loss 0.3889, total avg loss: 0.3926, batch size: 42
2021-08-25 11:03:19,481 INFO [train.py:450] Epoch 3, batch 19410, batch avg loss 0.3695, total avg loss: 0.3560, batch size: 43
2021-08-25 11:03:25,426 INFO [train.py:450] Epoch 3, batch 19420, batch avg loss 0.3467, total avg loss: 0.3543, batch size: 41
2021-08-25 11:03:31,324 INFO [train.py:450] Epoch 3, batch 19430, batch avg loss 0.3473, total avg loss: 0.3578, batch size: 43
2021-08-25 11:03:37,258 INFO [train.py:450] Epoch 3, batch 19440, batch avg loss 0.3870, total avg loss: 0.3610, batch size: 39
2021-08-25 11:03:43,173 INFO [train.py:450] Epoch 3, batch 19450, batch avg loss 0.3400, total avg loss: 0.3633, batch size: 40
2021-08-25 11:03:49,024 INFO [train.py:450] Epoch 3, batch 19460, batch avg loss 0.4326, total avg loss: 0.3617, batch size: 38
2021-08-25 11:03:54,935 INFO [train.py:450] Epoch 3, batch 19470, batch avg loss 0.3037, total avg loss: 0.3598, batch size: 41
2021-08-25 11:04:01,121 INFO [train.py:450] Epoch 3, batch 19480, batch avg loss 0.3450, total avg loss: 0.3606, batch size: 41
2021-08-25 11:04:07,039 INFO [train.py:450] Epoch 3, batch 19490, batch avg loss 0.3923, total avg loss: 0.3611, batch size: 41
2021-08-25 11:04:12,875 INFO [train.py:450] Epoch 3, batch 19500, batch avg loss 0.3254, total avg loss: 0.3620, batch size: 42
2021-08-25 11:04:18,710 INFO [train.py:450] Epoch 3, batch 19510, batch avg loss 0.3263, total avg loss: 0.3609, batch size: 42
2021-08-25 11:04:24,558 INFO [train.py:450] Epoch 3, batch 19520, batch avg loss 0.3450, total avg loss: 0.3615, batch size: 39
2021-08-25 11:04:30,451 INFO [train.py:450] Epoch 3, batch 19530, batch avg loss 0.4058, total avg loss: 0.3623, batch size: 41
2021-08-25 11:04:36,297 INFO [train.py:450] Epoch 3, batch 19540, batch avg loss 0.3930, total avg loss: 0.3620, batch size: 42
2021-08-25 11:04:42,278 INFO [train.py:450] Epoch 3, batch 19550, batch avg loss 0.3607, total avg loss: 0.3621, batch size: 41
2021-08-25 11:04:48,139 INFO [train.py:450] Epoch 3, batch 19560, batch avg loss 0.3471, total avg loss: 0.3624, batch size: 45
2021-08-25 11:04:54,034 INFO [train.py:450] Epoch 3, batch 19570, batch avg loss 0.3455, total avg loss: 0.3618, batch size: 40
2021-08-25 11:04:59,989 INFO [train.py:450] Epoch 3, batch 19580, batch avg loss 0.3889, total avg loss: 0.3615, batch size: 39
2021-08-25 11:05:05,737 INFO [train.py:450] Epoch 3, batch 19590, batch avg loss 0.3411, total avg loss: 0.3616, batch size: 39
2021-08-25 11:05:11,590 INFO [train.py:450] Epoch 3, batch 19600, batch avg loss 0.3712, total avg loss: 0.3622, batch size: 39
2021-08-25 11:05:17,316 INFO [train.py:450] Epoch 3, batch 19610, batch avg loss 0.3500, total avg loss: 0.3745, batch size: 40
2021-08-25 11:05:23,054 INFO [train.py:450] Epoch 3, batch 19620, batch avg loss 0.3062, total avg loss: 0.3638, batch size: 38
2021-08-25 11:05:28,910 INFO [train.py:450] Epoch 3, batch 19630, batch avg loss 0.3556, total avg loss: 0.3615, batch size: 39
2021-08-25 11:05:34,682 INFO [train.py:450] Epoch 3, batch 19640, batch avg loss 0.3610, total avg loss: 0.3645, batch size: 42
2021-08-25 11:05:40,663 INFO [train.py:450] Epoch 3, batch 19650, batch avg loss 0.3928, total avg loss: 0.3660, batch size: 40
2021-08-25 11:05:46,484 INFO [train.py:450] Epoch 3, batch 19660, batch avg loss 0.3690, total avg loss: 0.3655, batch size: 45
2021-08-25 11:05:52,238 INFO [train.py:450] Epoch 3, batch 19670, batch avg loss 0.3513, total avg loss: 0.3630, batch size: 38
2021-08-25 11:05:58,083 INFO [train.py:450] Epoch 3, batch 19680, batch avg loss 0.3769, total avg loss: 0.3640, batch size: 41
2021-08-25 11:06:03,908 INFO [train.py:450] Epoch 3, batch 19690, batch avg loss 0.4032, total avg loss: 0.3645, batch size: 39
2021-08-25 11:06:09,714 INFO [train.py:450] Epoch 3, batch 19700, batch avg loss 0.3208, total avg loss: 0.3664, batch size: 41
2021-08-25 11:06:15,441 INFO [train.py:450] Epoch 3, batch 19710, batch avg loss 0.3682, total avg loss: 0.3648, batch size: 40
2021-08-25 11:06:21,441 INFO [train.py:450] Epoch 3, batch 19720, batch avg loss 0.4004, total avg loss: 0.3649, batch size: 41
2021-08-25 11:06:27,259 INFO [train.py:450] Epoch 3, batch 19730, batch avg loss 0.3717, total avg loss: 0.3646, batch size: 41
2021-08-25 11:06:33,252 INFO [train.py:450] Epoch 3, batch 19740, batch avg loss 0.3752, total avg loss: 0.3654, batch size: 43
2021-08-25 11:06:39,111 INFO [train.py:450] Epoch 3, batch 19750, batch avg loss 0.4510, total avg loss: 0.3675, batch size: 39
2021-08-25 11:06:44,877 INFO [train.py:450] Epoch 3, batch 19760, batch avg loss 0.3934, total avg loss: 0.3686, batch size: 40
2021-08-25 11:06:50,841 INFO [train.py:450] Epoch 3, batch 19770, batch avg loss 0.3492, total avg loss: 0.3677, batch size: 39
2021-08-25 11:06:56,883 INFO [train.py:450] Epoch 3, batch 19780, batch avg loss 0.3756, total avg loss: 0.3672, batch size: 44
2021-08-25 11:07:02,830 INFO [train.py:450] Epoch 3, batch 19790, batch avg loss 0.4032, total avg loss: 0.3679, batch size: 41
2021-08-25 11:07:08,975 INFO [train.py:450] Epoch 3, batch 19800, batch avg loss 0.3853, total avg loss: 0.3670, batch size: 41
2021-08-25 11:07:14,814 INFO [train.py:450] Epoch 3, batch 19810, batch avg loss 0.3657, total avg loss: 0.3822, batch size: 40
2021-08-25 11:07:20,578 INFO [train.py:450] Epoch 3, batch 19820, batch avg loss 0.3419, total avg loss: 0.3803, batch size: 39
2021-08-25 11:07:26,412 INFO [train.py:450] Epoch 3, batch 19830, batch avg loss 0.3346, total avg loss: 0.3753, batch size: 42
2021-08-25 11:07:32,143 INFO [train.py:450] Epoch 3, batch 19840, batch avg loss 0.3603, total avg loss: 0.3704, batch size: 39
2021-08-25 11:07:37,950 INFO [train.py:450] Epoch 3, batch 19850, batch avg loss 0.3852, total avg loss: 0.3688, batch size: 39
2021-08-25 11:07:43,718 INFO [train.py:450] Epoch 3, batch 19860, batch avg loss 0.3500, total avg loss: 0.3687, batch size: 37
2021-08-25 11:07:49,673 INFO [train.py:450] Epoch 3, batch 19870, batch avg loss 0.3247, total avg loss: 0.3695, batch size: 39
2021-08-25 11:07:55,575 INFO [train.py:450] Epoch 3, batch 19880, batch avg loss 0.3996, total avg loss: 0.3683, batch size: 41
2021-08-25 11:08:01,487 INFO [train.py:450] Epoch 3, batch 19890, batch avg loss 0.3172, total avg loss: 0.3662, batch size: 39
2021-08-25 11:08:07,396 INFO [train.py:450] Epoch 3, batch 19900, batch avg loss 0.4050, total avg loss: 0.3658, batch size: 40
2021-08-25 11:08:13,334 INFO [train.py:450] Epoch 3, batch 19910, batch avg loss 0.3706, total avg loss: 0.3665, batch size: 38
2021-08-25 11:08:19,205 INFO [train.py:450] Epoch 3, batch 19920, batch avg loss 0.3564, total avg loss: 0.3664, batch size: 42
2021-08-25 11:08:25,049 INFO [train.py:450] Epoch 3, batch 19930, batch avg loss 0.3739, total avg loss: 0.3663, batch size: 41
2021-08-25 11:08:30,906 INFO [train.py:450] Epoch 3, batch 19940, batch avg loss 0.3521, total avg loss: 0.3659, batch size: 39
2021-08-25 11:08:36,970 INFO [train.py:450] Epoch 3, batch 19950, batch avg loss 0.3255, total avg loss: 0.3655, batch size: 40
2021-08-25 11:08:42,850 INFO [train.py:450] Epoch 3, batch 19960, batch avg loss 0.3534, total avg loss: 0.3666, batch size: 39
2021-08-25 11:08:48,717 INFO [train.py:450] Epoch 3, batch 19970, batch avg loss 0.3365, total avg loss: 0.3661, batch size: 39
2021-08-25 11:08:54,517 INFO [train.py:450] Epoch 3, batch 19980, batch avg loss 0.3569, total avg loss: 0.3660, batch size: 39
2021-08-25 11:09:00,339 INFO [train.py:450] Epoch 3, batch 19990, batch avg loss 0.3468, total avg loss: 0.3664, batch size: 39
2021-08-25 11:09:06,257 INFO [train.py:450] Epoch 3, batch 20000, batch avg loss 0.3725, total avg loss: 0.3664, batch size: 39
2021-08-25 11:09:43,620 INFO [train.py:482] Epoch 3, valid loss 0.2571, best valid loss: 0.2434 best valid epoch: 2
2021-08-25 11:09:49,490 INFO [train.py:450] Epoch 3, batch 20010, batch avg loss 0.4020, total avg loss: 0.3583, batch size: 42
2021-08-25 11:09:55,298 INFO [train.py:450] Epoch 3, batch 20020, batch avg loss 0.3697, total avg loss: 0.3527, batch size: 39
2021-08-25 11:10:01,211 INFO [train.py:450] Epoch 3, batch 20030, batch avg loss 0.3224, total avg loss: 0.3554, batch size: 39
2021-08-25 11:10:07,099 INFO [train.py:450] Epoch 3, batch 20040, batch avg loss 0.3809, total avg loss: 0.3566, batch size: 41
2021-08-25 11:10:12,959 INFO [train.py:450] Epoch 3, batch 20050, batch avg loss 0.3912, total avg loss: 0.3591, batch size: 40
2021-08-25 11:10:18,913 INFO [train.py:450] Epoch 3, batch 20060, batch avg loss 0.4099, total avg loss: 0.3577, batch size: 41
2021-08-25 11:10:24,700 INFO [train.py:450] Epoch 3, batch 20070, batch avg loss 0.3489, total avg loss: 0.3603, batch size: 39
2021-08-25 11:10:30,623 INFO [train.py:450] Epoch 3, batch 20080, batch avg loss 0.2983, total avg loss: 0.3592, batch size: 40
2021-08-25 11:10:36,341 INFO [train.py:450] Epoch 3, batch 20090, batch avg loss 0.4341, total avg loss: 0.3620, batch size: 41
2021-08-25 11:10:42,195 INFO [train.py:450] Epoch 3, batch 20100, batch avg loss 0.3249, total avg loss: 0.3644, batch size: 39
2021-08-25 11:10:47,997 INFO [train.py:450] Epoch 3, batch 20110, batch avg loss 0.2926, total avg loss: 0.3633, batch size: 38
2021-08-25 11:10:53,892 INFO [train.py:450] Epoch 3, batch 20120, batch avg loss 0.3542, total avg loss: 0.3639, batch size: 44
2021-08-25 11:11:00,233 INFO [train.py:450] Epoch 3, batch 20130, batch avg loss 0.3371, total avg loss: 0.3633, batch size: 42
2021-08-25 11:11:06,049 INFO [train.py:450] Epoch 3, batch 20140, batch avg loss 0.3584, total avg loss: 0.3649, batch size: 38
2021-08-25 11:11:11,840 INFO [train.py:450] Epoch 3, batch 20150, batch avg loss 0.3810, total avg loss: 0.3658, batch size: 40
2021-08-25 11:11:17,640 INFO [train.py:450] Epoch 3, batch 20160, batch avg loss 0.3583, total avg loss: 0.3655, batch size: 38
2021-08-25 11:11:23,556 INFO [train.py:450] Epoch 3, batch 20170, batch avg loss 0.4268, total avg loss: 0.3647, batch size: 41
2021-08-25 11:11:29,387 INFO [train.py:450] Epoch 3, batch 20180, batch avg loss 0.3919, total avg loss: 0.3641, batch size: 40
2021-08-25 11:11:35,285 INFO [train.py:450] Epoch 3, batch 20190, batch avg loss 0.3314, total avg loss: 0.3641, batch size: 37
2021-08-25 11:11:41,161 INFO [train.py:450] Epoch 3, batch 20200, batch avg loss 0.3539, total avg loss: 0.3642, batch size: 40
2021-08-25 11:11:47,010 INFO [train.py:450] Epoch 3, batch 20210, batch avg loss 0.3622, total avg loss: 0.3671, batch size: 41
2021-08-25 11:11:52,892 INFO [train.py:450] Epoch 3, batch 20220, batch avg loss 0.3569, total avg loss: 0.3639, batch size: 39
2021-08-25 11:11:58,733 INFO [train.py:450] Epoch 3, batch 20230, batch avg loss 0.3635, total avg loss: 0.3634, batch size: 40
2021-08-25 11:12:04,603 INFO [train.py:450] Epoch 3, batch 20240, batch avg loss 0.3314, total avg loss: 0.3624, batch size: 38
2021-08-25 11:12:10,455 INFO [train.py:450] Epoch 3, batch 20250, batch avg loss 0.3750, total avg loss: 0.3653, batch size: 41
2021-08-25 11:12:16,243 INFO [train.py:450] Epoch 3, batch 20260, batch avg loss 0.4070, total avg loss: 0.3651, batch size: 39
2021-08-25 11:12:21,978 INFO [train.py:450] Epoch 3, batch 20270, batch avg loss 0.3210, total avg loss: 0.3631, batch size: 39
2021-08-25 11:12:27,735 INFO [train.py:450] Epoch 3, batch 20280, batch avg loss 0.3489, total avg loss: 0.3633, batch size: 39
2021-08-25 11:12:33,527 INFO [train.py:450] Epoch 3, batch 20290, batch avg loss 0.3099, total avg loss: 0.3622, batch size: 40
2021-08-25 11:12:39,453 INFO [train.py:450] Epoch 3, batch 20300, batch avg loss 0.2765, total avg loss: 0.3602, batch size: 41
2021-08-25 11:12:45,390 INFO [train.py:450] Epoch 3, batch 20310, batch avg loss 0.3508, total avg loss: 0.3582, batch size: 38
2021-08-25 11:12:51,430 INFO [train.py:450] Epoch 3, batch 20320, batch avg loss 0.3501, total avg loss: 0.3574, batch size: 39
2021-08-25 11:12:57,331 INFO [train.py:450] Epoch 3, batch 20330, batch avg loss 0.3671, total avg loss: 0.3573, batch size: 40
2021-08-25 11:13:03,136 INFO [train.py:450] Epoch 3, batch 20340, batch avg loss 0.3147, total avg loss: 0.3569, batch size: 37
2021-08-25 11:13:09,129 INFO [train.py:450] Epoch 3, batch 20350, batch avg loss 0.4539, total avg loss: 0.3584, batch size: 42
2021-08-25 11:13:14,960 INFO [train.py:450] Epoch 3, batch 20360, batch avg loss 0.4247, total avg loss: 0.3599, batch size: 38
2021-08-25 11:13:20,829 INFO [train.py:450] Epoch 3, batch 20370, batch avg loss 0.3402, total avg loss: 0.3601, batch size: 42
2021-08-25 11:13:26,802 INFO [train.py:450] Epoch 3, batch 20380, batch avg loss 0.3411, total avg loss: 0.3598, batch size: 38
2021-08-25 11:13:32,739 INFO [train.py:450] Epoch 3, batch 20390, batch avg loss 0.3767, total avg loss: 0.3612, batch size: 37
2021-08-25 11:13:38,555 INFO [train.py:450] Epoch 3, batch 20400, batch avg loss 0.2702, total avg loss: 0.3603, batch size: 39
2021-08-25 11:13:44,490 INFO [train.py:450] Epoch 3, batch 20410, batch avg loss 0.3930, total avg loss: 0.3727, batch size: 38
2021-08-25 11:13:50,291 INFO [train.py:450] Epoch 3, batch 20420, batch avg loss 0.3922, total avg loss: 0.3665, batch size: 37
2021-08-25 11:13:56,140 INFO [train.py:450] Epoch 3, batch 20430, batch avg loss 0.3558, total avg loss: 0.3637, batch size: 38
2021-08-25 11:14:01,906 INFO [train.py:450] Epoch 3, batch 20440, batch avg loss 0.3769, total avg loss: 0.3588, batch size: 36
2021-08-25 11:14:07,825 INFO [train.py:450] Epoch 3, batch 20450, batch avg loss 0.3054, total avg loss: 0.3583, batch size: 41
2021-08-25 11:14:13,643 INFO [train.py:450] Epoch 3, batch 20460, batch avg loss 0.3513, total avg loss: 0.3619, batch size: 43
2021-08-25 11:14:19,389 INFO [train.py:450] Epoch 3, batch 20470, batch avg loss 0.4271, total avg loss: 0.3635, batch size: 38
2021-08-25 11:14:25,290 INFO [train.py:450] Epoch 3, batch 20480, batch avg loss 0.4460, total avg loss: 0.3671, batch size: 42
2021-08-25 11:14:31,214 INFO [train.py:450] Epoch 3, batch 20490, batch avg loss 0.4196, total avg loss: 0.3699, batch size: 37
2021-08-25 11:14:37,092 INFO [train.py:450] Epoch 3, batch 20500, batch avg loss 0.3344, total avg loss: 0.3704, batch size: 41
2021-08-25 11:14:42,896 INFO [train.py:450] Epoch 3, batch 20510, batch avg loss 0.4709, total avg loss: 0.3713, batch size: 39
2021-08-25 11:14:48,761 INFO [train.py:450] Epoch 3, batch 20520, batch avg loss 0.4403, total avg loss: 0.3727, batch size: 41
2021-08-25 11:14:54,707 INFO [train.py:450] Epoch 3, batch 20530, batch avg loss 0.3426, total avg loss: 0.3732, batch size: 42
2021-08-25 11:15:00,894 INFO [train.py:450] Epoch 3, batch 20540, batch avg loss 0.3902, total avg loss: 0.3738, batch size: 39
2021-08-25 11:15:06,809 INFO [train.py:450] Epoch 3, batch 20550, batch avg loss 0.3933, total avg loss: 0.3731, batch size: 43
2021-08-25 11:15:12,850 INFO [train.py:450] Epoch 3, batch 20560, batch avg loss 0.3438, total avg loss: 0.3728, batch size: 47
2021-08-25 11:15:18,730 INFO [train.py:450] Epoch 3, batch 20570, batch avg loss 0.3258, total avg loss: 0.3727, batch size: 43
2021-08-25 11:15:24,513 INFO [train.py:450] Epoch 3, batch 20580, batch avg loss 0.3640, total avg loss: 0.3728, batch size: 41
2021-08-25 11:15:30,302 INFO [train.py:450] Epoch 3, batch 20590, batch avg loss 0.3375, total avg loss: 0.3718, batch size: 36
2021-08-25 11:15:36,127 INFO [train.py:450] Epoch 3, batch 20600, batch avg loss 0.4255, total avg loss: 0.3729, batch size: 38
2021-08-25 11:15:42,051 INFO [train.py:450] Epoch 3, batch 20610, batch avg loss 0.4391, total avg loss: 0.3766, batch size: 43
2021-08-25 11:15:47,759 INFO [train.py:450] Epoch 3, batch 20620, batch avg loss 0.4180, total avg loss: 0.3773, batch size: 37
2021-08-25 11:15:53,686 INFO [train.py:450] Epoch 3, batch 20630, batch avg loss 0.3731, total avg loss: 0.3772, batch size: 37
2021-08-25 11:15:59,527 INFO [train.py:450] Epoch 3, batch 20640, batch avg loss 0.3865, total avg loss: 0.3747, batch size: 36
2021-08-25 11:16:05,286 INFO [train.py:450] Epoch 3, batch 20650, batch avg loss 0.3589, total avg loss: 0.3746, batch size: 36
2021-08-25 11:16:11,104 INFO [train.py:450] Epoch 3, batch 20660, batch avg loss 0.4254, total avg loss: 0.3748, batch size: 44
2021-08-25 11:16:17,055 INFO [train.py:450] Epoch 3, batch 20670, batch avg loss 0.3518, total avg loss: 0.3763, batch size: 40
2021-08-25 11:16:22,859 INFO [train.py:450] Epoch 3, batch 20680, batch avg loss 0.3404, total avg loss: 0.3767, batch size: 36
2021-08-25 11:16:28,699 INFO [train.py:450] Epoch 3, batch 20690, batch avg loss 0.3242, total avg loss: 0.3752, batch size: 38
2021-08-25 11:16:34,674 INFO [train.py:450] Epoch 3, batch 20700, batch avg loss 0.3323, total avg loss: 0.3747, batch size: 38
2021-08-25 11:16:40,573 INFO [train.py:450] Epoch 3, batch 20710, batch avg loss 0.3717, total avg loss: 0.3742, batch size: 42
2021-08-25 11:16:46,351 INFO [train.py:450] Epoch 3, batch 20720, batch avg loss 0.3929, total avg loss: 0.3735, batch size: 35
2021-08-25 11:16:52,215 INFO [train.py:450] Epoch 3, batch 20730, batch avg loss 0.3790, total avg loss: 0.3745, batch size: 45
2021-08-25 11:16:58,007 INFO [train.py:450] Epoch 3, batch 20740, batch avg loss 0.3718, total avg loss: 0.3732, batch size: 42
2021-08-25 11:17:03,842 INFO [train.py:450] Epoch 3, batch 20750, batch avg loss 0.3659, total avg loss: 0.3728, batch size: 41
2021-08-25 11:17:09,736 INFO [train.py:450] Epoch 3, batch 20760, batch avg loss 0.3033, total avg loss: 0.3726, batch size: 40
2021-08-25 11:17:15,681 INFO [train.py:450] Epoch 3, batch 20770, batch avg loss 0.3514, total avg loss: 0.3717, batch size: 41
2021-08-25 11:17:16,513 WARNING [cut.py:1694] To perform mix, energy must be non-zero and non-negative (got 0.0).  MonoCut with id "6c78be91-67b8-40bb-bf94-e10dcd98eb3f" will not be mixed in.
2021-08-25 11:17:21,592 INFO [train.py:450] Epoch 3, batch 20780, batch avg loss 0.4132, total avg loss: 0.3715, batch size: 41
2021-08-25 11:17:27,450 INFO [train.py:450] Epoch 3, batch 20790, batch avg loss 0.3263, total avg loss: 0.3705, batch size: 38
2021-08-25 11:17:33,308 INFO [train.py:450] Epoch 3, batch 20800, batch avg loss 0.4522, total avg loss: 0.3701, batch size: 41
2021-08-25 11:17:39,157 INFO [train.py:450] Epoch 3, batch 20810, batch avg loss 0.2858, total avg loss: 0.3644, batch size: 42
2021-08-25 11:17:44,982 INFO [train.py:450] Epoch 3, batch 20820, batch avg loss 0.4163, total avg loss: 0.3590, batch size: 42
2021-08-25 11:17:50,753 INFO [train.py:450] Epoch 3, batch 20830, batch avg loss 0.3289, total avg loss: 0.3593, batch size: 42
2021-08-25 11:17:56,580 INFO [train.py:450] Epoch 3, batch 20840, batch avg loss 0.3744, total avg loss: 0.3595, batch size: 40
2021-08-25 11:18:02,472 INFO [train.py:450] Epoch 3, batch 20850, batch avg loss 0.3501, total avg loss: 0.3581, batch size: 39
2021-08-25 11:18:08,339 INFO [train.py:450] Epoch 3, batch 20860, batch avg loss 0.3582, total avg loss: 0.3601, batch size: 41
2021-08-25 11:18:21,728 INFO [train.py:450] Epoch 3, batch 20870, batch avg loss 0.3396, total avg loss: 0.3605, batch size: 43
2021-08-25 11:18:27,680 INFO [train.py:450] Epoch 3, batch 20880, batch avg loss 0.3797, total avg loss: 0.3628, batch size: 36
2021-08-25 11:18:33,622 INFO [train.py:450] Epoch 3, batch 20890, batch avg loss 0.3704, total avg loss: 0.3638, batch size: 36
2021-08-25 11:18:39,650 INFO [train.py:450] Epoch 3, batch 20900, batch avg loss 0.3717, total avg loss: 0.3656, batch size: 40
2021-08-25 11:18:45,455 INFO [train.py:450] Epoch 3, batch 20910, batch avg loss 0.4172, total avg loss: 0.3668, batch size: 40
2021-08-25 11:18:51,354 INFO [train.py:450] Epoch 3, batch 20920, batch avg loss 0.3397, total avg loss: 0.3642, batch size: 41
2021-08-25 11:18:57,146 INFO [train.py:450] Epoch 3, batch 20930, batch avg loss 0.3326, total avg loss: 0.3653, batch size: 35
2021-08-25 11:19:02,979 INFO [train.py:450] Epoch 3, batch 20940, batch avg loss 0.3554, total avg loss: 0.3656, batch size: 37
2021-08-25 11:19:08,780 INFO [train.py:450] Epoch 3, batch 20950, batch avg loss 0.3404, total avg loss: 0.3642, batch size: 39
2021-08-25 11:19:14,525 INFO [train.py:450] Epoch 3, batch 20960, batch avg loss 0.3487, total avg loss: 0.3638, batch size: 37
2021-08-25 11:19:20,255 INFO [train.py:450] Epoch 3, batch 20970, batch avg loss 0.3837, total avg loss: 0.3636, batch size: 40
2021-08-25 11:19:26,258 INFO [train.py:450] Epoch 3, batch 20980, batch avg loss 0.3919, total avg loss: 0.3645, batch size: 37
2021-08-25 11:19:32,090 INFO [train.py:450] Epoch 3, batch 20990, batch avg loss 0.3946, total avg loss: 0.3647, batch size: 41
2021-08-25 11:19:38,108 INFO [train.py:450] Epoch 3, batch 21000, batch avg loss 0.3612, total avg loss: 0.3650, batch size: 38
2021-08-25 11:20:15,720 INFO [train.py:482] Epoch 3, valid loss 0.2564, best valid loss: 0.2434 best valid epoch: 2
2021-08-25 11:20:21,758 INFO [train.py:450] Epoch 3, batch 21010, batch avg loss 0.4182, total avg loss: 0.3693, batch size: 44
2021-08-25 11:20:27,682 INFO [train.py:450] Epoch 3, batch 21020, batch avg loss 0.3402, total avg loss: 0.3637, batch size: 36
2021-08-25 11:20:33,600 INFO [train.py:450] Epoch 3, batch 21030, batch avg loss 0.3972, total avg loss: 0.3640, batch size: 37
2021-08-25 11:20:39,559 INFO [train.py:450] Epoch 3, batch 21040, batch avg loss 0.3638, total avg loss: 0.3667, batch size: 38
2021-08-25 11:20:45,581 INFO [train.py:450] Epoch 3, batch 21050, batch avg loss 0.3418, total avg loss: 0.3657, batch size: 42
2021-08-25 11:20:51,560 INFO [train.py:450] Epoch 3, batch 21060, batch avg loss 0.3787, total avg loss: 0.3668, batch size: 42
2021-08-25 11:20:57,387 INFO [train.py:450] Epoch 3, batch 21070, batch avg loss 0.4125, total avg loss: 0.3678, batch size: 37
2021-08-25 11:21:03,142 INFO [train.py:450] Epoch 3, batch 21080, batch avg loss 0.4058, total avg loss: 0.3679, batch size: 37
2021-08-25 11:21:09,007 INFO [train.py:450] Epoch 3, batch 21090, batch avg loss 0.4133, total avg loss: 0.3683, batch size: 39
2021-08-25 11:21:15,004 INFO [train.py:450] Epoch 3, batch 21100, batch avg loss 0.3517, total avg loss: 0.3676, batch size: 41
2021-08-25 11:21:20,833 INFO [train.py:450] Epoch 3, batch 21110, batch avg loss 0.3277, total avg loss: 0.3676, batch size: 39
2021-08-25 11:21:26,590 INFO [train.py:450] Epoch 3, batch 21120, batch avg loss 0.3553, total avg loss: 0.3692, batch size: 43
2021-08-25 11:21:32,437 INFO [train.py:450] Epoch 3, batch 21130, batch avg loss 0.3151, total avg loss: 0.3685, batch size: 40
2021-08-25 11:21:38,255 INFO [train.py:450] Epoch 3, batch 21140, batch avg loss 0.4243, total avg loss: 0.3695, batch size: 40
2021-08-25 11:21:44,106 INFO [train.py:450] Epoch 3, batch 21150, batch avg loss 0.4247, total avg loss: 0.3705, batch size: 40
2021-08-25 11:21:49,969 INFO [train.py:450] Epoch 3, batch 21160, batch avg loss 0.2963, total avg loss: 0.3707, batch size: 38
2021-08-25 11:21:55,758 INFO [train.py:450] Epoch 3, batch 21170, batch avg loss 0.3791, total avg loss: 0.3700, batch size: 39
2021-08-25 11:22:01,832 INFO [train.py:450] Epoch 3, batch 21180, batch avg loss 0.3088, total avg loss: 0.3693, batch size: 36
2021-08-25 11:22:07,067 INFO [checkpoint.py:62] Saving checkpoint to tdnn_lstm_ctc/exp/epoch-3.pt
2021-08-25 11:22:08,233 INFO [train.py:563] epoch 4, lr: 0.001
2021-08-25 11:22:26,665 INFO [train.py:450] Epoch 4, batch 0, batch avg loss 0.3605, total avg loss: 0.3605, batch size: 38
2021-08-25 11:22:48,825 INFO [train.py:450] Epoch 4, batch 10, batch avg loss 0.4033, total avg loss: 0.3599, batch size: 39
2021-08-25 11:23:08,154 INFO [train.py:450] Epoch 4, batch 20, batch avg loss 0.3615, total avg loss: 0.3617, batch size: 40
2021-08-25 11:23:34,189 INFO [train.py:450] Epoch 4, batch 30, batch avg loss 0.3532, total avg loss: 0.3638, batch size: 41
2021-08-25 11:23:53,046 INFO [train.py:450] Epoch 4, batch 40, batch avg loss 0.3597, total avg loss: 0.3655, batch size: 42
2021-08-25 11:24:09,781 INFO [train.py:450] Epoch 4, batch 50, batch avg loss 0.3258, total avg loss: 0.3631, batch size: 40
2021-08-25 11:24:29,214 INFO [train.py:450] Epoch 4, batch 60, batch avg loss 0.3442, total avg loss: 0.3625, batch size: 42
2021-08-25 11:24:44,610 INFO [train.py:450] Epoch 4, batch 70, batch avg loss 0.4005, total avg loss: 0.3621, batch size: 39
2021-08-25 11:25:01,004 INFO [train.py:450] Epoch 4, batch 80, batch avg loss 0.3467, total avg loss: 0.3624, batch size: 41
2021-08-25 11:25:16,942 INFO [train.py:450] Epoch 4, batch 90, batch avg loss 0.2906, total avg loss: 0.3619, batch size: 40
2021-08-25 11:25:32,711 INFO [train.py:450] Epoch 4, batch 100, batch avg loss 0.4089, total avg loss: 0.3626, batch size: 40
2021-08-25 11:25:48,138 INFO [train.py:450] Epoch 4, batch 110, batch avg loss 0.3256, total avg loss: 0.3647, batch size: 38
2021-08-25 11:26:04,036 INFO [train.py:450] Epoch 4, batch 120, batch avg loss 0.3396, total avg loss: 0.3657, batch size: 38
2021-08-25 11:26:19,692 INFO [train.py:450] Epoch 4, batch 130, batch avg loss 0.3394, total avg loss: 0.3651, batch size: 39
2021-08-25 11:26:37,599 INFO [train.py:450] Epoch 4, batch 140, batch avg loss 0.3669, total avg loss: 0.3655, batch size: 37
2021-08-25 11:26:52,489 INFO [train.py:450] Epoch 4, batch 150, batch avg loss 0.3562, total avg loss: 0.3668, batch size: 39
2021-08-25 11:27:06,568 INFO [train.py:450] Epoch 4, batch 160, batch avg loss 0.3163, total avg loss: 0.3674, batch size: 41
2021-08-25 11:27:19,891 INFO [train.py:450] Epoch 4, batch 170, batch avg loss 0.3238, total avg loss: 0.3673, batch size: 39
2021-08-25 11:27:33,943 INFO [train.py:450] Epoch 4, batch 180, batch avg loss 0.3628, total avg loss: 0.3666, batch size: 44
2021-08-25 11:27:46,324 INFO [train.py:450] Epoch 4, batch 190, batch avg loss 0.3524, total avg loss: 0.3673, batch size: 38
2021-08-25 11:27:59,239 INFO [train.py:450] Epoch 4, batch 200, batch avg loss 0.3923, total avg loss: 0.3674, batch size: 38
2021-08-25 11:28:12,895 INFO [train.py:450] Epoch 4, batch 210, batch avg loss 0.4082, total avg loss: 0.3744, batch size: 44
2021-08-25 11:28:26,030 INFO [train.py:450] Epoch 4, batch 220, batch avg loss 0.3765, total avg loss: 0.3675, batch size: 44
2021-08-25 11:28:38,117 INFO [train.py:450] Epoch 4, batch 230, batch avg loss 0.3820, total avg loss: 0.3684, batch size: 38
2021-08-25 11:28:50,781 INFO [train.py:450] Epoch 4, batch 240, batch avg loss 0.3975, total avg loss: 0.3751, batch size: 40
2021-08-25 11:29:02,544 INFO [train.py:450] Epoch 4, batch 250, batch avg loss 0.3731, total avg loss: 0.3707, batch size: 39
2021-08-25 11:29:15,733 INFO [train.py:450] Epoch 4, batch 260, batch avg loss 0.3740, total avg loss: 0.3717, batch size: 41
2021-08-25 11:29:28,946 INFO [train.py:450] Epoch 4, batch 270, batch avg loss 0.3746, total avg loss: 0.3703, batch size: 40
2021-08-25 11:29:43,168 INFO [train.py:450] Epoch 4, batch 280, batch avg loss 0.3249, total avg loss: 0.3667, batch size: 38
2021-08-25 11:29:55,558 INFO [train.py:450] Epoch 4, batch 290, batch avg loss 0.3213, total avg loss: 0.3669, batch size: 41
2021-08-25 11:30:07,628 INFO [train.py:450] Epoch 4, batch 300, batch avg loss 0.3617, total avg loss: 0.3665, batch size: 40
2021-08-25 11:30:19,530 INFO [train.py:450] Epoch 4, batch 310, batch avg loss 0.3703, total avg loss: 0.3682, batch size: 40
2021-08-25 11:30:30,991 INFO [train.py:450] Epoch 4, batch 320, batch avg loss 0.3158, total avg loss: 0.3705, batch size: 40
2021-08-25 11:30:43,079 INFO [train.py:450] Epoch 4, batch 330, batch avg loss 0.3342, total avg loss: 0.3717, batch size: 41
2021-08-25 11:30:54,324 INFO [train.py:450] Epoch 4, batch 340, batch avg loss 0.3860, total avg loss: 0.3721, batch size: 38
2021-08-25 11:31:05,079 INFO [train.py:450] Epoch 4, batch 350, batch avg loss 0.3433, total avg loss: 0.3711, batch size: 39
2021-08-25 11:31:17,106 INFO [train.py:450] Epoch 4, batch 360, batch avg loss 0.3485, total avg loss: 0.3715, batch size: 40
2021-08-25 11:31:28,782 INFO [train.py:450] Epoch 4, batch 370, batch avg loss 0.3592, total avg loss: 0.3717, batch size: 38
2021-08-25 11:31:40,972 INFO [train.py:450] Epoch 4, batch 380, batch avg loss 0.3682, total avg loss: 0.3724, batch size: 41
2021-08-25 11:31:52,455 INFO [train.py:450] Epoch 4, batch 390, batch avg loss 0.3557, total avg loss: 0.3729, batch size: 45
2021-08-25 11:32:03,928 INFO [train.py:450] Epoch 4, batch 400, batch avg loss 0.3769, total avg loss: 0.3729, batch size: 42
2021-08-25 11:32:14,525 INFO [train.py:450] Epoch 4, batch 410, batch avg loss 0.3758, total avg loss: 0.3729, batch size: 40
2021-08-25 11:32:26,294 INFO [train.py:450] Epoch 4, batch 420, batch avg loss 0.3833, total avg loss: 0.3710, batch size: 40
2021-08-25 11:32:38,957 INFO [train.py:450] Epoch 4, batch 430, batch avg loss 0.3655, total avg loss: 0.3683, batch size: 38
2021-08-25 11:32:49,260 INFO [train.py:450] Epoch 4, batch 440, batch avg loss 0.3586, total avg loss: 0.3690, batch size: 39
2021-08-25 11:32:59,590 INFO [train.py:450] Epoch 4, batch 450, batch avg loss 0.3619, total avg loss: 0.3663, batch size: 41
2021-08-25 11:33:09,459 INFO [train.py:450] Epoch 4, batch 460, batch avg loss 0.3894, total avg loss: 0.3703, batch size: 38
2021-08-25 11:33:20,418 INFO [train.py:450] Epoch 4, batch 470, batch avg loss 0.4750, total avg loss: 0.3776, batch size: 38
2021-08-25 11:33:31,309 INFO [train.py:450] Epoch 4, batch 480, batch avg loss 0.4012, total avg loss: 0.3777, batch size: 40
2021-08-25 11:33:41,672 INFO [train.py:450] Epoch 4, batch 490, batch avg loss 0.3361, total avg loss: 0.3755, batch size: 39
2021-08-25 11:33:51,601 INFO [train.py:450] Epoch 4, batch 500, batch avg loss 0.3731, total avg loss: 0.3733, batch size: 38
2021-08-25 11:34:01,982 INFO [train.py:450] Epoch 4, batch 510, batch avg loss 0.3850, total avg loss: 0.3725, batch size: 43
2021-08-25 11:34:11,332 INFO [train.py:450] Epoch 4, batch 520, batch avg loss 0.3459, total avg loss: 0.3719, batch size: 39
2021-08-25 11:34:20,707 INFO [train.py:450] Epoch 4, batch 530, batch avg loss 0.3450, total avg loss: 0.3724, batch size: 38
2021-08-25 11:34:30,965 INFO [train.py:450] Epoch 4, batch 540, batch avg loss 0.3684, total avg loss: 0.3739, batch size: 40
2021-08-25 11:34:41,208 INFO [train.py:450] Epoch 4, batch 550, batch avg loss 0.3248, total avg loss: 0.3733, batch size: 41
2021-08-25 11:34:47,105 WARNING [cut.py:1694] To perform mix, energy must be non-zero and non-negative (got 0.0).  MonoCut with id "2af2aaa8-4b62-0c20-f271-5398378e5442" will not be mixed in.
2021-08-25 11:34:51,676 INFO [train.py:450] Epoch 4, batch 560, batch avg loss 0.3603, total avg loss: 0.3734, batch size: 38
2021-08-25 11:35:01,758 INFO [train.py:450] Epoch 4, batch 570, batch avg loss 0.3747, total avg loss: 0.3726, batch size: 38
2021-08-25 11:35:12,301 INFO [train.py:450] Epoch 4, batch 580, batch avg loss 0.3926, total avg loss: 0.3722, batch size: 41
2021-08-25 11:35:21,641 INFO [train.py:450] Epoch 4, batch 590, batch avg loss 0.3420, total avg loss: 0.3724, batch size: 39
2021-08-25 11:35:31,907 INFO [train.py:450] Epoch 4, batch 600, batch avg loss 0.3874, total avg loss: 0.3723, batch size: 39
2021-08-25 11:35:44,413 INFO [train.py:450] Epoch 4, batch 610, batch avg loss 0.3551, total avg loss: 0.3540, batch size: 36
2021-08-25 11:35:54,064 INFO [train.py:450] Epoch 4, batch 620, batch avg loss 0.3417, total avg loss: 0.3587, batch size: 37
2021-08-25 11:36:03,611 INFO [train.py:450] Epoch 4, batch 630, batch avg loss 0.3896, total avg loss: 0.3615, batch size: 42
2021-08-25 11:36:13,007 INFO [train.py:450] Epoch 4, batch 640, batch avg loss 0.4332, total avg loss: 0.3670, batch size: 38
2021-08-25 11:36:22,618 INFO [train.py:450] Epoch 4, batch 650, batch avg loss 0.3839, total avg loss: 0.3702, batch size: 39
2021-08-25 11:36:32,054 INFO [train.py:450] Epoch 4, batch 660, batch avg loss 0.3487, total avg loss: 0.3711, batch size: 42
2021-08-25 11:36:41,373 INFO [train.py:450] Epoch 4, batch 670, batch avg loss 0.3313, total avg loss: 0.3694, batch size: 40
2021-08-25 11:36:50,973 INFO [train.py:450] Epoch 4, batch 680, batch avg loss 0.3763, total avg loss: 0.3695, batch size: 38
2021-08-25 11:37:00,987 INFO [train.py:450] Epoch 4, batch 690, batch avg loss 0.4021, total avg loss: 0.3720, batch size: 43
2021-08-25 11:37:10,778 INFO [train.py:450] Epoch 4, batch 700, batch avg loss 0.3885, total avg loss: 0.3739, batch size: 39
2021-08-25 11:37:20,412 INFO [train.py:450] Epoch 4, batch 710, batch avg loss 0.3901, total avg loss: 0.3733, batch size: 40
2021-08-25 11:37:29,758 INFO [train.py:450] Epoch 4, batch 720, batch avg loss 0.3847, total avg loss: 0.3725, batch size: 36
2021-08-25 11:37:40,030 INFO [train.py:450] Epoch 4, batch 730, batch avg loss 0.3474, total avg loss: 0.3719, batch size: 38
2021-08-25 11:37:49,906 INFO [train.py:450] Epoch 4, batch 740, batch avg loss 0.3500, total avg loss: 0.3716, batch size: 40
2021-08-25 11:37:59,688 INFO [train.py:450] Epoch 4, batch 750, batch avg loss 0.3371, total avg loss: 0.3709, batch size: 41
2021-08-25 11:38:09,982 INFO [train.py:450] Epoch 4, batch 760, batch avg loss 0.3946, total avg loss: 0.3710, batch size: 37
2021-08-25 11:38:19,578 INFO [train.py:450] Epoch 4, batch 770, batch avg loss 0.3923, total avg loss: 0.3710, batch size: 40
2021-08-25 11:38:31,295 INFO [train.py:450] Epoch 4, batch 780, batch avg loss 0.4028, total avg loss: 0.3709, batch size: 39
2021-08-25 11:38:40,562 INFO [train.py:450] Epoch 4, batch 790, batch avg loss 0.4108, total avg loss: 0.3708, batch size: 37
2021-08-25 11:38:49,756 INFO [train.py:450] Epoch 4, batch 800, batch avg loss 0.3498, total avg loss: 0.3698, batch size: 39
2021-08-25 11:38:58,957 INFO [train.py:450] Epoch 4, batch 810, batch avg loss 0.3297, total avg loss: 0.3743, batch size: 37
2021-08-25 11:39:08,206 INFO [train.py:450] Epoch 4, batch 820, batch avg loss 0.3556, total avg loss: 0.3663, batch size: 41
2021-08-25 11:39:17,050 INFO [train.py:450] Epoch 4, batch 830, batch avg loss 0.3401, total avg loss: 0.3592, batch size: 43
2021-08-25 11:39:26,954 INFO [train.py:450] Epoch 4, batch 840, batch avg loss 0.3407, total avg loss: 0.3596, batch size: 40
2021-08-25 11:39:36,636 INFO [train.py:450] Epoch 4, batch 850, batch avg loss 0.4255, total avg loss: 0.3609, batch size: 45
2021-08-25 11:39:45,858 INFO [train.py:450] Epoch 4, batch 860, batch avg loss 0.4613, total avg loss: 0.3643, batch size: 39
2021-08-25 11:39:54,930 INFO [train.py:450] Epoch 4, batch 870, batch avg loss 0.4006, total avg loss: 0.3652, batch size: 43
2021-08-25 11:40:04,437 INFO [train.py:450] Epoch 4, batch 880, batch avg loss 0.3990, total avg loss: 0.3648, batch size: 41
2021-08-25 11:40:12,661 INFO [train.py:450] Epoch 4, batch 890, batch avg loss 0.3927, total avg loss: 0.3647, batch size: 37
2021-08-25 11:40:21,839 INFO [train.py:450] Epoch 4, batch 900, batch avg loss 0.3398, total avg loss: 0.3661, batch size: 39
2021-08-25 11:40:30,838 INFO [train.py:450] Epoch 4, batch 910, batch avg loss 0.3614, total avg loss: 0.3659, batch size: 41
2021-08-25 11:40:39,718 INFO [train.py:450] Epoch 4, batch 920, batch avg loss 0.3676, total avg loss: 0.3662, batch size: 38
2021-08-25 11:40:48,507 INFO [train.py:450] Epoch 4, batch 930, batch avg loss 0.3792, total avg loss: 0.3668, batch size: 41
2021-08-25 11:40:57,584 INFO [train.py:450] Epoch 4, batch 940, batch avg loss 0.2951, total avg loss: 0.3656, batch size: 39
2021-08-25 11:41:06,094 INFO [train.py:450] Epoch 4, batch 950, batch avg loss 0.3282, total avg loss: 0.3653, batch size: 41
2021-08-25 11:41:15,766 INFO [train.py:450] Epoch 4, batch 960, batch avg loss 0.4263, total avg loss: 0.3654, batch size: 38
2021-08-25 11:41:25,898 INFO [train.py:450] Epoch 4, batch 970, batch avg loss 0.3682, total avg loss: 0.3650, batch size: 36
2021-08-25 11:41:34,187 INFO [train.py:450] Epoch 4, batch 980, batch avg loss 0.3646, total avg loss: 0.3644, batch size: 40
2021-08-25 11:41:45,929 INFO [train.py:450] Epoch 4, batch 990, batch avg loss 0.3394, total avg loss: 0.3635, batch size: 40
2021-08-25 11:41:54,606 INFO [train.py:450] Epoch 4, batch 1000, batch avg loss 0.3511, total avg loss: 0.3627, batch size: 37
2021-08-25 11:42:32,572 INFO [train.py:482] Epoch 4, valid loss 0.2580, best valid loss: 0.2434 best valid epoch: 2
2021-08-25 11:42:39,133 INFO [train.py:450] Epoch 4, batch 1010, batch avg loss 0.3605, total avg loss: 0.3755, batch size: 41
2021-08-25 11:42:47,648 INFO [train.py:450] Epoch 4, batch 1020, batch avg loss 0.3524, total avg loss: 0.3831, batch size: 38
2021-08-25 11:42:56,703 INFO [train.py:450] Epoch 4, batch 1030, batch avg loss 0.3887, total avg loss: 0.3825, batch size: 41
2021-08-25 11:43:06,459 INFO [train.py:450] Epoch 4, batch 1040, batch avg loss 0.2758, total avg loss: 0.3721, batch size: 42
2021-08-25 11:43:14,665 INFO [train.py:450] Epoch 4, batch 1050, batch avg loss 0.3650, total avg loss: 0.3702, batch size: 38
2021-08-25 11:43:23,457 INFO [train.py:450] Epoch 4, batch 1060, batch avg loss 0.3358, total avg loss: 0.3706, batch size: 39
2021-08-25 11:43:32,442 INFO [train.py:450] Epoch 4, batch 1070, batch avg loss 0.3283, total avg loss: 0.3716, batch size: 43
2021-08-25 11:43:40,728 INFO [train.py:450] Epoch 4, batch 1080, batch avg loss 0.3046, total avg loss: 0.3692, batch size: 44
2021-08-25 11:43:48,871 INFO [train.py:450] Epoch 4, batch 1090, batch avg loss 0.3473, total avg loss: 0.3681, batch size: 39
2021-08-25 11:43:56,966 INFO [train.py:450] Epoch 4, batch 1100, batch avg loss 0.3634, total avg loss: 0.3669, batch size: 40
2021-08-25 11:44:05,653 INFO [train.py:450] Epoch 4, batch 1110, batch avg loss 0.4111, total avg loss: 0.3673, batch size: 41
2021-08-25 11:44:14,075 INFO [train.py:450] Epoch 4, batch 1120, batch avg loss 0.3141, total avg loss: 0.3663, batch size: 38
2021-08-25 11:44:22,458 INFO [train.py:450] Epoch 4, batch 1130, batch avg loss 0.3891, total avg loss: 0.3669, batch size: 40
2021-08-25 11:44:31,302 INFO [train.py:450] Epoch 4, batch 1140, batch avg loss 0.3669, total avg loss: 0.3675, batch size: 40
2021-08-25 11:44:40,482 INFO [train.py:450] Epoch 4, batch 1150, batch avg loss 0.3677, total avg loss: 0.3679, batch size: 41
2021-08-25 11:44:48,413 INFO [train.py:450] Epoch 4, batch 1160, batch avg loss 0.3610, total avg loss: 0.3676, batch size: 40
2021-08-25 11:44:59,746 INFO [train.py:450] Epoch 4, batch 1170, batch avg loss 0.4265, total avg loss: 0.3688, batch size: 40
2021-08-25 11:45:08,927 INFO [train.py:450] Epoch 4, batch 1180, batch avg loss 0.3733, total avg loss: 0.3683, batch size: 39
2021-08-25 11:45:18,094 INFO [train.py:450] Epoch 4, batch 1190, batch avg loss 0.3569, total avg loss: 0.3681, batch size: 38
2021-08-25 11:45:25,610 INFO [train.py:450] Epoch 4, batch 1200, batch avg loss 0.3409, total avg loss: 0.3689, batch size: 40
2021-08-25 11:45:33,894 INFO [train.py:450] Epoch 4, batch 1210, batch avg loss 0.4060, total avg loss: 0.3847, batch size: 39
2021-08-25 11:45:42,153 INFO [train.py:450] Epoch 4, batch 1220, batch avg loss 0.4252, total avg loss: 0.3806, batch size: 39
2021-08-25 11:45:50,430 INFO [train.py:450] Epoch 4, batch 1230, batch avg loss 0.3388, total avg loss: 0.3807, batch size: 39
2021-08-25 11:45:59,679 INFO [train.py:450] Epoch 4, batch 1240, batch avg loss 0.3781, total avg loss: 0.3758, batch size: 40
2021-08-25 11:46:08,144 INFO [train.py:450] Epoch 4, batch 1250, batch avg loss 0.3796, total avg loss: 0.3713, batch size: 39
2021-08-25 11:46:16,549 INFO [train.py:450] Epoch 4, batch 1260, batch avg loss 0.4291, total avg loss: 0.3680, batch size: 41
2021-08-25 11:46:24,352 INFO [train.py:450] Epoch 4, batch 1270, batch avg loss 0.3244, total avg loss: 0.3686, batch size: 39
2021-08-25 11:46:32,109 INFO [train.py:450] Epoch 4, batch 1280, batch avg loss 0.3807, total avg loss: 0.3677, batch size: 39
2021-08-25 11:46:40,454 INFO [train.py:450] Epoch 4, batch 1290, batch avg loss 0.4180, total avg loss: 0.3697, batch size: 42
2021-08-25 11:46:49,783 INFO [train.py:450] Epoch 4, batch 1300, batch avg loss 0.3928, total avg loss: 0.3703, batch size: 42
2021-08-25 11:46:57,520 INFO [train.py:450] Epoch 4, batch 1310, batch avg loss 0.4142, total avg loss: 0.3699, batch size: 38
2021-08-25 11:47:05,632 INFO [train.py:450] Epoch 4, batch 1320, batch avg loss 0.3207, total avg loss: 0.3699, batch size: 40
2021-08-25 11:47:13,753 INFO [train.py:450] Epoch 4, batch 1330, batch avg loss 0.3537, total avg loss: 0.3694, batch size: 40
2021-08-25 11:47:22,019 INFO [train.py:450] Epoch 4, batch 1340, batch avg loss 0.3291, total avg loss: 0.3685, batch size: 42
2021-08-25 11:47:31,314 INFO [train.py:450] Epoch 4, batch 1350, batch avg loss 0.3632, total avg loss: 0.3697, batch size: 42
2021-08-25 11:47:39,390 INFO [train.py:450] Epoch 4, batch 1360, batch avg loss 0.3752, total avg loss: 0.3685, batch size: 41
2021-08-25 11:47:48,857 INFO [train.py:450] Epoch 4, batch 1370, batch avg loss 0.3130, total avg loss: 0.3686, batch size: 40
2021-08-25 11:47:58,508 INFO [train.py:450] Epoch 4, batch 1380, batch avg loss 0.3863, total avg loss: 0.3689, batch size: 42
2021-08-25 11:48:06,549 INFO [train.py:450] Epoch 4, batch 1390, batch avg loss 0.3280, total avg loss: 0.3690, batch size: 38
2021-08-25 11:48:14,530 INFO [train.py:450] Epoch 4, batch 1400, batch avg loss 0.4243, total avg loss: 0.3701, batch size: 38
2021-08-25 11:48:22,711 INFO [train.py:450] Epoch 4, batch 1410, batch avg loss 0.3424, total avg loss: 0.3635, batch size: 39
2021-08-25 11:48:30,845 INFO [train.py:450] Epoch 4, batch 1420, batch avg loss 0.3614, total avg loss: 0.3643, batch size: 41
2021-08-25 11:48:38,578 INFO [train.py:450] Epoch 4, batch 1430, batch avg loss 0.4338, total avg loss: 0.3695, batch size: 39
2021-08-25 11:48:47,046 INFO [train.py:450] Epoch 4, batch 1440, batch avg loss 0.3526, total avg loss: 0.3730, batch size: 41
2021-08-25 11:48:54,805 INFO [train.py:450] Epoch 4, batch 1450, batch avg loss 0.3400, total avg loss: 0.3711, batch size: 40
2021-08-25 11:49:02,641 INFO [train.py:450] Epoch 4, batch 1460, batch avg loss 0.3119, total avg loss: 0.3697, batch size: 36
2021-08-25 11:49:10,861 INFO [train.py:450] Epoch 4, batch 1470, batch avg loss 0.3467, total avg loss: 0.3693, batch size: 40
2021-08-25 11:49:19,665 INFO [train.py:450] Epoch 4, batch 1480, batch avg loss 0.4344, total avg loss: 0.3715, batch size: 45
2021-08-25 11:49:27,411 INFO [train.py:450] Epoch 4, batch 1490, batch avg loss 0.3994, total avg loss: 0.3726, batch size: 39
2021-08-25 11:49:35,242 INFO [train.py:450] Epoch 4, batch 1500, batch avg loss 0.3786, total avg loss: 0.3717, batch size: 36
2021-08-25 11:49:43,409 INFO [train.py:450] Epoch 4, batch 1510, batch avg loss 0.4450, total avg loss: 0.3731, batch size: 40
2021-08-25 11:49:51,071 INFO [train.py:450] Epoch 4, batch 1520, batch avg loss 0.3233, total avg loss: 0.3738, batch size: 38
2021-08-25 11:49:58,442 INFO [train.py:450] Epoch 4, batch 1530, batch avg loss 0.3545, total avg loss: 0.3741, batch size: 41
2021-08-25 11:50:06,189 INFO [train.py:450] Epoch 4, batch 1540, batch avg loss 0.3690, total avg loss: 0.3739, batch size: 38
2021-08-25 11:50:14,033 INFO [train.py:450] Epoch 4, batch 1550, batch avg loss 0.3647, total avg loss: 0.3753, batch size: 37
2021-08-25 11:50:21,600 INFO [train.py:450] Epoch 4, batch 1560, batch avg loss 0.3895, total avg loss: 0.3747, batch size: 40
2021-08-25 11:50:29,276 INFO [train.py:450] Epoch 4, batch 1570, batch avg loss 0.3548, total avg loss: 0.3747, batch size: 40
2021-08-25 11:50:37,427 INFO [train.py:450] Epoch 4, batch 1580, batch avg loss 0.3920, total avg loss: 0.3755, batch size: 38
2021-08-25 11:50:44,947 INFO [train.py:450] Epoch 4, batch 1590, batch avg loss 0.3714, total avg loss: 0.3760, batch size: 41
2021-08-25 11:50:53,736 INFO [train.py:450] Epoch 4, batch 1600, batch avg loss 0.3534, total avg loss: 0.3759, batch size: 39
2021-08-25 11:51:01,726 INFO [train.py:450] Epoch 4, batch 1610, batch avg loss 0.3774, total avg loss: 0.3709, batch size: 41
2021-08-25 11:51:11,219 INFO [train.py:450] Epoch 4, batch 1620, batch avg loss 0.3938, total avg loss: 0.3792, batch size: 39
2021-08-25 11:51:18,871 INFO [train.py:450] Epoch 4, batch 1630, batch avg loss 0.3998, total avg loss: 0.3816, batch size: 40
2021-08-25 11:51:26,649 INFO [train.py:450] Epoch 4, batch 1640, batch avg loss 0.3995, total avg loss: 0.3832, batch size: 40
2021-08-25 11:51:33,468 INFO [train.py:450] Epoch 4, batch 1650, batch avg loss 0.3929, total avg loss: 0.3839, batch size: 37
2021-08-25 11:51:41,073 INFO [train.py:450] Epoch 4, batch 1660, batch avg loss 0.3511, total avg loss: 0.3856, batch size: 43
2021-08-25 11:51:48,776 INFO [train.py:450] Epoch 4, batch 1670, batch avg loss 0.3835, total avg loss: 0.3848, batch size: 43
2021-08-25 11:51:56,608 INFO [train.py:450] Epoch 4, batch 1680, batch avg loss 0.4152, total avg loss: 0.3835, batch size: 38
2021-08-25 11:52:03,884 INFO [train.py:450] Epoch 4, batch 1690, batch avg loss 0.4414, total avg loss: 0.3841, batch size: 42
2021-08-25 11:52:11,606 INFO [train.py:450] Epoch 4, batch 1700, batch avg loss 0.4045, total avg loss: 0.3857, batch size: 43
2021-08-25 11:52:19,181 INFO [train.py:450] Epoch 4, batch 1710, batch avg loss 0.4444, total avg loss: 0.3856, batch size: 37
2021-08-25 11:52:26,266 INFO [train.py:450] Epoch 4, batch 1720, batch avg loss 0.3808, total avg loss: 0.3834, batch size: 40
2021-08-25 11:52:33,571 INFO [train.py:450] Epoch 4, batch 1730, batch avg loss 0.4347, total avg loss: 0.3831, batch size: 38
2021-08-25 11:52:41,190 INFO [train.py:450] Epoch 4, batch 1740, batch avg loss 0.3765, total avg loss: 0.3826, batch size: 40
2021-08-25 11:52:48,052 INFO [train.py:450] Epoch 4, batch 1750, batch avg loss 0.3647, total avg loss: 0.3821, batch size: 41
2021-08-25 11:52:55,306 INFO [train.py:450] Epoch 4, batch 1760, batch avg loss 0.3255, total avg loss: 0.3806, batch size: 44
2021-08-25 11:53:02,752 INFO [train.py:450] Epoch 4, batch 1770, batch avg loss 0.3870, total avg loss: 0.3807, batch size: 42
2021-08-25 11:53:10,566 INFO [train.py:450] Epoch 4, batch 1780, batch avg loss 0.3835, total avg loss: 0.3814, batch size: 42
2021-08-25 11:53:17,619 INFO [train.py:450] Epoch 4, batch 1790, batch avg loss 0.4049, total avg loss: 0.3808, batch size: 41
2021-08-25 11:53:24,828 INFO [train.py:450] Epoch 4, batch 1800, batch avg loss 0.3461, total avg loss: 0.3798, batch size: 39
2021-08-25 11:53:32,723 INFO [train.py:450] Epoch 4, batch 1810, batch avg loss 0.4323, total avg loss: 0.3668, batch size: 42
2021-08-25 11:53:40,050 INFO [train.py:450] Epoch 4, batch 1820, batch avg loss 0.3328, total avg loss: 0.3681, batch size: 40
2021-08-25 11:53:46,888 INFO [train.py:450] Epoch 4, batch 1830, batch avg loss 0.3991, total avg loss: 0.3688, batch size: 40
2021-08-25 11:53:56,001 INFO [train.py:450] Epoch 4, batch 1840, batch avg loss 0.3337, total avg loss: 0.3678, batch size: 41
2021-08-25 11:54:03,303 INFO [train.py:450] Epoch 4, batch 1850, batch avg loss 0.3629, total avg loss: 0.3693, batch size: 39
2021-08-25 11:54:13,203 INFO [train.py:450] Epoch 4, batch 1860, batch avg loss 0.3391, total avg loss: 0.3673, batch size: 42
2021-08-25 11:54:20,656 INFO [train.py:450] Epoch 4, batch 1870, batch avg loss 0.3322, total avg loss: 0.3671, batch size: 41
2021-08-25 11:54:27,609 INFO [train.py:450] Epoch 4, batch 1880, batch avg loss 0.3585, total avg loss: 0.3690, batch size: 38
2021-08-25 11:54:35,050 INFO [train.py:450] Epoch 4, batch 1890, batch avg loss 0.3554, total avg loss: 0.3676, batch size: 43
2021-08-25 11:54:42,511 INFO [train.py:450] Epoch 4, batch 1900, batch avg loss 0.3366, total avg loss: 0.3684, batch size: 38
2021-08-25 11:54:49,984 INFO [train.py:450] Epoch 4, batch 1910, batch avg loss 0.4716, total avg loss: 0.3705, batch size: 37
2021-08-25 11:54:57,132 INFO [train.py:450] Epoch 4, batch 1920, batch avg loss 0.3063, total avg loss: 0.3701, batch size: 39
2021-08-25 11:55:04,116 INFO [train.py:450] Epoch 4, batch 1930, batch avg loss 0.3579, total avg loss: 0.3704, batch size: 38
2021-08-25 11:55:11,139 INFO [train.py:450] Epoch 4, batch 1940, batch avg loss 0.3268, total avg loss: 0.3696, batch size: 40
2021-08-25 11:55:18,432 INFO [train.py:450] Epoch 4, batch 1950, batch avg loss 0.3291, total avg loss: 0.3696, batch size: 40
2021-08-25 11:55:25,360 INFO [train.py:450] Epoch 4, batch 1960, batch avg loss 0.3902, total avg loss: 0.3695, batch size: 39
2021-08-25 11:55:32,364 INFO [train.py:450] Epoch 4, batch 1970, batch avg loss 0.3621, total avg loss: 0.3691, batch size: 39
2021-08-25 11:55:39,289 INFO [train.py:450] Epoch 4, batch 1980, batch avg loss 0.3448, total avg loss: 0.3688, batch size: 41
2021-08-25 11:55:46,462 INFO [train.py:450] Epoch 4, batch 1990, batch avg loss 0.3654, total avg loss: 0.3688, batch size: 37
2021-08-25 11:55:53,514 INFO [train.py:450] Epoch 4, batch 2000, batch avg loss 0.3350, total avg loss: 0.3682, batch size: 39
2021-08-25 11:56:31,896 INFO [train.py:482] Epoch 4, valid loss 0.2599, best valid loss: 0.2434 best valid epoch: 2
2021-08-25 11:56:37,723 INFO [train.py:450] Epoch 4, batch 2010, batch avg loss 0.2987, total avg loss: 0.3722, batch size: 41
2021-08-25 11:56:44,335 INFO [train.py:450] Epoch 4, batch 2020, batch avg loss 0.3280, total avg loss: 0.3632, batch size: 37
2021-08-25 11:56:51,586 INFO [train.py:450] Epoch 4, batch 2030, batch avg loss 0.3764, total avg loss: 0.3640, batch size: 43
2021-08-25 11:56:59,964 INFO [train.py:450] Epoch 4, batch 2040, batch avg loss 0.3936, total avg loss: 0.3672, batch size: 38
2021-08-25 11:57:06,979 INFO [train.py:450] Epoch 4, batch 2050, batch avg loss 0.3854, total avg loss: 0.3687, batch size: 41
2021-08-25 11:57:15,834 INFO [train.py:450] Epoch 4, batch 2060, batch avg loss 0.4156, total avg loss: 0.3724, batch size: 37
2021-08-25 11:57:23,382 INFO [train.py:450] Epoch 4, batch 2070, batch avg loss 0.3709, total avg loss: 0.3743, batch size: 39
2021-08-25 11:57:30,340 INFO [train.py:450] Epoch 4, batch 2080, batch avg loss 0.3571, total avg loss: 0.3724, batch size: 40
2021-08-25 11:57:37,472 INFO [train.py:450] Epoch 4, batch 2090, batch avg loss 0.3676, total avg loss: 0.3742, batch size: 39
2021-08-25 11:57:44,426 INFO [train.py:450] Epoch 4, batch 2100, batch avg loss 0.3552, total avg loss: 0.3740, batch size: 39
2021-08-25 11:57:51,215 INFO [train.py:450] Epoch 4, batch 2110, batch avg loss 0.4176, total avg loss: 0.3740, batch size: 40
2021-08-25 11:57:58,112 INFO [train.py:450] Epoch 4, batch 2120, batch avg loss 0.3635, total avg loss: 0.3751, batch size: 41
2021-08-25 11:58:05,043 INFO [train.py:450] Epoch 4, batch 2130, batch avg loss 0.3443, total avg loss: 0.3749, batch size: 43
2021-08-25 11:58:12,261 INFO [train.py:450] Epoch 4, batch 2140, batch avg loss 0.4032, total avg loss: 0.3746, batch size: 42
2021-08-25 11:58:18,653 INFO [train.py:450] Epoch 4, batch 2150, batch avg loss 0.3071, total avg loss: 0.3754, batch size: 38
2021-08-25 11:58:25,081 INFO [train.py:450] Epoch 4, batch 2160, batch avg loss 0.3351, total avg loss: 0.3739, batch size: 38
2021-08-25 11:58:31,777 INFO [train.py:450] Epoch 4, batch 2170, batch avg loss 0.4068, total avg loss: 0.3742, batch size: 34
2021-08-25 11:58:38,554 INFO [train.py:450] Epoch 4, batch 2180, batch avg loss 0.3734, total avg loss: 0.3753, batch size: 43
2021-08-25 11:58:45,380 INFO [train.py:450] Epoch 4, batch 2190, batch avg loss 0.3293, total avg loss: 0.3739, batch size: 43
2021-08-25 11:58:52,379 INFO [train.py:450] Epoch 4, batch 2200, batch avg loss 0.4033, total avg loss: 0.3743, batch size: 41
2021-08-25 11:58:59,663 INFO [train.py:450] Epoch 4, batch 2210, batch avg loss 0.3507, total avg loss: 0.3627, batch size: 38
2021-08-25 11:59:06,532 INFO [train.py:450] Epoch 4, batch 2220, batch avg loss 0.3755, total avg loss: 0.3706, batch size: 37
2021-08-25 11:59:14,055 INFO [train.py:450] Epoch 4, batch 2230, batch avg loss 0.4550, total avg loss: 0.3784, batch size: 40
2021-08-25 11:59:21,058 INFO [train.py:450] Epoch 4, batch 2240, batch avg loss 0.4155, total avg loss: 0.3868, batch size: 37
2021-08-25 11:59:27,599 INFO [train.py:450] Epoch 4, batch 2250, batch avg loss 0.4119, total avg loss: 0.3900, batch size: 41
2021-08-25 11:59:34,179 INFO [train.py:450] Epoch 4, batch 2260, batch avg loss 0.3330, total avg loss: 0.3876, batch size: 42
2021-08-25 11:59:40,971 INFO [train.py:450] Epoch 4, batch 2270, batch avg loss 0.3407, total avg loss: 0.3871, batch size: 39
2021-08-25 11:59:49,195 INFO [train.py:450] Epoch 4, batch 2280, batch avg loss 0.3342, total avg loss: 0.3850, batch size: 40
2021-08-25 11:59:55,837 INFO [train.py:450] Epoch 4, batch 2290, batch avg loss 0.3931, total avg loss: 0.3839, batch size: 39
2021-08-25 12:00:04,581 INFO [train.py:450] Epoch 4, batch 2300, batch avg loss 0.3416, total avg loss: 0.3824, batch size: 40
2021-08-25 12:00:12,536 INFO [train.py:450] Epoch 4, batch 2310, batch avg loss 0.3528, total avg loss: 0.3820, batch size: 41
2021-08-25 12:00:18,567 INFO [train.py:450] Epoch 4, batch 2320, batch avg loss 0.3529, total avg loss: 0.3823, batch size: 39
2021-08-25 12:00:24,841 INFO [train.py:450] Epoch 4, batch 2330, batch avg loss 0.3542, total avg loss: 0.3812, batch size: 38
2021-08-25 12:00:31,545 INFO [train.py:450] Epoch 4, batch 2340, batch avg loss 0.4278, total avg loss: 0.3810, batch size: 39
2021-08-25 12:00:38,243 INFO [train.py:450] Epoch 4, batch 2350, batch avg loss 0.3567, total avg loss: 0.3796, batch size: 41
2021-08-25 12:00:44,826 INFO [train.py:450] Epoch 4, batch 2360, batch avg loss 0.3974, total avg loss: 0.3797, batch size: 35
2021-08-25 12:00:51,488 INFO [train.py:450] Epoch 4, batch 2370, batch avg loss 0.3354, total avg loss: 0.3789, batch size: 38
2021-08-25 12:00:57,892 INFO [train.py:450] Epoch 4, batch 2380, batch avg loss 0.3873, total avg loss: 0.3784, batch size: 39
2021-08-25 12:01:04,809 INFO [train.py:450] Epoch 4, batch 2390, batch avg loss 0.4277, total avg loss: 0.3783, batch size: 40
2021-08-25 12:01:11,160 INFO [train.py:450] Epoch 4, batch 2400, batch avg loss 0.3457, total avg loss: 0.3775, batch size: 40
2021-08-25 12:01:17,410 INFO [train.py:450] Epoch 4, batch 2410, batch avg loss 0.3360, total avg loss: 0.3683, batch size: 38
2021-08-25 12:01:24,132 INFO [train.py:450] Epoch 4, batch 2420, batch avg loss 0.4330, total avg loss: 0.3790, batch size: 40
2021-08-25 12:01:31,218 INFO [train.py:450] Epoch 4, batch 2430, batch avg loss 0.4154, total avg loss: 0.3840, batch size: 39
2021-08-25 12:01:37,817 INFO [train.py:450] Epoch 4, batch 2440, batch avg loss 0.3676, total avg loss: 0.3855, batch size: 44
2021-08-25 12:01:44,506 INFO [train.py:450] Epoch 4, batch 2450, batch avg loss 0.3447, total avg loss: 0.3824, batch size: 38
2021-08-25 12:01:50,991 INFO [train.py:450] Epoch 4, batch 2460, batch avg loss 0.3629, total avg loss: 0.3786, batch size: 39
2021-08-25 12:01:57,218 INFO [train.py:450] Epoch 4, batch 2470, batch avg loss 0.2966, total avg loss: 0.3764, batch size: 38
2021-08-25 12:02:03,912 INFO [train.py:450] Epoch 4, batch 2480, batch avg loss 0.3869, total avg loss: 0.3752, batch size: 38
2021-08-25 12:02:10,308 INFO [train.py:450] Epoch 4, batch 2490, batch avg loss 0.3673, total avg loss: 0.3758, batch size: 38
2021-08-25 12:02:17,293 INFO [train.py:450] Epoch 4, batch 2500, batch avg loss 0.3702, total avg loss: 0.3739, batch size: 37
2021-08-25 12:02:23,868 INFO [train.py:450] Epoch 4, batch 2510, batch avg loss 0.3604, total avg loss: 0.3718, batch size: 40
2021-08-25 12:02:30,878 INFO [train.py:450] Epoch 4, batch 2520, batch avg loss 0.3705, total avg loss: 0.3724, batch size: 39
2021-08-25 12:02:37,052 INFO [train.py:450] Epoch 4, batch 2530, batch avg loss 0.3598, total avg loss: 0.3719, batch size: 42
2021-08-25 12:02:43,239 INFO [train.py:450] Epoch 4, batch 2540, batch avg loss 0.4180, total avg loss: 0.3720, batch size: 40
2021-08-25 12:02:49,570 INFO [train.py:450] Epoch 4, batch 2550, batch avg loss 0.3403, total avg loss: 0.3709, batch size: 41
2021-08-25 12:02:56,300 INFO [train.py:450] Epoch 4, batch 2560, batch avg loss 0.3589, total avg loss: 0.3693, batch size: 37
2021-08-25 12:03:04,033 INFO [train.py:450] Epoch 4, batch 2570, batch avg loss 0.4135, total avg loss: 0.3694, batch size: 38
2021-08-25 12:03:11,511 INFO [train.py:450] Epoch 4, batch 2580, batch avg loss 0.3518, total avg loss: 0.3694, batch size: 36
2021-08-25 12:03:20,039 INFO [train.py:450] Epoch 4, batch 2590, batch avg loss 0.3922, total avg loss: 0.3694, batch size: 37
2021-08-25 12:03:26,078 INFO [train.py:450] Epoch 4, batch 2600, batch avg loss 0.3644, total avg loss: 0.3685, batch size: 37
2021-08-25 12:03:32,704 INFO [train.py:450] Epoch 4, batch 2610, batch avg loss 0.4408, total avg loss: 0.3902, batch size: 41
2021-08-25 12:03:39,240 INFO [train.py:450] Epoch 4, batch 2620, batch avg loss 0.3706, total avg loss: 0.3845, batch size: 38
2021-08-25 12:03:45,332 INFO [train.py:450] Epoch 4, batch 2630, batch avg loss 0.3571, total avg loss: 0.3863, batch size: 42
2021-08-25 12:03:51,728 INFO [train.py:450] Epoch 4, batch 2640, batch avg loss 0.3977, total avg loss: 0.3881, batch size: 38
2021-08-25 12:03:58,385 INFO [train.py:450] Epoch 4, batch 2650, batch avg loss 0.3534, total avg loss: 0.3866, batch size: 41
2021-08-25 12:04:04,509 INFO [train.py:450] Epoch 4, batch 2660, batch avg loss 0.3302, total avg loss: 0.3833, batch size: 39
2021-08-25 12:04:11,054 INFO [train.py:450] Epoch 4, batch 2670, batch avg loss 0.4048, total avg loss: 0.3821, batch size: 43
2021-08-25 12:04:17,550 INFO [train.py:450] Epoch 4, batch 2680, batch avg loss 0.3944, total avg loss: 0.3800, batch size: 41
2021-08-25 12:04:23,567 INFO [train.py:450] Epoch 4, batch 2690, batch avg loss 0.3646, total avg loss: 0.3808, batch size: 40
2021-08-25 12:04:29,866 INFO [train.py:450] Epoch 4, batch 2700, batch avg loss 0.3640, total avg loss: 0.3789, batch size: 38
2021-08-25 12:04:36,162 INFO [train.py:450] Epoch 4, batch 2710, batch avg loss 0.4079, total avg loss: 0.3786, batch size: 40
2021-08-25 12:04:42,280 INFO [train.py:450] Epoch 4, batch 2720, batch avg loss 0.4040, total avg loss: 0.3787, batch size: 42
2021-08-25 12:04:48,218 INFO [train.py:450] Epoch 4, batch 2730, batch avg loss 0.4086, total avg loss: 0.3796, batch size: 41
2021-08-25 12:04:54,414 INFO [train.py:450] Epoch 4, batch 2740, batch avg loss 0.3498, total avg loss: 0.3791, batch size: 38
2021-08-25 12:05:00,426 INFO [train.py:450] Epoch 4, batch 2750, batch avg loss 0.3598, total avg loss: 0.3795, batch size: 38
2021-08-25 12:05:06,360 INFO [train.py:450] Epoch 4, batch 2760, batch avg loss 0.3992, total avg loss: 0.3796, batch size: 44
2021-08-25 12:05:12,974 INFO [train.py:450] Epoch 4, batch 2770, batch avg loss 0.3874, total avg loss: 0.3794, batch size: 41
2021-08-25 12:05:19,290 INFO [train.py:450] Epoch 4, batch 2780, batch avg loss 0.3582, total avg loss: 0.3782, batch size: 39
2021-08-25 12:05:25,798 INFO [train.py:450] Epoch 4, batch 2790, batch avg loss 0.3714, total avg loss: 0.3780, batch size: 39
2021-08-25 12:05:32,193 INFO [train.py:450] Epoch 4, batch 2800, batch avg loss 0.3571, total avg loss: 0.3775, batch size: 40
2021-08-25 12:05:38,690 INFO [train.py:450] Epoch 4, batch 2810, batch avg loss 0.3382, total avg loss: 0.3923, batch size: 41
2021-08-25 12:05:44,684 INFO [train.py:450] Epoch 4, batch 2820, batch avg loss 0.4157, total avg loss: 0.3896, batch size: 40
2021-08-25 12:05:51,284 INFO [train.py:450] Epoch 4, batch 2830, batch avg loss 0.4021, total avg loss: 0.3790, batch size: 41
2021-08-25 12:05:57,218 INFO [train.py:450] Epoch 4, batch 2840, batch avg loss 0.3932, total avg loss: 0.3766, batch size: 40
2021-08-25 12:06:02,988 INFO [train.py:450] Epoch 4, batch 2850, batch avg loss 0.3310, total avg loss: 0.3751, batch size: 39
2021-08-25 12:06:08,855 INFO [train.py:450] Epoch 4, batch 2860, batch avg loss 0.3899, total avg loss: 0.3800, batch size: 42
2021-08-25 12:06:16,380 INFO [train.py:450] Epoch 4, batch 2870, batch avg loss 0.3848, total avg loss: 0.3809, batch size: 38
2021-08-25 12:06:22,242 INFO [train.py:450] Epoch 4, batch 2880, batch avg loss 0.4008, total avg loss: 0.3811, batch size: 38
2021-08-25 12:06:30,199 INFO [train.py:450] Epoch 4, batch 2890, batch avg loss 0.3505, total avg loss: 0.3805, batch size: 39
2021-08-25 12:06:38,205 INFO [train.py:450] Epoch 4, batch 2900, batch avg loss 0.3804, total avg loss: 0.3793, batch size: 39
2021-08-25 12:06:44,301 INFO [train.py:450] Epoch 4, batch 2910, batch avg loss 0.3718, total avg loss: 0.3797, batch size: 40
2021-08-25 12:06:50,317 INFO [train.py:450] Epoch 4, batch 2920, batch avg loss 0.3621, total avg loss: 0.3785, batch size: 39
2021-08-25 12:06:56,718 INFO [train.py:450] Epoch 4, batch 2930, batch avg loss 0.3876, total avg loss: 0.3774, batch size: 39
2021-08-25 12:07:02,587 INFO [train.py:450] Epoch 4, batch 2940, batch avg loss 0.3434, total avg loss: 0.3771, batch size: 40
2021-08-25 12:07:08,558 INFO [train.py:450] Epoch 4, batch 2950, batch avg loss 0.3455, total avg loss: 0.3767, batch size: 37
2021-08-25 12:07:14,305 INFO [train.py:450] Epoch 4, batch 2960, batch avg loss 0.3701, total avg loss: 0.3768, batch size: 36
2021-08-25 12:07:20,258 INFO [train.py:450] Epoch 4, batch 2970, batch avg loss 0.4340, total avg loss: 0.3771, batch size: 42
2021-08-25 12:07:26,336 INFO [train.py:450] Epoch 4, batch 2980, batch avg loss 0.3842, total avg loss: 0.3766, batch size: 39
2021-08-25 12:07:32,189 INFO [train.py:450] Epoch 4, batch 2990, batch avg loss 0.3531, total avg loss: 0.3768, batch size: 40
2021-08-25 12:07:38,226 INFO [train.py:450] Epoch 4, batch 3000, batch avg loss 0.3370, total avg loss: 0.3760, batch size: 37
2021-08-25 12:08:16,000 INFO [train.py:482] Epoch 4, valid loss 0.2591, best valid loss: 0.2434 best valid epoch: 2
2021-08-25 12:08:21,787 INFO [train.py:450] Epoch 4, batch 3010, batch avg loss 0.4615, total avg loss: 0.3544, batch size: 41
2021-08-25 12:08:27,679 INFO [train.py:450] Epoch 4, batch 3020, batch avg loss 0.4001, total avg loss: 0.3631, batch size: 44
2021-08-25 12:08:33,532 INFO [train.py:450] Epoch 4, batch 3030, batch avg loss 0.3668, total avg loss: 0.3644, batch size: 42
2021-08-25 12:08:39,373 INFO [train.py:450] Epoch 4, batch 3040, batch avg loss 0.3345, total avg loss: 0.3627, batch size: 41
2021-08-25 12:08:45,232 INFO [train.py:450] Epoch 4, batch 3050, batch avg loss 0.3772, total avg loss: 0.3643, batch size: 38
2021-08-25 12:08:50,997 INFO [train.py:450] Epoch 4, batch 3060, batch avg loss 0.3843, total avg loss: 0.3659, batch size: 38
2021-08-25 12:08:56,940 INFO [train.py:450] Epoch 4, batch 3070, batch avg loss 0.3084, total avg loss: 0.3697, batch size: 41
2021-08-25 12:09:00,111 WARNING [cut.py:1694] To perform mix, energy must be non-zero and non-negative (got 0.0).  MonoCut with id "c6b656e4-0d9a-57f2-9a10-9ce82eb96b07" will not be mixed in.
2021-08-25 12:09:02,855 INFO [train.py:450] Epoch 4, batch 3080, batch avg loss 0.3859, total avg loss: 0.3703, batch size: 41
2021-08-25 12:09:08,789 INFO [train.py:450] Epoch 4, batch 3090, batch avg loss 0.3569, total avg loss: 0.3694, batch size: 47
2021-08-25 12:09:14,823 INFO [train.py:450] Epoch 4, batch 3100, batch avg loss 0.3825, total avg loss: 0.3692, batch size: 42
2021-08-25 12:09:21,133 INFO [train.py:450] Epoch 4, batch 3110, batch avg loss 0.3783, total avg loss: 0.3703, batch size: 40
2021-08-25 12:09:28,497 INFO [train.py:450] Epoch 4, batch 3120, batch avg loss 0.4002, total avg loss: 0.3713, batch size: 40
2021-08-25 12:09:34,325 INFO [train.py:450] Epoch 4, batch 3130, batch avg loss 0.3345, total avg loss: 0.3721, batch size: 39
2021-08-25 12:09:40,122 INFO [train.py:450] Epoch 4, batch 3140, batch avg loss 0.3324, total avg loss: 0.3713, batch size: 41
2021-08-25 12:09:48,904 INFO [train.py:450] Epoch 4, batch 3150, batch avg loss 0.3678, total avg loss: 0.3719, batch size: 38
2021-08-25 12:09:54,694 INFO [train.py:450] Epoch 4, batch 3160, batch avg loss 0.3723, total avg loss: 0.3730, batch size: 39
2021-08-25 12:10:00,526 INFO [train.py:450] Epoch 4, batch 3170, batch avg loss 0.3872, total avg loss: 0.3727, batch size: 44
2021-08-25 12:10:06,271 INFO [train.py:450] Epoch 4, batch 3180, batch avg loss 0.4266, total avg loss: 0.3721, batch size: 40
2021-08-25 12:10:12,055 INFO [train.py:450] Epoch 4, batch 3190, batch avg loss 0.3785, total avg loss: 0.3724, batch size: 39
2021-08-25 12:10:17,948 INFO [train.py:450] Epoch 4, batch 3200, batch avg loss 0.4310, total avg loss: 0.3729, batch size: 41
2021-08-25 12:10:23,845 INFO [train.py:450] Epoch 4, batch 3210, batch avg loss 0.3798, total avg loss: 0.3799, batch size: 39
2021-08-25 12:10:29,719 INFO [train.py:450] Epoch 4, batch 3220, batch avg loss 0.3095, total avg loss: 0.3604, batch size: 42
2021-08-25 12:10:35,551 INFO [train.py:450] Epoch 4, batch 3230, batch avg loss 0.4074, total avg loss: 0.3655, batch size: 38
2021-08-25 12:10:41,336 INFO [train.py:450] Epoch 4, batch 3240, batch avg loss 0.3101, total avg loss: 0.3580, batch size: 37
2021-08-25 12:10:47,166 INFO [train.py:450] Epoch 4, batch 3250, batch avg loss 0.3496, total avg loss: 0.3617, batch size: 37
2021-08-25 12:10:52,977 INFO [train.py:450] Epoch 4, batch 3260, batch avg loss 0.3246, total avg loss: 0.3627, batch size: 37
2021-08-25 12:10:59,178 INFO [train.py:450] Epoch 4, batch 3270, batch avg loss 0.3453, total avg loss: 0.3650, batch size: 39
2021-08-25 12:11:05,202 INFO [train.py:450] Epoch 4, batch 3280, batch avg loss 0.3461, total avg loss: 0.3642, batch size: 41
2021-08-25 12:11:11,125 INFO [train.py:450] Epoch 4, batch 3290, batch avg loss 0.3618, total avg loss: 0.3649, batch size: 43
2021-08-25 12:11:17,074 INFO [train.py:450] Epoch 4, batch 3300, batch avg loss 0.3798, total avg loss: 0.3644, batch size: 41
2021-08-25 12:11:23,098 INFO [train.py:450] Epoch 4, batch 3310, batch avg loss 0.3786, total avg loss: 0.3653, batch size: 40
2021-08-25 12:11:28,873 INFO [train.py:450] Epoch 4, batch 3320, batch avg loss 0.3364, total avg loss: 0.3636, batch size: 38
2021-08-25 12:11:34,813 INFO [train.py:450] Epoch 4, batch 3330, batch avg loss 0.3230, total avg loss: 0.3631, batch size: 42
2021-08-25 12:11:40,760 INFO [train.py:450] Epoch 4, batch 3340, batch avg loss 0.3530, total avg loss: 0.3629, batch size: 39
2021-08-25 12:11:46,600 INFO [train.py:450] Epoch 4, batch 3350, batch avg loss 0.4333, total avg loss: 0.3630, batch size: 40
2021-08-25 12:11:52,386 INFO [train.py:450] Epoch 4, batch 3360, batch avg loss 0.3074, total avg loss: 0.3614, batch size: 44
2021-08-25 12:11:58,147 INFO [train.py:450] Epoch 4, batch 3370, batch avg loss 0.3227, total avg loss: 0.3610, batch size: 39
2021-08-25 12:12:03,967 INFO [train.py:450] Epoch 4, batch 3380, batch avg loss 0.4045, total avg loss: 0.3622, batch size: 37
2021-08-25 12:12:09,863 INFO [train.py:450] Epoch 4, batch 3390, batch avg loss 0.3388, total avg loss: 0.3632, batch size: 41
2021-08-25 12:12:15,770 INFO [train.py:450] Epoch 4, batch 3400, batch avg loss 0.3695, total avg loss: 0.3631, batch size: 41
2021-08-25 12:12:21,601 INFO [train.py:450] Epoch 4, batch 3410, batch avg loss 0.3858, total avg loss: 0.3781, batch size: 41
2021-08-25 12:12:27,400 INFO [train.py:450] Epoch 4, batch 3420, batch avg loss 0.3574, total avg loss: 0.3709, batch size: 40
2021-08-25 12:12:33,309 INFO [train.py:450] Epoch 4, batch 3430, batch avg loss 0.3729, total avg loss: 0.3653, batch size: 40
2021-08-25 12:12:35,669 WARNING [cut.py:1694] To perform mix, energy must be non-zero and non-negative (got 0.0).  MonoCut with id "6b6c3f69-afd3-b9cc-79af-801fd5e99f6a" will not be mixed in.
2021-08-25 12:12:39,290 INFO [train.py:450] Epoch 4, batch 3440, batch avg loss 0.3380, total avg loss: 0.3631, batch size: 39
2021-08-25 12:12:45,264 INFO [train.py:450] Epoch 4, batch 3450, batch avg loss 0.3511, total avg loss: 0.3609, batch size: 41
2021-08-25 12:12:51,032 INFO [train.py:450] Epoch 4, batch 3460, batch avg loss 0.4162, total avg loss: 0.3617, batch size: 38
2021-08-25 12:12:58,236 INFO [train.py:450] Epoch 4, batch 3470, batch avg loss 0.3604, total avg loss: 0.3614, batch size: 39
2021-08-25 12:13:04,176 INFO [train.py:450] Epoch 4, batch 3480, batch avg loss 0.3863, total avg loss: 0.3633, batch size: 41
2021-08-25 12:13:10,033 INFO [train.py:450] Epoch 4, batch 3490, batch avg loss 0.3596, total avg loss: 0.3634, batch size: 41
2021-08-25 12:13:15,922 INFO [train.py:450] Epoch 4, batch 3500, batch avg loss 0.3959, total avg loss: 0.3623, batch size: 41
2021-08-25 12:13:21,850 INFO [train.py:450] Epoch 4, batch 3510, batch avg loss 0.4016, total avg loss: 0.3626, batch size: 39
2021-08-25 12:13:27,717 INFO [train.py:450] Epoch 4, batch 3520, batch avg loss 0.3615, total avg loss: 0.3624, batch size: 43
2021-08-25 12:13:33,563 INFO [train.py:450] Epoch 4, batch 3530, batch avg loss 0.4183, total avg loss: 0.3629, batch size: 36
2021-08-25 12:13:39,390 INFO [train.py:450] Epoch 4, batch 3540, batch avg loss 0.3863, total avg loss: 0.3644, batch size: 42
2021-08-25 12:13:45,132 INFO [train.py:450] Epoch 4, batch 3550, batch avg loss 0.3280, total avg loss: 0.3639, batch size: 38
2021-08-25 12:13:51,072 INFO [train.py:450] Epoch 4, batch 3560, batch avg loss 0.4099, total avg loss: 0.3647, batch size: 40
2021-08-25 12:13:56,856 INFO [train.py:450] Epoch 4, batch 3570, batch avg loss 0.3817, total avg loss: 0.3635, batch size: 39
2021-08-25 12:14:02,760 INFO [train.py:450] Epoch 4, batch 3580, batch avg loss 0.4172, total avg loss: 0.3639, batch size: 45
2021-08-25 12:14:08,578 INFO [train.py:450] Epoch 4, batch 3590, batch avg loss 0.3538, total avg loss: 0.3637, batch size: 39
2021-08-25 12:14:14,399 INFO [train.py:450] Epoch 4, batch 3600, batch avg loss 0.3673, total avg loss: 0.3639, batch size: 44
2021-08-25 12:14:20,133 INFO [train.py:450] Epoch 4, batch 3610, batch avg loss 0.3973, total avg loss: 0.3530, batch size: 37
2021-08-25 12:14:25,853 INFO [train.py:450] Epoch 4, batch 3620, batch avg loss 0.4793, total avg loss: 0.3623, batch size: 40
2021-08-25 12:14:31,748 INFO [train.py:450] Epoch 4, batch 3630, batch avg loss 0.3313, total avg loss: 0.3712, batch size: 41
2021-08-25 12:14:37,187 WARNING [cut.py:1694] To perform mix, energy must be non-zero and non-negative (got 0.0).  MonoCut with id "346c7eb5-a64d-ddda-cb61-c0e2eaf010a0" will not be mixed in.
2021-08-25 12:14:37,588 INFO [train.py:450] Epoch 4, batch 3640, batch avg loss 0.3589, total avg loss: 0.3721, batch size: 40
2021-08-25 12:14:43,574 INFO [train.py:450] Epoch 4, batch 3650, batch avg loss 0.3822, total avg loss: 0.3730, batch size: 42
2021-08-25 12:14:49,436 INFO [train.py:450] Epoch 4, batch 3660, batch avg loss 0.3215, total avg loss: 0.3708, batch size: 41
2021-08-25 12:14:55,135 INFO [train.py:450] Epoch 4, batch 3670, batch avg loss 0.4085, total avg loss: 0.3714, batch size: 39
2021-08-25 12:15:00,908 INFO [train.py:450] Epoch 4, batch 3680, batch avg loss 0.3071, total avg loss: 0.3715, batch size: 36
2021-08-25 12:15:06,747 INFO [train.py:450] Epoch 4, batch 3690, batch avg loss 0.3493, total avg loss: 0.3713, batch size: 38
2021-08-25 12:15:12,541 INFO [train.py:450] Epoch 4, batch 3700, batch avg loss 0.3691, total avg loss: 0.3696, batch size: 42
2021-08-25 12:15:18,384 INFO [train.py:450] Epoch 4, batch 3710, batch avg loss 0.3987, total avg loss: 0.3703, batch size: 38
2021-08-25 12:15:24,298 INFO [train.py:450] Epoch 4, batch 3720, batch avg loss 0.3724, total avg loss: 0.3695, batch size: 42
2021-08-25 12:15:30,269 INFO [train.py:450] Epoch 4, batch 3730, batch avg loss 0.4165, total avg loss: 0.3701, batch size: 42
2021-08-25 12:15:36,030 INFO [train.py:450] Epoch 4, batch 3740, batch avg loss 0.3233, total avg loss: 0.3705, batch size: 39
2021-08-25 12:15:41,848 INFO [train.py:450] Epoch 4, batch 3750, batch avg loss 0.3156, total avg loss: 0.3698, batch size: 39
2021-08-25 12:15:47,670 INFO [train.py:450] Epoch 4, batch 3760, batch avg loss 0.4093, total avg loss: 0.3697, batch size: 43
2021-08-25 12:15:53,458 INFO [train.py:450] Epoch 4, batch 3770, batch avg loss 0.3383, total avg loss: 0.3691, batch size: 39
2021-08-25 12:15:59,245 INFO [train.py:450] Epoch 4, batch 3780, batch avg loss 0.3642, total avg loss: 0.3683, batch size: 41
2021-08-25 12:16:05,876 INFO [train.py:450] Epoch 4, batch 3790, batch avg loss 0.3466, total avg loss: 0.3680, batch size: 40
2021-08-25 12:16:11,934 INFO [train.py:450] Epoch 4, batch 3800, batch avg loss 0.3672, total avg loss: 0.3686, batch size: 39
2021-08-25 12:16:17,874 INFO [train.py:450] Epoch 4, batch 3810, batch avg loss 0.3346, total avg loss: 0.3703, batch size: 34
2021-08-25 12:16:23,664 INFO [train.py:450] Epoch 4, batch 3820, batch avg loss 0.3664, total avg loss: 0.3673, batch size: 37
2021-08-25 12:16:29,510 INFO [train.py:450] Epoch 4, batch 3830, batch avg loss 0.3500, total avg loss: 0.3668, batch size: 40
2021-08-25 12:16:35,385 INFO [train.py:450] Epoch 4, batch 3840, batch avg loss 0.3231, total avg loss: 0.3629, batch size: 42
2021-08-25 12:16:41,268 INFO [train.py:450] Epoch 4, batch 3850, batch avg loss 0.3344, total avg loss: 0.3657, batch size: 44
2021-08-25 12:16:47,286 INFO [train.py:450] Epoch 4, batch 3860, batch avg loss 0.3300, total avg loss: 0.3668, batch size: 38
2021-08-25 12:16:53,016 INFO [train.py:450] Epoch 4, batch 3870, batch avg loss 0.3688, total avg loss: 0.3660, batch size: 40
2021-08-25 12:16:58,940 INFO [train.py:450] Epoch 4, batch 3880, batch avg loss 0.3737, total avg loss: 0.3661, batch size: 35
2021-08-25 12:17:04,747 INFO [train.py:450] Epoch 4, batch 3890, batch avg loss 0.3568, total avg loss: 0.3666, batch size: 40
2021-08-25 12:17:10,594 INFO [train.py:450] Epoch 4, batch 3900, batch avg loss 0.3533, total avg loss: 0.3661, batch size: 43
2021-08-25 12:17:16,369 INFO [train.py:450] Epoch 4, batch 3910, batch avg loss 0.3601, total avg loss: 0.3666, batch size: 39
2021-08-25 12:17:22,199 INFO [train.py:450] Epoch 4, batch 3920, batch avg loss 0.3897, total avg loss: 0.3662, batch size: 38
2021-08-25 12:17:28,162 INFO [train.py:450] Epoch 4, batch 3930, batch avg loss 0.3819, total avg loss: 0.3683, batch size: 42
