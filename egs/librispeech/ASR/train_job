Saved current collection of modules to: "default"

SGE_HGR_gpu=0
CUDA_VISIBLE_DEVICES=0
Tue Aug 24 17:28:37 2021       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 465.19.01    Driver Version: 465.19.01    CUDA Version: 11.3     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  NVIDIA Tesla V1...  On   | 00000000:1A:00.0 Off |                    0 |
| N/A   27C    P0    24W / 200W |      0MiB / 32510MiB |      0%   E. Process |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   1  NVIDIA Tesla V1...  On   | 00000000:1B:00.0 Off |                    0 |
| N/A   27C    P0    24W / 200W |      0MiB / 32510MiB |      0%   E. Process |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   2  NVIDIA Tesla V1...  On   | 00000000:1C:00.0 Off |                    0 |
| N/A   27C    P0    25W / 200W |      0MiB / 32510MiB |      0%   E. Process |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   3  NVIDIA Tesla V1...  On   | 00000000:3D:00.0 Off |                    0 |
| N/A   28C    P0    24W / 200W |      0MiB / 32510MiB |      0%   E. Process |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   4  NVIDIA Tesla V1...  On   | 00000000:3E:00.0 Off |                    0 |
| N/A   30C    P0    35W / 200W |   1741MiB / 32510MiB |      0%   E. Process |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   5  NVIDIA Tesla V1...  On   | 00000000:8B:00.0 Off |                    0 |
| N/A   29C    P0    36W / 200W |   1789MiB / 32510MiB |      0%   E. Process |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   6  NVIDIA Tesla V1...  On   | 00000000:8C:00.0 Off |                    0 |
| N/A   28C    P0    35W / 200W |   1837MiB / 32510MiB |      0%   E. Process |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   7  NVIDIA Tesla V1...  On   | 00000000:B4:00.0 Off |                    0 |
| N/A   28C    P0    36W / 200W |   1789MiB / 32510MiB |      0%   E. Process |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   8  NVIDIA Tesla V1...  On   | 00000000:B5:00.0 Off |                    0 |
| N/A   27C    P0    24W / 200W |      0MiB / 32510MiB |      0%   E. Process |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   9  NVIDIA Tesla V1...  On   | 00000000:B6:00.0 Off |                    0 |
| N/A   50C    P0   207W / 200W |  13913MiB / 32510MiB |     79%   E. Process |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|    4   N/A  N/A    429028      C   ...a3/envs/visrep/bin/python     1737MiB |
|    5   N/A  N/A    429029      C   ...a3/envs/visrep/bin/python     1785MiB |
|    6   N/A  N/A    429030      C   ...a3/envs/visrep/bin/python     1833MiB |
|    7   N/A  N/A    429031      C   ...a3/envs/visrep/bin/python     1785MiB |
|    9   N/A  N/A    437053      C   python                          13909MiB |
+-----------------------------------------------------------------------------+
/cm/local/apps/uge/var/spool/r7n04/job_scripts/9492449: Running on r7n04
/cm/local/apps/uge/var/spool/r7n04/job_scripts/9492449: Started at Tue Aug 24 17:28:38 EDT 2021
/cm/local/apps/uge/var/spool/r7n04/job_scripts/9492449: Running the job on GPU(s) 0
2021-08-24 17:28:40,148 INFO [train.py:515] Training started
2021-08-24 17:28:40,148 INFO [train.py:516] {'exp_dir': PosixPath('tdnn_lstm_ctc/exp'), 'lang_dir': PosixPath('data/lang_phone'), 'lr': 0.001, 'feature_dim': 80, 'weight_decay': 0.0005, 'subsampling_factor': 3, 'best_train_loss': inf, 'best_valid_loss': inf, 'best_train_epoch': -1, 'best_valid_epoch': -1, 'batch_idx_train': 0, 'log_interval': 10, 'reset_interval': 200, 'valid_interval': 1000, 'beam_size': 10, 'reduction': 'sum', 'use_double_scores': True, 'world_size': 1, 'master_port': 12354, 'tensorboard': True, 'num_epochs': 20, 'start_epoch': 0, 'full_libri': True, 'feature_dir': PosixPath('data/fbank'), 'max_duration': 500.0, 'bucketing_sampler': False, 'num_buckets': 30, 'concatenate_cuts': False, 'duration_factor': 1.0, 'gap': 1.0, 'on_the_fly_feats': False, 'shuffle': True, 'return_cuts': True, 'num_workers': 2}
2021-08-24 17:28:40,376 INFO [lexicon.py:113] Loading pre-compiled data/lang_phone/Linv.pt
2021-08-24 17:28:43,843 INFO [asr_datamodule.py:158] About to get train cuts
2021-08-24 17:28:43,844 INFO [asr_datamodule.py:319] About to get train cuts
2021-08-24 17:29:37,303 INFO [asr_datamodule.py:161] About to get Musan cuts
2021-08-24 17:29:38,225 INFO [asr_datamodule.py:164] About to create train dataset
2021-08-24 17:29:38,225 INFO [asr_datamodule.py:226] Using SingleCutSampler.
2021-08-24 17:29:38,462 INFO [asr_datamodule.py:232] About to create train dataloader
2021-08-24 17:29:38,462 INFO [asr_datamodule.py:245] About to get dev cuts
2021-08-24 17:29:38,462 INFO [asr_datamodule.py:337] About to get dev cuts
2021-08-24 17:29:45,287 INFO [asr_datamodule.py:256] About to create dev dataset
2021-08-24 17:29:45,289 INFO [asr_datamodule.py:275] About to create dev dataloader
2021-08-24 17:29:54,387 INFO [train.py:450] Epoch 0, batch 0, batch avg loss 3.3120, total avg loss: 3.3120, batch size: 40
2021-08-24 17:30:13,875 INFO [train.py:450] Epoch 0, batch 10, batch avg loss 1.2856, total avg loss: 1.7632, batch size: 42
2021-08-24 17:30:30,753 INFO [train.py:450] Epoch 0, batch 20, batch avg loss 1.0774, total avg loss: 1.4729, batch size: 39
2021-08-24 17:30:47,982 INFO [train.py:450] Epoch 0, batch 30, batch avg loss 1.2948, total avg loss: 1.3630, batch size: 42
2021-08-24 17:31:03,286 INFO [train.py:450] Epoch 0, batch 40, batch avg loss 1.0899, total avg loss: 1.2964, batch size: 41
2021-08-24 17:31:14,339 INFO [train.py:450] Epoch 0, batch 50, batch avg loss 1.0611, total avg loss: 1.2459, batch size: 40
2021-08-24 17:31:24,360 INFO [train.py:450] Epoch 0, batch 60, batch avg loss 1.0433, total avg loss: 1.2117, batch size: 39
2021-08-24 17:31:35,214 INFO [train.py:450] Epoch 0, batch 70, batch avg loss 1.0432, total avg loss: 1.1874, batch size: 46
2021-08-24 17:31:43,874 INFO [train.py:450] Epoch 0, batch 80, batch avg loss 1.0535, total avg loss: 1.1669, batch size: 34
2021-08-24 17:31:49,979 INFO [train.py:450] Epoch 0, batch 90, batch avg loss 0.9668, total avg loss: 1.1449, batch size: 38
2021-08-24 17:31:56,394 INFO [train.py:450] Epoch 0, batch 100, batch avg loss 1.0352, total avg loss: 1.1314, batch size: 42
2021-08-24 17:32:03,111 INFO [train.py:450] Epoch 0, batch 110, batch avg loss 0.9710, total avg loss: 1.1200, batch size: 38
2021-08-24 17:32:09,112 INFO [train.py:450] Epoch 0, batch 120, batch avg loss 0.9032, total avg loss: 1.1051, batch size: 40
2021-08-24 17:32:14,830 INFO [train.py:450] Epoch 0, batch 130, batch avg loss 0.8522, total avg loss: 1.0904, batch size: 41
2021-08-24 17:32:20,633 INFO [train.py:450] Epoch 0, batch 140, batch avg loss 0.8975, total avg loss: 1.0744, batch size: 42
2021-08-24 17:32:26,712 INFO [train.py:450] Epoch 0, batch 150, batch avg loss 0.8478, total avg loss: 1.0596, batch size: 41
2021-08-24 17:32:32,506 INFO [train.py:450] Epoch 0, batch 160, batch avg loss 0.8813, total avg loss: 1.0465, batch size: 41
2021-08-24 17:32:47,484 INFO [train.py:450] Epoch 0, batch 170, batch avg loss 0.8546, total avg loss: 1.0351, batch size: 40
2021-08-24 17:33:01,901 INFO [train.py:450] Epoch 0, batch 180, batch avg loss 0.7667, total avg loss: 1.0224, batch size: 39
2021-08-24 17:33:15,181 INFO [train.py:450] Epoch 0, batch 190, batch avg loss 0.8004, total avg loss: 1.0116, batch size: 39
2021-08-24 17:33:27,912 INFO [train.py:450] Epoch 0, batch 200, batch avg loss 0.8219, total avg loss: 1.0029, batch size: 41
2021-08-24 17:33:40,574 INFO [train.py:450] Epoch 0, batch 210, batch avg loss 0.7767, total avg loss: 0.7904, batch size: 43
2021-08-24 17:33:53,806 INFO [train.py:450] Epoch 0, batch 220, batch avg loss 0.8023, total avg loss: 0.7833, batch size: 43
2021-08-24 17:34:06,418 INFO [train.py:450] Epoch 0, batch 230, batch avg loss 0.8049, total avg loss: 0.7839, batch size: 40
2021-08-24 17:34:18,629 INFO [train.py:450] Epoch 0, batch 240, batch avg loss 0.7663, total avg loss: 0.7781, batch size: 39
2021-08-24 17:34:30,614 INFO [train.py:450] Epoch 0, batch 250, batch avg loss 0.8019, total avg loss: 0.7728, batch size: 43
2021-08-24 17:34:42,221 INFO [train.py:450] Epoch 0, batch 260, batch avg loss 0.7767, total avg loss: 0.7727, batch size: 40
2021-08-24 17:34:53,445 INFO [train.py:450] Epoch 0, batch 270, batch avg loss 0.7437, total avg loss: 0.7710, batch size: 40
2021-08-24 17:35:05,062 INFO [train.py:450] Epoch 0, batch 280, batch avg loss 0.7400, total avg loss: 0.7709, batch size: 39
2021-08-24 17:35:16,587 INFO [train.py:450] Epoch 0, batch 290, batch avg loss 0.7063, total avg loss: 0.7683, batch size: 41
2021-08-24 17:35:27,929 INFO [train.py:450] Epoch 0, batch 300, batch avg loss 0.7613, total avg loss: 0.7644, batch size: 41
2021-08-24 17:35:39,823 INFO [train.py:450] Epoch 0, batch 310, batch avg loss 0.7191, total avg loss: 0.7623, batch size: 44
2021-08-24 17:35:51,588 INFO [train.py:450] Epoch 0, batch 320, batch avg loss 0.8156, total avg loss: 0.7595, batch size: 43
2021-08-24 17:36:03,252 INFO [train.py:450] Epoch 0, batch 330, batch avg loss 0.6701, total avg loss: 0.7563, batch size: 39
2021-08-24 17:36:14,513 INFO [train.py:450] Epoch 0, batch 340, batch avg loss 0.6928, total avg loss: 0.7532, batch size: 39
2021-08-24 17:36:25,212 INFO [train.py:450] Epoch 0, batch 350, batch avg loss 0.6681, total avg loss: 0.7501, batch size: 37
2021-08-24 17:36:36,026 INFO [train.py:450] Epoch 0, batch 360, batch avg loss 0.7385, total avg loss: 0.7474, batch size: 39
2021-08-24 17:36:47,064 INFO [train.py:450] Epoch 0, batch 370, batch avg loss 0.6444, total avg loss: 0.7442, batch size: 40
2021-08-24 17:36:58,233 INFO [train.py:450] Epoch 0, batch 380, batch avg loss 0.6676, total avg loss: 0.7423, batch size: 37
2021-08-24 17:37:09,100 INFO [train.py:450] Epoch 0, batch 390, batch avg loss 0.6849, total avg loss: 0.7401, batch size: 39
2021-08-24 17:37:19,841 INFO [train.py:450] Epoch 0, batch 400, batch avg loss 0.7218, total avg loss: 0.7380, batch size: 43
2021-08-24 17:37:30,702 INFO [train.py:450] Epoch 0, batch 410, batch avg loss 0.6901, total avg loss: 0.6707, batch size: 38
2021-08-24 17:37:41,726 INFO [train.py:450] Epoch 0, batch 420, batch avg loss 0.6577, total avg loss: 0.6747, batch size: 43
2021-08-24 17:37:53,639 INFO [train.py:450] Epoch 0, batch 430, batch avg loss 0.6984, total avg loss: 0.6805, batch size: 36
2021-08-24 17:38:07,162 INFO [train.py:450] Epoch 0, batch 440, batch avg loss 0.6567, total avg loss: 0.6815, batch size: 39
2021-08-24 17:38:18,009 INFO [train.py:450] Epoch 0, batch 450, batch avg loss 0.7588, total avg loss: 0.6839, batch size: 39
2021-08-24 17:38:28,481 INFO [train.py:450] Epoch 0, batch 460, batch avg loss 0.6846, total avg loss: 0.6829, batch size: 38
2021-08-24 17:38:39,459 INFO [train.py:450] Epoch 0, batch 470, batch avg loss 0.6752, total avg loss: 0.6831, batch size: 40
2021-08-24 17:38:50,090 INFO [train.py:450] Epoch 0, batch 480, batch avg loss 0.6835, total avg loss: 0.6837, batch size: 40
2021-08-24 17:39:00,780 INFO [train.py:450] Epoch 0, batch 490, batch avg loss 0.6926, total avg loss: 0.6812, batch size: 45
2021-08-24 17:39:11,138 INFO [train.py:450] Epoch 0, batch 500, batch avg loss 0.7087, total avg loss: 0.6792, batch size: 41
2021-08-24 17:39:21,895 INFO [train.py:450] Epoch 0, batch 510, batch avg loss 0.7145, total avg loss: 0.6772, batch size: 40
2021-08-24 17:39:32,084 INFO [train.py:450] Epoch 0, batch 520, batch avg loss 0.6849, total avg loss: 0.6747, batch size: 41
2021-08-24 17:39:42,623 INFO [train.py:450] Epoch 0, batch 530, batch avg loss 0.6900, total avg loss: 0.6739, batch size: 40
2021-08-24 17:39:52,526 INFO [train.py:450] Epoch 0, batch 540, batch avg loss 0.6629, total avg loss: 0.6720, batch size: 37
2021-08-24 17:40:02,896 INFO [train.py:450] Epoch 0, batch 550, batch avg loss 0.6109, total avg loss: 0.6699, batch size: 39
2021-08-24 17:40:12,992 INFO [train.py:450] Epoch 0, batch 560, batch avg loss 0.6208, total avg loss: 0.6674, batch size: 38
2021-08-24 17:40:23,157 INFO [train.py:450] Epoch 0, batch 570, batch avg loss 0.6387, total avg loss: 0.6656, batch size: 40
2021-08-24 17:40:33,067 INFO [train.py:450] Epoch 0, batch 580, batch avg loss 0.6110, total avg loss: 0.6634, batch size: 39
2021-08-24 17:40:43,022 INFO [train.py:450] Epoch 0, batch 590, batch avg loss 0.5705, total avg loss: 0.6624, batch size: 38
2021-08-24 17:40:53,340 INFO [train.py:450] Epoch 0, batch 600, batch avg loss 0.6720, total avg loss: 0.6613, batch size: 40
2021-08-24 17:41:03,614 INFO [train.py:450] Epoch 0, batch 610, batch avg loss 0.6386, total avg loss: 0.6355, batch size: 41
2021-08-24 17:41:14,447 INFO [train.py:450] Epoch 0, batch 620, batch avg loss 0.6505, total avg loss: 0.6399, batch size: 37
2021-08-24 17:41:24,545 INFO [train.py:450] Epoch 0, batch 630, batch avg loss 0.6394, total avg loss: 0.6371, batch size: 40
2021-08-24 17:41:34,837 INFO [train.py:450] Epoch 0, batch 640, batch avg loss 0.6109, total avg loss: 0.6330, batch size: 37
2021-08-24 17:41:44,769 INFO [train.py:450] Epoch 0, batch 650, batch avg loss 0.7263, total avg loss: 0.6315, batch size: 37
2021-08-24 17:41:54,363 INFO [train.py:450] Epoch 0, batch 660, batch avg loss 0.6826, total avg loss: 0.6313, batch size: 40
2021-08-24 17:42:04,270 INFO [train.py:450] Epoch 0, batch 670, batch avg loss 0.6173, total avg loss: 0.6309, batch size: 40
2021-08-24 17:42:14,464 INFO [train.py:450] Epoch 0, batch 680, batch avg loss 0.5725, total avg loss: 0.6292, batch size: 37
2021-08-24 17:42:24,591 INFO [train.py:450] Epoch 0, batch 690, batch avg loss 0.5735, total avg loss: 0.6280, batch size: 39
2021-08-24 17:42:34,642 INFO [train.py:450] Epoch 0, batch 700, batch avg loss 0.6501, total avg loss: 0.6280, batch size: 39
2021-08-24 17:42:45,003 INFO [train.py:450] Epoch 0, batch 710, batch avg loss 0.6436, total avg loss: 0.6289, batch size: 42
2021-08-24 17:42:55,407 INFO [train.py:450] Epoch 0, batch 720, batch avg loss 0.6183, total avg loss: 0.6280, batch size: 38
2021-08-24 17:43:06,606 INFO [train.py:450] Epoch 0, batch 730, batch avg loss 0.5708, total avg loss: 0.6265, batch size: 42
2021-08-24 17:43:15,684 INFO [train.py:450] Epoch 0, batch 740, batch avg loss 0.5772, total avg loss: 0.6259, batch size: 36
2021-08-24 17:43:28,515 INFO [train.py:450] Epoch 0, batch 750, batch avg loss 0.5282, total avg loss: 0.6237, batch size: 40
2021-08-24 17:43:38,881 INFO [train.py:450] Epoch 0, batch 760, batch avg loss 0.5515, total avg loss: 0.6218, batch size: 41
2021-08-24 17:43:48,709 INFO [train.py:450] Epoch 0, batch 770, batch avg loss 0.5419, total avg loss: 0.6207, batch size: 36
2021-08-24 17:43:58,541 INFO [train.py:450] Epoch 0, batch 780, batch avg loss 0.5616, total avg loss: 0.6204, batch size: 38
2021-08-24 17:44:08,174 INFO [train.py:450] Epoch 0, batch 790, batch avg loss 0.5542, total avg loss: 0.6198, batch size: 37
2021-08-24 17:44:17,801 INFO [train.py:450] Epoch 0, batch 800, batch avg loss 0.5823, total avg loss: 0.6177, batch size: 39
2021-08-24 17:44:27,269 INFO [train.py:450] Epoch 0, batch 810, batch avg loss 0.5711, total avg loss: 0.5943, batch size: 38
2021-08-24 17:44:37,268 INFO [train.py:450] Epoch 0, batch 820, batch avg loss 0.6189, total avg loss: 0.6010, batch size: 39
2021-08-24 17:44:47,275 INFO [train.py:450] Epoch 0, batch 830, batch avg loss 0.6182, total avg loss: 0.6003, batch size: 41
2021-08-24 17:44:57,468 INFO [train.py:450] Epoch 0, batch 840, batch avg loss 0.6143, total avg loss: 0.6015, batch size: 36
2021-08-24 17:45:07,300 INFO [train.py:450] Epoch 0, batch 850, batch avg loss 0.6171, total avg loss: 0.6012, batch size: 39
2021-08-24 17:45:17,462 INFO [train.py:450] Epoch 0, batch 860, batch avg loss 0.6110, total avg loss: 0.6006, batch size: 40
2021-08-24 17:45:28,160 INFO [train.py:450] Epoch 0, batch 870, batch avg loss 0.6327, total avg loss: 0.5997, batch size: 41
2021-08-24 17:45:38,412 INFO [train.py:450] Epoch 0, batch 880, batch avg loss 0.5662, total avg loss: 0.5997, batch size: 39
2021-08-24 17:45:47,700 INFO [train.py:450] Epoch 0, batch 890, batch avg loss 0.5411, total avg loss: 0.5966, batch size: 39
2021-08-24 17:45:57,518 INFO [train.py:450] Epoch 0, batch 900, batch avg loss 0.6330, total avg loss: 0.5946, batch size: 38
2021-08-24 17:46:07,732 INFO [train.py:450] Epoch 0, batch 910, batch avg loss 0.5240, total avg loss: 0.5920, batch size: 39
2021-08-24 17:46:17,579 INFO [train.py:450] Epoch 0, batch 920, batch avg loss 0.5667, total avg loss: 0.5924, batch size: 39
2021-08-24 17:46:27,101 INFO [train.py:450] Epoch 0, batch 930, batch avg loss 0.5657, total avg loss: 0.5918, batch size: 40
2021-08-24 17:46:37,306 INFO [train.py:450] Epoch 0, batch 940, batch avg loss 0.5779, total avg loss: 0.5914, batch size: 39
2021-08-24 17:46:46,900 INFO [train.py:450] Epoch 0, batch 950, batch avg loss 0.6132, total avg loss: 0.5907, batch size: 39
2021-08-24 17:46:56,197 INFO [train.py:450] Epoch 0, batch 960, batch avg loss 0.5979, total avg loss: 0.5903, batch size: 43
2021-08-24 17:47:05,653 INFO [train.py:450] Epoch 0, batch 970, batch avg loss 0.5794, total avg loss: 0.5891, batch size: 38
2021-08-24 17:47:15,623 INFO [train.py:450] Epoch 0, batch 980, batch avg loss 0.5801, total avg loss: 0.5888, batch size: 40
2021-08-24 17:47:25,325 INFO [train.py:450] Epoch 0, batch 990, batch avg loss 0.5529, total avg loss: 0.5878, batch size: 40
2021-08-24 17:47:34,605 INFO [train.py:450] Epoch 0, batch 1000, batch avg loss 0.5913, total avg loss: 0.5872, batch size: 40
2021-08-24 17:48:13,076 INFO [train.py:482] Epoch 0, valid loss 0.4630, best valid loss: 0.4630 best valid epoch: 0
2021-08-24 17:48:21,182 INFO [train.py:450] Epoch 0, batch 1010, batch avg loss 0.5605, total avg loss: 0.5756, batch size: 41
2021-08-24 17:48:32,731 INFO [train.py:450] Epoch 0, batch 1020, batch avg loss 0.5716, total avg loss: 0.5641, batch size: 39
2021-08-24 17:48:43,220 INFO [train.py:450] Epoch 0, batch 1030, batch avg loss 0.6371, total avg loss: 0.5731, batch size: 43
2021-08-24 17:48:52,696 INFO [train.py:450] Epoch 0, batch 1040, batch avg loss 0.5473, total avg loss: 0.5686, batch size: 41
2021-08-24 17:49:01,785 INFO [train.py:450] Epoch 0, batch 1050, batch avg loss 0.5319, total avg loss: 0.5668, batch size: 40
2021-08-24 17:49:11,710 INFO [train.py:450] Epoch 0, batch 1060, batch avg loss 0.5180, total avg loss: 0.5658, batch size: 36
2021-08-24 17:49:21,643 INFO [train.py:450] Epoch 0, batch 1070, batch avg loss 0.5949, total avg loss: 0.5684, batch size: 41
2021-08-24 17:49:30,767 INFO [train.py:450] Epoch 0, batch 1080, batch avg loss 0.5714, total avg loss: 0.5699, batch size: 40
2021-08-24 17:49:39,825 INFO [train.py:450] Epoch 0, batch 1090, batch avg loss 0.5614, total avg loss: 0.5684, batch size: 40
2021-08-24 17:49:49,550 INFO [train.py:450] Epoch 0, batch 1100, batch avg loss 0.6215, total avg loss: 0.5684, batch size: 36
2021-08-24 17:49:58,971 INFO [train.py:450] Epoch 0, batch 1110, batch avg loss 0.6205, total avg loss: 0.5694, batch size: 42
2021-08-24 17:50:08,540 INFO [train.py:450] Epoch 0, batch 1120, batch avg loss 0.5359, total avg loss: 0.5698, batch size: 38
2021-08-24 17:50:17,616 INFO [train.py:450] Epoch 0, batch 1130, batch avg loss 0.5648, total avg loss: 0.5683, batch size: 40
2021-08-24 17:50:27,418 INFO [train.py:450] Epoch 0, batch 1140, batch avg loss 0.5303, total avg loss: 0.5669, batch size: 42
2021-08-24 17:50:36,746 INFO [train.py:450] Epoch 0, batch 1150, batch avg loss 0.5845, total avg loss: 0.5675, batch size: 37
2021-08-24 17:50:45,912 INFO [train.py:450] Epoch 0, batch 1160, batch avg loss 0.5821, total avg loss: 0.5669, batch size: 42
2021-08-24 17:50:55,086 INFO [train.py:450] Epoch 0, batch 1170, batch avg loss 0.5008, total avg loss: 0.5663, batch size: 38
2021-08-24 17:51:04,192 INFO [train.py:450] Epoch 0, batch 1180, batch avg loss 0.6187, total avg loss: 0.5665, batch size: 42
2021-08-24 17:51:13,451 INFO [train.py:450] Epoch 0, batch 1190, batch avg loss 0.5898, total avg loss: 0.5654, batch size: 44
2021-08-24 17:51:22,320 INFO [train.py:450] Epoch 0, batch 1200, batch avg loss 0.5792, total avg loss: 0.5645, batch size: 44
2021-08-24 17:51:31,269 INFO [train.py:450] Epoch 0, batch 1210, batch avg loss 0.5701, total avg loss: 0.5683, batch size: 42
2021-08-24 17:51:40,793 INFO [train.py:450] Epoch 0, batch 1220, batch avg loss 0.5568, total avg loss: 0.5591, batch size: 37
2021-08-24 17:51:49,865 INFO [train.py:450] Epoch 0, batch 1230, batch avg loss 0.5337, total avg loss: 0.5555, batch size: 37
2021-08-24 17:51:59,768 INFO [train.py:450] Epoch 0, batch 1240, batch avg loss 0.6040, total avg loss: 0.5563, batch size: 38
2021-08-24 17:52:08,535 INFO [train.py:450] Epoch 0, batch 1250, batch avg loss 0.5855, total avg loss: 0.5548, batch size: 39
2021-08-24 17:52:18,348 INFO [train.py:450] Epoch 0, batch 1260, batch avg loss 0.5635, total avg loss: 0.5527, batch size: 40
2021-08-24 17:52:26,971 INFO [train.py:450] Epoch 0, batch 1270, batch avg loss 0.4927, total avg loss: 0.5518, batch size: 39
2021-08-24 17:52:36,757 INFO [train.py:450] Epoch 0, batch 1280, batch avg loss 0.5697, total avg loss: 0.5498, batch size: 39
2021-08-24 17:52:46,188 INFO [train.py:450] Epoch 0, batch 1290, batch avg loss 0.5661, total avg loss: 0.5507, batch size: 40
2021-08-24 17:52:55,299 INFO [train.py:450] Epoch 0, batch 1300, batch avg loss 0.5135, total avg loss: 0.5498, batch size: 40
2021-08-24 17:53:04,735 INFO [train.py:450] Epoch 0, batch 1310, batch avg loss 0.5580, total avg loss: 0.5480, batch size: 40
2021-08-24 17:53:13,685 INFO [train.py:450] Epoch 0, batch 1320, batch avg loss 0.4935, total avg loss: 0.5478, batch size: 36
2021-08-24 17:53:22,927 INFO [train.py:450] Epoch 0, batch 1330, batch avg loss 0.5192, total avg loss: 0.5481, batch size: 43
2021-08-24 17:53:32,089 INFO [train.py:450] Epoch 0, batch 1340, batch avg loss 0.5254, total avg loss: 0.5469, batch size: 40
2021-08-24 17:53:43,156 INFO [train.py:450] Epoch 0, batch 1350, batch avg loss 0.5665, total avg loss: 0.5466, batch size: 38
2021-08-24 17:53:56,221 INFO [train.py:450] Epoch 0, batch 1360, batch avg loss 0.5459, total avg loss: 0.5473, batch size: 38
2021-08-24 17:54:05,060 INFO [train.py:450] Epoch 0, batch 1370, batch avg loss 0.5319, total avg loss: 0.5472, batch size: 37
2021-08-24 17:54:14,540 INFO [train.py:450] Epoch 0, batch 1380, batch avg loss 0.5466, total avg loss: 0.5473, batch size: 41
2021-08-24 17:54:23,260 INFO [train.py:450] Epoch 0, batch 1390, batch avg loss 0.5706, total avg loss: 0.5474, batch size: 37
2021-08-24 17:54:32,426 INFO [train.py:450] Epoch 0, batch 1400, batch avg loss 0.4982, total avg loss: 0.5462, batch size: 41
2021-08-24 17:54:41,784 INFO [train.py:450] Epoch 0, batch 1410, batch avg loss 0.5557, total avg loss: 0.5514, batch size: 41
2021-08-24 17:54:51,400 INFO [train.py:450] Epoch 0, batch 1420, batch avg loss 0.5776, total avg loss: 0.5588, batch size: 38
2021-08-24 17:55:01,013 INFO [train.py:450] Epoch 0, batch 1430, batch avg loss 0.5361, total avg loss: 0.5523, batch size: 42
2021-08-24 17:55:10,783 INFO [train.py:450] Epoch 0, batch 1440, batch avg loss 0.5424, total avg loss: 0.5521, batch size: 41
2021-08-24 17:55:19,768 INFO [train.py:450] Epoch 0, batch 1450, batch avg loss 0.5775, total avg loss: 0.5532, batch size: 43
2021-08-24 17:55:29,584 INFO [train.py:450] Epoch 0, batch 1460, batch avg loss 0.5313, total avg loss: 0.5549, batch size: 41
2021-08-24 17:55:39,017 INFO [train.py:450] Epoch 0, batch 1470, batch avg loss 0.6132, total avg loss: 0.5557, batch size: 41
2021-08-24 17:55:48,822 INFO [train.py:450] Epoch 0, batch 1480, batch avg loss 0.5653, total avg loss: 0.5544, batch size: 37
2021-08-24 17:55:58,851 INFO [train.py:450] Epoch 0, batch 1490, batch avg loss 0.5384, total avg loss: 0.5539, batch size: 38
2021-08-24 17:56:07,417 INFO [train.py:450] Epoch 0, batch 1500, batch avg loss 0.4826, total avg loss: 0.5522, batch size: 40
2021-08-24 17:56:16,109 INFO [train.py:450] Epoch 0, batch 1510, batch avg loss 0.5605, total avg loss: 0.5506, batch size: 39
2021-08-24 17:56:25,944 INFO [train.py:450] Epoch 0, batch 1520, batch avg loss 0.5403, total avg loss: 0.5501, batch size: 42
2021-08-24 17:56:36,960 INFO [train.py:450] Epoch 0, batch 1530, batch avg loss 0.5354, total avg loss: 0.5484, batch size: 40
2021-08-24 17:56:46,943 INFO [train.py:450] Epoch 0, batch 1540, batch avg loss 0.4638, total avg loss: 0.5481, batch size: 37
2021-08-24 17:56:56,236 INFO [train.py:450] Epoch 0, batch 1550, batch avg loss 0.5116, total avg loss: 0.5476, batch size: 46
2021-08-24 17:57:05,493 INFO [train.py:450] Epoch 0, batch 1560, batch avg loss 0.6295, total avg loss: 0.5485, batch size: 39
2021-08-24 17:57:15,282 INFO [train.py:450] Epoch 0, batch 1570, batch avg loss 0.5318, total avg loss: 0.5478, batch size: 44
2021-08-24 17:57:24,714 INFO [train.py:450] Epoch 0, batch 1580, batch avg loss 0.5548, total avg loss: 0.5470, batch size: 37
2021-08-24 17:57:34,103 INFO [train.py:450] Epoch 0, batch 1590, batch avg loss 0.5458, total avg loss: 0.5449, batch size: 36
2021-08-24 17:57:43,860 INFO [train.py:450] Epoch 0, batch 1600, batch avg loss 0.5526, total avg loss: 0.5444, batch size: 41
2021-08-24 17:57:52,498 INFO [train.py:450] Epoch 0, batch 1610, batch avg loss 0.5341, total avg loss: 0.5375, batch size: 42
2021-08-24 17:58:00,641 INFO [train.py:450] Epoch 0, batch 1620, batch avg loss 0.5130, total avg loss: 0.5328, batch size: 39
2021-08-24 17:58:09,241 INFO [train.py:450] Epoch 0, batch 1630, batch avg loss 0.5351, total avg loss: 0.5374, batch size: 39
2021-08-24 17:58:18,328 INFO [train.py:450] Epoch 0, batch 1640, batch avg loss 0.5676, total avg loss: 0.5354, batch size: 40
2021-08-24 17:58:27,119 INFO [train.py:450] Epoch 0, batch 1650, batch avg loss 0.5142, total avg loss: 0.5357, batch size: 42
2021-08-24 17:58:36,259 INFO [train.py:450] Epoch 0, batch 1660, batch avg loss 0.5428, total avg loss: 0.5334, batch size: 40
2021-08-24 17:58:45,230 INFO [train.py:450] Epoch 0, batch 1670, batch avg loss 0.5738, total avg loss: 0.5313, batch size: 38
2021-08-24 17:58:54,504 INFO [train.py:450] Epoch 0, batch 1680, batch avg loss 0.4929, total avg loss: 0.5321, batch size: 39
2021-08-24 17:59:03,588 INFO [train.py:450] Epoch 0, batch 1690, batch avg loss 0.5156, total avg loss: 0.5327, batch size: 39
2021-08-24 17:59:13,016 INFO [train.py:450] Epoch 0, batch 1700, batch avg loss 0.5189, total avg loss: 0.5313, batch size: 39
2021-08-24 17:59:24,960 INFO [train.py:450] Epoch 0, batch 1710, batch avg loss 0.5322, total avg loss: 0.5307, batch size: 38
2021-08-24 17:59:34,039 INFO [train.py:450] Epoch 0, batch 1720, batch avg loss 0.5009, total avg loss: 0.5284, batch size: 39
2021-08-24 17:59:42,775 INFO [train.py:450] Epoch 0, batch 1730, batch avg loss 0.5393, total avg loss: 0.5281, batch size: 40
2021-08-24 17:59:51,830 INFO [train.py:450] Epoch 0, batch 1740, batch avg loss 0.5020, total avg loss: 0.5282, batch size: 40
2021-08-24 18:00:01,051 INFO [train.py:450] Epoch 0, batch 1750, batch avg loss 0.5425, total avg loss: 0.5285, batch size: 40
2021-08-24 18:00:09,898 INFO [train.py:450] Epoch 0, batch 1760, batch avg loss 0.6174, total avg loss: 0.5297, batch size: 37
2021-08-24 18:00:19,250 INFO [train.py:450] Epoch 0, batch 1770, batch avg loss 0.4515, total avg loss: 0.5297, batch size: 37
2021-08-24 18:00:28,173 INFO [train.py:450] Epoch 0, batch 1780, batch avg loss 0.5188, total avg loss: 0.5297, batch size: 39
2021-08-24 18:00:37,152 INFO [train.py:450] Epoch 0, batch 1790, batch avg loss 0.5326, total avg loss: 0.5289, batch size: 35
2021-08-24 18:00:45,856 INFO [train.py:450] Epoch 0, batch 1800, batch avg loss 0.5524, total avg loss: 0.5290, batch size: 42
2021-08-24 18:00:54,229 INFO [train.py:450] Epoch 0, batch 1810, batch avg loss 0.5105, total avg loss: 0.5270, batch size: 36
2021-08-24 18:01:02,798 INFO [train.py:450] Epoch 0, batch 1820, batch avg loss 0.4997, total avg loss: 0.5249, batch size: 37
2021-08-24 18:01:11,411 INFO [train.py:450] Epoch 0, batch 1830, batch avg loss 0.4820, total avg loss: 0.5222, batch size: 41
2021-08-24 18:01:20,382 INFO [train.py:450] Epoch 0, batch 1840, batch avg loss 0.5740, total avg loss: 0.5213, batch size: 41
2021-08-24 18:01:29,742 INFO [train.py:450] Epoch 0, batch 1850, batch avg loss 0.5576, total avg loss: 0.5253, batch size: 40
2021-08-24 18:01:38,123 INFO [train.py:450] Epoch 0, batch 1860, batch avg loss 0.5377, total avg loss: 0.5216, batch size: 45
2021-08-24 18:01:46,753 INFO [train.py:450] Epoch 0, batch 1870, batch avg loss 0.5076, total avg loss: 0.5205, batch size: 40
2021-08-24 18:01:55,589 INFO [train.py:450] Epoch 0, batch 1880, batch avg loss 0.5677, total avg loss: 0.5215, batch size: 38
2021-08-24 18:02:04,228 INFO [train.py:450] Epoch 0, batch 1890, batch avg loss 0.5118, total avg loss: 0.5204, batch size: 41
2021-08-24 18:02:13,280 INFO [train.py:450] Epoch 0, batch 1900, batch avg loss 0.5834, total avg loss: 0.5209, batch size: 43
2021-08-24 18:02:22,249 INFO [train.py:450] Epoch 0, batch 1910, batch avg loss 0.5813, total avg loss: 0.5236, batch size: 40
2021-08-24 18:02:31,096 INFO [train.py:450] Epoch 0, batch 1920, batch avg loss 0.4913, total avg loss: 0.5226, batch size: 40
2021-08-24 18:02:39,430 INFO [train.py:450] Epoch 0, batch 1930, batch avg loss 0.4695, total avg loss: 0.5219, batch size: 40
2021-08-24 18:02:48,048 INFO [train.py:450] Epoch 0, batch 1940, batch avg loss 0.5765, total avg loss: 0.5226, batch size: 38
2021-08-24 18:02:56,512 INFO [train.py:450] Epoch 0, batch 1950, batch avg loss 0.5614, total avg loss: 0.5234, batch size: 45
2021-08-24 18:03:05,103 INFO [train.py:450] Epoch 0, batch 1960, batch avg loss 0.5098, total avg loss: 0.5225, batch size: 40
2021-08-24 18:03:13,815 INFO [train.py:450] Epoch 0, batch 1970, batch avg loss 0.5733, total avg loss: 0.5225, batch size: 39
2021-08-24 18:03:22,698 INFO [train.py:450] Epoch 0, batch 1980, batch avg loss 0.4750, total avg loss: 0.5228, batch size: 43
2021-08-24 18:03:31,905 INFO [train.py:450] Epoch 0, batch 1990, batch avg loss 0.5205, total avg loss: 0.5227, batch size: 38
2021-08-24 18:03:41,361 INFO [train.py:450] Epoch 0, batch 2000, batch avg loss 0.5100, total avg loss: 0.5217, batch size: 39
2021-08-24 18:04:20,409 INFO [train.py:482] Epoch 0, valid loss 0.4005, best valid loss: 0.4005 best valid epoch: 0
2021-08-24 18:04:27,040 INFO [train.py:450] Epoch 0, batch 2010, batch avg loss 0.5319, total avg loss: 0.5152, batch size: 38
2021-08-24 18:04:35,750 INFO [train.py:450] Epoch 0, batch 2020, batch avg loss 0.4962, total avg loss: 0.5121, batch size: 38
2021-08-24 18:04:45,948 INFO [train.py:450] Epoch 0, batch 2030, batch avg loss 0.5134, total avg loss: 0.5106, batch size: 38
2021-08-24 18:04:54,841 INFO [train.py:450] Epoch 0, batch 2040, batch avg loss 0.5648, total avg loss: 0.5123, batch size: 40
2021-08-24 18:05:05,574 INFO [train.py:450] Epoch 0, batch 2050, batch avg loss 0.5723, total avg loss: 0.5115, batch size: 43
2021-08-24 18:05:14,491 INFO [train.py:450] Epoch 0, batch 2060, batch avg loss 0.4907, total avg loss: 0.5104, batch size: 40
2021-08-24 18:05:23,220 INFO [train.py:450] Epoch 0, batch 2070, batch avg loss 0.4695, total avg loss: 0.5109, batch size: 38
2021-08-24 18:05:31,929 INFO [train.py:450] Epoch 0, batch 2080, batch avg loss 0.4652, total avg loss: 0.5100, batch size: 40
2021-08-24 18:05:40,305 INFO [train.py:450] Epoch 0, batch 2090, batch avg loss 0.5348, total avg loss: 0.5098, batch size: 38
2021-08-24 18:05:48,359 INFO [train.py:450] Epoch 0, batch 2100, batch avg loss 0.5079, total avg loss: 0.5082, batch size: 41
2021-08-24 18:05:56,809 INFO [train.py:450] Epoch 0, batch 2110, batch avg loss 0.5012, total avg loss: 0.5084, batch size: 39
2021-08-24 18:06:05,149 INFO [train.py:450] Epoch 0, batch 2120, batch avg loss 0.5485, total avg loss: 0.5086, batch size: 40
2021-08-24 18:06:13,321 INFO [train.py:450] Epoch 0, batch 2130, batch avg loss 0.5101, total avg loss: 0.5098, batch size: 38
2021-08-24 18:06:21,556 INFO [train.py:450] Epoch 0, batch 2140, batch avg loss 0.4859, total avg loss: 0.5101, batch size: 40
2021-08-24 18:06:29,811 INFO [train.py:450] Epoch 0, batch 2150, batch avg loss 0.5174, total avg loss: 0.5101, batch size: 39
2021-08-24 18:06:38,366 INFO [train.py:450] Epoch 0, batch 2160, batch avg loss 0.4836, total avg loss: 0.5094, batch size: 37
2021-08-24 18:06:46,167 INFO [train.py:450] Epoch 0, batch 2170, batch avg loss 0.5150, total avg loss: 0.5096, batch size: 39
2021-08-24 18:06:54,600 INFO [train.py:450] Epoch 0, batch 2180, batch avg loss 0.4813, total avg loss: 0.5100, batch size: 39
2021-08-24 18:07:03,369 INFO [train.py:450] Epoch 0, batch 2190, batch avg loss 0.5153, total avg loss: 0.5092, batch size: 41
2021-08-24 18:07:12,297 INFO [train.py:450] Epoch 0, batch 2200, batch avg loss 0.4708, total avg loss: 0.5081, batch size: 41
2021-08-24 18:07:20,132 INFO [train.py:450] Epoch 0, batch 2210, batch avg loss 0.5207, total avg loss: 0.4980, batch size: 38
2021-08-24 18:07:28,143 INFO [train.py:450] Epoch 0, batch 2220, batch avg loss 0.4474, total avg loss: 0.5040, batch size: 39
2021-08-24 18:07:35,851 INFO [train.py:450] Epoch 0, batch 2230, batch avg loss 0.4533, total avg loss: 0.5042, batch size: 37
2021-08-24 18:07:44,238 INFO [train.py:450] Epoch 0, batch 2240, batch avg loss 0.4735, total avg loss: 0.5001, batch size: 44
2021-08-24 18:07:52,946 INFO [train.py:450] Epoch 0, batch 2250, batch avg loss 0.5173, total avg loss: 0.5016, batch size: 42
2021-08-24 18:08:00,546 INFO [train.py:450] Epoch 0, batch 2260, batch avg loss 0.5010, total avg loss: 0.5013, batch size: 41
2021-08-24 18:08:08,325 INFO [train.py:450] Epoch 0, batch 2270, batch avg loss 0.4862, total avg loss: 0.5002, batch size: 40
2021-08-24 18:08:16,287 INFO [train.py:450] Epoch 0, batch 2280, batch avg loss 0.5511, total avg loss: 0.5028, batch size: 39
2021-08-24 18:08:24,555 INFO [train.py:450] Epoch 0, batch 2290, batch avg loss 0.5342, total avg loss: 0.5026, batch size: 41
2021-08-24 18:08:32,909 INFO [train.py:450] Epoch 0, batch 2300, batch avg loss 0.5178, total avg loss: 0.5027, batch size: 41
2021-08-24 18:08:40,736 INFO [train.py:450] Epoch 0, batch 2310, batch avg loss 0.4646, total avg loss: 0.5025, batch size: 38
2021-08-24 18:08:49,048 INFO [train.py:450] Epoch 0, batch 2320, batch avg loss 0.5311, total avg loss: 0.5032, batch size: 38
2021-08-24 18:08:57,072 INFO [train.py:450] Epoch 0, batch 2330, batch avg loss 0.5071, total avg loss: 0.5039, batch size: 36
2021-08-24 18:09:05,431 INFO [train.py:450] Epoch 0, batch 2340, batch avg loss 0.5494, total avg loss: 0.5038, batch size: 38
2021-08-24 18:09:14,057 INFO [train.py:450] Epoch 0, batch 2350, batch avg loss 0.5020, total avg loss: 0.5045, batch size: 43
2021-08-24 18:09:22,544 INFO [train.py:450] Epoch 0, batch 2360, batch avg loss 0.5062, total avg loss: 0.5047, batch size: 42
2021-08-24 18:09:32,161 INFO [train.py:450] Epoch 0, batch 2370, batch avg loss 0.4766, total avg loss: 0.5048, batch size: 45
2021-08-24 18:09:41,156 INFO [train.py:450] Epoch 0, batch 2380, batch avg loss 0.5027, total avg loss: 0.5043, batch size: 38
2021-08-24 18:09:50,651 INFO [train.py:450] Epoch 0, batch 2390, batch avg loss 0.4848, total avg loss: 0.5047, batch size: 39
2021-08-24 18:09:59,274 INFO [train.py:450] Epoch 0, batch 2400, batch avg loss 0.5479, total avg loss: 0.5036, batch size: 42
2021-08-24 18:10:07,430 INFO [train.py:450] Epoch 0, batch 2410, batch avg loss 0.4767, total avg loss: 0.4991, batch size: 44
2021-08-24 18:10:16,745 INFO [train.py:450] Epoch 0, batch 2420, batch avg loss 0.4708, total avg loss: 0.5018, batch size: 42
2021-08-24 18:10:25,069 INFO [train.py:450] Epoch 0, batch 2430, batch avg loss 0.5287, total avg loss: 0.5096, batch size: 39
2021-08-24 18:10:33,190 INFO [train.py:450] Epoch 0, batch 2440, batch avg loss 0.4948, total avg loss: 0.5056, batch size: 46
2021-08-24 18:10:41,723 INFO [train.py:450] Epoch 0, batch 2450, batch avg loss 0.5056, total avg loss: 0.5051, batch size: 37
2021-08-24 18:10:50,192 INFO [train.py:450] Epoch 0, batch 2460, batch avg loss 0.4853, total avg loss: 0.5036, batch size: 43
2021-08-24 18:10:58,237 INFO [train.py:450] Epoch 0, batch 2470, batch avg loss 0.5287, total avg loss: 0.5028, batch size: 39
2021-08-24 18:11:06,234 INFO [train.py:450] Epoch 0, batch 2480, batch avg loss 0.5213, total avg loss: 0.5036, batch size: 43
2021-08-24 18:11:14,245 INFO [train.py:450] Epoch 0, batch 2490, batch avg loss 0.4396, total avg loss: 0.5026, batch size: 40
2021-08-24 18:11:22,290 INFO [train.py:450] Epoch 0, batch 2500, batch avg loss 0.4575, total avg loss: 0.5015, batch size: 40
2021-08-24 18:11:30,450 INFO [train.py:450] Epoch 0, batch 2510, batch avg loss 0.5337, total avg loss: 0.4984, batch size: 40
2021-08-24 18:11:38,437 INFO [train.py:450] Epoch 0, batch 2520, batch avg loss 0.5163, total avg loss: 0.4994, batch size: 41
2021-08-24 18:11:46,674 INFO [train.py:450] Epoch 0, batch 2530, batch avg loss 0.4868, total avg loss: 0.4991, batch size: 43
2021-08-24 18:11:54,475 INFO [train.py:450] Epoch 0, batch 2540, batch avg loss 0.5003, total avg loss: 0.4988, batch size: 36
2021-08-24 18:12:02,433 INFO [train.py:450] Epoch 0, batch 2550, batch avg loss 0.5092, total avg loss: 0.4985, batch size: 42
2021-08-24 18:12:10,849 INFO [train.py:450] Epoch 0, batch 2560, batch avg loss 0.4491, total avg loss: 0.4976, batch size: 38
2021-08-24 18:12:18,715 INFO [train.py:450] Epoch 0, batch 2570, batch avg loss 0.5040, total avg loss: 0.4971, batch size: 39
2021-08-24 18:12:26,600 INFO [train.py:450] Epoch 0, batch 2580, batch avg loss 0.4776, total avg loss: 0.4972, batch size: 36
2021-08-24 18:12:33,853 INFO [train.py:450] Epoch 0, batch 2590, batch avg loss 0.5296, total avg loss: 0.4969, batch size: 34
2021-08-24 18:12:41,786 INFO [train.py:450] Epoch 0, batch 2600, batch avg loss 0.4580, total avg loss: 0.4968, batch size: 43
2021-08-24 18:12:49,940 INFO [train.py:450] Epoch 0, batch 2610, batch avg loss 0.5299, total avg loss: 0.4780, batch size: 42
2021-08-24 18:12:57,734 INFO [train.py:450] Epoch 0, batch 2620, batch avg loss 0.4800, total avg loss: 0.4796, batch size: 36
2021-08-24 18:13:05,529 INFO [train.py:450] Epoch 0, batch 2630, batch avg loss 0.5753, total avg loss: 0.4862, batch size: 41
2021-08-24 18:13:13,650 INFO [train.py:450] Epoch 0, batch 2640, batch avg loss 0.4798, total avg loss: 0.4836, batch size: 38
2021-08-24 18:13:22,050 INFO [train.py:450] Epoch 0, batch 2650, batch avg loss 0.5420, total avg loss: 0.4844, batch size: 40
2021-08-24 18:13:29,921 INFO [train.py:450] Epoch 0, batch 2660, batch avg loss 0.5179, total avg loss: 0.4865, batch size: 42
2021-08-24 18:13:37,842 INFO [train.py:450] Epoch 0, batch 2670, batch avg loss 0.5508, total avg loss: 0.4889, batch size: 40
2021-08-24 18:13:45,599 INFO [train.py:450] Epoch 0, batch 2680, batch avg loss 0.4613, total avg loss: 0.4902, batch size: 39
2021-08-24 18:13:53,392 INFO [train.py:450] Epoch 0, batch 2690, batch avg loss 0.4863, total avg loss: 0.4897, batch size: 43
2021-08-24 18:14:01,873 INFO [train.py:450] Epoch 0, batch 2700, batch avg loss 0.4593, total avg loss: 0.4885, batch size: 38
2021-08-24 18:14:12,323 INFO [train.py:450] Epoch 0, batch 2710, batch avg loss 0.4797, total avg loss: 0.4888, batch size: 38
2021-08-24 18:14:19,692 INFO [train.py:450] Epoch 0, batch 2720, batch avg loss 0.5485, total avg loss: 0.4887, batch size: 42
2021-08-24 18:14:29,872 INFO [train.py:450] Epoch 0, batch 2730, batch avg loss 0.5588, total avg loss: 0.4881, batch size: 40
2021-08-24 18:14:38,018 INFO [train.py:450] Epoch 0, batch 2740, batch avg loss 0.5512, total avg loss: 0.4890, batch size: 42
2021-08-24 18:14:46,364 INFO [train.py:450] Epoch 0, batch 2750, batch avg loss 0.5469, total avg loss: 0.4889, batch size: 42
2021-08-24 18:14:54,068 INFO [train.py:450] Epoch 0, batch 2760, batch avg loss 0.4746, total avg loss: 0.4885, batch size: 41
2021-08-24 18:15:01,711 INFO [train.py:450] Epoch 0, batch 2770, batch avg loss 0.5019, total avg loss: 0.4892, batch size: 40
2021-08-24 18:15:09,446 INFO [train.py:450] Epoch 0, batch 2780, batch avg loss 0.4459, total avg loss: 0.4890, batch size: 40
2021-08-24 18:15:17,330 INFO [train.py:450] Epoch 0, batch 2790, batch avg loss 0.5048, total avg loss: 0.4889, batch size: 39
2021-08-24 18:15:25,521 INFO [train.py:450] Epoch 0, batch 2800, batch avg loss 0.5032, total avg loss: 0.4883, batch size: 41
2021-08-24 18:15:33,427 INFO [train.py:450] Epoch 0, batch 2810, batch avg loss 0.4658, total avg loss: 0.4786, batch size: 38
2021-08-24 18:15:40,758 INFO [train.py:450] Epoch 0, batch 2820, batch avg loss 0.4734, total avg loss: 0.4829, batch size: 39
2021-08-24 18:15:48,511 INFO [train.py:450] Epoch 0, batch 2830, batch avg loss 0.4413, total avg loss: 0.4851, batch size: 39
2021-08-24 18:15:55,963 INFO [train.py:450] Epoch 0, batch 2840, batch avg loss 0.4833, total avg loss: 0.4883, batch size: 41
2021-08-24 18:16:04,040 INFO [train.py:450] Epoch 0, batch 2850, batch avg loss 0.4570, total avg loss: 0.4870, batch size: 37
2021-08-24 18:16:11,561 INFO [train.py:450] Epoch 0, batch 2860, batch avg loss 0.5717, total avg loss: 0.4872, batch size: 40
2021-08-24 18:16:19,511 INFO [train.py:450] Epoch 0, batch 2870, batch avg loss 0.4353, total avg loss: 0.4851, batch size: 39
2021-08-24 18:16:27,517 INFO [train.py:450] Epoch 0, batch 2880, batch avg loss 0.4386, total avg loss: 0.4835, batch size: 41
2021-08-24 18:16:34,995 INFO [train.py:450] Epoch 0, batch 2890, batch avg loss 0.4386, total avg loss: 0.4832, batch size: 39
2021-08-24 18:16:42,470 INFO [train.py:450] Epoch 0, batch 2900, batch avg loss 0.4437, total avg loss: 0.4843, batch size: 39
2021-08-24 18:16:50,283 INFO [train.py:450] Epoch 0, batch 2910, batch avg loss 0.4742, total avg loss: 0.4846, batch size: 43
2021-08-24 18:16:58,077 INFO [train.py:450] Epoch 0, batch 2920, batch avg loss 0.4780, total avg loss: 0.4863, batch size: 37
2021-08-24 18:17:05,788 INFO [train.py:450] Epoch 0, batch 2930, batch avg loss 0.4979, total avg loss: 0.4864, batch size: 40
2021-08-24 18:17:13,502 INFO [train.py:450] Epoch 0, batch 2940, batch avg loss 0.4557, total avg loss: 0.4880, batch size: 41
2021-08-24 18:17:21,021 INFO [train.py:450] Epoch 0, batch 2950, batch avg loss 0.5172, total avg loss: 0.4879, batch size: 38
2021-08-24 18:17:28,929 INFO [train.py:450] Epoch 0, batch 2960, batch avg loss 0.4697, total avg loss: 0.4872, batch size: 40
2021-08-24 18:17:36,790 INFO [train.py:450] Epoch 0, batch 2970, batch avg loss 0.4053, total avg loss: 0.4869, batch size: 39
2021-08-24 18:17:44,285 INFO [train.py:450] Epoch 0, batch 2980, batch avg loss 0.4920, total avg loss: 0.4870, batch size: 41
2021-08-24 18:17:51,931 INFO [train.py:450] Epoch 0, batch 2990, batch avg loss 0.5584, total avg loss: 0.4870, batch size: 39
2021-08-24 18:18:00,051 INFO [train.py:450] Epoch 0, batch 3000, batch avg loss 0.4788, total avg loss: 0.4876, batch size: 37
2021-08-24 18:18:38,694 INFO [train.py:482] Epoch 0, valid loss 0.3651, best valid loss: 0.3651 best valid epoch: 0
2021-08-24 18:18:44,549 INFO [train.py:450] Epoch 0, batch 3010, batch avg loss 0.4795, total avg loss: 0.4790, batch size: 41
2021-08-24 18:18:52,315 INFO [train.py:450] Epoch 0, batch 3020, batch avg loss 0.4646, total avg loss: 0.4745, batch size: 38
2021-08-24 18:18:59,893 INFO [train.py:450] Epoch 0, batch 3030, batch avg loss 0.5177, total avg loss: 0.4772, batch size: 37
2021-08-24 18:19:07,998 INFO [train.py:450] Epoch 0, batch 3040, batch avg loss 0.4551, total avg loss: 0.4770, batch size: 40
2021-08-24 18:19:16,240 INFO [train.py:450] Epoch 0, batch 3050, batch avg loss 0.5326, total avg loss: 0.4772, batch size: 36
2021-08-24 18:19:25,105 INFO [train.py:450] Epoch 0, batch 3060, batch avg loss 0.4484, total avg loss: 0.4774, batch size: 39
2021-08-24 18:19:34,470 INFO [train.py:450] Epoch 0, batch 3070, batch avg loss 0.4799, total avg loss: 0.4756, batch size: 41
2021-08-24 18:19:43,390 INFO [train.py:450] Epoch 0, batch 3080, batch avg loss 0.4962, total avg loss: 0.4763, batch size: 41
2021-08-24 18:19:50,718 INFO [train.py:450] Epoch 0, batch 3090, batch avg loss 0.4622, total avg loss: 0.4780, batch size: 39
2021-08-24 18:19:58,223 INFO [train.py:450] Epoch 0, batch 3100, batch avg loss 0.5158, total avg loss: 0.4782, batch size: 38
2021-08-24 18:20:06,149 INFO [train.py:450] Epoch 0, batch 3110, batch avg loss 0.4258, total avg loss: 0.4789, batch size: 36
2021-08-24 18:20:14,010 INFO [train.py:450] Epoch 0, batch 3120, batch avg loss 0.4837, total avg loss: 0.4783, batch size: 36
2021-08-24 18:20:21,913 INFO [train.py:450] Epoch 0, batch 3130, batch avg loss 0.5497, total avg loss: 0.4777, batch size: 38
2021-08-24 18:20:29,202 INFO [train.py:450] Epoch 0, batch 3140, batch avg loss 0.3965, total avg loss: 0.4761, batch size: 38
2021-08-24 18:20:37,110 INFO [train.py:450] Epoch 0, batch 3150, batch avg loss 0.4975, total avg loss: 0.4748, batch size: 43
2021-08-24 18:20:44,401 INFO [train.py:450] Epoch 0, batch 3160, batch avg loss 0.5116, total avg loss: 0.4745, batch size: 41
2021-08-24 18:20:45,632 WARNING [cut.py:1694] To perform mix, energy must be non-zero and non-negative (got 0.0).  MonoCut with id "a0b3aa5d-2ded-fff9-6ed4-c4db649582c5" will not be mixed in.
2021-08-24 18:20:51,876 INFO [train.py:450] Epoch 0, batch 3170, batch avg loss 0.5057, total avg loss: 0.4757, batch size: 37
2021-08-24 18:20:58,956 INFO [train.py:450] Epoch 0, batch 3180, batch avg loss 0.5211, total avg loss: 0.4754, batch size: 39
2021-08-24 18:21:06,490 INFO [train.py:450] Epoch 0, batch 3190, batch avg loss 0.4023, total avg loss: 0.4749, batch size: 39
2021-08-24 18:21:14,485 INFO [train.py:450] Epoch 0, batch 3200, batch avg loss 0.4616, total avg loss: 0.4756, batch size: 41
2021-08-24 18:21:22,874 INFO [train.py:450] Epoch 0, batch 3210, batch avg loss 0.4345, total avg loss: 0.4727, batch size: 42
2021-08-24 18:21:30,685 INFO [train.py:450] Epoch 0, batch 3220, batch avg loss 0.5402, total avg loss: 0.4812, batch size: 39
2021-08-24 18:21:38,751 INFO [train.py:450] Epoch 0, batch 3230, batch avg loss 0.5009, total avg loss: 0.4832, batch size: 41
2021-08-24 18:21:46,599 INFO [train.py:450] Epoch 0, batch 3240, batch avg loss 0.4925, total avg loss: 0.4835, batch size: 41
2021-08-24 18:21:54,441 INFO [train.py:450] Epoch 0, batch 3250, batch avg loss 0.4672, total avg loss: 0.4829, batch size: 41
2021-08-24 18:22:02,775 INFO [train.py:450] Epoch 0, batch 3260, batch avg loss 0.4858, total avg loss: 0.4828, batch size: 39
2021-08-24 18:22:10,875 INFO [train.py:450] Epoch 0, batch 3270, batch avg loss 0.4807, total avg loss: 0.4844, batch size: 43
2021-08-24 18:22:18,956 INFO [train.py:450] Epoch 0, batch 3280, batch avg loss 0.5171, total avg loss: 0.4831, batch size: 43
2021-08-24 18:22:23,339 WARNING [cut.py:1694] To perform mix, energy must be non-zero and non-negative (got 0.0).  MonoCut with id "fb6fce01-1bd9-5b11-f8b9-4f4dcb341453" will not be mixed in.
2021-08-24 18:22:26,961 INFO [train.py:450] Epoch 0, batch 3290, batch avg loss 0.4398, total avg loss: 0.4828, batch size: 42
2021-08-24 18:22:34,904 INFO [train.py:450] Epoch 0, batch 3300, batch avg loss 0.5329, total avg loss: 0.4841, batch size: 39
2021-08-24 18:22:42,727 INFO [train.py:450] Epoch 0, batch 3310, batch avg loss 0.4443, total avg loss: 0.4828, batch size: 44
2021-08-24 18:22:51,056 INFO [train.py:450] Epoch 0, batch 3320, batch avg loss 0.5120, total avg loss: 0.4826, batch size: 36
2021-08-24 18:22:59,008 INFO [train.py:450] Epoch 0, batch 3330, batch avg loss 0.4206, total avg loss: 0.4822, batch size: 41
2021-08-24 18:23:06,590 INFO [train.py:450] Epoch 0, batch 3340, batch avg loss 0.4768, total avg loss: 0.4820, batch size: 37
2021-08-24 18:23:14,477 INFO [train.py:450] Epoch 0, batch 3350, batch avg loss 0.4797, total avg loss: 0.4819, batch size: 38
2021-08-24 18:23:22,161 INFO [train.py:450] Epoch 0, batch 3360, batch avg loss 0.4635, total avg loss: 0.4803, batch size: 42
2021-08-24 18:23:29,592 INFO [train.py:450] Epoch 0, batch 3370, batch avg loss 0.5024, total avg loss: 0.4805, batch size: 40
2021-08-24 18:23:37,438 INFO [train.py:450] Epoch 0, batch 3380, batch avg loss 0.5628, total avg loss: 0.4816, batch size: 44
2021-08-24 18:23:45,986 INFO [train.py:450] Epoch 0, batch 3390, batch avg loss 0.4642, total avg loss: 0.4815, batch size: 42
2021-08-24 18:23:53,728 INFO [train.py:450] Epoch 0, batch 3400, batch avg loss 0.4848, total avg loss: 0.4808, batch size: 40
2021-08-24 18:24:02,201 INFO [train.py:450] Epoch 0, batch 3410, batch avg loss 0.5091, total avg loss: 0.4852, batch size: 43
2021-08-24 18:24:10,012 INFO [train.py:450] Epoch 0, batch 3420, batch avg loss 0.5198, total avg loss: 0.4882, batch size: 36
2021-08-24 18:24:18,142 INFO [train.py:450] Epoch 0, batch 3430, batch avg loss 0.5087, total avg loss: 0.4828, batch size: 39
2021-08-24 18:24:25,771 INFO [train.py:450] Epoch 0, batch 3440, batch avg loss 0.4665, total avg loss: 0.4768, batch size: 38
2021-08-24 18:24:35,287 INFO [train.py:450] Epoch 0, batch 3450, batch avg loss 0.4646, total avg loss: 0.4769, batch size: 42
2021-08-24 18:24:42,870 INFO [train.py:450] Epoch 0, batch 3460, batch avg loss 0.5455, total avg loss: 0.4761, batch size: 39
2021-08-24 18:24:54,627 INFO [train.py:450] Epoch 0, batch 3470, batch avg loss 0.4607, total avg loss: 0.4771, batch size: 40
2021-08-24 18:25:02,756 INFO [train.py:450] Epoch 0, batch 3480, batch avg loss 0.4675, total avg loss: 0.4756, batch size: 37
2021-08-24 18:25:10,700 INFO [train.py:450] Epoch 0, batch 3490, batch avg loss 0.4035, total avg loss: 0.4743, batch size: 40
2021-08-24 18:25:18,584 INFO [train.py:450] Epoch 0, batch 3500, batch avg loss 0.4287, total avg loss: 0.4740, batch size: 38
2021-08-24 18:25:26,752 INFO [train.py:450] Epoch 0, batch 3510, batch avg loss 0.4881, total avg loss: 0.4738, batch size: 40
2021-08-24 18:25:34,231 INFO [train.py:450] Epoch 0, batch 3520, batch avg loss 0.4745, total avg loss: 0.4724, batch size: 37
2021-08-24 18:25:41,912 INFO [train.py:450] Epoch 0, batch 3530, batch avg loss 0.4489, total avg loss: 0.4718, batch size: 34
2021-08-24 18:25:50,089 INFO [train.py:450] Epoch 0, batch 3540, batch avg loss 0.5156, total avg loss: 0.4725, batch size: 41
2021-08-24 18:25:58,580 INFO [train.py:450] Epoch 0, batch 3550, batch avg loss 0.4797, total avg loss: 0.4734, batch size: 39
2021-08-24 18:26:05,945 INFO [train.py:450] Epoch 0, batch 3560, batch avg loss 0.4650, total avg loss: 0.4739, batch size: 41
2021-08-24 18:26:13,178 INFO [train.py:450] Epoch 0, batch 3570, batch avg loss 0.3928, total avg loss: 0.4736, batch size: 40
2021-08-24 18:26:21,165 INFO [train.py:450] Epoch 0, batch 3580, batch avg loss 0.4996, total avg loss: 0.4747, batch size: 42
2021-08-24 18:26:29,273 INFO [train.py:450] Epoch 0, batch 3590, batch avg loss 0.4259, total avg loss: 0.4746, batch size: 41
2021-08-24 18:26:37,297 INFO [train.py:450] Epoch 0, batch 3600, batch avg loss 0.5012, total avg loss: 0.4746, batch size: 42
2021-08-24 18:26:45,103 INFO [train.py:450] Epoch 0, batch 3610, batch avg loss 0.5052, total avg loss: 0.4757, batch size: 41
2021-08-24 18:26:52,668 INFO [train.py:450] Epoch 0, batch 3620, batch avg loss 0.4570, total avg loss: 0.4650, batch size: 43
2021-08-24 18:27:00,127 INFO [train.py:450] Epoch 0, batch 3630, batch avg loss 0.4276, total avg loss: 0.4683, batch size: 37
2021-08-24 18:27:07,847 INFO [train.py:450] Epoch 0, batch 3640, batch avg loss 0.4824, total avg loss: 0.4653, batch size: 41
2021-08-24 18:27:15,154 INFO [train.py:450] Epoch 0, batch 3650, batch avg loss 0.4298, total avg loss: 0.4630, batch size: 41
2021-08-24 18:27:22,714 INFO [train.py:450] Epoch 0, batch 3660, batch avg loss 0.4822, total avg loss: 0.4615, batch size: 39
2021-08-24 18:27:29,984 INFO [train.py:450] Epoch 0, batch 3670, batch avg loss 0.5146, total avg loss: 0.4626, batch size: 40
2021-08-24 18:27:38,162 INFO [train.py:450] Epoch 0, batch 3680, batch avg loss 0.4389, total avg loss: 0.4655, batch size: 42
2021-08-24 18:27:45,493 INFO [train.py:450] Epoch 0, batch 3690, batch avg loss 0.5356, total avg loss: 0.4669, batch size: 38
2021-08-24 18:27:53,201 INFO [train.py:450] Epoch 0, batch 3700, batch avg loss 0.5103, total avg loss: 0.4667, batch size: 40
2021-08-24 18:28:00,917 INFO [train.py:450] Epoch 0, batch 3710, batch avg loss 0.5002, total avg loss: 0.4660, batch size: 41
2021-08-24 18:28:08,338 INFO [train.py:450] Epoch 0, batch 3720, batch avg loss 0.5263, total avg loss: 0.4652, batch size: 40
2021-08-24 18:28:15,857 INFO [train.py:450] Epoch 0, batch 3730, batch avg loss 0.5052, total avg loss: 0.4644, batch size: 40
2021-08-24 18:28:23,510 INFO [train.py:450] Epoch 0, batch 3740, batch avg loss 0.4694, total avg loss: 0.4647, batch size: 42
2021-08-24 18:28:31,457 INFO [train.py:450] Epoch 0, batch 3750, batch avg loss 0.4396, total avg loss: 0.4655, batch size: 38
2021-08-24 18:28:39,160 INFO [train.py:450] Epoch 0, batch 3760, batch avg loss 0.4583, total avg loss: 0.4654, batch size: 40
2021-08-24 18:28:46,406 INFO [train.py:450] Epoch 0, batch 3770, batch avg loss 0.4666, total avg loss: 0.4652, batch size: 40
2021-08-24 18:28:53,604 INFO [train.py:450] Epoch 0, batch 3780, batch avg loss 0.4428, total avg loss: 0.4649, batch size: 41
2021-08-24 18:29:01,503 INFO [train.py:450] Epoch 0, batch 3790, batch avg loss 0.5331, total avg loss: 0.4659, batch size: 40
2021-08-24 18:29:08,837 INFO [train.py:450] Epoch 0, batch 3800, batch avg loss 0.4788, total avg loss: 0.4659, batch size: 43
2021-08-24 18:29:15,896 INFO [train.py:450] Epoch 0, batch 3810, batch avg loss 0.4476, total avg loss: 0.4563, batch size: 38
2021-08-24 18:29:23,313 INFO [train.py:450] Epoch 0, batch 3820, batch avg loss 0.4472, total avg loss: 0.4659, batch size: 37
2021-08-24 18:29:30,748 INFO [train.py:450] Epoch 0, batch 3830, batch avg loss 0.4945, total avg loss: 0.4631, batch size: 36
2021-08-24 18:29:38,405 INFO [train.py:450] Epoch 0, batch 3840, batch avg loss 0.4594, total avg loss: 0.4657, batch size: 41
2021-08-24 18:29:46,104 INFO [train.py:450] Epoch 0, batch 3850, batch avg loss 0.4509, total avg loss: 0.4663, batch size: 42
2021-08-24 18:29:55,255 INFO [train.py:450] Epoch 0, batch 3860, batch avg loss 0.4765, total avg loss: 0.4638, batch size: 41
2021-08-24 18:30:03,063 INFO [train.py:450] Epoch 0, batch 3870, batch avg loss 0.5040, total avg loss: 0.4680, batch size: 36
2021-08-24 18:30:13,169 INFO [train.py:450] Epoch 0, batch 3880, batch avg loss 0.4462, total avg loss: 0.4671, batch size: 41
2021-08-24 18:30:20,995 INFO [train.py:450] Epoch 0, batch 3890, batch avg loss 0.4547, total avg loss: 0.4675, batch size: 43
2021-08-24 18:30:29,019 INFO [train.py:450] Epoch 0, batch 3900, batch avg loss 0.5020, total avg loss: 0.4665, batch size: 42
2021-08-24 18:30:36,545 INFO [train.py:450] Epoch 0, batch 3910, batch avg loss 0.5285, total avg loss: 0.4662, batch size: 41
2021-08-24 18:30:44,271 INFO [train.py:450] Epoch 0, batch 3920, batch avg loss 0.4269, total avg loss: 0.4670, batch size: 37
2021-08-24 18:30:51,960 INFO [train.py:450] Epoch 0, batch 3930, batch avg loss 0.4035, total avg loss: 0.4662, batch size: 40
2021-08-24 18:30:59,540 INFO [train.py:450] Epoch 0, batch 3940, batch avg loss 0.4845, total avg loss: 0.4669, batch size: 41
2021-08-24 18:31:06,584 INFO [train.py:450] Epoch 0, batch 3950, batch avg loss 0.4621, total avg loss: 0.4672, batch size: 39
2021-08-24 18:31:14,117 INFO [train.py:450] Epoch 0, batch 3960, batch avg loss 0.4197, total avg loss: 0.4675, batch size: 40
2021-08-24 18:31:21,693 INFO [train.py:450] Epoch 0, batch 3970, batch avg loss 0.5409, total avg loss: 0.4692, batch size: 45
2021-08-24 18:31:28,647 INFO [train.py:450] Epoch 0, batch 3980, batch avg loss 0.4566, total avg loss: 0.4693, batch size: 39
2021-08-24 18:31:36,249 INFO [train.py:450] Epoch 0, batch 3990, batch avg loss 0.4610, total avg loss: 0.4696, batch size: 41
2021-08-24 18:31:43,438 INFO [train.py:450] Epoch 0, batch 4000, batch avg loss 0.4709, total avg loss: 0.4689, batch size: 41
2021-08-24 18:32:20,885 INFO [train.py:482] Epoch 0, valid loss 0.3513, best valid loss: 0.3513 best valid epoch: 0
2021-08-24 18:32:27,058 INFO [train.py:450] Epoch 0, batch 4010, batch avg loss 0.4324, total avg loss: 0.4818, batch size: 39
2021-08-24 18:32:34,502 INFO [train.py:450] Epoch 0, batch 4020, batch avg loss 0.4895, total avg loss: 0.4683, batch size: 42
2021-08-24 18:32:42,022 INFO [train.py:450] Epoch 0, batch 4030, batch avg loss 0.3969, total avg loss: 0.4652, batch size: 37
2021-08-24 18:32:49,687 INFO [train.py:450] Epoch 0, batch 4040, batch avg loss 0.4614, total avg loss: 0.4657, batch size: 42
2021-08-24 18:32:56,910 INFO [train.py:450] Epoch 0, batch 4050, batch avg loss 0.5073, total avg loss: 0.4650, batch size: 41
2021-08-24 18:33:04,156 INFO [train.py:450] Epoch 0, batch 4060, batch avg loss 0.4174, total avg loss: 0.4624, batch size: 36
2021-08-24 18:33:12,236 INFO [train.py:450] Epoch 0, batch 4070, batch avg loss 0.4583, total avg loss: 0.4593, batch size: 41
2021-08-24 18:33:19,801 INFO [train.py:450] Epoch 0, batch 4080, batch avg loss 0.4192, total avg loss: 0.4600, batch size: 40
2021-08-24 18:33:27,563 INFO [train.py:450] Epoch 0, batch 4090, batch avg loss 0.4326, total avg loss: 0.4590, batch size: 41
2021-08-24 18:33:35,035 INFO [train.py:450] Epoch 0, batch 4100, batch avg loss 0.5261, total avg loss: 0.4578, batch size: 40
2021-08-24 18:33:42,031 INFO [train.py:450] Epoch 0, batch 4110, batch avg loss 0.4574, total avg loss: 0.4591, batch size: 38
2021-08-24 18:33:49,572 INFO [train.py:450] Epoch 0, batch 4120, batch avg loss 0.5077, total avg loss: 0.4589, batch size: 42
2021-08-24 18:33:57,130 INFO [train.py:450] Epoch 0, batch 4130, batch avg loss 0.4220, total avg loss: 0.4597, batch size: 37
2021-08-24 18:34:04,228 INFO [train.py:450] Epoch 0, batch 4140, batch avg loss 0.4034, total avg loss: 0.4597, batch size: 38
2021-08-24 18:34:11,824 INFO [train.py:450] Epoch 0, batch 4150, batch avg loss 0.4758, total avg loss: 0.4605, batch size: 42
2021-08-24 18:34:19,365 INFO [train.py:450] Epoch 0, batch 4160, batch avg loss 0.4407, total avg loss: 0.4602, batch size: 41
2021-08-24 18:34:26,741 INFO [train.py:450] Epoch 0, batch 4170, batch avg loss 0.4491, total avg loss: 0.4596, batch size: 37
2021-08-24 18:34:33,879 INFO [train.py:450] Epoch 0, batch 4180, batch avg loss 0.3930, total avg loss: 0.4592, batch size: 39
2021-08-24 18:34:41,964 INFO [train.py:450] Epoch 0, batch 4190, batch avg loss 0.4914, total avg loss: 0.4598, batch size: 39
2021-08-24 18:34:50,665 INFO [train.py:450] Epoch 0, batch 4200, batch avg loss 0.4602, total avg loss: 0.4597, batch size: 39
2021-08-24 18:34:59,555 INFO [train.py:450] Epoch 0, batch 4210, batch avg loss 0.4313, total avg loss: 0.4571, batch size: 36
2021-08-24 18:35:08,397 INFO [train.py:450] Epoch 0, batch 4220, batch avg loss 0.4733, total avg loss: 0.4629, batch size: 38
2021-08-24 18:35:15,755 INFO [train.py:450] Epoch 0, batch 4230, batch avg loss 0.4343, total avg loss: 0.4670, batch size: 41
2021-08-24 18:35:23,009 INFO [train.py:450] Epoch 0, batch 4240, batch avg loss 0.4818, total avg loss: 0.4659, batch size: 37
2021-08-24 18:35:30,677 INFO [train.py:450] Epoch 0, batch 4250, batch avg loss 0.4521, total avg loss: 0.4657, batch size: 38
2021-08-24 18:35:38,184 INFO [train.py:450] Epoch 0, batch 4260, batch avg loss 0.4267, total avg loss: 0.4618, batch size: 40
2021-08-24 18:35:45,306 INFO [train.py:450] Epoch 0, batch 4270, batch avg loss 0.4837, total avg loss: 0.4611, batch size: 40
2021-08-24 18:35:52,667 INFO [train.py:450] Epoch 0, batch 4280, batch avg loss 0.5237, total avg loss: 0.4620, batch size: 43
2021-08-24 18:35:59,919 INFO [train.py:450] Epoch 0, batch 4290, batch avg loss 0.4245, total avg loss: 0.4601, batch size: 40
2021-08-24 18:36:07,083 INFO [train.py:450] Epoch 0, batch 4300, batch avg loss 0.4657, total avg loss: 0.4596, batch size: 37
2021-08-24 18:36:14,958 INFO [train.py:450] Epoch 0, batch 4310, batch avg loss 0.4986, total avg loss: 0.4586, batch size: 39
2021-08-24 18:36:22,353 INFO [train.py:450] Epoch 0, batch 4320, batch avg loss 0.4884, total avg loss: 0.4591, batch size: 42
2021-08-24 18:36:29,671 INFO [train.py:450] Epoch 0, batch 4330, batch avg loss 0.4320, total avg loss: 0.4588, batch size: 40
2021-08-24 18:36:36,206 INFO [train.py:450] Epoch 0, batch 4340, batch avg loss 0.5098, total avg loss: 0.4585, batch size: 40
2021-08-24 18:36:43,721 INFO [train.py:450] Epoch 0, batch 4350, batch avg loss 0.4422, total avg loss: 0.4585, batch size: 40
2021-08-24 18:36:51,235 INFO [train.py:450] Epoch 0, batch 4360, batch avg loss 0.4222, total avg loss: 0.4576, batch size: 39
2021-08-24 18:36:58,140 INFO [train.py:450] Epoch 0, batch 4370, batch avg loss 0.4394, total avg loss: 0.4580, batch size: 36
2021-08-24 18:37:05,340 INFO [train.py:450] Epoch 0, batch 4380, batch avg loss 0.4219, total avg loss: 0.4582, batch size: 41
2021-08-24 18:37:07,112 WARNING [cut.py:1694] To perform mix, energy must be non-zero and non-negative (got 0.0).  MonoCut with id "73ab4477-b7cc-8f45-4043-abfcb8f9d25a" will not be mixed in.
2021-08-24 18:37:12,679 INFO [train.py:450] Epoch 0, batch 4390, batch avg loss 0.5217, total avg loss: 0.4577, batch size: 36
2021-08-24 18:37:19,997 INFO [train.py:450] Epoch 0, batch 4400, batch avg loss 0.4502, total avg loss: 0.4586, batch size: 39
2021-08-24 18:37:27,457 INFO [train.py:450] Epoch 0, batch 4410, batch avg loss 0.4248, total avg loss: 0.4560, batch size: 38
2021-08-24 18:37:34,782 INFO [train.py:450] Epoch 0, batch 4420, batch avg loss 0.4133, total avg loss: 0.4463, batch size: 35
2021-08-24 18:37:42,432 INFO [train.py:450] Epoch 0, batch 4430, batch avg loss 0.5269, total avg loss: 0.4540, batch size: 41
2021-08-24 18:37:49,885 INFO [train.py:450] Epoch 0, batch 4440, batch avg loss 0.4599, total avg loss: 0.4561, batch size: 38
2021-08-24 18:37:57,333 INFO [train.py:450] Epoch 0, batch 4450, batch avg loss 0.4711, total avg loss: 0.4579, batch size: 39
2021-08-24 18:38:04,703 INFO [train.py:450] Epoch 0, batch 4460, batch avg loss 0.4557, total avg loss: 0.4589, batch size: 40
2021-08-24 18:38:12,160 INFO [train.py:450] Epoch 0, batch 4470, batch avg loss 0.4567, total avg loss: 0.4585, batch size: 40
2021-08-24 18:38:20,060 INFO [train.py:450] Epoch 0, batch 4480, batch avg loss 0.4339, total avg loss: 0.4590, batch size: 37
2021-08-24 18:38:27,171 INFO [train.py:450] Epoch 0, batch 4490, batch avg loss 0.4194, total avg loss: 0.4579, batch size: 41
2021-08-24 18:38:34,727 INFO [train.py:450] Epoch 0, batch 4500, batch avg loss 0.4901, total avg loss: 0.4570, batch size: 39
2021-08-24 18:38:42,312 INFO [train.py:450] Epoch 0, batch 4510, batch avg loss 0.4456, total avg loss: 0.4568, batch size: 42
2021-08-24 18:38:49,610 INFO [train.py:450] Epoch 0, batch 4520, batch avg loss 0.4298, total avg loss: 0.4565, batch size: 41
2021-08-24 18:38:56,911 INFO [train.py:450] Epoch 0, batch 4530, batch avg loss 0.4522, total avg loss: 0.4563, batch size: 41
2021-08-24 18:39:03,966 INFO [train.py:450] Epoch 0, batch 4540, batch avg loss 0.4861, total avg loss: 0.4567, batch size: 42
2021-08-24 18:39:11,849 INFO [train.py:450] Epoch 0, batch 4550, batch avg loss 0.4044, total avg loss: 0.4567, batch size: 38
2021-08-24 18:39:19,745 INFO [train.py:450] Epoch 0, batch 4560, batch avg loss 0.4286, total avg loss: 0.4565, batch size: 40
2021-08-24 18:39:28,101 INFO [train.py:450] Epoch 0, batch 4570, batch avg loss 0.4611, total avg loss: 0.4567, batch size: 40
2021-08-24 18:39:35,929 INFO [train.py:450] Epoch 0, batch 4580, batch avg loss 0.4359, total avg loss: 0.4557, batch size: 39
2021-08-24 18:39:44,052 INFO [train.py:450] Epoch 0, batch 4590, batch avg loss 0.4156, total avg loss: 0.4553, batch size: 40
2021-08-24 18:39:54,328 INFO [train.py:450] Epoch 0, batch 4600, batch avg loss 0.5279, total avg loss: 0.4556, batch size: 41
2021-08-24 18:40:04,656 INFO [train.py:450] Epoch 0, batch 4610, batch avg loss 0.4123, total avg loss: 0.4349, batch size: 40
2021-08-24 18:40:14,780 INFO [train.py:450] Epoch 0, batch 4620, batch avg loss 0.4694, total avg loss: 0.4444, batch size: 42
2021-08-24 18:40:23,389 INFO [train.py:450] Epoch 0, batch 4630, batch avg loss 0.4576, total avg loss: 0.4429, batch size: 44
2021-08-24 18:40:31,417 INFO [train.py:450] Epoch 0, batch 4640, batch avg loss 0.4906, total avg loss: 0.4444, batch size: 40
2021-08-24 18:40:39,511 INFO [train.py:450] Epoch 0, batch 4650, batch avg loss 0.4625, total avg loss: 0.4437, batch size: 36
2021-08-24 18:40:47,758 INFO [train.py:450] Epoch 0, batch 4660, batch avg loss 0.3848, total avg loss: 0.4455, batch size: 38
2021-08-24 18:40:56,875 INFO [train.py:450] Epoch 0, batch 4670, batch avg loss 0.4550, total avg loss: 0.4480, batch size: 40
2021-08-24 18:41:05,022 INFO [train.py:450] Epoch 0, batch 4680, batch avg loss 0.4576, total avg loss: 0.4483, batch size: 40
2021-08-24 18:41:13,308 INFO [train.py:450] Epoch 0, batch 4690, batch avg loss 0.4949, total avg loss: 0.4469, batch size: 42
2021-08-24 18:41:21,263 INFO [train.py:450] Epoch 0, batch 4700, batch avg loss 0.4788, total avg loss: 0.4480, batch size: 39
2021-08-24 18:41:29,177 INFO [train.py:450] Epoch 0, batch 4710, batch avg loss 0.5135, total avg loss: 0.4493, batch size: 35
2021-08-24 18:41:37,283 INFO [train.py:450] Epoch 0, batch 4720, batch avg loss 0.4204, total avg loss: 0.4495, batch size: 38
2021-08-24 18:41:45,148 INFO [train.py:450] Epoch 0, batch 4730, batch avg loss 0.4637, total avg loss: 0.4497, batch size: 38
2021-08-24 18:41:53,054 INFO [train.py:450] Epoch 0, batch 4740, batch avg loss 0.4774, total avg loss: 0.4491, batch size: 40
2021-08-24 18:42:00,914 INFO [train.py:450] Epoch 0, batch 4750, batch avg loss 0.4135, total avg loss: 0.4477, batch size: 39
2021-08-24 18:42:09,004 INFO [train.py:450] Epoch 0, batch 4760, batch avg loss 0.4037, total avg loss: 0.4476, batch size: 41
2021-08-24 18:42:17,100 INFO [train.py:450] Epoch 0, batch 4770, batch avg loss 0.4354, total avg loss: 0.4463, batch size: 40
2021-08-24 18:42:25,070 INFO [train.py:450] Epoch 0, batch 4780, batch avg loss 0.4969, total avg loss: 0.4459, batch size: 43
2021-08-24 18:42:32,714 INFO [train.py:450] Epoch 0, batch 4790, batch avg loss 0.4294, total avg loss: 0.4457, batch size: 44
2021-08-24 18:42:39,740 INFO [train.py:450] Epoch 0, batch 4800, batch avg loss 0.4162, total avg loss: 0.4446, batch size: 40
2021-08-24 18:42:47,641 INFO [train.py:450] Epoch 0, batch 4810, batch avg loss 0.4778, total avg loss: 0.4385, batch size: 41
2021-08-24 18:42:55,652 INFO [train.py:450] Epoch 0, batch 4820, batch avg loss 0.5025, total avg loss: 0.4366, batch size: 35
2021-08-24 18:43:03,130 INFO [train.py:450] Epoch 0, batch 4830, batch avg loss 0.4712, total avg loss: 0.4356, batch size: 38
2021-08-24 18:43:10,689 INFO [train.py:450] Epoch 0, batch 4840, batch avg loss 0.3942, total avg loss: 0.4314, batch size: 42
2021-08-24 18:43:18,723 INFO [train.py:450] Epoch 0, batch 4850, batch avg loss 0.4575, total avg loss: 0.4359, batch size: 39
2021-08-24 18:43:26,058 INFO [train.py:450] Epoch 0, batch 4860, batch avg loss 0.3793, total avg loss: 0.4344, batch size: 36
2021-08-24 18:43:33,438 INFO [train.py:450] Epoch 0, batch 4870, batch avg loss 0.3942, total avg loss: 0.4370, batch size: 42
2021-08-24 18:43:41,231 INFO [train.py:450] Epoch 0, batch 4880, batch avg loss 0.4241, total avg loss: 0.4369, batch size: 40
2021-08-24 18:43:49,448 INFO [train.py:450] Epoch 0, batch 4890, batch avg loss 0.4786, total avg loss: 0.4383, batch size: 37
2021-08-24 18:43:56,867 INFO [train.py:450] Epoch 0, batch 4900, batch avg loss 0.4088, total avg loss: 0.4378, batch size: 40
2021-08-24 18:44:04,575 INFO [train.py:450] Epoch 0, batch 4910, batch avg loss 0.4221, total avg loss: 0.4386, batch size: 42
2021-08-24 18:44:11,771 INFO [train.py:450] Epoch 0, batch 4920, batch avg loss 0.4661, total avg loss: 0.4390, batch size: 38
2021-08-24 18:44:19,189 INFO [train.py:450] Epoch 0, batch 4930, batch avg loss 0.5092, total avg loss: 0.4401, batch size: 38
2021-08-24 18:44:27,061 INFO [train.py:450] Epoch 0, batch 4940, batch avg loss 0.3948, total avg loss: 0.4410, batch size: 42
2021-08-24 18:44:34,477 INFO [train.py:450] Epoch 0, batch 4950, batch avg loss 0.3779, total avg loss: 0.4406, batch size: 38
2021-08-24 18:44:42,193 INFO [train.py:450] Epoch 0, batch 4960, batch avg loss 0.3894, total avg loss: 0.4402, batch size: 37
2021-08-24 18:44:51,384 INFO [train.py:450] Epoch 0, batch 4970, batch avg loss 0.4773, total avg loss: 0.4408, batch size: 40
2021-08-24 18:44:58,959 INFO [train.py:450] Epoch 0, batch 4980, batch avg loss 0.4652, total avg loss: 0.4412, batch size: 39
2021-08-24 18:45:10,028 INFO [train.py:450] Epoch 0, batch 4990, batch avg loss 0.4103, total avg loss: 0.4410, batch size: 42
2021-08-24 18:45:17,681 INFO [train.py:450] Epoch 0, batch 5000, batch avg loss 0.3881, total avg loss: 0.4413, batch size: 39
2021-08-24 18:45:56,248 INFO [train.py:482] Epoch 0, valid loss 0.3312, best valid loss: 0.3312 best valid epoch: 0
2021-08-24 18:46:02,464 INFO [train.py:450] Epoch 0, batch 5010, batch avg loss 0.4256, total avg loss: 0.4380, batch size: 41
2021-08-24 18:46:10,509 INFO [train.py:450] Epoch 0, batch 5020, batch avg loss 0.4477, total avg loss: 0.4452, batch size: 40
2021-08-24 18:46:18,423 INFO [train.py:450] Epoch 0, batch 5030, batch avg loss 0.3785, total avg loss: 0.4530, batch size: 41
2021-08-24 18:46:26,194 INFO [train.py:450] Epoch 0, batch 5040, batch avg loss 0.4641, total avg loss: 0.4491, batch size: 42
2021-08-24 18:46:34,260 INFO [train.py:450] Epoch 0, batch 5050, batch avg loss 0.4475, total avg loss: 0.4491, batch size: 42
2021-08-24 18:46:41,706 INFO [train.py:450] Epoch 0, batch 5060, batch avg loss 0.4386, total avg loss: 0.4508, batch size: 40
2021-08-24 18:46:49,276 INFO [train.py:450] Epoch 0, batch 5070, batch avg loss 0.4271, total avg loss: 0.4485, batch size: 43
2021-08-24 18:46:56,236 INFO [train.py:450] Epoch 0, batch 5080, batch avg loss 0.4392, total avg loss: 0.4485, batch size: 38
2021-08-24 18:47:03,591 INFO [train.py:450] Epoch 0, batch 5090, batch avg loss 0.4830, total avg loss: 0.4498, batch size: 38
2021-08-24 18:47:11,551 INFO [train.py:450] Epoch 0, batch 5100, batch avg loss 0.4442, total avg loss: 0.4483, batch size: 38
2021-08-24 18:47:19,012 INFO [train.py:450] Epoch 0, batch 5110, batch avg loss 0.4041, total avg loss: 0.4469, batch size: 38
2021-08-24 18:47:26,550 INFO [train.py:450] Epoch 0, batch 5120, batch avg loss 0.4020, total avg loss: 0.4511, batch size: 43
2021-08-24 18:47:34,081 INFO [train.py:450] Epoch 0, batch 5130, batch avg loss 0.3906, total avg loss: 0.4494, batch size: 38
2021-08-24 18:47:41,515 INFO [train.py:450] Epoch 0, batch 5140, batch avg loss 0.4505, total avg loss: 0.4479, batch size: 38
2021-08-24 18:47:49,264 INFO [train.py:450] Epoch 0, batch 5150, batch avg loss 0.5146, total avg loss: 0.4480, batch size: 41
2021-08-24 18:47:56,670 INFO [train.py:450] Epoch 0, batch 5160, batch avg loss 0.4764, total avg loss: 0.4482, batch size: 40
2021-08-24 18:48:03,905 INFO [train.py:450] Epoch 0, batch 5170, batch avg loss 0.4016, total avg loss: 0.4478, batch size: 37
2021-08-24 18:48:11,124 INFO [train.py:450] Epoch 0, batch 5180, batch avg loss 0.3862, total avg loss: 0.4463, batch size: 37
2021-08-24 18:48:18,465 INFO [train.py:450] Epoch 0, batch 5190, batch avg loss 0.3904, total avg loss: 0.4451, batch size: 38
2021-08-24 18:48:25,574 INFO [train.py:450] Epoch 0, batch 5200, batch avg loss 0.4244, total avg loss: 0.4444, batch size: 41
2021-08-24 18:48:32,763 INFO [train.py:450] Epoch 0, batch 5210, batch avg loss 0.4394, total avg loss: 0.4502, batch size: 44
2021-08-24 18:48:39,856 INFO [train.py:450] Epoch 0, batch 5220, batch avg loss 0.4828, total avg loss: 0.4472, batch size: 41
2021-08-24 18:48:47,087 INFO [train.py:450] Epoch 0, batch 5230, batch avg loss 0.4438, total avg loss: 0.4488, batch size: 37
2021-08-24 18:48:54,376 INFO [train.py:450] Epoch 0, batch 5240, batch avg loss 0.4417, total avg loss: 0.4485, batch size: 38
2021-08-24 18:49:01,319 INFO [train.py:450] Epoch 0, batch 5250, batch avg loss 0.4588, total avg loss: 0.4507, batch size: 38
2021-08-24 18:49:08,620 INFO [train.py:450] Epoch 0, batch 5260, batch avg loss 0.4207, total avg loss: 0.4494, batch size: 36
2021-08-24 18:49:16,035 INFO [train.py:450] Epoch 0, batch 5270, batch avg loss 0.4370, total avg loss: 0.4509, batch size: 42
2021-08-24 18:49:23,309 INFO [train.py:450] Epoch 0, batch 5280, batch avg loss 0.4643, total avg loss: 0.4501, batch size: 38
2021-08-24 18:49:30,597 INFO [train.py:450] Epoch 0, batch 5290, batch avg loss 0.4280, total avg loss: 0.4482, batch size: 41
2021-08-24 18:49:37,949 INFO [train.py:450] Epoch 0, batch 5300, batch avg loss 0.4296, total avg loss: 0.4481, batch size: 40
2021-08-24 18:49:38,433 WARNING [cut.py:1694] To perform mix, energy must be non-zero and non-negative (got 0.0).  MonoCut with id "d59c717a-feba-0ed7-c53d-c0072597db23" will not be mixed in.
2021-08-24 18:49:45,476 INFO [train.py:450] Epoch 0, batch 5310, batch avg loss 0.4625, total avg loss: 0.4480, batch size: 41
2021-08-24 18:49:52,320 INFO [train.py:450] Epoch 0, batch 5320, batch avg loss 0.4209, total avg loss: 0.4475, batch size: 39
2021-08-24 18:50:01,032 INFO [train.py:450] Epoch 0, batch 5330, batch avg loss 0.4017, total avg loss: 0.4467, batch size: 39
2021-08-24 18:50:08,053 INFO [train.py:450] Epoch 0, batch 5340, batch avg loss 0.4174, total avg loss: 0.4452, batch size: 42
2021-08-24 18:50:18,573 INFO [train.py:450] Epoch 0, batch 5350, batch avg loss 0.4813, total avg loss: 0.4454, batch size: 42
2021-08-24 18:50:26,195 INFO [train.py:450] Epoch 0, batch 5360, batch avg loss 0.4252, total avg loss: 0.4448, batch size: 38
2021-08-24 18:50:34,178 INFO [train.py:450] Epoch 0, batch 5370, batch avg loss 0.5154, total avg loss: 0.4450, batch size: 38
2021-08-24 18:50:40,911 INFO [train.py:450] Epoch 0, batch 5380, batch avg loss 0.4515, total avg loss: 0.4450, batch size: 37
2021-08-24 18:50:48,065 INFO [train.py:450] Epoch 0, batch 5390, batch avg loss 0.4493, total avg loss: 0.4445, batch size: 38
2021-08-24 18:50:55,162 INFO [train.py:450] Epoch 0, batch 5400, batch avg loss 0.4092, total avg loss: 0.4439, batch size: 45
2021-08-24 18:51:02,071 INFO [train.py:450] Epoch 0, batch 5410, batch avg loss 0.4362, total avg loss: 0.4408, batch size: 41
2021-08-24 18:51:09,523 INFO [train.py:450] Epoch 0, batch 5420, batch avg loss 0.3932, total avg loss: 0.4395, batch size: 41
2021-08-24 18:51:16,660 INFO [train.py:450] Epoch 0, batch 5430, batch avg loss 0.3785, total avg loss: 0.4446, batch size: 40
2021-08-24 18:51:24,818 INFO [train.py:450] Epoch 0, batch 5440, batch avg loss 0.3880, total avg loss: 0.4371, batch size: 36
2021-08-24 18:51:32,046 INFO [train.py:450] Epoch 0, batch 5450, batch avg loss 0.4558, total avg loss: 0.4370, batch size: 41
2021-08-24 18:51:39,041 INFO [train.py:450] Epoch 0, batch 5460, batch avg loss 0.4264, total avg loss: 0.4380, batch size: 41
2021-08-24 18:51:45,982 INFO [train.py:450] Epoch 0, batch 5470, batch avg loss 0.4138, total avg loss: 0.4390, batch size: 41
2021-08-24 18:51:53,182 INFO [train.py:450] Epoch 0, batch 5480, batch avg loss 0.4746, total avg loss: 0.4391, batch size: 38
2021-08-24 18:52:00,828 INFO [train.py:450] Epoch 0, batch 5490, batch avg loss 0.4268, total avg loss: 0.4379, batch size: 41
2021-08-24 18:52:08,261 INFO [train.py:450] Epoch 0, batch 5500, batch avg loss 0.3985, total avg loss: 0.4370, batch size: 40
2021-08-24 18:52:15,085 INFO [train.py:450] Epoch 0, batch 5510, batch avg loss 0.4759, total avg loss: 0.4376, batch size: 40
2021-08-24 18:52:22,193 INFO [train.py:450] Epoch 0, batch 5520, batch avg loss 0.4286, total avg loss: 0.4383, batch size: 40
2021-08-24 18:52:29,383 INFO [train.py:450] Epoch 0, batch 5530, batch avg loss 0.4179, total avg loss: 0.4391, batch size: 36
2021-08-24 18:52:37,215 INFO [train.py:450] Epoch 0, batch 5540, batch avg loss 0.3974, total avg loss: 0.4385, batch size: 41
2021-08-24 18:52:44,721 INFO [train.py:450] Epoch 0, batch 5550, batch avg loss 0.4295, total avg loss: 0.4387, batch size: 43
2021-08-24 18:52:52,269 INFO [train.py:450] Epoch 0, batch 5560, batch avg loss 0.4139, total avg loss: 0.4395, batch size: 42
2021-08-24 18:52:59,810 INFO [train.py:450] Epoch 0, batch 5570, batch avg loss 0.5002, total avg loss: 0.4406, batch size: 41
2021-08-24 18:53:07,538 INFO [train.py:450] Epoch 0, batch 5580, batch avg loss 0.4126, total avg loss: 0.4407, batch size: 42
2021-08-24 18:53:14,871 INFO [train.py:450] Epoch 0, batch 5590, batch avg loss 0.4030, total avg loss: 0.4408, batch size: 41
2021-08-24 18:53:22,140 INFO [train.py:450] Epoch 0, batch 5600, batch avg loss 0.3988, total avg loss: 0.4414, batch size: 40
2021-08-24 18:53:29,727 INFO [train.py:450] Epoch 0, batch 5610, batch avg loss 0.5333, total avg loss: 0.4506, batch size: 43
2021-08-24 18:53:36,837 INFO [train.py:450] Epoch 0, batch 5620, batch avg loss 0.4776, total avg loss: 0.4480, batch size: 41
2021-08-24 18:53:44,040 INFO [train.py:450] Epoch 0, batch 5630, batch avg loss 0.4582, total avg loss: 0.4431, batch size: 40
2021-08-24 18:53:52,180 INFO [train.py:450] Epoch 0, batch 5640, batch avg loss 0.4974, total avg loss: 0.4444, batch size: 39
2021-08-24 18:54:00,406 INFO [train.py:450] Epoch 0, batch 5650, batch avg loss 0.5521, total avg loss: 0.4454, batch size: 41
2021-08-24 18:54:07,870 INFO [train.py:450] Epoch 0, batch 5660, batch avg loss 0.4364, total avg loss: 0.4466, batch size: 40
2021-08-24 18:54:15,645 INFO [train.py:450] Epoch 0, batch 5670, batch avg loss 0.3772, total avg loss: 0.4437, batch size: 36
2021-08-24 18:54:23,233 INFO [train.py:450] Epoch 0, batch 5680, batch avg loss 0.4111, total avg loss: 0.4421, batch size: 36
2021-08-24 18:54:30,784 INFO [train.py:450] Epoch 0, batch 5690, batch avg loss 0.4200, total avg loss: 0.4415, batch size: 41
2021-08-24 18:54:38,522 INFO [train.py:450] Epoch 0, batch 5700, batch avg loss 0.4702, total avg loss: 0.4406, batch size: 40
2021-08-24 18:54:45,818 INFO [train.py:450] Epoch 0, batch 5710, batch avg loss 0.4236, total avg loss: 0.4404, batch size: 37
2021-08-24 18:54:52,959 INFO [train.py:450] Epoch 0, batch 5720, batch avg loss 0.3918, total avg loss: 0.4410, batch size: 38
2021-08-24 18:55:00,796 INFO [train.py:450] Epoch 0, batch 5730, batch avg loss 0.4292, total avg loss: 0.4400, batch size: 39
2021-08-24 18:55:09,420 INFO [train.py:450] Epoch 0, batch 5740, batch avg loss 0.4064, total avg loss: 0.4391, batch size: 37
2021-08-24 18:55:16,931 INFO [train.py:450] Epoch 0, batch 5750, batch avg loss 0.4673, total avg loss: 0.4390, batch size: 39
2021-08-24 18:55:27,748 INFO [train.py:450] Epoch 0, batch 5760, batch avg loss 0.4799, total avg loss: 0.4384, batch size: 40
2021-08-24 18:55:34,637 INFO [train.py:450] Epoch 0, batch 5770, batch avg loss 0.4706, total avg loss: 0.4373, batch size: 38
2021-08-24 18:55:41,728 INFO [train.py:450] Epoch 0, batch 5780, batch avg loss 0.4619, total avg loss: 0.4374, batch size: 39
2021-08-24 18:55:49,124 INFO [train.py:450] Epoch 0, batch 5790, batch avg loss 0.4501, total avg loss: 0.4375, batch size: 40
2021-08-24 18:55:57,424 INFO [train.py:450] Epoch 0, batch 5800, batch avg loss 0.4305, total avg loss: 0.4376, batch size: 39
2021-08-24 18:56:04,803 INFO [train.py:450] Epoch 0, batch 5810, batch avg loss 0.4417, total avg loss: 0.4336, batch size: 40
2021-08-24 18:56:12,358 INFO [train.py:450] Epoch 0, batch 5820, batch avg loss 0.4164, total avg loss: 0.4448, batch size: 43
2021-08-24 18:56:20,093 INFO [train.py:450] Epoch 0, batch 5830, batch avg loss 0.3735, total avg loss: 0.4384, batch size: 42
2021-08-24 18:56:27,075 INFO [train.py:450] Epoch 0, batch 5840, batch avg loss 0.4489, total avg loss: 0.4402, batch size: 40
2021-08-24 18:56:34,609 INFO [train.py:450] Epoch 0, batch 5850, batch avg loss 0.4304, total avg loss: 0.4366, batch size: 38
2021-08-24 18:56:41,526 INFO [train.py:450] Epoch 0, batch 5860, batch avg loss 0.4358, total avg loss: 0.4364, batch size: 44
2021-08-24 18:56:48,472 INFO [train.py:450] Epoch 0, batch 5870, batch avg loss 0.4274, total avg loss: 0.4378, batch size: 38
2021-08-24 18:56:55,420 INFO [train.py:450] Epoch 0, batch 5880, batch avg loss 0.4141, total avg loss: 0.4373, batch size: 43
2021-08-24 18:57:02,632 INFO [train.py:450] Epoch 0, batch 5890, batch avg loss 0.3917, total avg loss: 0.4383, batch size: 40
2021-08-24 18:57:10,170 INFO [train.py:450] Epoch 0, batch 5900, batch avg loss 0.4259, total avg loss: 0.4388, batch size: 43
2021-08-24 18:57:17,539 INFO [train.py:450] Epoch 0, batch 5910, batch avg loss 0.4973, total avg loss: 0.4386, batch size: 44
2021-08-24 18:57:25,145 INFO [train.py:450] Epoch 0, batch 5920, batch avg loss 0.4387, total avg loss: 0.4377, batch size: 39
2021-08-24 18:57:32,549 INFO [train.py:450] Epoch 0, batch 5930, batch avg loss 0.4602, total avg loss: 0.4382, batch size: 40
2021-08-24 18:57:37,923 WARNING [cut.py:1694] To perform mix, energy must be non-zero and non-negative (got 0.0).  MonoCut with id "8196ab58-e5ef-a70b-b574-33dcb48db840" will not be mixed in.
2021-08-24 18:57:40,081 INFO [train.py:450] Epoch 0, batch 5940, batch avg loss 0.3763, total avg loss: 0.4380, batch size: 36
2021-08-24 18:57:47,208 INFO [train.py:450] Epoch 0, batch 5950, batch avg loss 0.5004, total avg loss: 0.4373, batch size: 37
2021-08-24 18:57:54,625 INFO [train.py:450] Epoch 0, batch 5960, batch avg loss 0.4590, total avg loss: 0.4366, batch size: 42
2021-08-24 18:58:01,902 INFO [train.py:450] Epoch 0, batch 5970, batch avg loss 0.4081, total avg loss: 0.4360, batch size: 41
2021-08-24 18:58:09,202 INFO [train.py:450] Epoch 0, batch 5980, batch avg loss 0.3895, total avg loss: 0.4359, batch size: 39
2021-08-24 18:58:17,263 INFO [train.py:450] Epoch 0, batch 5990, batch avg loss 0.3823, total avg loss: 0.4358, batch size: 40
2021-08-24 18:58:24,683 INFO [train.py:450] Epoch 0, batch 6000, batch avg loss 0.3969, total avg loss: 0.4349, batch size: 37
2021-08-24 18:59:02,537 INFO [train.py:482] Epoch 0, valid loss 0.3209, best valid loss: 0.3209 best valid epoch: 0
2021-08-24 18:59:08,432 INFO [train.py:450] Epoch 0, batch 6010, batch avg loss 0.4318, total avg loss: 0.4487, batch size: 41
2021-08-24 18:59:15,678 INFO [train.py:450] Epoch 0, batch 6020, batch avg loss 0.4505, total avg loss: 0.4475, batch size: 41
2021-08-24 18:59:22,643 INFO [train.py:450] Epoch 0, batch 6030, batch avg loss 0.4270, total avg loss: 0.4421, batch size: 40
2021-08-24 18:59:30,613 INFO [train.py:450] Epoch 0, batch 6040, batch avg loss 0.4023, total avg loss: 0.4399, batch size: 37
2021-08-24 18:59:37,926 INFO [train.py:450] Epoch 0, batch 6050, batch avg loss 0.4199, total avg loss: 0.4332, batch size: 42
2021-08-24 18:59:45,382 INFO [train.py:450] Epoch 0, batch 6060, batch avg loss 0.3825, total avg loss: 0.4354, batch size: 41
2021-08-24 18:59:52,898 INFO [train.py:450] Epoch 0, batch 6070, batch avg loss 0.4799, total avg loss: 0.4360, batch size: 39
2021-08-24 19:00:00,459 INFO [train.py:450] Epoch 0, batch 6080, batch avg loss 0.4311, total avg loss: 0.4374, batch size: 39
2021-08-24 19:00:07,830 INFO [train.py:450] Epoch 0, batch 6090, batch avg loss 0.4218, total avg loss: 0.4375, batch size: 40
2021-08-24 19:00:15,426 INFO [train.py:450] Epoch 0, batch 6100, batch avg loss 0.4588, total avg loss: 0.4386, batch size: 37
2021-08-24 19:00:22,592 INFO [train.py:450] Epoch 0, batch 6110, batch avg loss 0.3976, total avg loss: 0.4373, batch size: 40
2021-08-24 19:00:30,768 INFO [train.py:450] Epoch 0, batch 6120, batch avg loss 0.4212, total avg loss: 0.4373, batch size: 39
2021-08-24 19:00:40,008 INFO [train.py:450] Epoch 0, batch 6130, batch avg loss 0.4442, total avg loss: 0.4367, batch size: 39
2021-08-24 19:00:49,324 INFO [train.py:450] Epoch 0, batch 6140, batch avg loss 0.4836, total avg loss: 0.4368, batch size: 40
2021-08-24 19:00:56,770 INFO [train.py:450] Epoch 0, batch 6150, batch avg loss 0.4000, total avg loss: 0.4361, batch size: 40
2021-08-24 19:01:04,711 INFO [train.py:450] Epoch 0, batch 6160, batch avg loss 0.4239, total avg loss: 0.4350, batch size: 42
2021-08-24 19:01:12,152 INFO [train.py:450] Epoch 0, batch 6170, batch avg loss 0.4500, total avg loss: 0.4340, batch size: 39
2021-08-24 19:01:19,794 INFO [train.py:450] Epoch 0, batch 6180, batch avg loss 0.4402, total avg loss: 0.4338, batch size: 41
2021-08-24 19:01:26,696 INFO [train.py:450] Epoch 0, batch 6190, batch avg loss 0.4079, total avg loss: 0.4327, batch size: 38
2021-08-24 19:01:33,879 INFO [train.py:450] Epoch 0, batch 6200, batch avg loss 0.3928, total avg loss: 0.4313, batch size: 39
2021-08-24 19:01:41,150 INFO [train.py:450] Epoch 0, batch 6210, batch avg loss 0.3823, total avg loss: 0.4346, batch size: 40
2021-08-24 19:01:48,043 INFO [train.py:450] Epoch 0, batch 6220, batch avg loss 0.4722, total avg loss: 0.4370, batch size: 45
2021-08-24 19:01:55,863 INFO [train.py:450] Epoch 0, batch 6230, batch avg loss 0.4182, total avg loss: 0.4349, batch size: 41
2021-08-24 19:02:03,088 INFO [train.py:450] Epoch 0, batch 6240, batch avg loss 0.4815, total avg loss: 0.4364, batch size: 40
2021-08-24 19:02:10,495 INFO [train.py:450] Epoch 0, batch 6250, batch avg loss 0.3704, total avg loss: 0.4349, batch size: 40
2021-08-24 19:02:17,991 INFO [train.py:450] Epoch 0, batch 6260, batch avg loss 0.4001, total avg loss: 0.4344, batch size: 39
2021-08-24 19:02:25,863 INFO [train.py:450] Epoch 0, batch 6270, batch avg loss 0.4568, total avg loss: 0.4348, batch size: 39
2021-08-24 19:02:33,677 INFO [train.py:450] Epoch 0, batch 6280, batch avg loss 0.4750, total avg loss: 0.4325, batch size: 38
2021-08-24 19:02:40,856 INFO [train.py:450] Epoch 0, batch 6290, batch avg loss 0.4533, total avg loss: 0.4295, batch size: 37
2021-08-24 19:02:48,744 INFO [train.py:450] Epoch 0, batch 6300, batch avg loss 0.4872, total avg loss: 0.4306, batch size: 41
2021-08-24 19:02:56,319 INFO [train.py:450] Epoch 0, batch 6310, batch avg loss 0.3830, total avg loss: 0.4301, batch size: 39
2021-08-24 19:03:03,567 INFO [train.py:450] Epoch 0, batch 6320, batch avg loss 0.4502, total avg loss: 0.4310, batch size: 39
2021-08-24 19:03:10,765 INFO [train.py:450] Epoch 0, batch 6330, batch avg loss 0.4632, total avg loss: 0.4315, batch size: 39
2021-08-24 19:03:18,055 INFO [train.py:450] Epoch 0, batch 6340, batch avg loss 0.4487, total avg loss: 0.4316, batch size: 40
2021-08-24 19:03:25,021 INFO [train.py:450] Epoch 0, batch 6350, batch avg loss 0.4819, total avg loss: 0.4311, batch size: 39
2021-08-24 19:03:28,941 WARNING [cut.py:1694] To perform mix, energy must be non-zero and non-negative (got 0.0).  MonoCut with id "59146992-bf53-dbdd-a69b-44cb438890cc" will not be mixed in.
2021-08-24 19:03:32,611 INFO [train.py:450] Epoch 0, batch 6360, batch avg loss 0.4428, total avg loss: 0.4310, batch size: 41
2021-08-24 19:03:40,283 INFO [train.py:450] Epoch 0, batch 6370, batch avg loss 0.3904, total avg loss: 0.4309, batch size: 37
2021-08-24 19:03:47,521 INFO [train.py:450] Epoch 0, batch 6380, batch avg loss 0.4397, total avg loss: 0.4311, batch size: 40
2021-08-24 19:03:54,816 INFO [train.py:450] Epoch 0, batch 6390, batch avg loss 0.4613, total avg loss: 0.4316, batch size: 36
2021-08-24 19:04:02,081 INFO [train.py:450] Epoch 0, batch 6400, batch avg loss 0.4729, total avg loss: 0.4311, batch size: 43
2021-08-24 19:04:09,361 INFO [train.py:450] Epoch 0, batch 6410, batch avg loss 0.3992, total avg loss: 0.4358, batch size: 42
2021-08-24 19:04:16,584 INFO [train.py:450] Epoch 0, batch 6420, batch avg loss 0.4074, total avg loss: 0.4317, batch size: 41
2021-08-24 19:04:23,862 INFO [train.py:450] Epoch 0, batch 6430, batch avg loss 0.4003, total avg loss: 0.4273, batch size: 42
2021-08-24 19:04:30,964 INFO [train.py:450] Epoch 0, batch 6440, batch avg loss 0.4229, total avg loss: 0.4242, batch size: 40
2021-08-24 19:04:38,068 INFO [train.py:450] Epoch 0, batch 6450, batch avg loss 0.4430, total avg loss: 0.4235, batch size: 41
2021-08-24 19:04:46,368 INFO [train.py:450] Epoch 0, batch 6460, batch avg loss 0.3423, total avg loss: 0.4230, batch size: 40
2021-08-24 19:04:54,421 INFO [train.py:450] Epoch 0, batch 6470, batch avg loss 0.4639, total avg loss: 0.4236, batch size: 37
2021-08-24 19:05:02,197 INFO [train.py:450] Epoch 0, batch 6480, batch avg loss 0.4118, total avg loss: 0.4245, batch size: 43
2021-08-24 19:05:11,652 INFO [train.py:450] Epoch 0, batch 6490, batch avg loss 0.4625, total avg loss: 0.4271, batch size: 37
2021-08-24 19:05:19,111 INFO [train.py:450] Epoch 0, batch 6500, batch avg loss 0.4506, total avg loss: 0.4282, batch size: 44
2021-08-24 19:05:29,160 INFO [train.py:450] Epoch 0, batch 6510, batch avg loss 0.4232, total avg loss: 0.4290, batch size: 40
2021-08-24 19:05:36,369 INFO [train.py:450] Epoch 0, batch 6520, batch avg loss 0.4445, total avg loss: 0.4306, batch size: 39
2021-08-24 19:05:43,816 INFO [train.py:450] Epoch 0, batch 6530, batch avg loss 0.4583, total avg loss: 0.4316, batch size: 45
2021-08-24 19:05:51,152 INFO [train.py:450] Epoch 0, batch 6540, batch avg loss 0.4172, total avg loss: 0.4307, batch size: 42
2021-08-24 19:05:58,663 INFO [train.py:450] Epoch 0, batch 6550, batch avg loss 0.4446, total avg loss: 0.4301, batch size: 38
2021-08-24 19:06:06,329 INFO [train.py:450] Epoch 0, batch 6560, batch avg loss 0.4407, total avg loss: 0.4298, batch size: 39
2021-08-24 19:06:13,702 INFO [train.py:450] Epoch 0, batch 6570, batch avg loss 0.4070, total avg loss: 0.4286, batch size: 39
2021-08-24 19:06:20,855 INFO [train.py:450] Epoch 0, batch 6580, batch avg loss 0.4394, total avg loss: 0.4286, batch size: 39
2021-08-24 19:06:27,872 INFO [train.py:450] Epoch 0, batch 6590, batch avg loss 0.4310, total avg loss: 0.4282, batch size: 40
2021-08-24 19:06:35,219 INFO [train.py:450] Epoch 0, batch 6600, batch avg loss 0.4032, total avg loss: 0.4278, batch size: 42
2021-08-24 19:06:42,606 INFO [train.py:450] Epoch 0, batch 6610, batch avg loss 0.3930, total avg loss: 0.4280, batch size: 42
2021-08-24 19:06:50,307 INFO [train.py:450] Epoch 0, batch 6620, batch avg loss 0.4781, total avg loss: 0.4328, batch size: 40
2021-08-24 19:06:58,142 INFO [train.py:450] Epoch 0, batch 6630, batch avg loss 0.4782, total avg loss: 0.4332, batch size: 39
2021-08-24 19:07:05,571 INFO [train.py:450] Epoch 0, batch 6640, batch avg loss 0.3625, total avg loss: 0.4283, batch size: 41
2021-08-24 19:07:12,580 INFO [train.py:450] Epoch 0, batch 6650, batch avg loss 0.4736, total avg loss: 0.4299, batch size: 39
2021-08-24 19:07:19,840 INFO [train.py:450] Epoch 0, batch 6660, batch avg loss 0.3752, total avg loss: 0.4290, batch size: 42
2021-08-24 19:07:34,723 INFO [train.py:450] Epoch 0, batch 6670, batch avg loss 0.4398, total avg loss: 0.4314, batch size: 38
2021-08-24 19:07:41,054 INFO [train.py:450] Epoch 0, batch 6680, batch avg loss 0.4335, total avg loss: 0.4322, batch size: 39
2021-08-24 19:07:48,577 INFO [train.py:450] Epoch 0, batch 6690, batch avg loss 0.4254, total avg loss: 0.4311, batch size: 39
2021-08-24 19:07:55,748 INFO [train.py:450] Epoch 0, batch 6700, batch avg loss 0.4089, total avg loss: 0.4295, batch size: 38
2021-08-24 19:08:03,155 INFO [train.py:450] Epoch 0, batch 6710, batch avg loss 0.4182, total avg loss: 0.4285, batch size: 42
2021-08-24 19:08:10,747 INFO [train.py:450] Epoch 0, batch 6720, batch avg loss 0.3811, total avg loss: 0.4274, batch size: 42
2021-08-24 19:08:18,424 INFO [train.py:450] Epoch 0, batch 6730, batch avg loss 0.4334, total avg loss: 0.4269, batch size: 38
2021-08-24 19:08:25,504 INFO [train.py:450] Epoch 0, batch 6740, batch avg loss 0.4949, total avg loss: 0.4265, batch size: 42
2021-08-24 19:08:32,912 INFO [train.py:450] Epoch 0, batch 6750, batch avg loss 0.3840, total avg loss: 0.4269, batch size: 36
2021-08-24 19:08:40,495 INFO [train.py:450] Epoch 0, batch 6760, batch avg loss 0.3967, total avg loss: 0.4261, batch size: 40
2021-08-24 19:08:47,711 INFO [train.py:450] Epoch 0, batch 6770, batch avg loss 0.4630, total avg loss: 0.4260, batch size: 41
2021-08-24 19:08:55,092 INFO [train.py:450] Epoch 0, batch 6780, batch avg loss 0.4985, total avg loss: 0.4270, batch size: 39
2021-08-24 19:09:02,335 INFO [train.py:450] Epoch 0, batch 6790, batch avg loss 0.4659, total avg loss: 0.4270, batch size: 39
2021-08-24 19:09:10,183 INFO [train.py:450] Epoch 0, batch 6800, batch avg loss 0.4025, total avg loss: 0.4263, batch size: 43
2021-08-24 19:09:17,506 INFO [train.py:450] Epoch 0, batch 6810, batch avg loss 0.3703, total avg loss: 0.4300, batch size: 38
2021-08-24 19:09:25,061 INFO [train.py:450] Epoch 0, batch 6820, batch avg loss 0.3871, total avg loss: 0.4211, batch size: 37
2021-08-24 19:09:33,965 INFO [train.py:450] Epoch 0, batch 6830, batch avg loss 0.4256, total avg loss: 0.4230, batch size: 40
2021-08-24 19:09:40,648 INFO [train.py:450] Epoch 0, batch 6840, batch avg loss 0.3945, total avg loss: 0.4178, batch size: 41
2021-08-24 19:09:51,777 INFO [train.py:450] Epoch 0, batch 6850, batch avg loss 0.4342, total avg loss: 0.4216, batch size: 37
2021-08-24 19:09:59,341 INFO [train.py:450] Epoch 0, batch 6860, batch avg loss 0.4148, total avg loss: 0.4222, batch size: 39
2021-08-24 19:10:07,044 INFO [train.py:450] Epoch 0, batch 6870, batch avg loss 0.4112, total avg loss: 0.4209, batch size: 39
2021-08-24 19:10:14,967 INFO [train.py:450] Epoch 0, batch 6880, batch avg loss 0.3953, total avg loss: 0.4222, batch size: 40
2021-08-24 19:10:23,054 INFO [train.py:450] Epoch 0, batch 6890, batch avg loss 0.4557, total avg loss: 0.4213, batch size: 36
2021-08-24 19:10:30,742 INFO [train.py:450] Epoch 0, batch 6900, batch avg loss 0.3879, total avg loss: 0.4235, batch size: 43
2021-08-24 19:10:38,129 INFO [train.py:450] Epoch 0, batch 6910, batch avg loss 0.4687, total avg loss: 0.4252, batch size: 39
2021-08-24 19:10:45,879 INFO [train.py:450] Epoch 0, batch 6920, batch avg loss 0.4205, total avg loss: 0.4250, batch size: 40
2021-08-24 19:10:53,701 INFO [train.py:450] Epoch 0, batch 6930, batch avg loss 0.4418, total avg loss: 0.4251, batch size: 39
2021-08-24 19:11:00,534 INFO [train.py:450] Epoch 0, batch 6940, batch avg loss 0.4243, total avg loss: 0.4249, batch size: 40
2021-08-24 19:11:08,251 INFO [train.py:450] Epoch 0, batch 6950, batch avg loss 0.4660, total avg loss: 0.4250, batch size: 46
2021-08-24 19:11:15,682 INFO [train.py:450] Epoch 0, batch 6960, batch avg loss 0.4185, total avg loss: 0.4263, batch size: 41
2021-08-24 19:11:23,084 INFO [train.py:450] Epoch 0, batch 6970, batch avg loss 0.4366, total avg loss: 0.4260, batch size: 41
2021-08-24 19:11:30,153 INFO [train.py:450] Epoch 0, batch 6980, batch avg loss 0.4000, total avg loss: 0.4260, batch size: 41
2021-08-24 19:11:36,882 INFO [train.py:450] Epoch 0, batch 6990, batch avg loss 0.3749, total avg loss: 0.4249, batch size: 39
2021-08-24 19:11:44,502 INFO [train.py:450] Epoch 0, batch 7000, batch avg loss 0.3749, total avg loss: 0.4244, batch size: 37
2021-08-24 19:12:23,440 INFO [train.py:482] Epoch 0, valid loss 0.3091, best valid loss: 0.3091 best valid epoch: 0
2021-08-24 19:12:29,859 INFO [train.py:450] Epoch 0, batch 7010, batch avg loss 0.4177, total avg loss: 0.4196, batch size: 38
2021-08-24 19:12:37,773 INFO [train.py:450] Epoch 0, batch 7020, batch avg loss 0.4640, total avg loss: 0.4250, batch size: 42
2021-08-24 19:12:45,524 INFO [train.py:450] Epoch 0, batch 7030, batch avg loss 0.4092, total avg loss: 0.4215, batch size: 39
2021-08-24 19:12:55,442 INFO [train.py:450] Epoch 0, batch 7040, batch avg loss 0.3795, total avg loss: 0.4246, batch size: 39
2021-08-24 19:13:04,769 INFO [train.py:450] Epoch 0, batch 7050, batch avg loss 0.4330, total avg loss: 0.4318, batch size: 41
2021-08-24 19:13:12,813 INFO [train.py:450] Epoch 0, batch 7060, batch avg loss 0.3922, total avg loss: 0.4307, batch size: 37
2021-08-24 19:13:19,733 INFO [train.py:450] Epoch 0, batch 7070, batch avg loss 0.4518, total avg loss: 0.4263, batch size: 44
2021-08-24 19:13:26,622 INFO [train.py:450] Epoch 0, batch 7080, batch avg loss 0.4360, total avg loss: 0.4249, batch size: 40
2021-08-24 19:13:34,207 INFO [train.py:450] Epoch 0, batch 7090, batch avg loss 0.4181, total avg loss: 0.4247, batch size: 39
2021-08-24 19:13:41,950 INFO [train.py:450] Epoch 0, batch 7100, batch avg loss 0.3555, total avg loss: 0.4232, batch size: 38
2021-08-24 19:13:49,093 INFO [train.py:450] Epoch 0, batch 7110, batch avg loss 0.3869, total avg loss: 0.4241, batch size: 38
2021-08-24 19:13:56,730 INFO [train.py:450] Epoch 0, batch 7120, batch avg loss 0.4156, total avg loss: 0.4238, batch size: 40
2021-08-24 19:14:03,980 INFO [train.py:450] Epoch 0, batch 7130, batch avg loss 0.4248, total avg loss: 0.4249, batch size: 44
2021-08-24 19:14:11,036 INFO [train.py:450] Epoch 0, batch 7140, batch avg loss 0.4693, total avg loss: 0.4241, batch size: 41
2021-08-24 19:14:18,207 INFO [train.py:450] Epoch 0, batch 7150, batch avg loss 0.3805, total avg loss: 0.4239, batch size: 38
2021-08-24 19:14:25,138 INFO [train.py:450] Epoch 0, batch 7160, batch avg loss 0.3855, total avg loss: 0.4232, batch size: 36
2021-08-24 19:14:32,358 INFO [train.py:450] Epoch 0, batch 7170, batch avg loss 0.4004, total avg loss: 0.4233, batch size: 38
2021-08-24 19:14:39,266 INFO [train.py:450] Epoch 0, batch 7180, batch avg loss 0.4631, total avg loss: 0.4236, batch size: 44
2021-08-24 19:14:46,871 INFO [train.py:450] Epoch 0, batch 7190, batch avg loss 0.4366, total avg loss: 0.4236, batch size: 38
2021-08-24 19:14:54,468 INFO [train.py:450] Epoch 0, batch 7200, batch avg loss 0.4520, total avg loss: 0.4233, batch size: 43
2021-08-24 19:15:01,157 INFO [train.py:450] Epoch 0, batch 7210, batch avg loss 0.4215, total avg loss: 0.3910, batch size: 38
2021-08-24 19:15:08,367 INFO [train.py:450] Epoch 0, batch 7220, batch avg loss 0.4523, total avg loss: 0.4076, batch size: 42
2021-08-24 19:15:15,413 INFO [train.py:450] Epoch 0, batch 7230, batch avg loss 0.4830, total avg loss: 0.4056, batch size: 42
2021-08-24 19:15:22,279 INFO [train.py:450] Epoch 0, batch 7240, batch avg loss 0.4004, total avg loss: 0.4124, batch size: 41
2021-08-24 19:15:29,569 INFO [train.py:450] Epoch 0, batch 7250, batch avg loss 0.4064, total avg loss: 0.4137, batch size: 43
2021-08-24 19:15:36,551 INFO [train.py:450] Epoch 0, batch 7260, batch avg loss 0.4072, total avg loss: 0.4116, batch size: 44
2021-08-24 19:15:43,598 INFO [train.py:450] Epoch 0, batch 7270, batch avg loss 0.4051, total avg loss: 0.4121, batch size: 38
2021-08-24 19:15:50,845 INFO [train.py:450] Epoch 0, batch 7280, batch avg loss 0.3992, total avg loss: 0.4135, batch size: 39
2021-08-24 19:15:58,044 INFO [train.py:450] Epoch 0, batch 7290, batch avg loss 0.4315, total avg loss: 0.4142, batch size: 37
2021-08-24 19:16:05,083 INFO [train.py:450] Epoch 0, batch 7300, batch avg loss 0.4041, total avg loss: 0.4164, batch size: 39
2021-08-24 19:16:12,122 INFO [train.py:450] Epoch 0, batch 7310, batch avg loss 0.3880, total avg loss: 0.4181, batch size: 39
2021-08-24 19:16:19,116 INFO [train.py:450] Epoch 0, batch 7320, batch avg loss 0.3860, total avg loss: 0.4162, batch size: 40
2021-08-24 19:16:26,173 INFO [train.py:450] Epoch 0, batch 7330, batch avg loss 0.4173, total avg loss: 0.4161, batch size: 40
2021-08-24 19:16:33,138 INFO [train.py:450] Epoch 0, batch 7340, batch avg loss 0.3318, total avg loss: 0.4156, batch size: 37
2021-08-24 19:16:39,857 INFO [train.py:450] Epoch 0, batch 7350, batch avg loss 0.4701, total avg loss: 0.4152, batch size: 37
2021-08-24 19:16:46,713 INFO [train.py:450] Epoch 0, batch 7360, batch avg loss 0.3784, total avg loss: 0.4138, batch size: 43
2021-08-24 19:16:53,878 INFO [train.py:450] Epoch 0, batch 7370, batch avg loss 0.4238, total avg loss: 0.4129, batch size: 40
2021-08-24 19:17:00,946 INFO [train.py:450] Epoch 0, batch 7380, batch avg loss 0.3516, total avg loss: 0.4132, batch size: 38
2021-08-24 19:17:08,218 INFO [train.py:450] Epoch 0, batch 7390, batch avg loss 0.4193, total avg loss: 0.4132, batch size: 41
2021-08-24 19:17:15,227 INFO [train.py:450] Epoch 0, batch 7400, batch avg loss 0.4682, total avg loss: 0.4138, batch size: 42
2021-08-24 19:17:22,200 INFO [train.py:450] Epoch 0, batch 7410, batch avg loss 0.4068, total avg loss: 0.4282, batch size: 39
2021-08-24 19:17:29,525 INFO [train.py:450] Epoch 0, batch 7420, batch avg loss 0.3986, total avg loss: 0.4198, batch size: 39
2021-08-24 19:17:35,984 INFO [train.py:450] Epoch 0, batch 7430, batch avg loss 0.4576, total avg loss: 0.4155, batch size: 37
2021-08-24 19:17:42,376 INFO [train.py:450] Epoch 0, batch 7440, batch avg loss 0.4032, total avg loss: 0.4173, batch size: 41
2021-08-24 19:17:49,394 INFO [train.py:450] Epoch 0, batch 7450, batch avg loss 0.4127, total avg loss: 0.4174, batch size: 36
2021-08-24 19:17:56,544 INFO [train.py:450] Epoch 0, batch 7460, batch avg loss 0.3626, total avg loss: 0.4136, batch size: 40
2021-08-24 19:18:04,486 INFO [train.py:450] Epoch 0, batch 7470, batch avg loss 0.4195, total avg loss: 0.4134, batch size: 43
2021-08-24 19:18:10,981 INFO [train.py:450] Epoch 0, batch 7480, batch avg loss 0.4283, total avg loss: 0.4124, batch size: 41
2021-08-24 19:18:20,794 INFO [train.py:450] Epoch 0, batch 7490, batch avg loss 0.3874, total avg loss: 0.4123, batch size: 41
2021-08-24 19:18:27,727 INFO [train.py:450] Epoch 0, batch 7500, batch avg loss 0.4133, total avg loss: 0.4129, batch size: 42
2021-08-24 19:18:34,812 INFO [train.py:450] Epoch 0, batch 7510, batch avg loss 0.3837, total avg loss: 0.4135, batch size: 40
2021-08-24 19:18:42,021 INFO [train.py:450] Epoch 0, batch 7520, batch avg loss 0.3548, total avg loss: 0.4149, batch size: 41
2021-08-24 19:18:48,940 INFO [train.py:450] Epoch 0, batch 7530, batch avg loss 0.3889, total avg loss: 0.4139, batch size: 41
2021-08-24 19:18:56,445 INFO [train.py:450] Epoch 0, batch 7540, batch avg loss 0.4229, total avg loss: 0.4141, batch size: 41
2021-08-24 19:19:03,552 INFO [train.py:450] Epoch 0, batch 7550, batch avg loss 0.3985, total avg loss: 0.4139, batch size: 39
2021-08-24 19:19:10,657 INFO [train.py:450] Epoch 0, batch 7560, batch avg loss 0.3882, total avg loss: 0.4137, batch size: 38
2021-08-24 19:19:17,312 INFO [train.py:450] Epoch 0, batch 7570, batch avg loss 0.3865, total avg loss: 0.4139, batch size: 38
2021-08-24 19:19:23,782 INFO [train.py:450] Epoch 0, batch 7580, batch avg loss 0.4254, total avg loss: 0.4138, batch size: 39
2021-08-24 19:19:30,519 INFO [train.py:450] Epoch 0, batch 7590, batch avg loss 0.3923, total avg loss: 0.4143, batch size: 40
2021-08-24 19:19:37,211 INFO [train.py:450] Epoch 0, batch 7600, batch avg loss 0.4742, total avg loss: 0.4142, batch size: 37
2021-08-24 19:19:44,215 INFO [train.py:450] Epoch 0, batch 7610, batch avg loss 0.3599, total avg loss: 0.4005, batch size: 41
2021-08-24 19:19:51,370 INFO [train.py:450] Epoch 0, batch 7620, batch avg loss 0.4209, total avg loss: 0.4070, batch size: 40
2021-08-24 19:19:57,978 INFO [train.py:450] Epoch 0, batch 7630, batch avg loss 0.4478, total avg loss: 0.4092, batch size: 41
2021-08-24 19:20:04,887 INFO [train.py:450] Epoch 0, batch 7640, batch avg loss 0.4968, total avg loss: 0.4124, batch size: 41
2021-08-24 19:20:11,996 INFO [train.py:450] Epoch 0, batch 7650, batch avg loss 0.4059, total avg loss: 0.4147, batch size: 37
2021-08-24 19:20:19,001 INFO [train.py:450] Epoch 0, batch 7660, batch avg loss 0.4234, total avg loss: 0.4149, batch size: 42
2021-08-24 19:20:25,800 INFO [train.py:450] Epoch 0, batch 7670, batch avg loss 0.3889, total avg loss: 0.4151, batch size: 37
2021-08-24 19:20:33,111 INFO [train.py:450] Epoch 0, batch 7680, batch avg loss 0.4876, total avg loss: 0.4151, batch size: 35
2021-08-24 19:20:40,109 INFO [train.py:450] Epoch 0, batch 7690, batch avg loss 0.4269, total avg loss: 0.4156, batch size: 41
2021-08-24 19:20:47,032 INFO [train.py:450] Epoch 0, batch 7700, batch avg loss 0.3903, total avg loss: 0.4156, batch size: 44
2021-08-24 19:20:53,883 INFO [train.py:450] Epoch 0, batch 7710, batch avg loss 0.4660, total avg loss: 0.4167, batch size: 38
2021-08-24 19:21:00,454 INFO [train.py:450] Epoch 0, batch 7720, batch avg loss 0.4281, total avg loss: 0.4165, batch size: 42
2021-08-24 19:21:07,373 INFO [train.py:450] Epoch 0, batch 7730, batch avg loss 0.3470, total avg loss: 0.4167, batch size: 39
2021-08-24 19:21:14,276 INFO [train.py:450] Epoch 0, batch 7740, batch avg loss 0.4141, total avg loss: 0.4164, batch size: 41
2021-08-24 19:21:21,643 INFO [train.py:450] Epoch 0, batch 7750, batch avg loss 0.4225, total avg loss: 0.4163, batch size: 39
2021-08-24 19:21:28,565 INFO [train.py:450] Epoch 0, batch 7760, batch avg loss 0.4000, total avg loss: 0.4156, batch size: 37
2021-08-24 19:21:35,523 INFO [train.py:450] Epoch 0, batch 7770, batch avg loss 0.3775, total avg loss: 0.4146, batch size: 39
2021-08-24 19:21:42,780 INFO [train.py:450] Epoch 0, batch 7780, batch avg loss 0.3837, total avg loss: 0.4147, batch size: 40
2021-08-24 19:21:50,077 INFO [train.py:450] Epoch 0, batch 7790, batch avg loss 0.3924, total avg loss: 0.4148, batch size: 43
2021-08-24 19:21:56,889 INFO [train.py:450] Epoch 0, batch 7800, batch avg loss 0.3776, total avg loss: 0.4152, batch size: 38
2021-08-24 19:22:03,552 INFO [train.py:450] Epoch 0, batch 7810, batch avg loss 0.4316, total avg loss: 0.4098, batch size: 38
2021-08-24 19:22:10,092 INFO [train.py:450] Epoch 0, batch 7820, batch avg loss 0.4520, total avg loss: 0.4069, batch size: 43
2021-08-24 19:22:17,105 INFO [train.py:450] Epoch 0, batch 7830, batch avg loss 0.4361, total avg loss: 0.4093, batch size: 38
2021-08-24 19:22:24,269 INFO [train.py:450] Epoch 0, batch 7840, batch avg loss 0.3959, total avg loss: 0.4097, batch size: 39
2021-08-24 19:22:31,870 INFO [train.py:450] Epoch 0, batch 7850, batch avg loss 0.4340, total avg loss: 0.4103, batch size: 40
2021-08-24 19:22:38,790 INFO [train.py:450] Epoch 0, batch 7860, batch avg loss 0.4117, total avg loss: 0.4097, batch size: 40
2021-08-24 19:22:47,304 INFO [train.py:450] Epoch 0, batch 7870, batch avg loss 0.3994, total avg loss: 0.4109, batch size: 39
2021-08-24 19:22:54,114 INFO [train.py:450] Epoch 0, batch 7880, batch avg loss 0.4130, total avg loss: 0.4105, batch size: 37
2021-08-24 19:23:04,856 INFO [train.py:450] Epoch 0, batch 7890, batch avg loss 0.4651, total avg loss: 0.4103, batch size: 39
2021-08-24 19:23:11,489 INFO [train.py:450] Epoch 0, batch 7900, batch avg loss 0.4175, total avg loss: 0.4133, batch size: 41
2021-08-24 19:23:19,504 INFO [train.py:450] Epoch 0, batch 7910, batch avg loss 0.4253, total avg loss: 0.4148, batch size: 44
2021-08-24 19:23:26,990 INFO [train.py:450] Epoch 0, batch 7920, batch avg loss 0.3967, total avg loss: 0.4139, batch size: 40
2021-08-24 19:23:33,696 INFO [train.py:450] Epoch 0, batch 7930, batch avg loss 0.3935, total avg loss: 0.4144, batch size: 39
2021-08-24 19:23:40,881 INFO [train.py:450] Epoch 0, batch 7940, batch avg loss 0.5087, total avg loss: 0.4146, batch size: 41
2021-08-24 19:23:47,974 INFO [train.py:450] Epoch 0, batch 7950, batch avg loss 0.3735, total avg loss: 0.4138, batch size: 37
2021-08-24 19:23:55,328 INFO [train.py:450] Epoch 0, batch 7960, batch avg loss 0.4033, total avg loss: 0.4126, batch size: 42
2021-08-24 19:24:01,714 INFO [train.py:450] Epoch 0, batch 7970, batch avg loss 0.4080, total avg loss: 0.4125, batch size: 38
2021-08-24 19:24:08,440 INFO [train.py:450] Epoch 0, batch 7980, batch avg loss 0.4243, total avg loss: 0.4130, batch size: 40
2021-08-24 19:24:15,592 INFO [train.py:450] Epoch 0, batch 7990, batch avg loss 0.3760, total avg loss: 0.4130, batch size: 37
2021-08-24 19:24:17,964 WARNING [cut.py:1694] To perform mix, energy must be non-zero and non-negative (got 0.0).  MonoCut with id "f5abb538-76a5-4b93-5759-fba329f07d05" will not be mixed in.
2021-08-24 19:24:22,242 INFO [train.py:450] Epoch 0, batch 8000, batch avg loss 0.4195, total avg loss: 0.4130, batch size: 41
2021-08-24 19:24:59,702 INFO [train.py:482] Epoch 0, valid loss 0.3046, best valid loss: 0.3046 best valid epoch: 0
2021-08-24 19:25:05,580 INFO [train.py:450] Epoch 0, batch 8010, batch avg loss 0.3911, total avg loss: 0.4035, batch size: 38
2021-08-24 19:25:13,706 INFO [train.py:450] Epoch 0, batch 8020, batch avg loss 0.3913, total avg loss: 0.4105, batch size: 39
2021-08-24 19:25:21,816 INFO [train.py:450] Epoch 0, batch 8030, batch avg loss 0.4206, total avg loss: 0.4134, batch size: 39
2021-08-24 19:25:29,909 INFO [train.py:450] Epoch 0, batch 8040, batch avg loss 0.4340, total avg loss: 0.4124, batch size: 43
2021-08-24 19:25:37,559 INFO [train.py:450] Epoch 0, batch 8050, batch avg loss 0.4480, total avg loss: 0.4112, batch size: 40
2021-08-24 19:25:45,925 INFO [train.py:450] Epoch 0, batch 8060, batch avg loss 0.3924, total avg loss: 0.4130, batch size: 37
2021-08-24 19:25:53,975 INFO [train.py:450] Epoch 0, batch 8070, batch avg loss 0.4509, total avg loss: 0.4124, batch size: 35
2021-08-24 19:26:01,568 INFO [train.py:450] Epoch 0, batch 8080, batch avg loss 0.3916, total avg loss: 0.4117, batch size: 37
2021-08-24 19:26:08,913 INFO [train.py:450] Epoch 0, batch 8090, batch avg loss 0.3529, total avg loss: 0.4099, batch size: 38
2021-08-24 19:26:16,828 INFO [train.py:450] Epoch 0, batch 8100, batch avg loss 0.4461, total avg loss: 0.4098, batch size: 46
2021-08-24 19:26:24,230 INFO [train.py:450] Epoch 0, batch 8110, batch avg loss 0.3933, total avg loss: 0.4099, batch size: 41
2021-08-24 19:26:32,166 INFO [train.py:450] Epoch 0, batch 8120, batch avg loss 0.4076, total avg loss: 0.4084, batch size: 40
2021-08-24 19:26:39,799 INFO [train.py:450] Epoch 0, batch 8130, batch avg loss 0.4317, total avg loss: 0.4088, batch size: 40
2021-08-24 19:26:47,976 INFO [train.py:450] Epoch 0, batch 8140, batch avg loss 0.3912, total avg loss: 0.4102, batch size: 44
2021-08-24 19:26:55,574 INFO [train.py:450] Epoch 0, batch 8150, batch avg loss 0.3973, total avg loss: 0.4102, batch size: 45
2021-08-24 19:27:03,445 INFO [train.py:450] Epoch 0, batch 8160, batch avg loss 0.3787, total avg loss: 0.4112, batch size: 43
2021-08-24 19:27:11,123 INFO [train.py:450] Epoch 0, batch 8170, batch avg loss 0.4237, total avg loss: 0.4124, batch size: 36
2021-08-24 19:27:19,041 INFO [train.py:450] Epoch 0, batch 8180, batch avg loss 0.3803, total avg loss: 0.4118, batch size: 41
2021-08-24 19:27:26,680 INFO [train.py:450] Epoch 0, batch 8190, batch avg loss 0.4061, total avg loss: 0.4120, batch size: 44
2021-08-24 19:27:34,701 INFO [train.py:450] Epoch 0, batch 8200, batch avg loss 0.4020, total avg loss: 0.4134, batch size: 40
2021-08-24 19:27:43,298 INFO [train.py:450] Epoch 0, batch 8210, batch avg loss 0.3702, total avg loss: 0.3979, batch size: 41
2021-08-24 19:27:51,756 INFO [train.py:450] Epoch 0, batch 8220, batch avg loss 0.4242, total avg loss: 0.4014, batch size: 42
2021-08-24 19:28:03,800 INFO [train.py:450] Epoch 0, batch 8230, batch avg loss 0.4018, total avg loss: 0.4065, batch size: 40
2021-08-24 19:28:11,163 INFO [train.py:450] Epoch 0, batch 8240, batch avg loss 0.4345, total avg loss: 0.4069, batch size: 37
2021-08-24 19:28:19,864 INFO [train.py:450] Epoch 0, batch 8250, batch avg loss 0.3974, total avg loss: 0.4064, batch size: 43
2021-08-24 19:28:28,074 INFO [train.py:450] Epoch 0, batch 8260, batch avg loss 0.4060, total avg loss: 0.4051, batch size: 37
2021-08-24 19:28:35,955 INFO [train.py:450] Epoch 0, batch 8270, batch avg loss 0.4012, total avg loss: 0.4071, batch size: 38
2021-08-24 19:28:43,556 INFO [train.py:450] Epoch 0, batch 8280, batch avg loss 0.4852, total avg loss: 0.4071, batch size: 42
2021-08-24 19:28:50,770 INFO [train.py:450] Epoch 0, batch 8290, batch avg loss 0.3951, total avg loss: 0.4091, batch size: 38
2021-08-24 19:28:58,254 INFO [train.py:450] Epoch 0, batch 8300, batch avg loss 0.4176, total avg loss: 0.4111, batch size: 43
2021-08-24 19:29:05,922 INFO [train.py:450] Epoch 0, batch 8310, batch avg loss 0.3729, total avg loss: 0.4116, batch size: 40
2021-08-24 19:29:13,559 INFO [train.py:450] Epoch 0, batch 8320, batch avg loss 0.3968, total avg loss: 0.4110, batch size: 40
2021-08-24 19:29:14,164 WARNING [cut.py:1694] To perform mix, energy must be non-zero and non-negative (got 0.0).  MonoCut with id "91b2b9c9-fe86-1d41-714b-d12844ea0c75" will not be mixed in.
2021-08-24 19:29:20,812 INFO [train.py:450] Epoch 0, batch 8330, batch avg loss 0.3384, total avg loss: 0.4109, batch size: 39
2021-08-24 19:29:28,644 INFO [train.py:450] Epoch 0, batch 8340, batch avg loss 0.3956, total avg loss: 0.4107, batch size: 37
2021-08-24 19:29:36,231 INFO [train.py:450] Epoch 0, batch 8350, batch avg loss 0.4624, total avg loss: 0.4107, batch size: 38
2021-08-24 19:29:44,102 INFO [train.py:450] Epoch 0, batch 8360, batch avg loss 0.4208, total avg loss: 0.4121, batch size: 39
2021-08-24 19:29:51,563 INFO [train.py:450] Epoch 0, batch 8370, batch avg loss 0.4121, total avg loss: 0.4120, batch size: 39
2021-08-24 19:29:59,566 INFO [train.py:450] Epoch 0, batch 8380, batch avg loss 0.3636, total avg loss: 0.4117, batch size: 41
2021-08-24 19:30:07,425 INFO [train.py:450] Epoch 0, batch 8390, batch avg loss 0.4165, total avg loss: 0.4118, batch size: 40
2021-08-24 19:30:14,885 INFO [train.py:450] Epoch 0, batch 8400, batch avg loss 0.3823, total avg loss: 0.4117, batch size: 37
2021-08-24 19:30:23,718 INFO [train.py:450] Epoch 0, batch 8410, batch avg loss 0.4523, total avg loss: 0.4246, batch size: 44
2021-08-24 19:30:31,597 INFO [train.py:450] Epoch 0, batch 8420, batch avg loss 0.3907, total avg loss: 0.4202, batch size: 44
2021-08-24 19:30:39,456 INFO [train.py:450] Epoch 0, batch 8430, batch avg loss 0.3740, total avg loss: 0.4114, batch size: 42
2021-08-24 19:30:46,838 INFO [train.py:450] Epoch 0, batch 8440, batch avg loss 0.3955, total avg loss: 0.4067, batch size: 45
2021-08-24 19:30:54,169 INFO [train.py:450] Epoch 0, batch 8450, batch avg loss 0.4182, total avg loss: 0.4034, batch size: 41
2021-08-24 19:31:01,680 INFO [train.py:450] Epoch 0, batch 8460, batch avg loss 0.4089, total avg loss: 0.4038, batch size: 43
2021-08-24 19:31:09,621 INFO [train.py:450] Epoch 0, batch 8470, batch avg loss 0.3570, total avg loss: 0.4052, batch size: 39
2021-08-24 19:31:17,251 INFO [train.py:450] Epoch 0, batch 8480, batch avg loss 0.4035, total avg loss: 0.4037, batch size: 42
2021-08-24 19:31:24,892 INFO [train.py:450] Epoch 0, batch 8490, batch avg loss 0.3582, total avg loss: 0.4042, batch size: 40
2021-08-24 19:31:32,179 INFO [train.py:450] Epoch 0, batch 8500, batch avg loss 0.3591, total avg loss: 0.4042, batch size: 38
2021-08-24 19:31:39,606 INFO [train.py:450] Epoch 0, batch 8510, batch avg loss 0.4498, total avg loss: 0.4052, batch size: 42
2021-08-24 19:31:47,169 INFO [train.py:450] Epoch 0, batch 8520, batch avg loss 0.4046, total avg loss: 0.4046, batch size: 40
2021-08-24 19:31:55,162 INFO [train.py:450] Epoch 0, batch 8530, batch avg loss 0.3962, total avg loss: 0.4048, batch size: 39
2021-08-24 19:32:02,975 INFO [train.py:450] Epoch 0, batch 8540, batch avg loss 0.4096, total avg loss: 0.4049, batch size: 41
2021-08-24 19:32:10,270 INFO [train.py:450] Epoch 0, batch 8550, batch avg loss 0.3833, total avg loss: 0.4048, batch size: 39
2021-08-24 19:32:17,511 INFO [train.py:450] Epoch 0, batch 8560, batch avg loss 0.4592, total avg loss: 0.4056, batch size: 45
2021-08-24 19:32:18,441 WARNING [cut.py:1694] To perform mix, energy must be non-zero and non-negative (got 0.0).  MonoCut with id "ad75ccf5-35d0-7929-c088-6b1c40de2c81" will not be mixed in.
2021-08-24 19:32:24,695 INFO [train.py:450] Epoch 0, batch 8570, batch avg loss 0.4474, total avg loss: 0.4073, batch size: 37
2021-08-24 19:32:35,550 INFO [train.py:450] Epoch 0, batch 8580, batch avg loss 0.4692, total avg loss: 0.4069, batch size: 40
2021-08-24 19:32:43,895 INFO [train.py:450] Epoch 0, batch 8590, batch avg loss 0.4425, total avg loss: 0.4073, batch size: 43
2021-08-24 19:32:53,503 INFO [train.py:450] Epoch 0, batch 8600, batch avg loss 0.4027, total avg loss: 0.4071, batch size: 38
2021-08-24 19:33:00,477 INFO [train.py:450] Epoch 0, batch 8610, batch avg loss 0.3678, total avg loss: 0.3991, batch size: 38
2021-08-24 19:33:08,160 INFO [train.py:450] Epoch 0, batch 8620, batch avg loss 0.3704, total avg loss: 0.4069, batch size: 40
2021-08-24 19:33:15,913 INFO [train.py:450] Epoch 0, batch 8630, batch avg loss 0.4127, total avg loss: 0.4064, batch size: 40
2021-08-24 19:33:23,626 INFO [train.py:450] Epoch 0, batch 8640, batch avg loss 0.4279, total avg loss: 0.4056, batch size: 36
2021-08-24 19:33:30,847 INFO [train.py:450] Epoch 0, batch 8650, batch avg loss 0.3636, total avg loss: 0.4053, batch size: 38
2021-08-24 19:33:37,990 INFO [train.py:450] Epoch 0, batch 8660, batch avg loss 0.4341, total avg loss: 0.4077, batch size: 42
2021-08-24 19:33:45,317 INFO [train.py:450] Epoch 0, batch 8670, batch avg loss 0.3772, total avg loss: 0.4089, batch size: 42
2021-08-24 19:33:52,722 INFO [train.py:450] Epoch 0, batch 8680, batch avg loss 0.3743, total avg loss: 0.4098, batch size: 38
2021-08-24 19:33:59,942 INFO [train.py:450] Epoch 0, batch 8690, batch avg loss 0.4226, total avg loss: 0.4091, batch size: 40
2021-08-24 19:34:07,651 INFO [train.py:450] Epoch 0, batch 8700, batch avg loss 0.4110, total avg loss: 0.4064, batch size: 42
2021-08-24 19:34:15,074 INFO [train.py:450] Epoch 0, batch 8710, batch avg loss 0.4329, total avg loss: 0.4044, batch size: 40
2021-08-24 19:34:22,164 INFO [train.py:450] Epoch 0, batch 8720, batch avg loss 0.4307, total avg loss: 0.4040, batch size: 41
2021-08-24 19:34:29,701 INFO [train.py:450] Epoch 0, batch 8730, batch avg loss 0.4697, total avg loss: 0.4060, batch size: 40
2021-08-24 19:34:37,100 INFO [train.py:450] Epoch 0, batch 8740, batch avg loss 0.4234, total avg loss: 0.4061, batch size: 39
2021-08-24 19:34:44,102 INFO [train.py:450] Epoch 0, batch 8750, batch avg loss 0.4316, total avg loss: 0.4058, batch size: 39
2021-08-24 19:34:51,554 INFO [train.py:450] Epoch 0, batch 8760, batch avg loss 0.3784, total avg loss: 0.4061, batch size: 39
2021-08-24 19:34:59,076 INFO [train.py:450] Epoch 0, batch 8770, batch avg loss 0.4312, total avg loss: 0.4053, batch size: 40
2021-08-24 19:35:06,469 INFO [train.py:450] Epoch 0, batch 8780, batch avg loss 0.4043, total avg loss: 0.4053, batch size: 39
2021-08-24 19:35:13,996 INFO [train.py:450] Epoch 0, batch 8790, batch avg loss 0.3926, total avg loss: 0.4048, batch size: 38
2021-08-24 19:35:21,147 INFO [train.py:450] Epoch 0, batch 8800, batch avg loss 0.4556, total avg loss: 0.4048, batch size: 41
2021-08-24 19:35:28,535 INFO [train.py:450] Epoch 0, batch 8810, batch avg loss 0.4229, total avg loss: 0.3931, batch size: 43
2021-08-24 19:35:35,859 INFO [train.py:450] Epoch 0, batch 8820, batch avg loss 0.3478, total avg loss: 0.3972, batch size: 40
2021-08-24 19:35:42,859 INFO [train.py:450] Epoch 0, batch 8830, batch avg loss 0.4048, total avg loss: 0.4004, batch size: 38
2021-08-24 19:35:50,200 INFO [train.py:450] Epoch 0, batch 8840, batch avg loss 0.3880, total avg loss: 0.3999, batch size: 39
2021-08-24 19:35:57,443 INFO [train.py:450] Epoch 0, batch 8850, batch avg loss 0.4149, total avg loss: 0.3985, batch size: 40
2021-08-24 19:36:04,788 INFO [train.py:450] Epoch 0, batch 8860, batch avg loss 0.4378, total avg loss: 0.4030, batch size: 46
2021-08-24 19:36:11,674 INFO [train.py:450] Epoch 0, batch 8870, batch avg loss 0.4529, total avg loss: 0.4044, batch size: 37
2021-08-24 19:36:18,708 INFO [train.py:450] Epoch 0, batch 8880, batch avg loss 0.4037, total avg loss: 0.4035, batch size: 42
2021-08-24 19:36:25,218 INFO [train.py:450] Epoch 0, batch 8890, batch avg loss 0.3911, total avg loss: 0.4041, batch size: 38
2021-08-24 19:36:32,177 INFO [train.py:450] Epoch 0, batch 8900, batch avg loss 0.4218, total avg loss: 0.4047, batch size: 39
2021-08-24 19:36:39,527 INFO [train.py:450] Epoch 0, batch 8910, batch avg loss 0.4173, total avg loss: 0.4044, batch size: 41
2021-08-24 19:36:46,560 INFO [train.py:450] Epoch 0, batch 8920, batch avg loss 0.4135, total avg loss: 0.4030, batch size: 38
2021-08-24 19:36:53,876 INFO [train.py:450] Epoch 0, batch 8930, batch avg loss 0.4551, total avg loss: 0.4043, batch size: 39
2021-08-24 19:36:56,619 WARNING [cut.py:1694] To perform mix, energy must be non-zero and non-negative (got 0.0).  MonoCut with id "ca69d00e-03ce-03b6-0623-7241a349cd05" will not be mixed in.
2021-08-24 19:37:00,600 INFO [train.py:450] Epoch 0, batch 8940, batch avg loss 0.3783, total avg loss: 0.4037, batch size: 39
2021-08-24 19:37:07,606 INFO [train.py:450] Epoch 0, batch 8950, batch avg loss 0.4164, total avg loss: 0.4036, batch size: 39
2021-08-24 19:37:14,491 INFO [train.py:450] Epoch 0, batch 8960, batch avg loss 0.4106, total avg loss: 0.4042, batch size: 41
2021-08-24 19:37:21,674 INFO [train.py:450] Epoch 0, batch 8970, batch avg loss 0.4480, total avg loss: 0.4047, batch size: 44
2021-08-24 19:37:29,066 INFO [train.py:450] Epoch 0, batch 8980, batch avg loss 0.4162, total avg loss: 0.4044, batch size: 41
2021-08-24 19:37:36,228 INFO [train.py:450] Epoch 0, batch 8990, batch avg loss 0.3667, total avg loss: 0.4035, batch size: 38
2021-08-24 19:37:44,526 INFO [train.py:450] Epoch 0, batch 9000, batch avg loss 0.4303, total avg loss: 0.4034, batch size: 41
2021-08-24 19:38:23,087 INFO [train.py:482] Epoch 0, valid loss 0.2972, best valid loss: 0.2972 best valid epoch: 0
2021-08-24 19:38:28,991 INFO [train.py:450] Epoch 0, batch 9010, batch avg loss 0.3990, total avg loss: 0.3985, batch size: 38
2021-08-24 19:38:35,385 INFO [train.py:450] Epoch 0, batch 9020, batch avg loss 0.3743, total avg loss: 0.3947, batch size: 38
2021-08-24 19:38:42,264 INFO [train.py:450] Epoch 0, batch 9030, batch avg loss 0.3721, total avg loss: 0.4023, batch size: 40
2021-08-24 19:38:49,695 INFO [train.py:450] Epoch 0, batch 9040, batch avg loss 0.4035, total avg loss: 0.4056, batch size: 40
2021-08-24 19:38:56,338 INFO [train.py:450] Epoch 0, batch 9050, batch avg loss 0.4115, total avg loss: 0.4052, batch size: 40
2021-08-24 19:39:03,362 INFO [train.py:450] Epoch 0, batch 9060, batch avg loss 0.4258, total avg loss: 0.4062, batch size: 41
2021-08-24 19:39:10,664 INFO [train.py:450] Epoch 0, batch 9070, batch avg loss 0.4693, total avg loss: 0.4088, batch size: 42
2021-08-24 19:39:17,390 INFO [train.py:450] Epoch 0, batch 9080, batch avg loss 0.4576, total avg loss: 0.4091, batch size: 40
2021-08-24 19:39:24,277 INFO [train.py:450] Epoch 0, batch 9090, batch avg loss 0.4529, total avg loss: 0.4088, batch size: 41
